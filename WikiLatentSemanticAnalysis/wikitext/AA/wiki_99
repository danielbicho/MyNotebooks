{"url": "https://en.wikipedia.org/wiki?curid=13210", "text": "History of the ancient Levant\n\nThe Levant is a geographical term that refers to a large area in Southwest Asia, south of the Taurus Mountains, bounded by the Mediterranean Sea in the west, the Arabian Desert in the south, and Mesopotamia in the east. It stretches 400 miles north to south from the Taurus Mountains to the Sinai desert, and 70 to 100 miles east to west between the sea and the Arabian desert. The term is also sometimes used to refer to modern events or states in the region immediately bordering the eastern Mediterranean Sea: Cyprus, Israel, Jordan, Lebanon, Palestine, and Syria.\n\nThe term normally does not include Anatolia (although at times Cilicia may be included), the Caucasus Mountains, Mesopotamia or any part of the Arabian Peninsula proper. The Sinai Peninsula is sometimes included, though it is more considered an intermediate, peripheral or marginal area forming a land bridge between the Levant and northern Egypt.\n\nMultiple waves of humans came Out of Africa I. Anatomically modern Homo sapiens are demonstrated at the area of Mount Carmel, during the Middle Paleolithic dating from about c. 90,000 BC. This move out of Africa seems to have been unsuccessful and by c. 60,000 BC in Palestine/Israel/Syria, especially at Amud, classic Neanderthal groups seem to have profited from the worsening climate to have replaced Homo sapiens, who seem to have been confined once more to Africa.\n\nA second move out of Africa is demonstrated by the Boker Tachtit Upper Paleolithic culture, from 52–50,000 BC, with humans at Ksar Akil XXV level being modern humans. This culture bears close resemblance to the Badoshan Aurignacian culture of Iran, and the later Sebilian I Egyptian culture of c. 50,000 BC. Stephen Oppenheimer suggests that this reflects a movement of modern human (possibly Caucasian) groups back into North Africa, at this time.\n\nIt would appear this sets the date by which Homo sapiens Upper Paleolithic cultures begin replacing Neanderthal Levalo-Mousterian, and by c. 40,000 BC Palestine was occupied by the Levanto-Aurignacian Ahmarian culture, lasting from 39–24,000 BC. This culture was quite successful spreading as the Antelian culture (late Aurignacian), as far as Southern Anatolia, with the Atlitan culture.\n\nAfter the Late Glacial Maxima, a new Epipaleolithic culture appears in Southern Palestine. The appearance of the Kebarian culture, of microlithic type implies a significant rupture in the cultural continuity of Levantine Upper Paleolithic. The Kebaran culture, with its use of microliths, is associated with the use of the bow and arrow and the domestication of the dog. Extending from 18–10,500 BC, the Kebaran culture shows clear connections to the earlier Microlithic cultures using the bow and arrow, and using grinding stones to harvest wild grains, that developed from the c. 24,000–17,000 BC Halfan culture of Egypt, that came from the still earlier Aterian tradition of the Sahara. Some linguists see this as the earliest arrival of Nostratic languages in the Middle East.\nKebaran culture was quite successful, and was ancestral to the later Natufian culture (10,500–8500 BC), which extended throughout the whole of the Levantine region. These people pioneered the first sedentary settlements, and may have supported themselves from fishing, and from the harvest of wild grains plentiful in the region at that time.\n\nNatufian culture also demonstrates the earliest domestication of the dog, and the assistance of this animal in hunting and guarding human settlements may have contributed to the successful spread of this culture. In the northern Syrian, eastern Anatolian region of the Levant, Natufian culture at Cayonu and Mureybet developed the first fully agricultural culture with the addition of wild grains, later being supplemented with domesticated sheep and goats, which were probably domesticated first by the Zarzian culture of Northern Iraq and Iran (which like the Natufian culture may have also developed from Kebaran).\n\nBy 8500–7500 BC, the Pre-Pottery Neolithic A (PPNA) culture developed out of the earlier local tradition of Natufian in Southern Palestine, dwelling in round houses, and building the first defensive site at Jericho (guarding a valuable fresh water spring). This was replaced in 7500 BC by Pre-Pottery Neolithic B (PPNB), dwelling in square houses, coming from Northern Syria and the Euphrates bend.\n\nDuring the period of 8500–7500 BC, another hunter-gatherer group, showing clear affinities with the cultures of Egypt (particularly the Outacha retouch technique for working stone) was in Sinai. This Harifian culture may have adopted the use of pottery from the Isnan culture and Helwan culture of Egypt (which lasted from 9000 to 4500 BC), and subsequently fused with elements from the PPNB culture during the climatic crisis of 6000 BC to form what Juris Zarins calls the Syro-Arabian pastoral technocomplex, which saw the spread of the first Nomadic pastoralists in the Ancient Near East. These extended southwards along the Red Sea coast and penetrating the Arabian bifacial cultures, which became progressively more Neolithic and pastoral, and extending north and eastwards, to lay the foundations for the tent-dwelling Martu and Akkadian peoples of Mesopotamia.\n\nIn the Amuq valley of Syria, PPNB culture seems to have survived, influencing further cultural developments further south. Nomadic elements fused with PPNB to form the Minhata Culture and Yarmukian Culture which were to spread southwards, beginning the development of the classic mixed farming Mediterranean culture, and from 5600 BC were associated with the Ghassulian culture of the region, the first chalcolithic culture of the Levant. This period also witnessed the development of megalithic structures, which continued into the Bronze Age.\n\nIn modern scholarship the chronology of the Bronze Age Levant is divided into Early/Proto Syrian, corresponding to the Early Bronze; Old Syrian, corresponding to the Middle Bronze; and Middle Syrian, corresponding to the Late Bronze. The term Neo-Syria is used to designate the early Iron Age.\n\nThe old Syrian period was dominated by the Eblaite first kingdom, Nagar and the Mariote second kingdom. The Akkadian Empire conquered large areas of the Levant and were followed by the Amorite kingdoms, ca. 2000–1600 BC, which arose in Mari, Yamkhad and Qatna. Also following the Akkadians was the extension of Khirbet Kerak ware culture, showing affinities with the Caucasus, and possibly linked to the later appearance of the Hurrians.\n\nAround the 17th and 16th centuries BC most of the older centers had been overrun. The Mitanni, for a time, menaced the Hittite kingdom, but were defeated by it around the middle of the 14th. The Semitic Hyksos used the new technologies to occupy Egypt, but were expelled, leaving the empire of the New Kingdom to develop in their wake. From 1550 until 1100, much of the Levant was conquered by Egypt, which in the latter half of this period contested Syria with the Hittite Empire.\n\nAt the end of the 13th century BC, all of these powers suddenly collapsed. Cities all around the eastern Mediterranean were sacked within a span of a few decades by assorted raiders.The Hittite empire was destroyed. Egypt repelled its attackers with only a major effort, and over the next century shrank to its territorial core, its central authority permanently weakened.\n\nThe destruction at the end of the Bronze Age left a number of tiny kingdoms and City-states behind. A few Hittite centres remained in northern Syria, along with some Phoenician ports in Canaan that escaped destruction and developed into great commercial powers. The Israelites emerged as a rural culture (possibly from the displaced Canaanite refugees escaping the Bronze Age Collapse to Judea and Samaria alongside groups like the Shasu and the Habiru) mainly in the Canaanite hill-country and the Eastern Galilee, quickly spreading through the land and forming an alliance in the struggle for the land against the Philistines to the West, Moab and Ammon to the East and Edom to the South. In the 12th century BC, most of the interior, as well as Babylonia, was overrun by Arameans, while the shoreline around today's Gaza Strip was settled by Philistines.\n\nIn this period a number of technological innovations spread, most notably iron working and the Phoenician alphabet, developed by the Phoenicians or the Canaanites around the 16th century BC.\n\nDuring the 9th century BC, the Assyrians began to reassert themselves against the incursions of the Aramaeans, and over the next few centuries developed into a powerful and well-organised empire. Their armies were among the first to employ cavalry, which took the place of chariots, and had a reputation for both prowess and brutality. At their height, the Assyrians dominated all of the Levant, Egypt, and Babylonia. However, the empire began to collapse toward the end of the 7th century BC, and was obliterated by an alliance between a resurgent New Kingdom of Babylonia and the Iranian Medes.\n\nThe subsequent balance of power was short-lived, though. In the 550s BC the Persians revolted against the Medes and gained control of their empire, and over the next few decades annexed to it the realms of Lydia in Anatolia, Damascus, Babylonia, and Egypt, as well as consolidating their control over the Iranian plateau nearly as far as India. This vast kingdom was divided up into various satrapies and governed roughly according to the Assyrian model, but with a far lighter hand. Around this time Zoroastrianism became the predominant religion in Persia.\n\nPersia controlled the Levant but by the 4th century BC, Persia had fallen into decline. The campaigns of Xenophon illustrated how very vulnerable Persia had become to attack by an army organized along Greek lines, and under Alexander the Great the Levant was conquered.\n\nAlexander did not live long enough to consolidate his realm, the greater share of the east went to the descendants of Seleucus I Nicator. This period saw great innovations in mathematics, science, architecture, and the like, and Greeks founded cities throughout the east, some of which grew to be the world's first major metropolises. Their culture did not, however, reach very far into the countryside.\n\nThe Seleucids adopted a pro-western stance that alienated both the powerful eastern satraps and the Greeks who had migrated to the east. During the 2nd century BC, Greek culture lost ground there, and the empire began to break apart. The Seleucid kingdom continued to decline and its remaining provinces were annexed by the Roman Republic in 64 BC as Iudaea Province.\n\nPersian dynasty, the Sassanids, entered in conflicts with Rome, and later with the Byzantine Empire. In 391, the Byzantine era began with the permanent division of the Roman Empire into East and Western halves. Byzantine control over the sites of Israel and Judah and other parts of the Levant lasted until 636, when it was conquered by Arabs and became a part of the Caliphate.\n\nThe Byzantines reached their lowest point under Phocas, with the Sassanids occupying the whole of the eastern Mediterranean. In 610, though, Heraclius took the throne of Constantinople and began a successful counter-attack, expelling the Persians and invading Media and Assyria. Unable to stop his advance, Khosrau II was assassinated and the Sassanid empire fell into anarchy. Weakened by their quarrels, neither empire was prepared to deal with the onslaught of the Arabs, newly unified under the banners of Islam and anxious to expand their faith. By 650, Arab forces had conquered all of Persia, Syria, and Egypt.\n\n\n\n", "id": "13210", "title": "History of the ancient Levant"}
{"url": "https://en.wikipedia.org/wiki?curid=13212", "text": "History of Europe\n\nThe history of Europe covers the peoples inhabiting the European continent from prehistory to the present. Some of the best-known civilizations of prehistoric Europe were the Minoan and the Mycenaean, which flourished during the Bronze Age until they collapsed in a short period of time around 1200 BC.\n\nThe period known as classical antiquity began with the emergence of the city-states of Ancient Greece. After ultimately checking the Persian advance in Europe through the Greco-Persian Wars in the 5th century BC, Greek influence reached its zenith under the expansive empire of Alexander the Great, spreading throughout Asia, Africa, and other parts of Europe. The Roman Empire came to dominate the entire Mediterranean basin in a vast empire based on Roman law. By 300 AD the Roman Empire was divided into the Western and Eastern empires. During the 4th and 5th centuries, the Germanic peoples of northern Europe grew in strength and repeated attacks led to the Fall of the Western Roman Empire. AD 476 traditionally marks the end of the classical period and the start of the Middle Ages.\n\nIn Western Europe, Germanic peoples moved into positions of power in the remnants of the former Western Roman Empire and established kingdoms and empires of their own. Of all of the Germanic peoples, the Franks would rise to a position of hegemony over western Europe, the Frankish Empire reaching its peak under Charlemagne around AD 800. This empire was later divided into several parts; West Francia would evolve into the Kingdom of France, while East Francia would evolve into the Holy Roman Empire, a precursor to modern Germany and Italy. The British Isles were the site of several large-scale migrations.\n\nThe Viking Age, a period of migrations of Scandinavian peoples, occurred from the late 8th century to the middle 11th century. The Normans, a Viking people who settled in Northern France, had a significant impact on many parts of Europe, from the Norman conquest of England to Southern Italy and Sicily. The Rus' people founded Kievan Rus', which evolved into Russia. After 1000 the Crusades were a series of religiously motivated military expeditions originally intended to bring the Levant back into Christian rule. The Crusaders opened trade routes which enabled the merchant republics of Genoa and Venice to become major economic powers. The Reconquista, a related movement, worked to reconquer Iberia for Christendom.\n\nEastern Europe in the High Middle Ages was dominated by the rise and fall of the Mongol Empire. Led by Genghis Khan, the Mongols were a group of steppe nomads who established a decentralized empire which, at its height, extended from China in the east to the Black and Baltic seas in Europe. As Mongol power waned towards the Late Middle Ages, the Grand Duchy of Moscow rose to become the strongest of the numerous Russian principalities and republics and would grow into the Tsardom of Russia in 1547. The Late Middle Ages represented a period of upheaval in Europe. The epidemic known as the Black Death and an associated famine caused demographic catastrophe in Europe as the population plummeted. Dynastic struggles and wars of conquest kept many of the states of Europe at war for much of the period. In Scandinavia, the Kalmar Union dominated the political landscape, while England fought with Scotland in the Wars of Scottish Independence and with France in the Hundred Years' War. In Central Europe, the Polish–Lithuanian Commonwealth became a large territorial empire, while the Holy Roman Empire, which was an elective monarchy, came to be dominated for centuries by the House of Habsburg. Russia continued to expand southward and eastward into former Mongol lands as well. In the Balkans, the Ottoman Empire overran Byzantine lands, culminating in the Fall of Constantinople in 1453, which historians mark as the end of the Middle Ages.\n\nBeginning in the 14th century in Florence, and later spreading through Europe a Renaissance of knowledge challenged traditional doctrines in science and theology. The rediscovery of classical Greek and Roman knowledge had an enormous liberating effect on intellectuals. Simultaneously, the Protestant Reformation under German Martin Luther questioned Papal authority. Henry VIII seized control of the English Church and its lands, allying in ensuing religious wars between German and Spanish rulers. The Reconquista expelled Muslim rule from Portugal and Spain. By the 1490s a series of oceanic explorations marked the Age of Discovery, establishing direct links with Africa, the Americas, and Asia, while religious wars continued to be fought in Europe, which ended in 1648 with the Peace of Westphalia. The Spanish crown maintained its hegemony in Europe and was the leading power on the continent until the signing of the Treaty of the Pyrenees, which ended a conflict between Spain and France that had begun during the Thirty Years' War. An unprecedented series of major wars and political revolutions took place around Europe and indeed the world in the period between 1610 and 1700. Observers at the time, and many historians since, have argued that wars caused the revolutions.\n\nThe Industrial Revolution began in Great Britain, based on coal, steam, textile mills and by the 1830s railways. Political change in continental Europe was spurred by the French Revolution under the motto \"liberté, égalité, fraternité\". Napoleon Bonaparte took control, made many reforms inside France, and transformed western Europe. But his rise stimulated both nationalism and reaction and he was defeated in 1814–15 as the old royal conservatives returned.\n\nThe period between 1815 and 1871 saw revolutionary attempts in much of Europe (apart from Britain and Russia). They all failed. As industrial work forces grew in Western Europe, socialism and trade union activity developed. The last vestiges of serfdom were abolished in Russia in 1861. Greece and the other and Balkan nations began a long slow road to independence from the Ottoman Empire starting in the 1820s. Italy was unified in its Risorgimento in 1860. After the Franco-Prussian War of 1870–71, Otto von Bismarck unified the German states into an empire that was politically and militarily dominant until 1914. Most of Europe scramble for imperial colonies in Africa and Asia in The Age of Empire. Britain and France built the largest empires, while diplomats endured there were no major wars (apart from the regional Crimean War in the 1850s).\n\nThe outbreak of the First World War in 1914 was precipitated by the rise of nationalism in Southeastern Europe as the Great Powers took up sides. The Allies, led by Britain and France, joined by Italy in 1915 and by the United States in 1917, defeated the Central Powers led by the German Empire and Austria-Hungary in 1918. During the Paris Peace Conference the Big Four imposed their terms in a series of treaties, especially the Treaty of Versailles. The human and material devastation was far greater than anyone dreamed. As Overy notes:\n\nGermany lost its overseas empire and several provinces, had to pay large reparations, and was humiliated by the victors. They in turn had large debts to the United States. The 1920s were prosperous until 1929 when Great Depression broke out in 1929, and led to the collapse of democracy in state after state. The Nazi regime under Adolf Hitler came to power in 1933, rearmed Germany, and along with Mussolini's Italy sought to gain full control of the continent by demands and appeasement, and then by the Second World War. The Nazis emphasize the destruction of the Jews in the Holocaust and the destruction of Slavic civilian populations in the east. France fell to the Nazis, but Britain and the Soviet Union held firm and the Germans were finally overwhelmed by the Allied land and air power in 1945.\n\nThe Iron Curtain by 1945 separated the east under Moscow's control from the capitalist West. The United States entered European affairs in terms of economics (the Marshall Plan of 1948–51) and military leadership (NATO from 1949), and rebuilt industrial economies that all were thriving by the 1950s. France and West Germany took the lead in forming the European Economic Community. It became the European Union (EU). Secularization saw the weakening of Protestant and Catholic churches across most of Europe, except where they were bastions of anti-Communism as in Poland. The Communist East fell further and further behind—it could build tanks and rockets but not computers. The Iron Curtain fell peacefully in 1989, and Communism collapsed overnight in 1991, with the old Soviet Union divided 15 ways. Germany was reunited, Europe's integration deepened, and both NATO and the European Union expanded to the east, much to the annoyance of Russia. The EU came under increasing pressure because of the worldwide recession after 2008. The major issues include financial aid to near-bankrupt countries, increasing intolerance of poorly assimilated immigrants from Europe and the Middle East, distrust of Germany's increasing power, tensions with Russia, and the rejection of Turkey's membership. Brexit is the decision of the United Kingdom to leave the EU in 2017.\n\n\"Homo erectus\" migrated from Africa to Europe before the emergence of modern humans. Lézignan-la-Cèbe in France, Orce in Spain, Pirro Nord in Italy and Kozarnika in Bulgaria are also amongst the oldest Palaeolithic sites in Europe.\n\nThe earliest appearance of anatomically modern people in Europe has been dated to 35,000 BC, usually referred to as the Cro-Magnon man. Some locally developed transitional cultures (Uluzzian in Italy and Greece, Altmühlian in Germany, Szeletian in Central Europe and Châtelperronian in the Southwest) use clearly Upper Palaeolithic technologies at very early dates.\n\nNevertheless, the definitive advance of these technologies is made by the Aurignacian culture. The origins of this culture can be located in what is now The Levant (Ahmarian) and Hungary (first full Aurignacian). By 35,000 BC, the Aurignacian culture and its technology had extended through most of Europe. The last Neanderthals seem to have been forced to retreat during this process to the southern half of the Iberian Peninsula.\n\nAround 28,000 BC a new technology/culture appeared in the western region of Europe: the Gravettian. This technology/culture has been theorised to have come with migrations of people from the Balkans.\n\nAround 16,000 BC, Europe witnessed the appearance of a new culture, known as Magdalenian, possibly rooted in the old Gravettian. This culture soon superseded the Solutrean area and the Gravettian of mainly France, Spain, Germany, Italy, Poland, Portugal and Ukraine. The Hamburg culture prevailed in Northern Europe in the 14th and the 13th millennium BC as the Creswellian (also termed the British Late Magdalenian) did shortly after in the British Islands.\nAround 12,500 BC, the Würm glaciation ended. Slowly, through the following millennia, temperatures and sea levels rose, changing the environment of prehistoric people. Nevertheless, Magdalenian culture persisted until c. 10,000 BC, when it quickly evolved into two \"microlithist\" cultures: Azilian (Federmesser), in Spain and southern France, and then Sauveterrian, in northern France and Central Europe, while in Northern Europe the Lyngby complex succeeded the Hamburg culture with the influence of the Federmesser group as well. Evidence of permanent settlement dates from the 8th millennium BC in the Balkans. Neolithic reached Central Europe in the 6th millennium BC and parts of Northern Europe in the 5th and 4th millennium BC.\n\nThe first well-known literate civilization in Europe was that of the Minoans. The Minoan civilization was a Bronze Age civilization that arose on the island of Crete and flourished from approximately the 27th century BC to the 15th century BC. It was rediscovered at the beginning of the 20th century through the work of the British archaeologist Arthur Evans. Will Durant referred to it as \"the first link in the European chain\".\n\nThe Minoans were replaced by the Mycenaean civilization which flourished during the period roughly between 1600 BC, when Helladic culture in mainland Greece was transformed under influences from Minoan Crete, and 1100 BC. The major Mycenaean cities were Mycenae and Tiryns in Argolis, Pylos in Messenia, Athens in Attica, Thebes and Orchomenus in Boeotia, and Iolkos in Thessaly. In Crete, the Mycenaeans occupied Knossos. Mycenaean settlement sites also appeared in Epirus, Macedonia, on islands in the Aegean Sea, on the coast of Asia Minor, the Levant, Cyprus and Italy. Mycenaean artefacts have been found well outside the limits of the Mycenean world.\n\nQuite unlike the Minoans, whose society benefited from trade, the Mycenaeans advanced through conquest. Mycenaean civilization was dominated by a warrior aristocracy. Around 1400 BC, the Mycenaeans extended their control to Crete, center of the Minoan civilization, and adopted a form of the Minoan script (called Linear A) to write their early form of Greek in Linear B.\n\nThe Mycenaean civilization perished with the collapse of Bronze-Age civilization on the eastern shores of the Mediterranean Sea. The collapse is commonly attributed to the Dorian invasion, although other theories describing natural disasters and climate change have been advanced as well. Whatever the causes, the Mycenaean civilization had definitely disappeared after LH III C, when the sites of Mycenae and Tirynth were again destroyed and lost their importance. This end, during the last years of the 12th century BC, occurred after a slow decline of the Mycenaean civilization, which lasted many years before dying out. The beginning of the 11th century BC opened a new context, that of the protogeometric, the beginning of the geometric period, the \"Greek Dark Ages\" of traditional historiography.\n\nThe Greeks and the Romans left a legacy in Europe which is evident in European languages, thought, visual arts and law. Ancient Greece was a collection of city-states, out of which the original form of democracy developed. Athens was the most powerful and developed city, and a cradle of learning from the time of Pericles. Citizens' forums debated and legislated policy of the state, and from here arose some of the most notable classical philosophers, such as Socrates, Plato, and Aristotle, the last of whom taught Alexander the Great.\n\nThrough his military campaigns, the king of the kingdom of Macedon, Alexander, spread Hellenistic culture and learning to the banks of the River Indus. Meanwhile, the Roman Republic strengthened through victory over Carthage in the Punic Wars. Greek wisdom passed into Roman institutions, as Athens itself was absorbed under the banner of the Senate and People of Rome; SPQR.\n\nThe Romans expanded from Arabia to Britannia. In 44 BC as it approached its height, its dictator Julius Caesar was murdered by senators in an attempt to restore the Republic. In the ensuing turmoil, Octavian (ruled as Augustus; and as \"divi filius\", or Son of God, as Julius had adopted him as an heir) usurped the reins of power and fought the Roman Senate. While proclaiming the rebirth of the Republic, he had ushered in the transfer of the Roman state from a republic to an empire, the Roman Empire, which lasted for more than four centuries until the fall of the Western Roman Empire.\n\nThe Hellenic civilisation was a collection of city-states or poleis with different governments and cultures that achieved notable developments in government, philosophy, science, mathematics, politics, sports, theatre and music.\n\nThe most powerful city-states were Athens, Sparta, Thebes, Corinth, and Syracuse. Athens was a powerful Hellenic city-state and governed itself with an early form of direct democracy invented by Cleisthenes; the citizens of Athens voted on legislation and executive bills themselves. Athens was the home of Socrates, Plato, and the Platonic Academy.\n\nThe Hellenic city-states established colonies on the shores of the Black Sea and the Mediterranean (Asian Minor, Sicily and Southern Italy in Magna Graecia). By the late 6th century BC, all the Greek city states in Asia Minor had been incorporated into the Persian Empire, while the latter had made territorial gains in the Balkans (such as Macedon, Thrace, Paeonia, etc.) and Eastern Europe proper as well. In the course of 5th century BC, some of the Greek city states attempted to overthrow Persian rule in the Ionian Revolt, which failed. This sparked the first Persian invasion of mainland Greece. At some point during the ensuing Greco-Persian Wars, namely during the Second Persian invasion of Greece, and precisely after the Battle of Thermopylae and the Battle of Artemisium, almost all of Greece to the north of the Isthmus of Corinth had been overrun by the Persians, but the Greek city states reached a decisive victory at the Battle of Plataea. With the end of the Greco-Persian wars, the Persians were eventually decisively forced to withdraw from their territories in Europe. The Greco-Persian Wars and the victory of the Greek city states directly influenced the entire further course of European history and would set its further tone. Some Greek city-states formed the Delian League to continue fighting Persia, but Athens' position as leader of this league led Sparta to form the rival Peloponnesian League. The Peloponnesian Wars ensued, and the Peloponnesian League was victorious. Subsequently, discontent with Spartan hegemony led to the Corinthian War and the defeat of Sparta at the Battle of Leuctra.\n\nHellenic infighting left Greek city states vulnerable, and Philip II of Macedon united the Greek city states under his control. The son of Philip II, known as Alexander the Great, invaded neighboring Persia, toppled and incorporated its domains, as well as invading Egypt and going as far off as India, increasing contact with people and cultures in these regions that marked the beginning of the Hellenistic period.\n\nMuch of Greek learning was assimilated by the nascent Roman state as it expanded outward from Italy, taking advantage of its enemies' inability to unite: the only challenge to Roman ascent came from the Phoenician colony of Carthage, and its defeats in the three Punic Wars marked the start of Roman hegemony. First governed by kings, then as a senatorial republic (the Roman Republic), Rome finally became an empire at the end of the 1st century BC, under Augustus and his authoritarian successors.\n\nThe Roman Empire had its centre in the Mediterranean, controlling all the countries on its shores; the northern border was marked by the Rhine and Danube rivers. Under emperor Trajan (2nd century AD) the empire reached its maximum expansion, controlling approximately of land surface, including Britain, Romania and parts of Mesopotamia. Pax Romana, a period of peace, civilisation and an efficient centralised government in the subject territories ended in the 3rd century, when a series of civil wars undermined Rome's economic and social strength.\n\nIn the 4th century, the emperors Diocletian and Constantine were able to slow down the process of decline by splitting the empire into a Western part with a capital in Rome and an Eastern part with the capital in Byzantium, or Constantinople (now Istanbul). Whereas Diocletian severely persecuted Christianity, Constantine declared an official end to state-sponsored persecution of Christians in 313 with the Edict of Milan, thus setting the stage for the Church to become the state church of the Roman Empire in about 380.\n\nThe Roman Empire had been repeatedly attacked by invading armies from Northern Europe and in 476, Rome finally fell. Romulus Augustus, the last Emperor of the Western Roman Empire, surrendered to the Germanic King Odoacer. The British historian Edward Gibbon argued in \"The History of the Decline and Fall of the Roman Empire\" (1776) that the Romans had become decadent, they had lost civic virtue.\n\nGibbon said that the adoption of Christianity, meant belief in a better life after death, and therefore made people lazy and indifferent to the present. \"From the eighteenth century onward\", Glen W. Bowersock has remarked, \"we have been obsessed with the fall: it has been valued as an archetype for every perceived decline, and, hence, as a symbol for our own fears.\" It remains one of the greatest historical questions, and has a tradition rich in scholarly interest.\n\nSome other notable dates are the Battle of Adrianople in 378, the death of Theodosius I in 395 (the last time the Roman Empire was politically unified), the crossing of the Rhine in 406 by Germanic tribes after the withdrawal of the legions to defend Italy against Alaric I, the death of Stilicho in 408, followed by the disintegration of the western legions, the death of Justinian I, the last Roman Emperor who tried to reconquer the west, in 565, and the coming of Islam after 632. Many scholars maintain that rather than a \"fall\", the changes can more accurately be described as a complex transformation. Over time many theories have been proposed on why the Empire fell, or whether indeed it fell at all.\n\nWhen Emperor Constantine had reconquered Rome under the banner of the cross in 312, he soon afterwards issued the Edict of Milan in 313, declaring the legality of Christianity in the Roman Empire. In addition, Constantine officially shifted the capital of the Roman Empire from Rome to the Greek town of Byzantium, which he renamed Nova Roma- it was later named Constantinople (\"City of Constantine\").\n\nIn 395 Theodosius I, who had made Christianity the official religion of the Roman Empire, would be the last emperor to preside over a united Roman Empire. The empire was split into two halves: the Western Roman Empire centred in Ravenna, and the Eastern Roman Empire (later to be referred to as the Byzantine Empire) centred in Constantinople. The Western Roman Empire was repeatedly attacked by Germanic tribes (see: Migration Period), and in 476 finally fell to the Heruli chieftain Odoacer.\n\nRoman authority in the Western part of the Empire collapsed and the western provinces soon were to be dominated by three great powers, the Franks (Merovingian dynasty) in Francia 481–843 AD (covered much of present France and Germany), the Visigothic kingdom 418–711 AD in the Iberian Peninsula and the Ostrogothic kingdom 493–553 AD in Italy and parts of Balkan this kingdom were later replaced by the Kingdom of the Lombards 568–774 AD.\nThese new powers of the west built upon the Roman traditions until they evolved into a synthesis of Roman and Germanic cultures. In Italy, Theodoric the Great began the cultural romanization of the new world he had constructed. He made Ravenna a center of Romano-Greek culture of art and his court fostered a flowering of literature and philosophy in Latin. In Iberia, King Chindasuinth created the Visigothic Code.\nIn Western Europe, a political structure was emerging: in the power vacuum left in the wake of Rome's collapse, localised hierarchies were based on the bond of common people to the land on which they worked. Tithes were paid to the lord of the land, and the lord owed duties to the regional prince. The tithes were used to pay for the state and wars.\n\nThis was the feudal system, in which new princes and kings arose, the greatest of which was the Frank ruler Charlemagne. In 800, Charlemagne, reinforced by his massive territorial conquests, was crowned Emperor of the Romans (Imperator Romanorum) by Pope Leo III, effectively solidifying his power in western Europe.\n\nCharlemagne's reign marked the beginning of a new Germanic Roman Empire in the west, the Holy Roman Empire. Outside his borders, new forces were gathering. The Kievan Rus' were marking out their territory, a Great Moravia was growing, while the Angles and the Saxons were securing their borders.\n\nFor the duration of the 6th century, the Eastern Roman Empire was embroiled in a series of deadly conflicts, first with the Persian Sassanid Empire (see Roman–Persian Wars), followed by the onslaught of the arising Islamic Caliphate (Rashidun and Umayyad). By 650, the provinces of Egypt, Palestine and Syria were lost to the Muslim forces, followed by Hispania and southern Italy in the 7th and 8th centuries (see Muslim conquests). The Arab invasion from the east was stopped after the intervention of the Bulgarian Empire (see Tervel of Bulgaria).\n\nThe Middle Ages are commonly dated from the fall of the Western Roman Empire (or by some scholars, before that) in the 5th century to the beginning of the early modern period in the 16th century, marked by the rise of nation states, the division of Western Christianity in the Reformation, the rise of humanism in the Italian Renaissance, and the beginnings of European overseas expansion which allowed for the Columbian Exchange.\n\nMany consider Emperor Constantine I (reigned 306–337) to be the first \"Byzantine Emperor\". It was he who moved the imperial capital in 324 from Nicomedia to Byzantium, which re-founded as Constantinople, or Nova Roma (\"New Rome\"). The city of Rome itself had not served as the capital since the reign of Diocletian. Some date the beginnings of the Empire to the reign of Theodosius I (379–395) and Christianity's official supplanting of the pagan Roman religion, or following his death in 395, when the empire was split into two parts, with capitals in Rome and Constantinople. Others place it yet later in 476, when Romulus Augustulus, traditionally considered the last western Emperor, was deposed, thus leaving sole imperial authority with the emperor in the Greek East. Others point to the reorganisation of the empire in the time of Heraclius (c. 620) when Latin titles and usages were officially replaced with Greek versions. In any case, the changeover was gradual and by 330, when Constantine inaugurated his new capital, the process of hellenization and increasing Christianisation was already under way. The Empire is generally considered to have ended after the fall of Constantinople to the Ottoman Turks in 1453. The Plague of Justinian was a pandemic that afflicted the Byzantine Empire, including its capital Constantinople, in the years 541–542. It is estimated that the Plague of Justinian killed as many as 100 million people across the world. It caused Europe's population to drop by around 50% between 541 and 700. It also may have contributed to the success of the Muslim conquests.\n\nThe Early Middle Ages span roughly five centuries from 500 to 1000.\n\nFrom the 7th century Byzantine history was greatly affected by the rise of Islam and the Caliphates. Muslim Arabs first invaded historically Roman territory under Abū Bakr, first Caliph of the Rashidun Caliphate, who entered Roman Syria and Roman Mesopotamia. As the Byzantines and neighboring Sasanids were severely weakened by the time, amongst the most important reason(s) being the protracted, centuries-lasting and frequent Byzantine–Sasanian wars, which included the climactic Byzantine–Sasanian War of 602–628, under Umar, the second Caliph, the Muslims entirely toppled the Sasanid Persian Empire, and decisively conquered Syria and Mesopotamia, as well as Roman Palestine, Roman Egypt, and parts of Asia Minor and Roman North Africa. In the mid 7th century AD, following the Muslim conquest of Persia, Islam penetrated into the Caucasus region, of which parts would later permanently become part of Russia. This trend, which included the conquests by the invading Muslim forces and by that the spread of Islam as well continued under Umar's successors and under the Umayyad Caliphate, which conquered the rest of Mediterranean North Africa and most of the Iberian Peninsula. Over the next centuries Muslim forces were able to take further European territory, including Cyprus, Malta, Crete, and Sicily and parts of southern Italy.\n\nThe Muslim conquest of Hispania began when the Moors (Berbers and Arabs) invaded the Christian Visigothic kingdom of Hispania in the year 711, under the Berber general Tariq ibn Ziyad. They landed at Gibraltar on 30 April and worked their way northward. Tariq's forces were joined the next year by those of his Arab superior, Musa ibn Nusair. During the eight-year campaign most of the Iberian Peninsula was brought under Muslim rule – save for small areas in the northwest (Asturias) and largely Basque regions in the Pyrenees. In 711, Visigothic Hispania was very weakened because it was immersed in a serious internal crisis caused by a war of succession to the throne involving two Visigoth suitors. The Muslims took advantage of the crisis that crossed the Hispano-Visigothic society to carry out their conquests. This territory, under the Arab name Al-Andalus, became part of the expanding Umayyad empire.\n\nThe unsuccessful second siege of Constantinople (717) weakened the Umayyad dynasty and reduced their prestige. In 722 Don Pelayo, a nobleman of Visigothic origin, formed an army of 300 Astur soldiers, to confront Munuza's Muslim troops. In the battle of Covadonga, the Astures defeated the Arab-Moors, who decided to retire. The Christian victory marked the beginning of the Reconquista and the establishment of the Kingdom of Asturias, whose first sovereign was Don Pelayo. The conquerors intended to continue their expansion in Europe and move northeast across the Pyrenees, but were defeated by the Frankish leader Charles Martel at the Battle of Poitiers in 732. The Umayyads were overthrown in 750 by the 'Abbāsids, and, in 756, the Umayyads established an independent emirate in the Iberian Peninsula.\n\nThe Holy Roman Empire emerged around 800, as Charlemagne, king of the Franks, was crowned by the pope as emperor. His empire based in modern France, the Low Countries and Germany expanded into modern Hungary, Italy, Bohemia, Lower Saxony and Spain. He and his father received substantial help from an alliance with the Pope, who wanted help against the Lombards.\n\nTo the east, Bulgaria was established in 681 and became the first Slavic country. The powerful Bulgarian Empire was the main rival of Byzantium for control of the Balkans for centuries and from the 9th century became the cultural centre of Slavic Europe. The Empire created the Cyrillic script during the 10th century AD, at the Preslav Literary School. Two states, Great Moravia and Kievan Rus', emerged among the Slavic peoples respectively in the 9th century. In the late 9th and 10th centuries, northern and western Europe felt the burgeoning power and influence of the Vikings who raided, traded, conquered and settled swiftly and efficiently with their advanced seagoing vessels such as the longships. The Hungarians pillaged mainland Europe, the Pechenegs raided Bulgaria, Rus States and the Arab states. In the 10th century independent kingdoms were established in Central Europe including Poland and the newly settled Kingdom of Hungary. The kingdoms of Croatia and Serbia also appeared in the Balkans. The subsequent period, ending around 1000, saw the further growth of feudalism, which weakened the Holy Roman Empire.\n\nIn eastern Europe, Volga Bulgaria became an Islamic state in 921, after Almış I converted to Islam under the missionary efforts of Ahmad ibn Fadlan.\n\nSlavery in the early medieval period had mostly died out in western Europe by about the year 1000 AD, replaced by serfdom. It lingered longer in England and in peripheral areas linked to the Muslim world, where slavery continued to flourish. Church rules suppressed slavery of Christians. Most historians argue the transition was quite abrupt around 1000, but some see a gradual transition from about 300 to 1000.\n\nThe slumber of the Dark Ages was shaken by a renewed crisis in the Church. In 1054, the East–West Schism, an insoluble split, occurred between the two remaining Christian seats in Rome and Constantinople (modern Istanbul).\n\nThe High Middle Ages of the 11th, 12th, and 13th centuries show a rapidly increasing population of Europe, which caused great social and political change from the preceding era. By 1250, the robust population increase greatly benefited the economy, reaching levels it would not see again in some areas until the 19th century.\nFrom about the year 1000 onwards, Western Europe saw the last of the barbarian invasions and became more politically organized. The Vikings had settled in Britain, Ireland, France and elsewhere, whilst Norse Christian kingdoms were developing in their Scandinavian homelands. The Magyars had ceased their expansion in the 10th century, and by the year 1000, the Roman Catholic Apostolic Kingdom of Hungary was recognised in central Europe. With the brief exception of the Mongol invasions, major barbarian incursions ceased.\n\nIn the 11th century, populations north of the Alps began to settle new lands, some of which had reverted to wilderness after the end of the Roman Empire. In what is known as the \"great clearances\", vast forests and marshes of Europe were cleared and cultivated. At the same time settlements moved beyond the traditional boundaries of the Frankish Empire to new frontiers in Europe, beyond the Elbe river, tripling the size of Germany in the process. Crusaders founded European colonies in the Levant, the majority of the Iberian Peninsula was conquered from the Muslims, and the Normans colonised southern Italy, all part of the major population increase and resettlement pattern.\n\nThe High Middle Ages produced many different forms of intellectual, spiritual and artistic works. The most famous are the great cathedrals as expressions of Gothic architecture, which evolved from Romanesque architecture. This age saw the rise of modern nation-states in Western Europe and the ascent of the famous Italian city-states, such as Florence and Venice. The influential popes of the Catholic Church called volunteer armies from across Europe to a series of Crusades against the Seljuq Turks, who occupied the Holy Land. The rediscovery of the works of Aristotle led Thomas Aquinas and other thinkers to develop the philosophy of Scholasticism.\n\nThe Great Schism between the Western (Catholic) and Eastern (Orthodox) Christian Churches was sparked in 1054 by Pope Leo IX asserting authority over three of the seats in the Pentarchy, in Antioch, Jerusalem and Alexandria. Since the mid-8th century, the Byzantine Empire's borders had been shrinking in the face of Islamic expansion. Antioch had been wrested back into Byzantine control by 1045, but the resurgent power of the Roman successors in the West claimed a right and a duty for the lost seats in Asia and Africa. Pope Leo sparked a further dispute by defending the filioque clause in the Nicene Creed which the West had adopted customarily. The Orthodox today state that the XXVIIIth Canon of the Council of Chalcedon explicitly proclaimed the equality of the Bishops of Rome and Constantinople. The Orthodox also state that the Bishop of Rome has authority only over his own diocese and does not have any authority outside his diocese. There were other less significant catalysts for the Schism however, including variance over liturgy. The Schism of Roman Catholic and Orthodox followed centuries of estrangement between the Latin and Greek worlds.\n\nFurther changes were set afoot with a redivision of power in Europe. William the Conqueror, a Duke of Normandy invaded England in 1066. The Norman Conquest was a pivotal event in English history for several reasons. This linked England more closely with continental Europe through the introduction of a Norman aristocracy, thereby lessening Scandinavian influence. It created one of the most powerful monarchies in Europe and engendered a sophisticated governmental system. Being based on an island, moreover, England was to develop a powerful navy and trade relationships that would come to constitute a vast part of the world including India, Australia, New Zealand, Canada and many key naval strategic points like Bermuda, Suez, Hong Kong and especially Gibraltar. These strategic advantages grew and were to prove decisive until after the Second World War.\n\nAfter the East–West Schism, Western Christianity was adopted by the newly created kingdoms of Central Europe: Poland, Hungary and Bohemia. The Roman Catholic Church developed as a major power, leading to conflicts between the Pope and Emperor. The geographic reach of the Roman Catholic Church expanded enormously due to the conversions of pagan kings (Scandinavia, Lithuania, Poland, Hungary), the Christian Reconquista of Al-Andalus, and the crusades. Most of Europe was Roman Catholic in the 15th century.\n\nEarly signs of the rebirth of civilization in western Europe began to appear in the 11th century as trade started again in Italy, leading to the economic and cultural growth of independent city-states such as Venice and Florence; at the same time, nation-states began to take form in places such as France, England, Spain, and Portugal, although the process of their formation (usually marked by rivalry between the monarchy, the aristocratic feudal lords and the church) actually took several centuries. These new nation-states began writing in their own cultural vernaculars, instead of the traditional Latin. Notable figures of this movement would include Dante Alighieri and Christine de Pizan (born Christina da Pizzano), the former writing in Italian, and the latter, although an Italian (Venice), relocated to France, writing in French. (See Reconquista for the latter two countries.) Elsewhere, the Holy Roman Empire, essentially based in Germany and Italy, further fragmented into a myriad of feudal principalities or small city states, whose subjection to the emperor was only formal.\n\nThe 13th and 14th century, when the Mongol Empire came to power, is often called the \"Age of the Mongols\". Mongol armies expanded westward under the command of Batu Khan. Their western conquests included almost all of Russia (save Novgorod, which became a vassal), the Kipchak-Cuman Confederation, Hungary, and Poland (which had remained a sovereign state). Mongolian records indicate that Batu Khan was planning a complete conquest of the remaining European powers, beginning with a winter attack on Austria, Italy and Germany, when he was recalled to Mongolia upon the death of Great Khan Ögedei. Most historians believe only his death prevented the complete conquest of Europe. The areas of Eastern Europe and most of Central Asia that were under direct Mongol rule became known as the Golden Horde. Under Uzbeg Khan, Islam became the official religion of the region in the early 14th century. The invading Mongols, together with their mostly Turkic subjects, were known as Tatars. In Russia, the Tatars ruled the various states of the Rus' through vassalage for over 300 years.\n\nThe Late Middle Ages span the 14th and 15th centuries. Around 1300, centuries of European prosperity and growth came to a halt. A series of famines and plagues, such as the Great Famine of 1315–1317 and the Black Death killed people in a matter of days, reducing the population of some areas by half as many survivors fled. Kishlansky reports:\n\nDepopulation caused labor to become scarcer; the survivors were better paid and peasants could drop some of the burdens of feudalism. There was also social unrest; France and England experienced serious peasant risings including the Jacquerie and the Peasants' Revolt. At the same time, the unity of the Catholic Church was shattered by the Great Schism. Collectively these events have been called the Crisis of the Late Middle Ages.\n\nBeginning in the 14th century, the Baltic Sea became one of the most important trade routes. The Hanseatic League, an alliance of trading cities, facilitated the absorption of vast areas of Poland, Lithuania and Livonia into trade with other European countries. This fed the growth of powerful states in this part of Europe including Poland-Lithuania, Hungary, Bohemia, and Muscovy later on. The conventional end of the Middle Ages is usually associated with the fall of the city of Constantinople and of the Byzantine Empire to the Ottoman Turks in 1453. The Turks made the city the capital of their Ottoman Empire, which lasted until 1922 and included Egypt, Syria and most of the Balkans. The Ottoman wars in Europe, also sometimes referred to as the Turkish wars, marked an essential part of the history of the continent as a whole.\n\nThe Early Modern period spans the centuries between the Middle Ages and the Industrial Revolution, roughly from 1500 to 1800, or from the discovery of the New World in 1492 to the French Revolution in 1789. The period is characterised by the rise to importance of science and increasingly rapid technological progress, secularised civic politics and the nation state. Capitalist economies began their rise, beginning in northern Italian republics such as Genoa. The early modern period also saw the rise and dominance of the economic theory of mercantilism. As such, the early modern period represents the decline and eventual disappearance, in much of the European sphere, of feudalism, serfdom and the power of the Catholic Church. The period includes the Protestant Reformation, the disastrous Thirty Years' War, the European colonisation of the Americas and the European witch-hunts.\n\nDespite these crises, the 14th century was also a time of great progress within the arts and sciences. A renewed interest in ancient Greek and Roman as well as more recent Arabic texts led to what has later been termed the Italian Renaissance.\n\nThe Renaissance was a cultural movement that profoundly affected European intellectual life in the early modern period. Beginning in Italy, and spreading to the north, west and middle Europe during a cultural lag of some two and a half centuries, its influence affected literature, philosophy, art, politics, science, history, religion, and other aspects of intellectual enquiry.\n\nThe Italian Petrarch (Francesco di Petracco), deemed the first full-blooded Humanist, wrote in the 1330s: \"I am alive now, yet I would rather have been born in another time.\" He was enthusiastic about Greek and Roman antiquity. In the 15th and 16th centuries the continuing enthusiasm for the ancients was reinforced by the feeling that the inherited culture was dissolving and here was a storehouse of ideas and attitudes with which to rebuild. Matteo Palmieri wrote in the 1430s: \"Now indeed may every thoughtful spirit thank god that it has been permitted to him to be born in a new age.\" The renaissance was born: a new age where learning was very important.\n\nThe Renaissance was inspired by the growth in study of Latin and Greek texts and the admiration of the Greco-Roman era as a golden age. This prompted many artists and writers to begin drawing from Roman and Greek examples for their works, but there was also much innovation in this period, especially by multi-faceted artists such as Leonardo da Vinci. The Humanists saw their repossession of a great past as a Renaissance—a rebirth of civilization itself.\n\nImportant political precedents were also set in this period. Niccolò Machiavelli's political writing in \"The Prince\" influenced later absolutism and real-politik. Also important were the many patrons who ruled states and used the artistry of the Renaissance as a sign of their power.\n\nIn all, the Renaissance could be viewed as an attempt by intellectuals to study and improve the secular and worldly, both through the revival of ideas from antiquity, and through novel approaches to thought—the immediate past being too \"Gothic\" in language, thought and sensibility.\n\nDuring this period, Spain experienced the greatest epoch of cultural splendor in its history. This epoch is known as the Spanish Golden age and took place between the sixteenth and seventeenth centuries.\n\nToward the end of the period, an era of discovery began. The growth of the Ottoman Empire, culminating in the fall of Constantinople in 1453, cut off trading possibilities with the east. Western Europe was forced to discover new trading routes, as happened with Columbus' travel to the Americas in 1492, and Vasco da Gama's circumnavigation of India and Africa in 1498.\n\nThe numerous wars did not prevent European states from exploring and conquering wide portions of the world, from Africa to Asia and the newly discovered Americas. In the 15th century, Portugal led the way in geographical exploration along the coast of Africa in search of a maritime route to India, followed by Spain near the close of the 15th century, dividing their exploration of the world according to the Treaty of Tordesillas in 1494. They were the first states to set up colonies in America and European trading posts (factories) along the shores of Africa and Asia, establishing the first direct European diplomatic contacts with Southeast Asian states in 1511, China in 1513 and Japan in 1542. In 1552, Russian tsar Ivan the Terrible conquered two major Tatar khanates, the Khanate of Kazan and the Astrakhan Khanate. The Yermak's voyage of 1580 led to the annexation of the Tatar Siberian Khanate into Russia, and the Russians would soon after conquer the rest of Siberia, steadily expanding to the east and south over the next centuries. Oceanic explorations soon followed by France, England and the Netherlands, who explored the Portuguese and Spanish trade routes into the Pacific Ocean, reaching Australia in 1606 and New Zealand in 1642.\n\nWith the development of the printing press, new ideas spread throughout Europe and challenged traditional doctrines in science and theology. Simultaneously, the Protestant Reformation under German Martin Luther questioned Papal authority. The most common dating of the Reformation begins in 1517, when Luther published \"The Ninety-Five Theses\", and concludes in 1648 with the Treaty of Westphalia that ended years of European religious wars.\n\nDuring this period corruption in the Catholic Church led to a sharp backlash in the Protestant Reformation. It gained many followers especially among princes and kings seeking a stronger state by ending the influence of the Catholic Church. Figures other than Martin Luther began to emerge as well like John Calvin whose Calvinism had influence in many countries and King Henry VIII of England who broke away from the Catholic Church in England and set up the Anglican Church; his daughter Queen Elizabeth finished the organization of the church. These religious divisions brought on a wave of wars inspired and driven by religion but also by the ambitious monarchs in Western Europe who were becoming more centralised and powerful.\n\nThe Protestant Reformation also led to a strong reform movement in the Catholic Church called the Counter-Reformation, which aimed to reduce corruption as well as to improve and strengthen Catholic Dogma. Two important groups in the Catholic Church who emerged from this movement were the Jesuits, who helped keep Spain, Portugal, Poland and other European countries within the Catholic fold, and the Oratorians of St Philip Neri, who ministered to the faithful in Rome, restoring their confidence in the Church of Jesus Christ that subsisted substantially in the Church of Rome. Still, the Catholic Church was somewhat weakened by the Reformation, portions of Europe were no longer under its sway and kings in the remaining Catholic countries began to take control of the Church institutions within their kingdoms.\n\nUnlike many European countries, the Polish–Lithuanian Commonwealth and Hungary were more tolerant. While still enforcing the predominance of Catholicism they continued to allow the large religious minorities to maintain their faiths, traditions and customs. The Polish–Lithuanian Commonwealth became divided between Catholics, Protestants, Orthodox, Jews and a small Muslim population.\n\nAnother important development in this period was the growth of pan-European sentiments. Eméric Crucé (1623) came up with the idea of the European Council, intended to end wars in Europe; attempts to create lasting peace were no success, although all European countries (except the Russian and Ottoman Empires, regarded as foreign) agreed to make peace in 1518 at the Treaty of London. Many wars broke out again in a few years. The Reformation also made European peace impossible for many centuries.\n\nAnother development was the idea of 'European superiority'. The ideal of civilisation was taken over from the ancient Greeks and Romans: discipline, education and living in the city were required to make people civilised; Europeans and non-Europeans were judged for their civility, and Europe regarded itself as superior to other continents. There was a movement by some such as Montaigne that regarded the non-Europeans as a better, more natural and primitive people. Post services were founded all over Europe, which allowed a humanistic interconnected network of intellectuals across Europe, despite religious divisions. However, the Roman Catholic Church banned many leading scientific works; this led to an intellectual advantage for Protestant countries, where the banning of books was regionally organised. Francis Bacon and other advocates of science tried to create unity in Europe by focusing on the unity in nature. In the 15th century, at the end of the Middle Ages, powerful sovereign states were appearing, built by the New Monarchs who were centralising power in France, England, and Spain. On the other hand, the Parliament in the Polish–Lithuanian Commonwealth grew in power, taking legislative rights from the Polish king. The new state power was contested by parliaments in other countries especially England. New kinds of states emerged which were co-operation agreements between territorial rulers, cities, farmer republics and knights.\n\nThe Iberian states (Spain and Portugal) were able to dominate New World (American) colonial activity in the 16th century. The Spanish constituted the first global empire and during the 16th century and the first half of the 17th century, Spain was the most powerful nation in the world, but was increasingly challenged by British, French, and the short-lived Dutch and Swedish colonial efforts of the 17th and 18th centuries. New forms of trade and expanding horizons made new forms of government, law and eco nomics necessary.\n\nColonial expansion continued in the following centuries (with some setbacks, such as successful wars of independence in the British American colonies and then later Haiti, Mexico, Argentina, Brazil, and others amid European turmoil of the Napoleonic Wars; Haiti unique in abolishing slavery). Spain had control of a large part of North America, all of Central America and a great part of South America, the Caribbean and the Philippines; Britain took the whole of Australia and New Zealand, most of India, and large parts of Africa and North America; France held parts of Canada and India (nearly all of which was lost to Britain in 1763), Indochina, large parts of Africa and Caribbean islands; the Netherlands gained the East Indies (now Indonesia) and islands in the Caribbean; Portugal obtained Brazil and several territories in Africa and Asia; and later, powers such as Germany, Belgium, Italy and Russia acquired further colonies.\n\nThis expansion helped the economy of the countries owning them. Trade flourished, because of the minor stability of the empires. By the late 16th century, American silver accounted for one-fifth of the Spain's total budget. The European countries fought wars that were largely paid for by the money coming in from the colonies. Nevertheless, the profits of the slave trade and of plantations of the West Indies, then the most profitable of all the British colonies, amounted to less than 5% of the British Empire's economy (but was generally more profitable) at the time of the Industrial Revolution in the late 18th century.\n\nThe 17th century was an era of crisis. Many historians have rejected the idea, while others promote it as an invaluable insight into the warfare, politics, economics, and even art. The Thirty Years' War (1618–1648) focused attention on the massive horrors that wars could bring to entire populations. The 1640s in particular saw more state breakdowns around the world than any previous or subsequent period. The Polish-Lithuanian Commonwealth, the largest state in Europe, temporarily disappeared. In addition, there were secessions and upheavals in several parts of the Spanish empire, the world's first global empire. In Britain the entire Stuart monarchy (England, Scotland, Ireland, and its North American colonies) rebelled. Political insurgency and a spate of popular revolts seldom equalled shook the foundations of most states in Europe and Asia. More wars took place around the world in the mid-17th century than in almost any other period of recorded history. The crises spread far beyond Europe—for example Ming China, the most populous state in the world, collapsed. Across the Northern Hemisphere, the mid-17th century experienced almost unprecedented death rates. Parker suggests that environmental factors may have been in part to blame, especially global cooling.\n\nThe \"absolute\" rule of powerful monarchs such as Louis XIV (ruled France 1643–1715), Peter the Great (ruled Russia 1682–1725), Maria Theresa (ruled Habsburg lands 1740–1780) and Frederick the Great (ruled Prussia 1740–86), produced powerful centralized states, with strong armies and powerful bureaucracies, all under the control of the king.\n\nThroughout the early part of this period, capitalism (through Mercantilism) was replacing feudalism as the principal form of economic organisation, at least in the western half of Europe. The expanding colonial frontiers resulted in a Commercial Revolution. The period is noted for the rise of modern science and the application of its findings to technological improvements, which animated the Industrial Revolution after 1750.\n\nThe Reformation had profound effects on the unity of Europe. Not only were nations divided one from another by their religious orientation, but some states were torn apart internally by religious strife, avidly fostered by their external enemies. France suffered this fate in the 16th century in the series of conflicts known as the French Wars of Religion, which ended in the triumph of the Bourbon Dynasty. England avoided this fate for a while and settled down under Elizabeth to a moderate Anglicanism. Much of modern-day Germany was made up of numerous small sovereign states under the theoretical framework of the Holy Roman Empire, which was further divided along internally drawn sectarian lines. The Polish–Lithuanian Commonwealth is notable in this time for its religious indifference and a general immunity to the horrors of European religious strife.\n\nThe Thirty Years' War was fought between 1618 and 1648, across Germany and neighboring areas, and involved most of the major European powers except England and Russia. Beginning as a religious conflict between Protestants and Catholics in Bohemia, it quickly developed into a general war involving Catholics versus Protestants for the most part. The major impact of the war, in which mercenary armies were extensively used, was the devastation of entire regions scavenged bare by the foraging armies. Episodes of widespread famine and disease devastated the population of the German states and, to a lesser extent, the Low Countries, Bohemia and Italy, while bankrupting many of the regional powers involved. Between one-fourth and one-third of the German population perished from direct military causes or from disease and starvation, as well as postponed births. The war lasted for thirty years, but the conflicts that triggered it continued unresolved for a much longer time.\n\nAfter the Peace of Westphalia, which ended the war in favour of nations deciding their own religious allegiance, absolutism became the norm of the continent, while parts of Europe experimented with constitutions foreshadowed by the English Civil War and particularly the Glorious Revolution. European military conflict did not cease, but had less disruptive effects on the lives of Europeans. In the advanced northwest, the Enlightenment gave a philosophical underpinning to the new outlook, and the continued spread of literacy, made possible by the printing press, created new secular forces in thought.\n\nFrom the Union of Krewo (1385) central and eastern Europe was dominated by Kingdom of Poland and Grand Duchy of Lithuania. In the 16th and 17th centuries Central and Eastern Europe was an arena of conflict for domination of the continent between Sweden, the Polish–Lithuanian Commonwealth and the Ottoman Empire. The Polish–Lithuanian Commonwealth continued dominance central and eastern Europe until series of wars: Khmelnytsky Uprising, Russo-Polish War and the Deluge. This period saw a gradual decline of these three powers which were eventually replaced by new enlightened absolutist monarchies: Russia, Prussia and Austria. By the turn of the 19th century they had become new powers, having divided Poland between themselves, with Sweden and Turkey having experienced substantial territorial losses to Russia and Austria respectively as well as pauperisation.\n\nThe War of the Spanish Succession (1701–1715) was a major war with France opposed by a coalition of England, the Netherlands, the Austrian Empire, and Prussia. Duke of Marlborough commander the English and Dutch victory at the Battle Blenheim in 1704. The main issue was whether France under King Louis XIV would take control of Spain's very extensive possessions and thereby become by far the dominant power, or be forced to share power with other major nations. After initial allied successes, the long war produced a military stalemate and ended with the Treaty of Utrecht, which was based on a balance of power in Europe. Historian Russell Weigley argues that the many wars almost never accomplished more than they cost.\n\nFrederick the Great, king of Prussia 1740–86, modernized the Prussian army, introduced new tactical and strategic concepts, fought mostly successful wars and doubled the size of Prussia. Frederick had a rationale based on Enlightenment thought: he fought total wars for limited objectives. The goal was to convince rival kings that it was better to negotiate and make peace than to fight him.\n\nRussia with its numerous wars and rapid expansion was in a continuous state of financial crisis, which it covered by borrowing from Amsterdam and issuing paper money that caused inflation. Russia boasted a large and powerful army, a very large and complex internal bureaucracy, and a splendid court that rivaled Paris and London. However the government was living far beyond its means and seized Church lands, leaving organized religion in a weak condition. Throughout the 18th century Russia remained \"a poor, backward, overwhelmingly agricultural, and illiterate country.\"\n\nThe \"Enlightenment\" was a powerful, widespread cultural movement of intellectuals beginning in late 17th-century Europe emphasizing the power of reason rather than tradition; it was especially favourable to science (especially Isaac Newton's physics) and hostile to religious orthodoxy (especially of the Catholic Church). It sought to analyze and reform society using reason, to challenge ideas grounded in tradition and faith, and to advance knowledge through the scientific method. It promoted scientific thought, skepticism, and intellectual interchange. The Enlightenment was a revolution in human thought. This new way of thinking was that rational thought begins with clearly stated principles, uses correct logic to arrive at conclusions, tests the conclusions against evidence, and then revises the principles in the light of the evidence.\n\nEnlightenment thinkers opposed superstition. Some Enlightenment thinkers collaborated with Enlightened despots, absolutist rulers who attempted to forcibly impose some of the new ideas about government into practice. The ideas of the Enlightenment exerted significant influence on the culture, politics, and governments of Europe.\n\nOriginating in the 17th century, it was sparked by philosophers Francis Bacon (1562–1626), Baruch Spinoza (1632–1677), John Locke (1632–1704), Pierre Bayle (1647–1706), Voltaire (1694–1778), Francis Hutcheson, (1694–1746), David Hume (1711–1776) and physicist Isaac Newton (1643–1727). Ruling princes often endorsed and fostered these figures and even attempted to apply their ideas of government in what was known as enlightened absolutism. The Scientific Revolution is closely tied to the Enlightenment, as its discoveries overturned many traditional concepts and introduced new perspectives on nature and man's place within it. The Enlightenment flourished until about 1790–1800, at which point the Enlightenment, with its emphasis on reason, gave way to Romanticism, which placed a new emphasis on emotion; a Counter-Enlightenment began to increase in prominence. The Romantics argued that the Enlightenment was reductionistic insofar as it had largely ignored the forces of imagination, mystery, and sentiment.\n\nIn France, Enlightenment was based in the salons and culminated in the great \"Encyclopédie\" (1751–72) edited by Denis Diderot (1713–1784) and (until 1759) Jean le Rond d'Alembert (1717–1783) with contributions by hundreds of leading intellectuals who were called \"philosophes\", notably Voltaire (1694–1778), Rousseau (1712–1778) and Montesquieu (1689–1755). Some 25,000 copies of the 35 volume encyclopedia were sold, half of them outside France. These new intellectual strains would spread to urban centres across Europe, notably England, Scotland, the German states, the Netherlands, Poland, Russia, Italy, Austria, and Spain, as well as Britain's American colonies.\n\nThe political ideals of the Enlightenment influenced the American Declaration of Independence, the United States Bill of Rights, the French Declaration of the Rights of Man and of the Citizen, and the Polish–Lithuanian Constitution of May 3, 1791.\n\nTaking a long-term historical perspective, Norman Davies has argued that Freemasonry was a powerful force on behalf of Liberalism and Enlightenment ideas in Europe, from about 1700 to the 20th century. It expanded rapidly during the Age of Enlightenment, reaching practically every country in Europe. It was especially attractive to royalty, powerful aristocrats and politicians as well as intellectuals, artists and political activists. Its great enemy was the Roman Catholic Church, so that in countries with a large Catholic element, such as France, Italy, Austria, Spain (and Mexico), much of the ferocity of the political battles involve the confrontation between the Church and Freemasonry. Twentieth century totalitarian movements, especially the Fascists and Communists, crushed the Freemasons.\n\nThe \"long 19th century\", from 1789 to 1914 saw the drastic social, political and economic changes initiated by the Industrial Revolution, the French Revolution and the Napoleonic Wars. Following the reorganisation of the political map of Europe at the Congress of Vienna in 1815, Europe experienced the rise of Nationalism, the rise of the Russian Empire and the peak of the British Empire, which was paralleled by the decline of the Ottoman Empire. Finally, the rise of the German Empire and the Austro-Hungarian Empire initiated the course of events that culminated in the outbreak of the First World War in 1914.\n\nThe Industrial Revolution was a period in the late 18th century and early 19th century when major changes in agriculture, manufacturing, and transport affected socioeconomic and cultural conditions in Britain and subsequently spread throughout Europe and North America and eventually the world, a process that continues as industrialisation. Technological advancements, most notably the invention of the steam engine by Scottish engineer James Watt, were major catalysts in the industrialisation of Britain and, later, the wider world. It started in England and Scotland in the mid-18th century with the mechanisation of the textile industries, the development of iron-making techniques and the increased use of refined coal. Trade expansion was enabled by the introduction of canals, improved roads and railways. The introduction of steam power (fuelled primarily by coal) and powered machinery (mainly in textile manufacturing) underpinned the dramatic increases in production capacity. The development of all-metal machine tools in the first two decades of the 19th century facilitated the manufacture of more production machines for manufacturing in other industries. The effects spread throughout Western Europe and North America during the 19th century, eventually affecting most of the world. The impact of this change on society was enormous.\n\nHistorians R.R. Palmer and Joel Colton argue:\n\nThe era of the French Revolution and the subsequent Napoleonic wars was a difficult time for monarchs. Tsar Paul I of Russia was assassinated; King Louis XVI of France was executed, as was his Queen Marie Antoinette. Furthermore, kings Charles IV of Spain, Ferdinand VII of Spain and Gustav IV Adolf of Sweden were deposed as were ultimately the Emperor Napoleon and all of the relatives he had installed on various European thrones. King Frederick William III of Prussia and Emperor Francis II of Austria barely clung to their thrones. King George III of England lost the better part of his empire.\n\nThe American Revolution (1775–1783) was the first successful revolt of a colony against a European power. It proclaimed, in the words of Thomas Jefferson, the Enlightenment position that \"all men are created equal.\" It rejected aristocracy and set up a republican form of government under George Washington that attracted worldwide attention.\n\nThe French Revolution (1789–1804) was a product of the same democratic forces in the Atlantic World and had an even greater impact. French historian François Aulard says:\n\nFrench intervention in the American Revolutionary War had nearly bankrupted the state. After repeated failed attempts at financial reform, King Louis XVI had to convene the Estates-General, a representative body of the country made up of three estates: the clergy, the nobility, and the commoners. The third estate, joined by members of the other two, declared itself to be a National Assembly and swore an oath not to dissolve until France had a constitution and created, in July, the National Constituent Assembly. At the same time the people of Paris revolted, famously storming the Bastille prison on 14 July 1789.\n\nAt the time the assembly wanted to create a constitutional monarchy, and over the following two years passed various laws including the Declaration of the Rights of Man and of the Citizen, the abolition of feudalism, and a fundamental change in the relationship between France and Rome. At first the king agreed with these changes and enjoyed reasonable popularity with the people. As anti-royalism increased along with threat of foreign invasion, the king tried to flee and join France's enemies. He was captured and on 12 January 1793, having been convicted of treason, he was guillotined.\n\nOn 20 September 1792 the National Convention abolished the monarchy and declared France a republic. Due to the emergency of war the National Convention created the Committee of Public Safety, controlled by Maximilien de Robespierre of the Jacobin Club, to act as the country's executive. Under Robespierre the committee initiated the Reign of Terror, during which up to 40,000 people were executed in Paris, mainly nobles and those convicted by the Revolutionary Tribunal, often on the flimsiest of evidence. Internal tensions at Paris drove the Committee towards increasing assertions of radicalism and increasing suspicions, fueling new terror: a few months into this phase, more and more prominent revolutionaries were being sent to the guilloutine by Robespierre and his faction, for example Madame Roland and Georges Danton. Elsewhere in the country, counter-revolutionary insurrections were brutally suppressed. The regime was overthrown in the coup of 9 Thermidor (27 July 1794) and Robespierre was executed. The regime which followed ended the Terror and relaxed Robespierre's more extreme policies.\n\nNapoleon Bonaparte was one of the world's most famous soldiers and statesmen, leading France to great victories over numerous European enemies. Despite modest origins he became Emperor and restructured much of European diplomacy, politics and law, until he was forced to abdicate in 1814. His 100-day comeback in 1815 failed at the Battle of Waterloo, and he died in exile on a remote island, remembered as a great hero by many Frenchmen and as a great villain by British and other enemies.\n\nNapoleon, despite his youth, was France's most successful general in the Revolutionary wars, having conquered large parts of Italy and forced the Austrians to sue for peace. In 1799 on 18 Brumaire (9 November) he overthrew the feeble government, replacing it with the Consulate, which he dominated. He gained popularity in France by restoring the Church, keeping taxes low, centralizing power in Paris, and winning glory on the battlefield. In 1804 he crowned himself Emperor. In 1805, Napoleon planned to invade Britain, but a renewed British alliance with Russia and Austria (Third Coalition), forced him to turn his attention towards the continent, while at the same time the French fleet was demolished by the British at the Battle of Trafalgar, ending any plan to invade Britain. On 2 December 1805, Napoleon defeated a numerically superior Austro-Russian army at Austerlitz, forcing Austria's withdrawal from the coalition (\"see Treaty of Pressburg\") and dissolving the Holy Roman Empire. In 1806, a Fourth Coalition was set up. On 14 October Napoleon defeated the Prussians at the Battle of Jena-Auerstedt, marched through Germany and defeated the Russians on 14 June 1807 at Friedland. The Treaties of Tilsit divided Europe between France and Russia and created the Duchy of Warsaw.\n\nOn 12 June 1812 Napoleon invaded Russia with a Grande Armée of nearly 700,000 troops. After the measured victories at Smolensk and Borodino Napoleon occupied Moscow, only to find it burned by the retreating Russian army. He was forced to withdraw. On the march back his army was harassed by Cossacks, and suffered disease and starvation. Only 20,000 of his men survived the campaign. By 1813 the tide had begun to turn from Napoleon. Having been defeated by a seven nation army at the Battle of Leipzig in October 1813, he was forced to abdicate after the Six Days' Campaign and the occupation of Paris. Under the Treaty of Fontainebleau he was exiled to the island of Elba. He returned to France on 1 March 1815 (\"see Hundred Days\"), raised an army, but was finally defeated by a British and Prussian force at the Battle of Waterloo on 18 June 1815 and exiled to a small British island in the South Atlantic.\n\nRoberts finds that the Revolutionary and Napoleonic wars, from 1793 to 1815, caused 4 million deaths (of whom 1 million were civilians); 1.4 million were French deaths.\n\nOutside France the Revolution had a major impact. Its ideas became widespread. Roberts argues that Napoleon was responsible for key ideas of the modern world, so that, \"meritocracy, equality before the law, property rights, religious toleration, modern secular education, sound finances, and so on-were protected, consolidated, codified, and geographically extended by Napoleon during his 16 years of power.\"\n\nFurthermore, the French armies in the 1790s and 1800s directly overthrew feudal remains in much of western Europe. They liberalised property laws, ended seigneurial dues, abolished the guild of merchants and craftsmen to facilitate entrepreneurship, legalised of divorce, closed the Jewish ghettos and made Jews equal to everyone else. The Inquisition ended as did the Holy Roman Empire. The power of church courts and religious authority was sharply reduced and equality under the law was proclaimed for all men.\n\nIn foreign affairs, the French Army down to 1812 was quite successful. Roberts says that Napoleon fought 60 battles, losing only seven. France conquered Belgium and turned it into another province of France. It conquered the Netherlands, and made it a puppet state. It took control of the German areas on the left bank of the Rhine River and set up a puppet regime. It conquered Switzerland and most of Italy, setting up a series of puppet states. The result was glory for France, and an infusion of much needed money from the conquered lands, which also provided direct support to the French Army. However the enemies of France, led by Britain and funded by the inexhaustible British Treasury, formed a Second Coalition in 1799 (with Britain joined by Russia, the Ottoman Empire and Austria). It scored a series of victories that rolled back French successes, and trapped the French Army in Egypt. Napoleon himself slipped through the British blockade in October 1799, returning to Paris, where he overthrew the government and made himself the ruler.\n\nNapoleon conquered most of Italy in the name of the French Revolution in 1797–99. He consolidated old units and split up Austria's holdings. He set up a series of new republics, complete with new codes of law and abolition of old feudal privileges. Napoleon's Cisalpine Republic was centered on Milan; Genoa became a republic; the Roman Republic was formed as well as the small Ligurian Republic around Genoa. The Neapolitan Republic was formed around Naples, but it lasted only five months. He later formed the Kingdom of Italy, with his brother as King. In addition, France turned the Netherlands into the Batavian Republic, and Switzerland into the Helvetic Republic. All these new countries were satellites of France, and had to pay large subsidies to Paris, as well as provide military support for Napoleon's wars. Their political and administrative systems were modernized, the metric system introduced, and trade barriers reduced. Jewish ghettos were abolished. Belgium and Piedmont became integral parts of France.\n\nMost of the new nations were abolished and returned to prewar owners in 1814. However, Artz emphasizes the benefits the Italians gained from the French Revolution:\n\nLikewise in Switzerland the long-term impact of the French Revolution has been assessed by Martin:\n\nThe greatest impact came of course in France itself. In addition to effects similar to those in Italy and Switzerland, France saw the introduction of the principle of legal equality, and the downgrading of the once powerful and rich Catholic Church to just a bureau controlled by the government. Power became centralized in Paris, with its strong bureaucracy and an army supplied by conscripting all young men. French politics were permanently polarized — new names were given, \"left\" and \"right\" for the supporters and opponents of the principles of the Revolution.\n\nBritish historian Max Hastings says there is no question that as a military genius Napoleon ranks with Alexander the Great and Julius Caesar in greatness. However, in the political realm, historians debate whether Napoleon was \"an enlightened despot who laid the foundations of modern Europe or, instead, a megalomaniac who wrought greater misery than any man before the coming of Hitler.\" \n\nHistorian Kenneth Scott Latourette argues that the outlook for Protestantism at the start of the 19th century was discouraging. It was a regional religion based in northwestern Europe, with an outpost in the sparsely settled United States. It was closely allied with government, as in Scandinavia, the Netherlands, Prussia, and especially Great Britain. The alliance came at the expense of independence, as the government made the basic policy decisions, down to such details as the salaries of ministers and location of new churches. The dominant intellectual currents of the Enlightenment promoted rationalism, and most Protestant leaders preached a sort of deism. Intellectually, the new methods of historical and anthropological study undermine automatic acceptance of biblical stories, as did the sciences of geology and biology. Industrialization was a strongly negative factor, as workers who moved to the city seldom joined churches. The gap between the church and the unchurched grew rapidly, and secular forces, based both in socialism and liberalism undermine the prestige of religion. Despite the negative forces, Protestantism demonstrated a striking vitality by 1900. Shrugging off Enlightenment rationalism, Protestants embraced romanticism, with the stress on the personal and the invisible. Entirely fresh ideas as expressed by Friedrich Schleiermacher, Soren Kierkegaard, Albrecht Ritschl and Adolf von Harnack restored the intellectual power of theology. There was more attention to historic creeds such as the Augsburg, the Heidelberg, and the Westminster confessions. In England, Anglicans emphasize the historically Catholic components of their heritage, as the High Church element reintroduced vestments and incense into their rituals. The stirrings of pietism on the Continent, and evangelicalism in Britain expanded enormously, leading the devout away from an emphasis on formality and ritual and toward an inner sensibility toward personal relationship to Christ. Social activities, in education and in opposition to social vices such as slavery, alcoholism and poverty provided new opportunities for social service. Above all, worldwide missionary activity became a highly prized goal, proving quite successful in close cooperation with the imperialism of the British, German, and Dutch empires.\n\nThe political development of nationalism and the push for popular sovereignty culminated with the ethnic/national revolutions of Europe. During the 19th century nationalism became one of the most significant political and social forces in history; it is typically listed among the top causes of World War I.\n\nNapoleon's conquests of the German and Italian states around 1800–1806 played a major role in stimulating nationalism and the demands for national unity.\n\nIn the German states east of Prussia Napoleon abolished many of the old or medieval relics, such as dissolving the Holy Roman Empire in 1806. He imposed rational legal systems and demonstrated how dramatic changes were possible. For example, his organization of the Confederation of the Rhine in 1806 promoted a feeling of nationalism. Nationalists sought to encompass masculinity in their quest for strength and unity. In the 1860s it was Prussian chancellor Otto von Bismarck who achieved German unification in 1870 after the many smaller states followed Prussia's leadership in wars against Denmark, Austria and France.\n\nItalian nationalism emerged in the 19th century and was the driving force for Italian unification or the \"Risorgimento\" (meaning the Resurgence or revival). It was the political and intellectual movement that consolidated different states of the Italian peninsula into the single state of the Kingdom of Italy in 1860. The memory of the Risorgimento is central to both Italian nationalism and Italian historiography.\n\nThe Greek drive for independence from the Ottoman Empire inspired supporters across Christian Europe, especially in Britain. France, Russia and Britain intervened to make this nationalist dream become reality.\n\nFor centuries the Orthodox Christian Serbs were ruled by the Moslem-controlled Ottoman Empire. The success of the Serbian revolution against Ottoman rule in 1817 marked the birth of the Principality of Serbia. It achieved \"de facto\" independence in 1867 and finally gained recognition by the Great Powers in the Berlin Congress of 1878. The Serbs developed a larger vision for nationalism in Pan-Slavism and with Russian support sought to pull the other Slavs out of the Austro-Hungarian Empire. Austria, with German backing, tried to crush Serbia in 1914 but Russia intervened, thus igniting the First World War in which Austria dissolved into nation states.\n\nIn 1918, the region of Vojvodina proclaimed its secession from Austria-Hungary to unite with the pan-Slavic State of Slovenes, Croats and Serbs; the Kingdom of Serbia joined the union on 1 December 1918, and the country was named Kingdom of Serbs, Croats, and Slovenes. It was renamed Yugoslavia, which was never able to tame the multiple nationalities and religions and it flew apart in civil war in the 1980s.\n\nThe cause of Polish nationalism was repeatedly frustrated before 1918. In the 1790s, Germany, Russia and Austria partitioned Poland. Napoleon set up the Duchy of Warsaw, a new Polish state that ignited a spirit of nationalism. Russia took it over in 1815 as Congress Poland with the tsar as King of Poland. Large-scale nationalist revolts erupted in 1830 and 1863–64 but were harshly crushed by Russia, which tried to Russify the Polish language, culture and religion. The collapse of the Russian Empire in the First World War enabled the major powers to reestablish an independent Poland, which survived until 1939. Meanwhile, Poles in areas controlled by Germany moved into heavy industry but their religion came under attack by Bismarck in the Kulturkampf of the 1870s. The Poles joined German Catholics in a well-organized new Centre Party, and defeated Bismarck politically. He responded by stopping the harassment and cooperating with the Centre Party.\n\nAfter the defeat of revolutionary France, the other great powers tried to restore the situation which existed before 1789. In 1815 at the Congress of Vienna, the major powers of Europe managed to produce a peaceful balance of power among the various European empires. This was known as the Metternich system. However, their efforts were unable to stop the spread of revolutionary movements: the middle classes had been deeply influenced by the ideals of the French revolution, the Industrial Revolution brought important economical and social changes. The working classes and some intellectuals became a base for socialist, communist and anarchistic ideas (especially those summarised by Karl Marx and Friedrich Engels in \"The Communist Manifesto\"). The middle classes and businessmen promoted liberalism, free trade and capitalism. Aristocratic elements concentrated in government service, the military and the established churches. Nationalist movements (in Germany, Italy, Poland, Hungary, and elsewhere) called upon the \"racial\" unity (which usually meant a common language and an imagined common ethnicity) to seek national unification and/or liberation from foreign rule. As a result, the period between 1815 and 1871 saw a large number of revolutionary attempts and independence wars. Greece successfully revolted against Ottoman rule in the 1820s. European diplomats and intellectuals saw the Greek struggle for independence, with its accounts of Turkish atrocities, in a romantic light.\n\nNapoleon III, nephew of Napoleon I, returned to France from exile in 1848, bringing a famous name that promised to stabilize the chaotic political situation. He was elected president and elected himself Emperor, a move approved later by a large majority of the French electorate. He modernized Paris, and build up the economy. He was most famous for his aggressive foreign policy in Europe, Mexico, and worldwide. He helped in the unification of Italy by fighting the Austrian Empire and joined the Crimean War on the side of the United Kingdom and the Ottoman Empire against Russia. His empire collapsed after being defeated in the Franco-Prussian War. France gave up monarchs and became the democratic but anti-clerical French Third Republic, which lasted until 1940.\n\nMost European states had become constitutional (rather than absolute) monarchies by 1871, and Germany and Italy merged many small city-states to become united nation-states. Germany in particular increasingly dominated the continent in terms of economics and political power. Meanwhile, on a global scale, Great Britain, with its far-flung British Empire, unmatched Royal Navy, and powerful bankers, became the world's first global power. The sun never set on its territories, while an informal empire operated through British financiers, entrepreneurs, traders and engineers who established operations in many countries, and largely dominated Latin America. The British were especially famous for financing and constructing railways around the world.\n\nFrom his base in Prussia, Otto von Bismarck in the 1860s engineered a series of short, decisive wars, that unified most of the German states (excluding Austria) into a powerful German Empire under Prussian leadership. He humiliated France in the process, but kept on good terms with Austria-Hungary. With that accomplished by 1871 he then skillfully used balance of power diplomacy to preserve Germany's new role and keep Europe at peace. He was removed from office in 1890 by an aggressive young Kaiser Wilhelm II, who pursued a disruptive foreign policy that polarized Europe into rival camps. These rival camps went to war with each other in 1914.\n\nColonial empires were the product of the European Age of Discovery from the 15th century. The initial impulse behind these dispersed maritime empires and those that followed was trade, driven by the new ideas and the capitalism that grew out of the Renaissance. Both the Portuguese Empire and Spanish Empire quickly grew into the first global political and economic systems with territories spread around the world.\n\nSubsequent major European colonial empires included the French, Dutch, and British empires. The latter, consolidated during the period of British maritime hegemony in the 19th century, became the largest empire in history because of the improved ocean transportation technologies of the time as well as electronic communication through the telegraph, cable, and radio. At its height in 1920, the British Empire covered a quarter of the Earth's land area and comprised a quarter of its population. Other European countries, such as Belgium, Germany, and Italy, pursued colonial empires as well (mostly in Africa), but they were smaller. Ignoring the oceans, Russia built its Russian Empire through conquest by land in Eastern Europe, and Asia.\n\nBy the mid-19th century, the Ottoman Empire had declined enough to become a target for other global powers (see History of the Balkans). This instigated the Crimean War in 1854 and began a tenser period of minor clashes among the globe-spanning empires of Europe that eventually set the stage for the First World War. In the second half of the 19th century, the Kingdom of Sardinia and the Kingdom of Prussia carried out a series of wars that resulted in the creation of Italy and Germany as nation-states, significantly changing the balance of power in Europe. From 1870, Otto von Bismarck engineered a German hegemony of Europe that put France in a critical situation. It slowly rebuilt its relationships, seeking alliances with Russia and Britain to control the growing power of Germany. In this way, two opposing sides—the Triple Alliance of 1882 (Germany, Austria-Hungary and Italy) and the Triple Entente of 1907 (Britain, France and Russia)—formed in Europe, improving their military forces and alliances year-by-year.\n\nGerman-American historian Konrad Jarausch, asked if he agreed that \"the European record of the past century [was] just one gigantic catastrophe\", argues:\n\nThe \"short twentieth century\", from 1914 to 1991, included the First World War, the Second World War and the Cold War. The First World War used modern technology to kill millions of soldiers. Victory by Britain, France, the United States and other allies drastically changed the map of Europe, ending four major land empires (the Russian, German, Austro-Hungarian and Ottoman empires) and leading to the creation of nation-states across Central and Eastern Europe. The October Revolution in Russia led to the creation of the Soviet Union (1917–1991) and the rise of the international communist movement. Widespread economic prosperity was typical of the period before 1914, and 1920–1929. After the onset of the Great Depression in 1929, however, democracy collapsed in most of Europe. Fascists took control in Italy, and the even more aggressive Nazi movement led by Adolf Hitler took control of Germany, 1933–45. The Second World War was fought on an even larger scale than the First war, killing many more people, and using even more advanced technology. It ended with the division of Europe between East and West, with the East under the control of the Soviet Union and the West dominated by NATO. The two sides engaged in the Cold War, with actual conflict taking place not in Europe but in Asia in the Korean War and the Vietnam War. The Imperial system collapsed. The remaining colonial empires ended through the decolonisation of European rule in Africa and Asia. The fall of Soviet Communism (1989– 1991) left the West dominant and enabled the reunification of Germany. It accelerated the process of a European integration to include Eastern Europe. The European Union continues today, but with German economic dominance. Since the worldwide Great Recession of 2008, European growth has been slow, and financial crises have hit Greece and other countries. Social divisiveness has been caused by large-scale immigration and radical Islamic rejection of European norms. While Russia is a weak version of the old Soviet Union, it has been confronting Europe in Ukraine and other areas.\n\nAfter the relative peace of most of the 19th century, the rivalry between European powers, compounded by a rising nationalism among ethnic groups, exploded in August 1914, when the First World War started. Over 65 million European soldiers were mobilised from 1914 to 1918; 20 million soldiers and civilians died, and 21 million were seriously wounded. On one side were Germany, Austria-Hungary, the Ottoman Empire and Bulgaria (the Central Powers/Triple Alliance), while on the other side stood Serbia and the \"Triple Entente\" – the coalition of France, Britain and Russia, which were joined by Italy in 1915, Romania in 1916 and by the United States in 1917. The Western Front involved especially brutal combat without any territorial gains by either side. Single battles like Verdun and the Some killed hundreds of thousands of men while leaving the stalemate unchanged. Heavy artillery and machine guns caused most of the casualties, supplemented by poison gas. Czarist Russia collapsed in the February Revolution of 1917 and Germany claimed victory on the Eastern Front. After eight months of liberal rule, the October Revolution brought Vladimir Lenin and the Bolsheviks to power, leading to the creation of the Soviet Union in place of the disintegrated Russian Empire. With American entry into the war in 1917 on the Allied side, and the failure of Germany's spring 1918 offensive, Germany had run out of manpower, while an average of 10,000 American troops were arriving in France every day in the summer of 1918. Germany's allies, Austria-Hungary and the Ottoman Empire, surrendered and dissolved, followed by Germany on 11 November 1918. The victors forced Germany to assume responsibility for the conflict and pay war reparations.\n\nOne factor in determining the outcome of the war was that the Allies had significantly more economic resources they could spend on the war. One estimate (using 1913 US dollars) is that the Allies spent $58 billion on the war and the Central Powers only $25 billion. Among the Allies, Britain spent $21 billion and the U.S. $17 billion; among the Central Powers Germany spent $20 billion.\n\nThe world war was settled by the victors at the Paris Peace Conference in 1919. Two dozen nations sent delegations, and there were many nongovernmental groups, but the defeated powers were not invited.\n\nThe \"Big Four\" were President Woodrow Wilson of the United States, Prime Minister David Lloyd George of Great Britain, George Clemenceau of France, and, of least importance, Italian Prime Minister Vittorio Orlando. They met together informally 145 times and made all the major decisions, which in turn were ratified by the others.\n\nThe major decisions were the creation of the League of Nations; the six peace treaties with defeated enemies, most notable the Treaty of Versailles with Germany; the awarding of German and Ottoman overseas possessions as \"mandates\", chiefly to Britain and France; and the drawing of new national boundaries (sometimes with plebiscites) to better reflect the forces of nationalism.\n\nAs the conference's decisions were enacted unilaterally, and largely on the whims of the Big Four, for its duration Paris was effectively the center of a world government, which deliberated over and implemented the sweeping changes to the political geography of Europe. Most famously, the Treaty of Versailles itself weakened Germany's military and placed full blame for the war and costly reparations on its shoulders – the humiliation and resentment in Germany is sometimes considered as one of the causes of Nazi success and indirectly a cause of World War II.\n\nAt the insistence of President Wilson, the Big Four required Poland to sign a treaty on 28 June 1919 that guaranteed minority rights in the new nation. Poland signed under protest, and made little effort to enforce the specified rights for Germans, Jews, Ukrainians, and other minorities. Similar treaties were signed by Czechoslovakia, Romania, Yugoslavia, Greece, Austria, Hungary, Bulgaria, and later by Latvia, Estonia and Lithuania. Finland and Germany were not asked to sign a minority rights treaty.\n\nIn the Treaty of Versailles (1919) the winners imposed relatively hard conditions on Germany and recognised the new states (such as Poland, Czechoslovakia, Hungary, Austria, Yugoslavia, Finland, Estonia, Latvia, Lithuania) created in central Europe from the defunct German, Austro-Hungarian and Russian empires, based on national (ethnic) self-determination. It was a peaceful era with a few small wars before 1922 such as the Ukrainian–Soviet War (1917–1921) and the Polish–Soviet War (1919–1921). Prosperity was widespread, and the major cities sponsored a youth culture called the \"Roaring Twenties\" that was often featured in the cinema, which attracted very large audiences.\n\nThe Allied victory in the First World War seem to mark the triumph of liberalism, not just in the Allied countries themselves, but also in Germany and in the new states of Eastern Europe. Authoritarian militarism as typified by Germany had been defeated and discredited. Historian Martin Blinkhorn argues that the liberal themes were ascendant in terms of \"cultural pluralism, religious and ethnic toleration, national self-determination, free-market economics, representative and responsible government, free trade, unionism, and the peaceful settlement of international disputes through a new body, the League of Nations.\" However, as early as 1917, the emerging liberal order was being challenged by the new communist movement taking inspiration from the Russian Revolution. Communist revolts were beaten back everywhere else, but they did succeed in Russia.\n\nItaly adopted an authoritarian system known as Fascism in 1922; it became a model for Hitler in Germany and for right wing elements in other countries. Historian Stanley G. Payne says Fascism in Italy was: \n\nAuthoritarian regimes were established in the 1930s in Germany, Portugal, Austria, Poland, Greece, the Baltic countries and Spain. By 1940, there were only four liberal democracies left on the European continent: France, Finland, Switzerland and Sweden.\n\nAfter the Wall Street Crash of 1929, nearly the whole world sank into a Great Depression, as prices fell, profits fell, and unemployment soared. The worst hit sectors included heavy industry, export-oriented agriculture, mining and lumbering, and construction. World trade fell by two thirds.\n\nLiberalism and democracy were discredited. In most of Europe, as well as in Japan and most of Latin America, nation after nation turned to dictators and authoritarian regimes. The most momentous change of government came when Hitler and his Nazis took power in Germany in 1933. A major civil war took place in Spain, with the nationalists winning. The League of Nations was helpless as Italy conquered Ethiopia and Japan seized Manchuria in 1931 and took over most of China starting in 1937.\n\nThe Spanish Civil War (1936–1939) was marked by numerous small battles and sieges, and many atrocities, until the rebels (the Nationalists), led by Francisco Franco, won in 1939. There was military intervention as Italy sent land forces, and Germany sent smaller elite air force and armoured units to the Nationalists. The Soviet Union sold armaments to the leftist Republicans on the other side, while the Communist parties in numerous countries sent soldiers to the \"International Brigades.\" The civil war did not escalate into a larger conflict, but did become a worldwide ideological battleground that pitted the left, the communist movement and many liberals against Catholics, conservatives, and fascists. Britain, France and the US remained neutral and refused to sell military supplies to either side. Worldwide there was a decline in pacifism and a growing sense that another world war was imminent, and that it would be worth fighting for.\n\nIn the Munich Agreement of 1938, Britain and France adopted a policy of appeasement as they gave Hitler what he wanted out of Czechoslovakia in the hope that it would bring peace. It did not. In 1939 Germany took over the rest of Czechoslovakia and appeasement policies gave way to hurried rearmament as Hitler next turned his attention to Poland.\n\nAfter allying with Japan in the Anti-Comintern Pact and then also with Benito Mussolini's Italy in the \"Pact of Steel\", and finally signing a non-aggression treaty with the Soviet Union in August 1939, Hitler launched the Second World War on 1 September 1939 by attacking Poland. To his surprise Britain and France declared war on Germany, but there was little fighting during the \"Phoney War\" period. War began in earnest in spring 1940 with the successful Blitzkrieg conquests of Denmark, Norway, the Low Countries, and France. Britain remained alone but refused to negotiate, and defeated Germany's air attacks in the Battle of Britain. Hitler's goal was to control Eastern Europe but because of his failure to defeat Britain and the Italian failures in North Africa and the Balkans, the great attack on the Soviet Union was delayed until June 1941. Despite initial successes, the German army was stopped close to Moscow in December 1941.\n\nOver the next year the tide was turned and the Germans started to suffer a series of defeats, for example in the siege of Stalingrad and at Kursk. Meanwhile, Japan (allied to Germany and Italy since September 1940) attacked Britain and the United States on 7 December 1941; Germany then completed its over-extension by declaring war on the United States. War raged between the Axis Powers (Germany, Italy, and Japan) and the Allied Forces (British Empire, Soviet Union, and the United States). The Allied Forces won in North Africa, invaded Italy in 1943, and recaptured France in 1944. In the spring of 1945 Germany itself was invaded from the east by the Soviet Union and from the west by the other Allies. As the Red Army conquered the Reichstag in Berlin, Hitler committed suicide and Germany surrendered in early May. World War II was the deadliest conflict in human history, causing between 50 and 80 million deaths, the majority of whom were civilians (approximately 38 to 55 million).\n\nThis period was also marked by systematic genocide. In 1942–45, separately from the war-related deaths, the Nazis killed an additional number of over 11 million civilians identified through IBM-enabled censuses, including the majority of the Jews and Gypsies of Europe, millions of Polish and Soviet Slavs, and also homosexuals, Jehovah's Witnesses, misfits, disabled, and political enemies. Meanwhile, in the 1930s the Soviet system of forced labour, expulsions and allegedly engineered famine had a similar death toll. During and after the war millions of civilians were affected by forced population transfers.\n\nThe world wars ended the pre-eminent position of the old European powers in the world. At the Yalta Conference, Europe was divided into spheres of influence between the victors of World War II, and soon became the principal zone of contention in the Cold War between the two power blocs, the Western countries and the Communist bloc. The United States and the majority of European liberal democracies at the time (United Kingdom, France, Italy, Netherlands, West Germany etc.) established the NATO military alliance. Later, the Soviet Union and its satellites in Europe (Bulgaria, Czechoslovakia, East Germany, Hungary, Poland, and Romania) established the Warsaw Pact as a counterpoint to NATO. Each alliance was intended to defend against a potential invasion by the other.\n\nCommunist states were established in the East, while parliamentary democracy became the dominant form of government in the West, and proved highly popular there until the turmoil of the late 1960s. Most historians point to its success as the product of exhaustion, economic prosperity, or the constraints imposed by the Cold War. Martin Conway also adds that an important impetus came from the anti-Nazi wartime political coalitions.\n\nWestern Europe launched a process of political and economic integration, with the aim to unite the region and defend it. This process included organisations such as the European Coal and Steel Community, which grew and evolved into the European Union, and the Council of Europe. The Solidarność movement in the 1980s weakened the Communist government in Poland. At the time the Soviet leader Mikhail Gorbachev initiated perestroika and glasnost, which weakened Soviet influence in Europe, particularly in the USSR. In 1989 the Berlin Wall came down and Communist governments outside the Soviet Union were deposed. In 1990 the Federal Republic of Germany absorbed East Germany, after making large cash payments to the USSR. In 1991 the Communist Party in Moscow collapsed, ending the USSR, which split into fifteen independent states. The largest, Russia, took the Soviet Union's seat on the United Nations Security Council. The most violent dissolution happened in Yugoslavia, in the Balkans. Four (Slovenia, Croatia, Bosnia and Herzegovina and Macedonia) out of six Yugoslav republics declared independence and for most of them a violent war ensued, in some parts lasting until 1995. In 2006 Montenegro seceded and became an independent state. In the post–Cold War era, NATO and the EU have been gradually admitting most of the former members of the Warsaw Pact.\n\nLooking at the half century after the war historian Walter Lacquer concluded:\n\nThe post-war period also witnessed a significant rise in the standard of living of the Western European working class. As noted by one historical text, \"within a single generation, the working classes of Western Europe came to enjoy the multiple pleasures of the consumer society.\"\n\nWestern Europe's industrial nations in the 1970s were hit by a global economic crisis. They had obsolescent heavy industry, and suddenly had to pay very high energy prices which caused sharp inflation. Some of them also had inefficient nationalized railways and heavy industries. In the important field of computer technology, European nations lagged behind the United States. They also faced high government deficits and growing unrest led by militant labour unions. There was an urgent need for new economic directions. Germany and Sweden sought to create a social consensus behind a gradual restructuring. Germany's efforts proved highly successful. In Britain under the leadership of Margaret Thatcher, the solution was shock therapy, high interest rates, austerity, and selling off inefficient corporations as well as the public housing, which was sold off to the tenants. One result was escalating social tensions in Britain, led by the militant coal miners. Thatcher eventually defeated her opponents and radically changed the British economy, but the controversy never went away as shown by the hostile demonstrations at the time of her death in 2013.\n\nFollowing the end of the Cold War, the European Economic Community pushed for closer integration, co-operation in foreign and home affairs, and started to increase its membership into the neutral and former communist countries. In 1993, the Maastricht Treaty established the European Union, succeeding the EEC and furthering political co-operation. The neutral countries of Austria, Finland and Sweden acceded to the EU, and those that didn't join were tied into the EU's economic market via the European Economic Area. These countries also entered the Schengen Agreement which lifted border controls between member states.\n\nThe Maastricht Treaty created a single currency for most EU members. The \"euro\" was created in 1999 and replaced all previous currencies in participating states in 2002. The most notable exception to the currency union, or \"eurozone\", was the United Kingdom, which also did not sign the Schengen Agreement.\n\nEU did not participate in the Yugoslav Wars, and was divided on supporting the United States in the 2003–2011 Iraq War. NATO has been part of the war in Afghanistan, but at a much lower level of involvement than the United States.\n\nIn 2004, the EU gained 10 new members. (Estonia, Latvia, and Lithuania, which had been part of the Soviet Union; Czech Republic, Hungary, Poland, Slovakia, and Slovenia, five former-communist countries; Malta, and the divided island of Cyprus.) These were followed by Bulgaria and Romania in 2007. These expansions violated a 1990 promise that NATO would not expand \"one inch to the east\", causing anger from Russia. Russia engaged in a number of bilateral disputes about gas supplies with Belarus and Ukraine which endangered gas supplies to Europe. Russia also engaged in a minor war with Georgia in 2008.\n\nSupported by the United States and some European countries, Kosovo's government unilaterally declared independence from Serbia on 17 February 2008.\n\nPublic opinion in the EU turned against enlargement, partially due to what was seen as over-eager expansion including Turkey gaining candidate status. The European Constitution was rejected in France and the Netherlands, and then (as the Treaty of Lisbon) in Ireland, although a second vote passed in Ireland in 2009.\n\nThe financial crisis of 2007–08 effected Europe, and government responded with austerity measures. Limited ability of the smaller EU nations (most notably Greece) to handle their debts led to social unrest, government liquidation, and financial insolvency. In May 2010, the German parliament agreed to loan 22.4 billion euros to Greece over three years, with the stipulation that Greece follow strict austerity measures. See European sovereign-debt crisis.\n\nBeginning in 2014, Ukraine has been in a state of revolution and unrest with two breakaway regions (Donetsk and Lugansk) attempting join Russia as full federal subjects. (\"See War in Donbass.\") On 16 March, a referendum was held in Crimea leading to the \"de facto\" secession of Crimea and its largely internationally unrecognized annexation to the Russian Federation as the Republic of Crimea.\n\nThe future of the EU was plunged into doubt in June 2016 when a United Kingdom membership referendum resulted in the country's intended withdrawal. 52% voted to leave the EU, leading into a complex separation process implying political and economic changes for the UK and other countries.\n\nAD\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n", "id": "13212", "title": "History of Europe"}
{"url": "https://en.wikipedia.org/wiki?curid=13216", "text": "Hold come what may\n\nHold come what may is a phrase popularized by logician Willard Van Orman Quine. Beliefs that are \"held come what may\" are beliefs one is unwilling to give up, regardless of any evidence with which one might be presented. Quine held (on a perhaps simplistic construal) that there are no beliefs that one ought to hold come what may—in other words, that all beliefs are rationally revisable (\"no statement is immune to revision\"), and compared this to the simplification of quantum mechanics.\n\nMany philosophers argue to the contrary, believing that, for example, the laws of thought cannot be revised and may be \"held come what may\". Quine believed that all beliefs are linked by a web of beliefs, in which a belief is linked to another belief by supporting relations, but if one belief is found untrue, there is ground to find the linked beliefs also untrue.\n\nA closely related concept is hold more stubbornly at least, also popularized by Quine. Some beliefs may be more useful than others, or may be implied by a large number of beliefs. Examples might be laws of logic, or the belief in an external world of physical objects. Altering such central portions of the web of beliefs would have immense, ramifying consequences, and affect many other beliefs. It is better to alter auxiliary beliefs around the edges of the web of beliefs (considered to be sense beliefs, rather than main beliefs) in the face of new evidence unfriendly to one's central principles. Thus, while one might agree that there is no belief one can hold come what may, there are some for which there is ample practical ground to \"hold more stubbornly at least\".\n", "id": "13216", "title": "Hold come what may"}
{"url": "https://en.wikipedia.org/wiki?curid=13217", "text": "Haiku\n\n\nIn Japanese, haiku are traditionally printed in a single vertical line while haiku in English often appear in three lines to parallel the three phrases of Japanese haiku. \n\nPreviously called \"hokku\", haiku was given its current name by the Japanese writer Masaoka Shiki at the end of the 19th century.\n\nIn Japanese haiku a \"kireji\", or cutting word, typically appears at the end of one of the verse's three phrases. A \"kireji\" fills a role somewhat analogous to a \"caesura\" in classical western poetry or to a volta in sonnets. Depending on which cutting word is chosen, and its position within the verse, it may briefly cut the stream of thought, suggesting a parallel between the preceding and following phrases, or it may provide a dignified ending, concluding the verse with a heightened sense of closure.\n\nThe fundamental aesthetic quality of both hokku and haiku is that it is internally sufficient, independent of context, and will bear consideration as a complete work. The \"kireji\" lends the verse structural support, allowing it to stand as an independent poem. The use of \"kireji\" distinguishes haiku and hokku from second and subsequent verses of renku; which may employ semantic and syntactic disjuncture, even to the point of occasionally end-stopping a phrase with a . However, renku typically employ \"kireji\".\n\nIn English, since \"kireji\" have no direct equivalent, poets sometimes use punctuation such as a dash or ellipsis, or an implied break to create a juxtaposition intended to prompt the reader to reflect on the relationship between the two parts.\n\nThe \"kireji\" in the Bashō examples \"old pond\" and \"the wind of Mt Fuji\" are both \"ya\" (). Neither the remaining Bashō example nor the Issa example contain a \"kireji\" although they do both balance a fragment in the first five \"on\" against a phrase in the remaining 12 \"on\" (it may not be apparent from the English translation of the Issa that the first five \"on\" mean \"Edo's rain\").\n\nIn comparison with English verse typically characterized by syllabic meter, Japanese verse counts sound units known as \"\"on\"\" or morae. Traditional haiku consist of 17 \"on\", in three phrases of five, seven and five \"on\" respectively. Among contemporary poems \"teikei\" ( fixed form) haiku continue to use the 5-7-5 pattern while \"jiyuritsu\" ( free form) haiku do not. One of the examples below illustrates that traditional haiku masters were not always constrained by the 5-7-5 pattern.\n\nAlthough the word \"\"on\"\" is sometimes translated as \"syllable\", one \"on\" is counted for a short syllable, two for an elongated vowel or doubled consonant, and one for an \"n\" at the end of a syllable. Thus, the word \"haibun\", though counted as two syllables in English, is counted as four \"on\" in Japanese (ha-i-bu-n); and the word \"\"on\"\" itself, which English-speakers would view as a single syllable, comprises two \"on\": the short vowel o and the . This is illustrated by the Issa haiku below, which contains 17 \"on\" but only 15 syllables. Conversely, some sounds, such as \"kyo\" () may look like two syllables to English speakers but are in fact a single \"on\" (as well as a single syllable) in Japanese.\n\nThe word \"onji\" (; \"sound character\") is sometimes used in referring to Japanese sound units in English although this word is no longer current in Japanese. In Japanese, each \"on\" corresponds to a kana character (or sometimes digraph) and hence \"ji\" (or \"character\") is also sometimes used as the count unit.\n\nIn 1973, the Haiku Society of America noted that the norm for writers of haiku in English was to use 17 syllables, but they also noted a trend toward shorter haiku.\n\nSome translators of Japanese poetry have noted that about 12 syllables in English approximate the duration of 17 Japanese \"on\". Also in translations four lines is more appropriate for the colloquialism of the language and is closest to natural conversational rhythm, necessary to carry the weight of the hokku\n\nA haiku traditionally contains a \"kigo\", a word or phrase that symbolizes or implies the season of the poem and which is drawn from a \"saijiki\", an extensive but prescriptive list of such words.\n\nKigo are often in the form of metonyms and can be difficult for those who lack Japanese cultural references to spot. The Bashō examples below include \"kawazu\", \"frog\" implying spring, and \"shigure\", a rain shower in late autumn or early winter. Kigo are not always included in non-Japanese haiku or by modern writers of Japanese \"free-form\" haiku.\n\nThe best-known Japanese haiku is Bashō's \"old pond\":\n\nThis separates into \"on\" as:\n\nTranslated:\n\nAnother haiku by Bashō:\n\nThis separates into \"on\" as:\n\nTranslated:\n\nThis haiku by Bashō illustrates that he was not always constrained to a 5-7-5 \"on\" pattern. It contains 18 \"on\" in the pattern 6-7-5 (\"ō\" or is treated as two \"on\".)\n\nThis separates into \"on\" as:\n\nTranslated:\n\nThis haiku by Issa illustrates that 17 Japanese \"on\" do not always equate to 17 English syllables (\"nan\" counts as two \"on\" and \"nonda\" as three.)\n\nThis separates into \"on\" as,\n\nTranslated:\n\nHokku is the opening stanza of an orthodox collaborative linked poem, or renga, and of its later derivative, renku (or \"haikai no renga\"). By the time of Matsuo Bashō (1644–1694), the hokku had begun to appear as an independent poem, and was also incorporated in haibun (a combination of prose and hokku), and haiga (a combination of painting with hokku). In the late 19th century, Masaoka Shiki (1867–1902) renamed the standalone hokku to haiku. The latter term is now generally applied retrospectively to all hokku appearing independently of renku or renga, irrespective of when they were written, and the use of the term hokku to describe a stand-alone poem is considered obsolete.\n\nIn the 17th century, two masters arose who elevated \"haikai\" and gave it a new popularity. They were Matsuo Bashō (1644–1694) and (1661–1738). \"Hokku\" is the first verse of the collaborative \"haikai\" or \"renku\", but its position as the opening verse made it the most important, setting the tone for the whole composition. Even though \"hokku\" had sometimes appeared individually, they were always understood in the context of \"renku\". The Bashō school promoted standalone \"hokku\" by including many in their anthologies, thus giving birth to what is now called \"haiku\". Bashō also used his \"hokku\" as torque points within his short prose sketches and longer travel diaries. This subgenre of \"haikai\" is known as \"haibun\". His best-known work, \"Oku no Hosomichi\", or \"Narrow Roads to the Interior\", is counted as one of the classics of Japanese literature and has been translated into English extensively.\n\nBashō was deified by both the imperial government and Shinto religious headquarters one hundred years after his death because he raised the haikai genre from a playful game of wit to sublime poetry. He continues to be revered as a saint of poetry in Japan, and is the one name from classical Japanese literature that is familiar throughout the world.\n\nThe next famous style of haikai to arise was that of Yosa Buson (1716–1783) and others such as Kitō, called the Tenmei style after the Tenmei Era (1781–1789) in which it was created.\n\nBuson is recognized as one of the greatest masters of haiga (an art form where painting is combined with haiku or haikai prose). His affection for painting can be seen in the painterly style of his haiku.\n\nNo new popular style followed Buson. However, a very individualistic, and at the same time humanistic, approach to writing haiku was demonstrated by the poet Kobayashi Issa (1763–1827), whose miserable childhood, poverty, sad life, and devotion to the Pure Land sect of Buddhism are evident in his poetry. Issa made the genre immediately accessible to wider audiences.\n\nMasaoka Shiki (1867–1902) was a reformer and modernizer. A prolific writer, even though chronically ill during a significant part of his life, Shiki disliked the 'stereotype' haikai writers of the 19th century who were known by the deprecatory term \"tsukinami\", meaning 'monthly', after the monthly or twice-monthly \"haikai\" gatherings of the end of the 18th century (in regard to this period of \"haikai\", it came to mean 'trite' and 'hackneyed'). Shiki also criticized Bashō. Like the Japanese intellectual world in general at that time, Shiki was strongly influenced by Western culture. He favored the painterly style of Buson and particularly the European concept of \"plein-air\" painting, which he adapted to create a style of haiku as a kind of nature sketch in words, an approach called \"shasei\" (, \"sketching from life\"). He popularized his views by verse columns and essays in newspapers.\n\nHokku up to the time of Shiki, even when appearing independently, were written in the context of renku. Shiki formally separated his new style of verse from the context of collaborative poetry. Being agnostic, he also separated it from the influence of Buddhism. Further, he discarded the term \"hokku\" and proposed the term \"haiku\" as an abbreviation of the phrase \"\"haikai no ku\"\" meaning a verse of \"haikai\", although the term predates Shiki by some two centuries, when it was used to mean \"any\" verse of haikai. Since then, \"haiku\" has been the term usually applied in both Japanese and English to all independent haiku, irrespective of their date of composition. Shiki's revisionism dealt a severe blow to renku and surviving haikai schools. The term \"hokku\" is now used chiefly in its original sense of the opening verse of a renku, and rarely to distinguish haiku written before Shiki's time.\n\nHaibun is a combination of prose and haiku, often autobiographical or written in the form of a travel journal.\n\nHaiga is a style of Japanese painting based on the aesthetics of haikai, and usually including a haiku. Today, haiga artists combine haiku with paintings, photographs and other art.\n\nThe carving of famous haiku on natural stone to make poem monuments known as \"kuhi\" () has been a popular practice for many centuries. The city of Matsuyama has more than two hundred \"kuhi\".\n\nThe earliest westerner known to have written haiku was the Dutchman Hendrik Doeff (1764–1837), who was the Dutch commissioner in the Dejima trading post in Nagasaki, during the first years of the 19th century. One of his haiku:\nAlthough there were further attempts outside Japan to imitate the \"hokku\" in the early 20th century, there was little understanding of its principles. Early Western scholars such as Basil Hall Chamberlain (1850–1935) and William George Aston were mostly dismissive of hokku's poetic value. One of the first advocates of English-language hokku was the Japanese poet Yone Noguchi. In \"A Proposal to American Poets,\" published in the \"Reader\" magazine in February 1904, Noguchi gave a brief outline of the hokku and some of his own English efforts, ending with the exhortation, \"Pray, you try Japanese Hokku, my American poets!\" At about the same time the poet Sadakichi Hartmann was publishing original English-language hokku, as well as other Japanese forms in both English and French.\n\nIn France, haiku was introduced by Paul-Louis Couchoud around 1906. Couchoud's articles were read by early Imagist theoretician F. S. Flint, who passed on Couchoud's ideas to other members of the proto-Imagist Poets' Club such as Ezra Pound. Amy Lowell made a trip to London to meet Pound and find out about haiku. She returned to the United States where she worked to interest others in this \"new\" form. Haiku subsequently had a considerable influence on Imagists in the 1910s, notably Pound's \"In a Station of the Metro\" of 1913, but, notwithstanding several efforts by Yone Noguchi to explain \"the hokku spirit\", there was as yet little understanding of the form and its history.\n\nR. H. Blyth was an Englishman who lived in Japan. He produced a series of works on Zen, haiku, senryū, and on other forms of Japanese and Asian literature. In 1949, with the publication in Japan of the first volume of \"Haiku\", the four-volume work by Blyth, haiku were introduced to the post-war English-speaking world. This four-volume series (1949–52) described haiku from the pre-modern period up to and including Shiki. Blyth's \"History of Haiku\" (1964) in two volumes is regarded as a classical study of haiku. Today Blyth is best known as a major interpreter of haiku to English speakers. His works have stimulated the writing of haiku in English.\n\nThe Japanese-American scholar and translator Kenneth Yasuda published \"The Japanese Haiku: Its Essential Nature, History, and Possibilities in English, with Selected Examples\" in 1957. The book includes both translations from Japanese and original poems of his own in English, which had previously appeared in his book titled \"A Pepper-Pod: Classic Japanese Poems together with Original Haiku\". In these books Yasuda presented a critical theory about haiku, to which he added comments on haiku poetry by early 20th-century poets and critics. His translations apply a 5–7–5 syllable count in English, with the first and third lines end-rhymed. Yasuda considered that haiku translated into English should utilize all of the poetic resources of the language. Yasuda's theory also includes the concept of a \"haiku moment\" based in personal experience, and provides the motive for writing a haiku (' an aesthestic moment' of a timeless feeling of enlightened harmony as the poet's nature and the environment are unified' ). This notion of the haiku moment has resonated with haiku writers in English, even though the notion is not widely promoted in Japanese haiku.(See however, 'Shiki's Haiku Moments for Us Today'\n\nIn 1958, \"An Introduction to Haiku: An Anthology of Poems and Poets from Bashô to Shiki\" by Harold G. Henderson was published by Doubleday Anchor Books. This book was a revision of Henderson's earlier book titled \"The Bamboo Broom\" (Houghton Mifflin, 1934). After World War II, Henderson and Blyth worked for the American Occupation in Japan and for the Imperial Household, respectively, and their shared appreciation of haiku helped form a bond between the two.\n\nHenderson translated every hokku and haiku into a rhymed tercet (a-b-a), whereas the Japanese originals never used rhyme. Unlike Yasuda, however, he recognized that 17 syllables in English are generally longer than the 17 \"on\" of a traditional Japanese haiku. Because the normal modes of English poetry depend on accentual meter rather than on syllabics, Henderson chose to emphasize the order of events and images in the originals. Nevertheless, many of Henderson's translations were in the five-seven-five pattern.\n\nThe first haiku written in English was by Ezra Pound, published in 1913. Since then, the haiku has become a fairly popular form among English-speaking poets. English haiku can follow the traditional Japanese rules, but are frequently less strict, particularly concerning the number of syllables and subject matter.\n\nThe loosening of traditional standards has resulted in the term \"haiku\" being applied, perhaps wrongly, to brief English-language poems such as \"mathemaku\" and other kinds of pseudohaiku. Some sources claim that this is justified by the blurring of definitional boundaries in Japan. Rich cross cultural haiku traditions continue to this day, evidenced by books like \"Baseball Haiku: American and Japanese Haiku and Senryu on Baseball\" edited by Cor van den Heuvel and Nanae Tamura (W.W. Norton 2007).\n\nSubsequent to Paul-Louis Couchoud’s popularisation of the form in France through his essays and translations, the next major haiku collection to appear there was the sequence of war poems by , \"Cent visions de guerre\" (1916). Later haiku by him were included among the work of the twelve published together in the \"Nouvelle Revue Française\" (No. 84, September 1920), among whom was the young Paul Éluard. This was followed by the anthology \"Le Haïkaï Français\" in 1923.\n\nIn Spain several prominent poets experimented with haiku, including Joan Alcover, Antonio Machado, Juan Ramón Jiménez and Luis Cernuda. Federico García Lorca also experimented with and learned conciseness from the form while still a student in 1921. The most persistent, however, was Isaac del Vando, whose \"La Sombrilla Japonesa\" (1924) went through several editions. The form was also used in Catalan by the avant-garde writers Josep Maria Junoy (1885-1955) and Joan Salvat-Papasseit, by the latter notably in his sequence \"Vibracions\" (1921).\n\nThe Mexican poet José Juan Tablada is credited with popularising haiku in his country, reinforced by the publication of two collections composed entirely in that form: \"Un dia\" (1919), and \"El jarro de flores\" (1922). In the introduction to the latter, Tablada noted that two young Mexicans, Rafael Lozano and Carlos Gutiérrez Cruz, had also begun writing them. They were followed soon after by Carlos Pellicer, Xavier Villaurrutia, and by Jaime Torres Bodet in his collection \"Biombo\" (1925). Much later, Octavio Paz included many haiku in \"Piedras Sueltas\" (1955).\n\nElsewhere the Ecuadorian poet and diplomat Jorge Carrera Andrade included haiku among the 31 poems contained in \"Microgramas\" (Tokio 1940) and the Argentine Jorge Luis Borges in the collection \"La cifra\" (1981). After several early false starts in Portungese-speaking Brazil, including a collection of 56 by Waldomiro Siqueira Jr. (1912-?) in his \"Haikais\" (São Paulo 1933), the form was popularised by Guilherme de Almeida, first through his 1937 magazine article \"Os Meus Haicais\" and then in his collection \"Poesia Vária\" (1947).\n\nIn 1992 Nobel laureate Czesław Miłosz published the volume \"Haiku\" in which he translated from English to Polish haiku of Japanese masters and American and Canadian contemporary haiku authors.\n\nThe former president of the European Council, Herman Van Rompuy, is a notable \"haijin\" (, haiku poets) and known as \"Haiku Herman.\" He published a book of haiku in April 2010.\n\nIn the early 20th century, Nobel laureate Rabindranath Tagore composed haiku in Bengali. He also translated some from Japanese. In Gujarati, Jhinabhai Desai 'Sneharashmi' popularized haiku and remained a popular haiku writer. In February 2008, the World Haiku Festival was held in Bangalore, gathering \"haijin\" from all over India and Bangladesh, as well as from Europe and the United States. In South Asia, some other poets also write Haiku from time to time, most notably including the Pakistani poet Omer Tarin, who is also active in the movement for global nuclear disarmament and some of his 'Hiroshima Haiku' have been read at various peace conferences in Japan and the UK.\n\n\n", "id": "13217", "title": "Haiku"}
{"url": "https://en.wikipedia.org/wiki?curid=13219", "text": "Howard Hawks\n\nHoward Winchester Hawks (May 30, 1896December 26, 1977) was an American film director, producer and screenwriter of the classic Hollywood era. Critic Leonard Maltin called him \"the greatest American director who is not a household name.\"\n\nHawks was a versatile director whose career included comedies, dramas, gangster films, science fiction, film noir, and westerns. His most popular films include \"Scarface\" (1932), \"Bringing Up Baby\" (1938), \"Only Angels Have Wings\" (1939), \"His Girl Friday\" (1940), \"To Have and Have Not\" (1944), \"The Big Sleep\" (1946), \"Red River\" (1948), \"The Thing from Another World\" (1951), and \"Rio Bravo\" (1959). His frequent portrayals of strong, tough-talking female characters came to define a type—the \"Hawksian woman\".\n\nIn 1942, Hawks was nominated for the Academy Award for Best Director for \"Sergeant York,\" and in 1975 he was awarded an Honorary Academy Award as \"a master American filmmaker whose creative efforts hold a distinguished place in world cinema.\" His work has influenced some of the most popular and respected directors such as Martin Scorsese, Robert Altman, John Carpenter, and Quentin Tarantino.\n\nHoward Winchester Hawks was born in Goshen, Indiana, the first-born child of Frank W. Hawks (1865–1950), a wealthy paper manufacturer, and his wife, Helen (née Howard; 1872–1952), the daughter of a wealthy industrialist. Hawks's family on his father's side were American pioneers and his ancestor John Hawks had emigrated from England to Massachusetts in 1630. The family eventually settled in Goshen and by the 1890s was one of the wealthiest families in the Midwest, due mostly to the highly profitable Goshen Milling Company.\n\nHawks's maternal grandfather, C. W. Howard (1845–1916), had homesteaded in Neenah, Wisconsin in 1862 at age 17. Within 15 years he had made his fortune in the town's paper mill and other industrial endeavors. Frank Hawks and Helen Howard met in the early 1890s and married in 1895. Howard Hawks was the eldest of five children and his birth was followed by Kenneth Neil Hawks (August 12, 1899 – January 2, 1930), William Bellinger Hawks (January 29, 1901 – January 10, 1969), Grace Louise Hawks (October 17, 1903 – December 23, 1927) and Helen Bernice Hawks (1906 – May 4, 1911). In 1898, the family moved to Neenah, Wisconsin where Frank Hawks began working for his father-in-law's Howard Paper Company.\n\nBetween 1906 and 1909, the Hawks family began to spend more time in Pasadena, California during the cold Wisconsin winters in order to improve Helen Hawks's ill health. Gradually they began to spend only their summers in Wisconsin before permanently moving to Pasadena in 1910. The family settled in a house down the street from Throop Polytechnic Institute (which would eventually become California Institute of Technology), and the Hawks children began attending the school's Polytechnic Elementary School in 1907.\n\nHawks was an average student at school and did not excel in sports, but by 1910 had discovered coaster racing, an early form of soapbox racing. In 1911, Hawks's youngest sibling Helen died suddenly of food poisoning. From 1910 to 1912, Hawks attended Pasadena High School. But in 1912, the Hawks family moved to nearby Glendora, California, where Frank Hawks owned orange groves. Hawks finished his junior year of high school at Citrus Union High School in Glendora and was then sent to Phillips Exeter Academy in New Hampshire from 1913 to 1914; his family's wealth may have influenced his acceptance to the elite private school. While in New England, Hawks often attended the theatres in nearby Boston. In 1914, Hawks returned to Glendora and graduated from Pasadena High School that year. That same year, Hawks was accepted to Cornell University in Ithaca, New York, where he majored in mechanical engineering and was a member of Delta Kappa Epsilon. College friend Ray S. Ashbury remembered Hawks spending more of his time playing craps and drinking alcohol than studying, although Hawks was also known to be a voracious reader of popular American and English novels in college.\n\nIn 1916, Hawks' grandfather, C.W. Howard, bought him a Mercer race car and Hawks began racing and working on his new car during the summer vacation in California. It was at this time that Hawks first met Victor Fleming, allegedly when the two men raced on a dirt track and caused an accident. Fleming had been an auto mechanic and early aviator when his old friend Marshall Neilan recommended him to film director Allan Dwan as a good mechanic. Fleming went on to impress Dwan by quickly fixing both his car and a faulty film camera and by 1916 had worked his way up to the position of cinematographer.\n\nThe meeting with Fleming led to Hawks's first job in the film industry, as a prop boy on the Douglas Fairbanks film \"In Again, Out Again\" (on which Fleming was employed as the cinematographer) for Famous Players-Lasky. According to Hawks, a new set needed to be built quickly when the studio's set designer was unavailable, so Hawks volunteered to do the job himself, much to Fairbanks's satisfaction. He was next employed as a prop boy and general assistant on an unspecified film directed by Cecil B. DeMille (Hawks never named the film in later interviews and DeMille made five films roughly in that time period). While still breaking into the film industry in the summer of 1916, Hawks made an unsuccessful attempt to transfer to Stanford University. He returned to Cornell that September, leaving in April 1917 when the United States entered World War I. Like many college students who joined the armed services during the war, he received a degree in absentia in 1918. Before Hawks was called for active duty, he took the opportunity to return to Hollywood and by the end of April 1917 was working on Cecil B. DeMille's \"The Little American\". On this film he met and befriended the then 18-year-old slate boy James Wong Howe, who was to become one of Hollywood's most significant cinematographers. Hawks then worked on the Mary Pickford film \"The Little Princess\", directed by Marshall Neilan. According to Hawks, Neilan did not show up to work one day, so the resourceful Hawks offered to direct a scene himself, to which Pickford consented.\n\nHawks began directing at age 21 after he and cinematographer Charles Rosher filmed a double exposure dream sequence with Mary Pickford. Hawks worked with Pickford and Neilan again on \"Amarilly of Clothes-Line Alley\" before joining the United States Army Air Service. Hawks's military records were destroyed in the 1973 Military Archive Fire, so the only account of his military service is his own. According to Hawks, he spent 15 weeks in basic training at the University of California in Berkeley where he was trained to be a squadron commander. When Pickford visited Hawks at basic training, his superior officers were so impressed by the appearance of the celebrity that they promoted him to flight instructor and sent him to Texas to teach new recruits. Bored by this work, Hawks attempted to secure a transfer during the first half of 1918 and was eventually sent to Fort Monroe, Virginia. The Armistice was signed in November of that year and Hawks was discharged as a Second Lieutenant without having seen active duty.\n\nAfter the War, Hawks was eager to return to Hollywood. His brother, Kenneth Hawks, who had also served in the Air Force, graduated from Yale University in 1919 and the two of them moved to Hollywood together to pursue their careers. They quickly made friends with Hollywood insider (and fellow Ivy Leaguer) Allan Dwan, but Hawks landed his first important job when he used his family's wealth to loan money to studio head Jack L. Warner. Warner quickly paid back the loan and hired Hawks as a producer to \"oversee\" the making of a new series of one-reel comedies starring the Italian comedian Monty Banks. Hawks later stated that he personally directed \"three or four\" of the shorts, though no documentation exists to confirm the claim. The films were profitable, but Hawks soon left to form his own production company, using his family's wealth and connections to secure financing. \"Associated Producers\" was a joint venture between Hawks, Allan Dwan, Marshall Neilan and director Allen Holubar, with a distribution deal with First National. The company made 14 films between 1920 and 1923, with eight directed by Neilan, three by Dwan and three by Holubar. More of a \"boy's club\" than a production company, the four men gradually drifted apart and went their separate ways in 1923, by which time Hawks had decided that he wanted to direct rather than produce.\n\nBeginning in early 1920, Hawks lived in rented houses in Hollywood with the group of friends he was accumulating. This rowdy group of mostly macho, risk-taking men included his brother Kenneth Hawks, Victor Fleming, Jack Conway, Harold Rosson, Richard Rosson, Arthur Rosson and Eddie Sutherland. During this time, Hawks first met Irving Thalberg, the frail and sickly vice-President in charge of production at Metro-Goldwyn-Mayer. Eventually many of the young men in this group would become successful at MGM under Thalberg. Hawks admired his intelligence and sense of story. Hawks also became friends with barn stormers and pioneer aviators at Rogers Airport in Los Angeles, getting to know men like Moye Stephens. In 1923, Famous Players-Lasky president Jesse Lasky was looking for a new Production Editor in the story department of his studio and Thalberg suggested Hawks. Hawks accepted and was immediately put in charge of over forty productions, including several literary acquisitions by Joseph Conrad, Jack London and Zane Grey. Hawks worked on the scripts for all of the films produced, but had his first official screenplay credit in 1924 on \"Tiger Love\". Hawks was the Story Editor at Famous Players (later Paramount Pictures) for almost two years, occasionally editing such films as \"Heritage of the Desert\". Hawks signed a new one-year contract with Famous-Players in the fall of 1924, though he broke his contract to become a story editor for Thalberg at MGM, having secured a promise from Thalberg that he would make him a director within a year. In 1925, when Thalberg hesitated to follow through on his promise, Hawks broke his contract at MGM and left.\n\nIn October 1925, Sol Wurtzel, William Fox's studio superintendent at the Fox Film Corporation, invited Hawks to join his company with the promise of letting Hawks direct. Over the next three years, Hawks directed his first eight films (six silent, two \"talkies\"). A few months after joining Fox, Kenneth Hawks was also hired and eventually became one of Fox's top production supervisors. Hawks reworked the scripts of most of the films he directed without always taking official credit for his work. He also worked on the scripts for \"Honesty – The Best Policy\" in 1926 and Joseph von Sternberg's \"Underworld\" in 1927, famous for being one of the first gangster films. In 1926, Hawks was introduced to Athole Shearer by his friend Victor Fleming, who was dating Athole's sister Norma Shearer at the time. Athole's first marriage to writer John Ward was unhappy. She and Hawks began dating throughout 1927, which led Shearer to ask Ward for a divorce in 1928. Shearer had a young son with Ward named Peter. At the same time, Kenneth Hawks began dating actress Mary Astor, while Hawks's youngest brother Bill began dating actress Bessie Love. Kenneth Hawks and Mary Astor eventually married in February 1928, while Bill Hawks and Bessie Love married in December 1929. After Hawks's mother refused to allow medical treatment because of her Christian Science beliefs, Hawks's sister Grace died of tuberculosis on December 23, 1927. Hawks and Athole Shearer married on May 28, 1928 and they honeymooned in Hawaii. Hawks's contract with Fox ended in May 1929 and he never again signed a long-term contract with a major studio but managed to remain an independent producer-director for the rest of his long career. In October 1929, Hawks and Shearer had their first child, David Hawks.\n\n\"The Road to Glory\" (1926)\n\nHawks's first film \"The Road to Glory\" was based on a 35-page treatment that Hawks wrote and is one of only two Hawks works that are lost films. The film starred May McAvoy as a young woman who is gradually going blind and tries to spare the two men in her life from the burden of her illness. The two men are her boyfriend Rockliffe Fellowes and her father Ford Sterling, with Leslie Fenton playing the greedy rich man whom she agrees to live with in order to get away from her father and lover. The film contained religious iconography and messages that would never again be seen in a Hawks film. It was shot from December 1925 to January 1926 and premiered in April. It received good reviews from film critics. In later interviews, Hawks said, \"It didn't have any fun in it. It was pretty bad. I don't think anybody enjoyed it except a few critics.\" Hawks was dissatisfied with the film after being certain that dramatic films would establish his reputation, but realized what he had done wrong when Sol Wurtzel told Hawks, \"Look, you've shown you can make a picture, but for God's sake, go out and make entertainment.\"\n\n\"Fig Leaves\" (1926)\n\nImmediately after completing \"The Road to Glory\", Hawks began writing his next film, \"Fig Leaves\", his first (and, until 1935, only) comedy. The film portrays a married couple by juxtaposing them in the Garden of Eden and in modern New York City. The Garden of Eden humorously depicts Adam and Eve awoken by a Flintstones-like coconut alarm clock and Adam reading the morning news on giant stone tablets. In the modern day, the biblical serpent is replaced by Eve's gossiping neighbor and Eve becomes a sexy flapper and fashion model when Adam is at work. The film starred George O'Brien as Adam and Olive Borden as Eve and received positive reviews, particularly for the art direction and costume designs. It was released in July 1926 and was Hawks's first hit as a director. Although he mainly dismissed his early work, Hawks praised this film in later interviews.\n\n\"Paid to Love\" (1927)\n\n\"Paid to Love\" is notable in Hawks's filmography as being the only time that he made a highly stylized, experimental film. He attempted to imitate the style of German film director F. W. Murnau, who had recently made \"The Last Laugh\" and \"Sunrise\" and was the most critically acclaimed director in Hollywood. Hawks's film includes atypical tracking shots, expressionistic lighting and stylistic film editing that was inspired by German Expressionist cinema. In a later interview, Hawks commented \"It isn't my type of stuff, at least I got it over in a hurry. You know the idea of wanting the camera to do those things: Now the camera's somebody's eyes.\" Hawks worked on the script with Seton I. Miller, with whom he would go on to collaborate on seven more films. The film stars George O'Brien as the introverted Crown Prince Michael, William Powell as his happy-go-lucky brother and Virginia Valli as Michael's flapper love interest Dolores. The characters played by Valli and O'Brien anticipate those found in later films by Hawks: a sexually aggressive showgirl, who is an early prototype of the \"Hawksian woman\", and a shy man disinterested in sex, found in later roles played by Cary Grant and Gary Cooper. \"Paid to Love\" was completed by September 1926, but remained unreleased until July 1927, when it was financially unsuccessful.\n\n\"Cradle Snatchers\" (1927)\n\n\"Cradle Snatchers\" was based on a 1925 hit stage play by Russell G. Medcraft and Norma Mitchell about three unhappy, middle-aged housewives who teach their adulterous husbands a lesson by starting affairs with college-aged young men during the jazz age. The film starred Louise Fazenda, Dorothy Phillips and Ethel Wales and was shot in early 1927. The film was released in May 1927 and was a minor hit. For many years it was believed to be a lost film until film director Peter Bogdanovich discovered a print in 20th Century Fox's film vaults, although the print was missing part of reel three and all of reel four.\n\n\"Fazil\" (1928)\n\nIn March 1927, Hawks signed a new one-year, three-picture contract with Fox and was assigned to direct \"Fazil\", based on the play \"L'Insoumise\" by Pierre Frondaie. Hawks again worked with Seton Miller on the script about a Middle Eastern prince who has an affair with a Parisienne showgirl and cast Charles Farrell as the prince and Greta Nissen as Fabienne. Hawks went both over schedule and over budget on the film, which began a rift between him and Sol Wurtzel that would eventually lead to Hawks leaving Fox. The film was finished in August 1927, though it was not released until June 1928.\n\n\"A Girl in Every Port\" (1928)\n\"A Girl in Every Port\" is considered by film scholars to be the most important film of Hawks's silent career. It is the first of his films to utilize many of the Hawksian themes and characters that would define much of his subsequent work. It was his first \"love story between two men,\" with two men bonding over their duty, skills and careers, who consider their friendship to be more important than their relationships with women. Hawks wrote the original story and developed the screenplay with James Kevin McGuinness and Seton Miller. In the film Victor McLaglen and Robert Armstrong play two merchant seamen who are archrivals when it comes to women, with McLaglen constantly finding Armstrong's tattoo on the women that he is attempting to seduce. Eventually the two rivals become friends. Louise Brooks plays the cabaret singer with whom the two men fall in love. The film was shot from October to December 1927 and released in February 1928. It was successful in the US, and a hit in Europe where Louise Brooks was developing a cult following. In France, Henri Langlois called Hawks \"the Gropius of the cinema\" and Swiss novelist and poet Blaise Cendrars said that the film \"definitely marked the first appearance of contemporary cinema.\" Hawks went over budget once again with this film, though, and his relationship with Sol Wurtzel deteriorated. After an advance screening that received positive reviews, Wurtzel told Hawks, \"This is the worst picture Fox has made in years.\"\n\n\"The Air Circus\" (1928)\n\n\"The Air Circus\" is Hawks' first film centered around aviation, one of his early passions. In 1928, Charles Lindbergh was the world's most famous person and \"Wings\" was one of the most popular films of the year. Wanting to capitalize on the country's aviation craze, Fox immediately bought Hawks's original story for \"The Air Circus\", a variation of the male friendship plot of \"A Girl in Every Port\" about two young pilots. Officially, the original story is credited to Graham Baker and Andrew Bennison, while the screenplay was written by Seton Miller and Norman Z. McLeod. In the film, Arthur Lake and David Rollins play two eager young pilots at flight school who compete over their flight instructor's aviatrix sister, played by Sue Carol. The film was shot from April to June 1928, but Fox ordered an additional 15 minutes of dialogue footage in order that the film could compete with the new \"talkies\" being released. Hawks hated the new dialogue written by Hugh Herbert and he refused to participate in the re-shoots. The film was released in September 1928 and was a moderate hit. It is one of two films directed by Hawks that are lost films.\n\n\"Trent's Last Case\" (1929)\n\n\"Trent's Last Case\" is an adaptation of British author E. C. Bentley's 1913 novel of the same name, which had already been adapted for cinema in England in 1920. Hawks considered the novel to be \"one of the greatest detective stories of all time\" and was eager to make it his first sound film. He cast Raymond Griffith in the lead role of Phillip Trent. Griffith's throat had been damaged by poison gas during World War I and his voice was a hoarse whisper, prompting Hawks to later state, \"I thought he ought to be great in talking pictures \"because\" of that voice.\" However, after shooting only a few scenes, Fox shut Hawks down and ordered him to make a silent film, both because of Griffith's voice and because they only owned the legal rights to make a silent film. The film did have a musical score and synchronized sound effects, but no dialogue. Due to the failing business of silent films, it was never released in the US and only briefly screened in England where film critics hated it. The film was believed lost until the mid-1970s and was screened for the first time in the US at a Hawks retrospective in 1974. Hawks was in attendance of the screening and attempted to have the only print of the film destroyed.\n\nBy 1930, Hollywood was in upheaval over the coming of \"talkies\" and the careers of many actors and directors were ruined. Hollywood studios were recruiting stage actors and directors that they believed were better suited for sound films. After having worked in the industry for 14 years and directed many financially successful films, Hawks found himself having to prove himself an asset to the studios once again. Leaving Fox on sour terms didn't help his reputation, but Hawks was one of the few people in Hollywood who never backed down from fights with studio heads. After several months of unemployment, Hawks renewed his career with his first sound film in 1930.\n\nOn January 2, 1930, Hawks's brother Kenneth Hawks died while shooting the film \"Such Men Are Dangerous\". Kenneth's career as a director had been gathering momentum after his debut film \"Big Time\" in 1929. This sound film starred Lee Tracy and Mae Clarke and was an early example of the \"fast-talking\" sound films that would later become one of Howard Hawks's signatures. \"Such Men Are Dangerous\" was based on the life Alfred Lowenstein, a Belgian captain who either jumped or fell out of his plane in 1928. On January 2, Kenneth Hawks and his crew flew three aircraft (two with cameras, one with a stunt actor) over Santa Monica Bay when the two camera aircraft crashed into each other, killing 10 men. The crash was the first major on-set accident in Hollywood history and made national news. Mary Astor kept her distance from the Hawks family after Kenneth's death.\n\n\"The Dawn Patrol\" (1930)\nHawks's first all sound film was \"The Dawn Patrol\", based on an original story by John Monk Saunders and (unofficially) Hawks. Saunders was a flight instructor during World War I and had written \"Wings\". He was considered one of the most talented writers in Hollywood and was often compared to F. Scott Fitzgerald and Ernest Hemingway. Accounts vary on who came up with the idea of the film, but Hawks and Saunders developed the story together and tried to sell it to several studios before First National agreed to produce it. Saunders received solo screen credit for the original story and won an Academy Award for Best Story in 1930. The screenplay was written by Hawks, Seton Miller and Dan Totheroh and starred Richard Barthelmess and Douglas Fairbanks, Jr. Shooting began in late February 1930, about the same time that Howard Hughes was finally finishing his epic World War I aviation epic \"Hell's Angels\", which had been in production since September 1927. Shrewdly, Hawks began to hire many of the aviation experts and cameramen that had been employed by Hughes, including Elmer Dyer, Harry Reynolds and Ira Reed. When Hughes found out about the rival film, he did everything he could to sabotage \"The Dawn Patrol\". He harassed Hawks and other studio personal, hired a spy that was quickly caught and finally sued First National for copyright infringement. Hughes eventually dropped the lawsuit in late 1930—he and Hawks had become good friends during the legal battle. In the film, Barthelmess and Fairbanks play two Royal Flying Corps pilots during World War I who deal with the pressure of wartime combat and constant death by drinking and fighting with their commanding officer. Filming was finished in late May 1930 and it premiered in July, setting a first-week box office record at the Winter Garden Theatre in New York. The film became one of the biggest hits of 1930.\n\n\"The Criminal Code\" (1931)\nHawks did not get along with Warner Brothers executive Hal B. Wallis and his contract allowed him to be loaned out to other studios. Hawks took the opportunity to accept a directing offer from Harry Cohn at Columbia Pictures: \"The Criminal Code\", based on a successful play by Martin Flavin. Hawks and Seton Miller worked on the script with Flavin for a month and filming began in September 1930. The film starred Walter Huston, Phillips Holmes, Constance Cummings and Boris Karloff. Huston plays a prison warden who wants to reform the conditions of the inmates and Holmes plays a wrongly convicted prisoner who learns about the \"code\" of not ratting on other inmates. Hawks called Huston \"the greatest actor I ever worked with\". Hawks also worked with his old friend James Wong Howe for the first time as a cinematographer. The film opened in January 1931 and was a hit. The film was banned in Chicago, though, and the experience of censorship which would continue in his next film project.\n\n\"Scarface\" (1932)\n\nIn 1930, Howard Hughes hired Hawks to direct \"Scarface\", a gangster film loosely based on the life of Chicago mobster Al Capone. The film starred Paul Muni in the title role, with memorable supporting performances from George Raft, Boris Karloff, and Osgood Perkins. The film was completed in September 1931, but the censorship of the Hays Code prevented it from being released as Hawks and Hughes had originally intended. The two men fought, negotiated and made compromises with the Hays Office for over a year, until the film was eventually released in 1932, after such other pivotal early gangster films as \"The Public Enemy\" and \"Little Caesar\". \"Scarface\" was the first film in which Hawks worked with screenwriter Ben Hecht, who became a close friend and collaborator for 20 years.\n\n\"The Crowd Roars\" (1932)\n\nAfter filming was complete on \"Scarface\", Hawks left Hughes to fight the legal battles and returned to First National to fulfill his contract, this time with producer Darryl F. Zanuck. For his next film, Hawks wanted to make a film about his childhood passion: car racing. \"The Crowd Roars\" is loosely based on the play \"The Barker: A Play of Carnival Life\" by Kenyon Nicholson. Hawks developed the script with Seton Miller for their eighth and final collaboration and the script was by Miller, Kubec Glasmon, John Bright and Niven Busch. The film starred James Cagney, Eric Linden, Joan Blondell and Ann Dvorak. In the film, Cagney plays a race car driver who tries to \"protect\" his younger brother Linden, who is also a driver, from being distracted by his girlfriend, Blondell. At the same time, Cagney must hide his own neurotic girlfriend, played by Dvorak, from his younger brother. Blondell and Dvorak were initially cast in each other's roles but swapped after a few days of shooting. Shooting began on December 7, 1931 at Legion Ascot Speedway and wrapped on February 1, 1932. Hawks used real race car drivers in the film, including the 1930 Indianapolis 500 winner Billy Arnold. The film was released in March and became a hit.\n\n\"Tiger Shark\" (1932)\n\nLater in 1932, he directed \"Tiger Shark\" starring Edward G. Robinson as a tuna fisherman. In these early films, Hawks established the prototypical \"Hawksian Man\", which film critic Andrew Sarris described as \"upheld by an instinctive professionalism.\" \"Tiger Shark\" demonstrated Hawks's ability to incorporate touches of humor into dramatic, tense, and even tragic story lines.\n\n\"Today We Live\" (1933)\nIn 1933, Hawks signed a three-picture deal at Metro-Goldwyn-Mayer Studios, the first of which was \"Today We Live\" in 1933, starring Joan Crawford and Gary Cooper. This World War I film was based on a short story by author William Faulkner, with whom Hawks would remain friends for over 20 years.\n\nHawks's next two films at MGM were the boxing drama \"The Prizefighter and the Lady\" and the bio-pic \"Viva Villa!\", starring Wallace Beery as Mexican Revolutionary leader Pancho Villa. Studio interference on both films led Hawks to walk out on his MGM contract without completing either film himself.\n\nIn 1934, Hawks went to Columbia Pictures to make his first screwball comedy, \"Twentieth Century\", starring John Barrymore and Hawks's distant cousin Carole Lombard. It was based on a stage play by Ben Hecht and Charles MacArthur and, along with Frank Capra's \"It Happened One Night\" (released the same year), is considered to be the defining film of the screwball comedy genre. In 1935, Hawks made \"Barbary Coast\" with Edward G. Robinson and Miriam Hopkins. In 1936, he made the aviation adventure \"Ceiling Zero\" with James Cagney and Pat O'Brien. Also in 1936, Hawks began filming \"Come and Get It\", starring Edward Arnold, Joel McCrea, Frances Farmer and Walter Brennan. But he was fired by Samuel Goldwyn in the middle of shooting and the film was completed by William Wyler.\n\nIn 1938, Hawks made the screwball comedy \"Bringing Up Baby\" for RKO Pictures. It starred Cary Grant and Katharine Hepburn and has been called \"the screwiest of the screwball comedies\" by film critic Andrew Sarris. Grant plays a near-sighted paleontologist who suffers one humiliation after another due to the lovestruck socialite played by Hepburn. \"Bringing Up Baby\" was a box office flop when initially released and, subsequently, RKO fired Hawks due to extreme losses; however, the film has become regarded as one of Hawks's masterpieces. Hawks followed this with the aviation drama \"Only Angels Have Wings\", again starring Cary Grant and made in 1939 for Columbia Pictures. It also starred Jean Arthur, Thomas Mitchell, Rita Hayworth and Richard Barthelmess.\n\nIn 1940, Hawks returned to the screwball comedy genre with \"His Girl Friday\", starring Cary Grant and Rosalind Russell. The film was an adaptation of the hit Broadway play \"The Front Page\" by Ben Hecht and Charles MacArthur, which had already been made into a film in 1931 and had also been reworked by the same screenwriters and transplanted to Rudyard Kipling's India for \"Gunga Din\" in 1939. In 1941, Hawks made \"Sergeant York\", starring Gary Cooper as a pacifist farmer who becomes a decorated World War I soldier. This was the highest-grossing film of 1941 and won two Academy Awards (Best Actor and Best Editing), as well as earning Hawks his only nomination for Best Director. Later that year, Hawks worked with Cooper again for \"Ball of Fire\", which also starred Barbara Stanwyck. The film was written by Billy Wilder and Charles Brackett and is a playful take on \"Snow White and the Seven Dwarfs\". Cooper plays a sheltered, intellectual linguist who is writing an encyclopedia with six other scientists, and hires street-wise Stanwyck to help them with modern slang terms. In 1941, Hawks began work on the Howard Hughes-produced (and later directed) film \"The Outlaw\", based on the life of Billy the Kid and starring Jane Russell. Hawks completed initial shooting of the film in early 1941, but due to perfectionism and battles with the Hollywood Production Code, Hughes continued to re-shoot and re-edit the film until 1943, when it was finally released with Hawks uncredited as director.\n\nAfter making the World War II film \"Air Force\" in 1943 starring John Garfield, Hawks did two films with real-life lovers Humphrey Bogart and Lauren Bacall. \"To Have and Have Not\", made in 1944, stars Bogart, Bacall and Walter Brennan and is based on a novel by Ernest Hemingway. Hawks was a close friend of Hemingway and made a bet with the author that he could make a good film out of Hemingway's \"worst book.\" Hawks, William Faulkner and Jules Furthman collaborated on the script about an American fishing boat captain working out of French Martinique in the Caribbean and various situations of espionage after the Fall of France in 1940. Bogart and Bacall fell in love on the set of the film and married soon afterwards. Hawks reteamed with the newlyweds in 1946 with \"The Big Sleep\", based on the Philip Marlowe detective novel by Raymond Chandler.\n\nIn 1948, Hawks made \"Red River\", an epic western reminiscent of \"Mutiny on the Bounty\" starring John Wayne and Montgomery Clift in his first film. Later that year, Hawks remade his earlier film \"Ball of Fire\" as \"A Song Is Born\", this time starring Danny Kaye and Virginia Mayo. This version follows the same plot but pays more attention to popular jazz music and includes such jazz legends as Tommy Dorsey, Benny Goodman, Louis Armstrong, Lionel Hampton, and Benny Carter playing themselves. In 1949, Hawks reteamed with Cary Grant in the screwball comedy \"I Was a Male War Bride\", also starring Ann Sheridan.\nIn 1951, Hawks produced, and some believe essentially directed, a science-fiction film, \"The Thing from Another World\". Director John Carpenter stated: \"And let's get the record straight. The movie was directed by Howard Hawks. Verifiably directed by Howard Hawks. He let his editor, Christian Nyby, take credit. But the kind of feeling between the male characters—the camaraderie, the group of men that has to fight off the evil—it's all pure Hawksian.\" He followed this with the 1952 western film \"The Big Sky\", starring Kirk Douglas. Later in 1952, Hawks work with Cary Grant for the fifth and final time in the screwball comedy \"Monkey Business\", which also starred Marilyn Monroe and Ginger Rogers. Grant plays a scientist (reminiscent of his character in \"Bringing up Baby\") who creates a formula that increases his vitality. Film critic John Belton called the film Hawks's \"most organic comedy.\" Hawks's third film of 1952 was a contribution to the omnibus film \"O. Henry's Full House\", which includes short stories by the writer O. Henry made by various directors. Hawks's short film \"The Ransom of Red Chief\" starred Fred Allen, Oscar Levant and Jeanne Crain.\n\nIn 1953, Hawks made \"Gentlemen Prefer Blondes\", which featured Marilyn Monroe famously singing \"Diamonds Are a Girl's Best Friend.\" The film starred Monroe and Jane Russell as two gold-digging, cabaret-performer best friends that many critics argue is the only female version of his celebrated \"buddy film\" genre that he made. In 1955, Hawks shot a film atypical within the context of his other work, \"Land of the Pharaohs\", which is a sword-and-sandal epic about ancient Egypt that stars Jack Hawkins and Joan Collins. The film was Hawks's final collaboration with longtime friend William Faulkner before the author's death. In 1959, Hawks worked with John Wayne in \"Rio Bravo\", also starring Dean Martin, Ricky Nelson and Walter Brennan as four lawmen \"defending the fort\" of their local jail in which a local criminal is awaiting a trial while his family attempt to break him out. Film critic Robin Wood has said that if he \"were asked to choose a film that would justify the existence of Hollywood ... it would be \"Rio Bravo\".\"\n\nIn 1962, Hawks made \"Hatari!\", again with John Wayne, who plays a big-game hunter in Africa. In 1964, Hawks made his final comedy, \"Man's Favorite Sport?\", starring Rock Hudson (since Cary Grant felt he was too old for the role) and Paula Prentiss. Hawks then returned to his childhood passion for car races with \"Red Line 7000\" in 1965, featuring a young James Caan in his first leading role. Hawks's final two films were both Western remakes of \"Rio Bravo\" starring John Wayne. In 1966, Hawks directed \"El Dorado\", starring Wayne, Robert Mitchum and Caan, which was released the following year. He then made \"Rio Lobo\", with Wayne in 1970.\n\nHawks was married three times: to actress Athole Shearer, sister of Norma Shearer, from 1928–40; to socialite Slim Keith from 1941–49; and to actress Dee Hartford from 1953–60.\n\nHawks died on December 26, 1977, at the age of 81, from complications arising from a fall when he tripped over his dog several weeks earlier at his home in Palm Springs, California. He was working with his last protege discovery at the time, Larraine Zax.\n\nHawks was a versatile director whose career includes comedies, dramas, gangster films, science fiction, film noir, and Westerns. Hawks's own functional definition of what constitutes a \"good movie\" is characteristic of his no-nonsense style: \"Three great scenes, no bad ones.\" Hawks also defined a good director as \"someone who doesn't annoy you.\"\n\nWhile Hawks was not sympathetic to feminism, he popularized the Hawksian woman archetype, which, according to Naomi Wise, has been cited as a prototype of the post-feminist movement.\n\nOrson Welles in an interview with Peter Bogdanovich said of Howard Hawks, in comparison with John Ford, that \"Hawks is great prose; Ford is poetry.\"\n\nDespite Hawks's work in a variety of Hollywood genres, he still retained an independent sensibility. Film critic David Thomson wrote of Hawks: \"Far from being the meek purveyor of Hollywood forms, he always chose to turn them upside down. \"To Have and Have Not\" and \"The Big Sleep\", ostensibly an adventure and a thriller, are really love stories. \"Rio Bravo\", apparently a Western – everyone wears a cowboy hat – is a comedy conversation piece. The ostensible comedies are shot through with exposed emotions, with the subtlest views of the sex war, and with a wry acknowledgment of the incompatibility of men and women.\" David Boxwell argues that the filmmaker's body of work \"has been accused of a historical and adolescent escapism, but Hawks' fans rejoice in his oeuvre's remarkable avoidance of Hollywood's religiosity, bathos, flag-waving, and sentimentality.\n\nHawks's directorial style and the use of natural, conversational dialogue in his films are cited as major influences on many noted filmmakers, including Robert Altman, John Carpenter, and Quentin Tarantino. His work is also admired by many notable directors including Peter Bogdanovich, Martin Scorsese, François Truffaut, Michael Mann and Jacques Rivette. Jean-Luc Godard called him \"the greatest American artist.\" Critic Leonard Maltin labeled Hawks \"the greatest American director who is not a household name.\" Andrew Sarris in his influential book of film criticism \"The American Cinema: Directors and Directions 1929–1968\" included Hawks in the \"pantheon\" of the 14 greatest film directors who had worked in the United States. Brian De Palma dedicated his version of \"Scarface\" to Hawks and Ben Hecht. Hawks was nicknamed \"The Gray Fox\" by members of the Hollywood community, thanks to his prematurely gray hair.\n\nHawks was venerated by French critics associated with \"Cahiers du cinéma\", who intellectualized his work in a way that Hawks himself found moderately amusing (his work was promoted in France by The Studio des Ursulines cinema), and though he was not taken seriously by British critics of the \"Sight and Sound\" circle at first, other independent British writers, such as Robin Wood, admired his films. Wood named the Hawks's \"Rio Bravo\" as his top film of all time.\n\nIn the 2012 Sight & Sound's \"Greatest Film Poll\", six of the films that Hawks had directed were in the Critics' Top 250 Films: \"Rio Bravo\" (number 63), \"Bringing Up Baby\" (number 110), \"Only Angels Have Wings\" (number 154), \"His Girl Friday\" (number 171), \"The Big Sleep\" (number 202) and \"Red River\" (number 235)\n\nHe was nominated for Academy Award for Best Director in 1942 for \"Sergeant York\", but he received his only Oscar in 1975 as an Honorary Award from the Academy.\n\nHis films \"The Big Sleep\", \"Bringing Up Baby\", \"His Girl Friday\", \"Red River\", \"Rio Bravo\", \"Scarface\", \"Sergeant York\", \"The Thing from Another World\" and \"Twentieth Century\" were rated \"culturally significant\" by the United States Library of Congress and inducted into the National Film Registry.\n\n\"Bringing Up Baby\" (1938) was listed number 97 on the American Film Institute's AFI's 100 Years...100 Movies. On the AFI's AFI's 100 Years...100 Laughs \"Bringing Up Baby\" was listed number 14, \"His Girl Friday\" (1940) was listed number 19 and \"Ball of Fire\" (1941) was listed number 92.\n\nFor his contribution to the motion picture industry, Howard Hawks has a star on the Hollywood Walk of Fame at 1708 Vine Street.\n\n", "id": "13219", "title": "Howard Hawks"}
{"url": "https://en.wikipedia.org/wiki?curid=13224", "text": "History of Germany\n\nThe concept of Germany as a distinct region in central Europe can be traced to Roman commander Julius Caesar, who referred to the unconquered area east of the Rhine as \"Germania\", thus distinguishing it from Gaul (France), which he had conquered. The victory of the Germanic tribes in the Battle of the Teutoburg Forest (AD 9) prevented annexation by the Roman Empire, although the Roman provinces of Germania Superior and Germania Inferior were established along the Rhine. Following the Fall of the Western Roman Empire, the Franks conquered the other West Germanic tribes. When the Frankish Empire was divided among Charlemagne's heirs in 843, the eastern part became East Francia. In 962, Otto I became the first emperor of the Holy Roman Empire, the medieval German state.\n\nIn the High Middle Ages, the regional dukes, princes and bishops gained power at the expense of the emperors. Martin Luther led the Protestant Reformation against the Catholic Church after 1517, as the northern states became Protestant, while the southern states remained Catholic. The two parts of the Holy Roman Empire clashed in the Thirty Years' War (1618–1648), which was ruinous to the twenty million civilians living in both states. The Thirty Years' War brought tremendous destruction to Germany, more than 1/4 of the population and 1/2 of the male population in the German states were killed by the catastrophic war. 1648 marked the effective end of the Holy Roman Empire and the beginning of the modern nation-state system, with Germany divided into numerous independent states, such as Prussia, Bavaria and Saxony.\n\nAfter the French Revolution and the Napoleonic Wars (1803–1815), feudalism fell away and liberalism and nationalism clashed with reaction. The 1848 March Revolution failed. The Industrial Revolution modernized the German economy, led to the rapid growth of cities and to the emergence of the Socialist movement in Germany. Prussia, with its capital Berlin, grew in power. German universities became world-class centers for science and the humanities, while music and the arts flourished. Unification was achieved with the formation of the German Empire in 1871 under the leadership of Prussian Chancellor Otto von Bismarck. The new \"Reichstag\", an elected parliament, had only a limited role in the imperial government. Germany joined the other powers in colonial expansion in Africa and the Pacific.\n\nGermany was the dominant power on the continent. By 1900, its rapidly expanding industrial economy passed Britain's, allowing a naval race and an aggressive foreign policy. Germany led the Central Powers in World War I (1914–1918) against France, Great Britain, Russia and (by 1917) the United States. Defeated and partly occupied, Germany was forced to pay war reparations by the Treaty of Versailles and was stripped of its colonies as well as Polish areas and Alsace-Lorraine. The German Revolution of 1918–19 deposed the emperor and the various kings and princes, leading to the establishment of the Weimar Republic, an unstable parliamentary democracy.\n\nIn the early 1930s, the worldwide Great Depression hit Germany hard, as unemployment soared and people lost confidence in the government. In 1933, the Nazis under Adolf Hitler came to power and established a totalitarian regime. Political opponents were killed or imprisoned. Nazi Germany's aggressive foreign policy took control of Austria and parts of Czechoslovakia, and its invasion of Poland initiated the Second World War. After forming a pact with the Soviet Union in 1939, Hitler and Stalin divided Eastern Europe. After a \"Phoney War\" in spring 1940 the German blitzkrieg swept Scandinavia, the Low Countries and France, giving Germany control of nearly all of Western Europe. Only the British Commonwealth and Empire stood opposed, along with Greece. Hitler invaded the Soviet Union in June 1941. In Germany, but predominantly in the German-occupied areas, the systematic genocide program known as The Holocaust killed six million Jews, as well as five million Poles, Romanies, Russians, Soviets (Russian and non-Russian), and others. In 1942, the German invasion of the Soviet Union faltered, and after the United States had entered the war, Britain became the base for massive Anglo-American bombings of German cities. Germany fought the war on multiple fronts through 1942–1944, however following the Allied invasion of Normandy (June 1944), the German army was pushed back on all fronts until the final collapse in May 1945.\n\nUnder occupation by the Allies, German territories were split up, denazification took place, and the Cold War resulted in the division of the country into democratic West Germany and communist East Germany. Millions of ethnic Germans fled from Communist areas into West Germany, which experienced rapid economic expansion, and became the dominant economy in Western Europe. West Germany was rearmed in the 1950s under the auspices of NATO, but without access to nuclear weapons. The Franco-German friendship became the basis for the political integration of Western Europe in the European Union. In 1989, the Berlin Wall was destroyed, the Soviet Union collapsed and East Germany was reunited with West Germany in 1990. In 1998–1999, Germany was one of the founding countries of the eurozone. Germany remains one of the economic powerhouses of Europe, contributing about one quarter of the eurozone's annual gross domestic product. In the early 2010s, Germany played a critical role in trying to resolve the escalating euro crisis, especially with regard to Greece and other Southern European nations. In the middle of the decade, the country faced the European migrant crisis, as the main receiver of asylum seekers from Syria and other troubled regions.\n\n\"For more events, see Timeline of German history\"\n\nThe discovery of the Mauer 1 mandible in 1907 shows that ancient humans were present in Germany at least 600,000 years ago. The oldest complete hunting weapons ever found anywhere in the world were discovered in a coal mine in Schoningen, Germany in 1995 where three 380,000-year-old wooden javelins 6-7.5 feet (1.8-2.3 meter) long were unearthed. The Neander valley in Germany was the location where the first ever non-modern human fossil was discovered and recognised in 1856; the new species of human was named Neanderthal man. The Neanderthal 1 fossils are now known to be 40,000 years old. At a similar age, evidence of modern humans has been found in caves in the Swabian Jura near Ulm. The finds include 42,000-year-old bird bone and mammoth ivory flutes which are the oldest musical instruments ever found, the 40,000-year-old Ice Age Löwenmensch figurine which is the oldest uncontested figurative art ever discovered, and the 35,000-year-old Venus of Hohle Fels which is the oldest uncontested human figurative art ever discovered.\n\nThe ethnogenesis of the Germanic tribes is assumed to have occurred during the Nordic Bronze Age, or at the latest during the Pre-Roman Iron Age. From their homes in southern Scandinavia and northern Germany the tribes began expanding south, east and west in the 1st century BC,\ncoming into contact with the Celtic tribes of Gaul, as well as with Iranian,\nBaltic,\nand Slavic\ncultures in Central/Eastern Europe.\n\nResearchers know few details of early Germanic activity, except through the tribes' recorded interactions with the Roman Empire, through etymological research and from archaeological finds.\n\nIn the first years of the 1st century AD Roman legions conducted a long campaign in Germania, the area north of the Upper Danube and east of the Rhine, in an attempt to expand the Empire's frontiers and to shorten its frontier line. Rome subdued several Germanic tribes, such as the Cherusci. The tribes became familiar with Roman tactics of warfare while maintaining their tribal identity. In 9 AD a Cherusci chieftain known to the Romans as Arminius defeated a Roman army in the Battle of the Teutoburg Forest, a victory credited with stopping the Roman advance into Germanic territories and marking the beginning of recorded German history. That part of the territory of modern Germany that lay east of the Rhine remained outside the Roman Empire. By AD 100, the time of Tacitus's \"Germania\", Germanic tribes had settled along the Roman frontier along the Rhine and the Danube (the \"Limes Germanicus\"), occupying most of the area of modern Germany; however, imperial Rome organised territory later included in the modern states of Austria, Baden-Württemberg, southern Bavaria, southern Hesse, Saarland and the Rhineland as Roman provinces (Noricum,\nRaetia\nand Germania). The Roman provinces in western Germany, Germania Inferior (with the capital situated at Colonia Claudia Ara Agrippinensium, modern Cologne) and Germania Superior (with its capital at Mogontiacum, modern Mainz), were formally established in 85 AD, after a long period of military occupation beginning in the reign of the Roman emperor Augustus (27 BC - 14 AD).\n\nThe 3rd century saw the emergence of a number of large West Germanic tribes: the Alamanni, Franks, Bavarii, Chatti, Saxons, Frisii, Sicambri, and Thuringii. Around 260 the Germanic peoples broke through the \"limes\" and the Danube frontier into Roman-controlled lands.\n\nSeven large German-speaking tribes – the Visigoths, Ostrogoths, Vandals, Burgundians, Lombards, Saxons and Franks – moved west and witnessed the decline of the Roman Empire and the transformation of the old Western Roman Empire.\n\nChristianity was spread to western Germany during the Roman era, and Christian religious structures such as the Aula Palatina of Trier were built during the reign of Constantine I (r. (306-337 AD). At the end of the 4th century the Huns invaded the unoccupied part of present-day Germany and the Migration Period began. Hunnic hegemony over Germania lasted until the death of Attila's son Dengizich in 469.\n\nStem duchies (tribal duchies) in Germany originated as the areas of the Germanic tribes of a given region. The concept of such duchies survived especially in the areas which in the mid-9th century would become part of East Francia\nrather than further west in Middle Francia (for example: Burgundy,\nLorraine).\n\nIn the 5th century, the \"Völkerwanderung\" (or Germanic migrations) brought a number of \"barbarian\" tribes into the failing Roman Empire. Tribes that became stem duchies were originally the Alamanni, the Thuringii, the Saxons, the Franks, the Burgundians, and the Rugii.\nIn contrast to later duchies, these entities did not have strictly delineated administrative boundaries, but approximated the area of settlement of major Germanic tribes. Over the next few centuries, some tribes warred, migrated, and merged. Eventually the Franks subjugated all these tribes in Germania.\nHowever, remnants of several stem duchies survive today as states or regions in modern Western Europe countries: German states such as Bavaria and Saxony, German regions like Swabia, and French \"région\"s such as of Burgundy/Franche-Comté and Lorraine.\n\nIn the east, successive rulers of the German lands founded a series of border counties or marches. To the north, these included Lusatia, the North March (which would become Brandenburg and the heart of the future Prussia), and the Billung March. In the south, the marches included Carniola, Styria, and the March of Austria that would become Austria.\n\nAfter the fall of the Western Roman Empire in the 5th century, the Franks under the Merovingian kings built their own empire, subjugating neighboring peoples - notably other Germanic tribes. The Merovingian kings of the Germanic Franks conquered northern Gaul in 486 AD. Swabia became a duchy under the Frankish Empire in 496, following the Battle of Tolbiac; in 530 Saxons and Franks destroyed the Kingdom of Thuringia. In the 5th and 6th centuries the Merovingian kings conquered several other Germanic tribes and kingdoms. King Chlothar I (reigned 558–561) ruled the greater part of what is now Germany and made expeditions into Saxony, while the Southeast of modern Germany remained under the influence of the Ostrogoths. Saxons inhabited the area down to the Unstrut River.\n\nThe Merovingians placed the various regions of their Frankish Empire under the control of semi-autonomous dukes - Franks or local rulers.\nFrankish colonists were encouraged to move to the newly conquered territories.\nWhile allowed to preserve their own laws,\nthe local Germanic tribes faced pressure to adopt non-Arian Christianity.\n\nThe territories which would later become parts of modern Germany came under the region of Austrasia (meaning \"eastern land\"), the northeastern portion of the Kingdom of the Merovingian Franks. As a whole, Austrasia comprised parts of present-day France, Germany, Belgium, Luxembourg and the Netherlands. After the death of the Frankish king Clovis I in 511, his four sons partitioned his kingdom including Austrasia. Authority over Austrasia passed back and forth from autonomy to royal subjugation, as successive Merovingian kings alternately united and subdivided the Frankish lands.\n\nIn 718 Charles Martel, the Frankish Mayor of the Palace, made war against Saxony because of its help for the Neustrians. His son Carloman started a new war against Saxony in 743, because the Saxons gave aid to Duke Odilo of Bavaria.\n\nIn 751 Pippin III, Mayor of the Palace under the Merovingian king, himself assumed the title of king and was anointed by the Church. Now the Frankish kings were set up as protectors of the pope, and Charles the Great (who ruled the Franks from 774 to 814) launched a decades-long military campaign against the Franks' heathen rivals, the Saxons and the Avars. The campaigns and insurrections of the Saxon Wars lasted from 772 to 804. The Franks eventually overwhelmed the Saxons and Avars, forcibly converted the people to Christianity, and annexed their lands to the Carolingian Empire.\n\nAfter the death of Frankish king Pepin the Short in 768 AD, his son Charles consolidated his control over his kingdom and became known as \"Charles the Great\" or \"Charlemagne.\" From 771 until his death in 814, Charlemagne extended the Carolingian empire into northern Italy and the territories of all west Germanic peoples, including the Saxons and the Baiuvarii (Bavarians). In 800, Charlemagne's authority was confirmed by his coronation as emperor by the pope on Christmas Day in Rome. Imperial strongholds (\"Kaiserpfalzen\") became economic and cultural centres, of which Aachen was the most famous.\n\nFighting among Charlemagne's grandchildren caused the Carolingian empire to be partitioned into several parts by the Treaty of Verdun (843), the Treaty of Meerssen (870), and the Treaty of Ribemont. The German region developed out of the East Frankish kingdom, East Francia. From 919 to 936, the Germanic peoples – Franks, Saxons, Swabians, and Bavarians – were united under Henry the Fowler, Duke of Saxony, who took the title of king. For the first time, the term \"Kingdom (Empire) of the Germans\" (\"Regnum Teutonicorum\") was applied to a Frankish kingdom, although \"Teutonicorum\" at its founding originally meant something closer to \"Realm of the Germanic peoples\" or \"Germanic Realm\" than \"realm of the Germans\".\n\nIn 936, Otto I the Great was crowned as king at Aachen; his coronation as emperor by the Pope at Rome in 962 inaugurated what became later known as the Holy Roman Empire, which came to be identified with Germany. Otto strengthened the royal authority by re-asserting the old Carolingian rights over ecclesiastical appointments. Otto wrested from the nobles the powers of appointment of the bishops and abbots, who controlled large land holdings. Additionally, Otto revived the old Carolingian program of appointing missionaries in the border lands. Otto continued to support celibacy for the higher clergy, so ecclesiastical appointments never became hereditary. By granting land to the abbotts and bishops he appointed, Otto actually made these bishops into \"princes of the Empire\" (\"Reichsfürsten\"); in this way, Otto was able to establish a national church. Outside threats to the kingdom were contained with the decisive defeat of the Hungarian Magyars at the Battle of Lechfeld in 955. The Slavs between the Elbe and the Oder rivers were also subjugated. Otto marched on Rome and drove John XII from the papal throne and for years controlled the election of the pope, setting a firm precedent for imperial control of the papacy for years to come.\n\nDuring the reign of Conrad II's son, Henry III (1039 to 1056), the empire supported the Cluniac reforms of the Church, the Peace of God, prohibition of simony (the purchase of clerical offices), and required celibacy of priests. Imperial authority over the Pope reached its peak. In the Investiture Controversy which began between Henry IV and Pope Gregory VII over appointments to ecclesiastical offices, the emperor was compelled to submit to the Pope at Canossa in 1077, after having been excommunicated. In 1122 a temporary reconciliation was reached between Henry V and the Pope with the Concordat of Worms. The consequences of the investiture dispute were a weakening of the Ottonian church (\"Reichskirche\"), and a strengthening of the Imperial secular princes.\n\nThe time between 1096 and 1291 was the age of the crusades. Knightly religious orders were established, including the Knights Templar, the Knights of St John (Knights Hospitaller), and the Teutonic Order.\n\nThe term \"sacrum imperium\" (Holy Empire) was first used under Friedrich I, documented first in 1157.\n\nLong-distance trade in the Baltic intensified, as the major trading towns became drawn together in the Hanseatic League, under the leadership of Lübeck. The Hanseatic League was a business alliance of trading cities and their guilds that dominated trade along the coast of Northern Europe. Each of the Hanseatic cities had its own legal system and a degree of political autonomy. The chief cities were Cologne on the Rhine River, Hamburg and Bremen on the North Sea, and Lübeck on the Baltic. The League flourished from 1200 to 1500, and continued with lesser importance after that.\n\nThe German colonisation and the chartering of new towns and villages began into largely Slav-inhabited territories east of the Elbe, such as Bohemia, Silesia, Pomerania, and Livonia. Beginning in 1226, the Teutonic Knights began their conquest of Prussia. The native Baltic Prussians were conquered and Christianized by the Knights with much warfare, and numerous German towns were established along the eastern shore of the Baltic Sea.\n\nHenry V (1086–1125), great-grandson of Conrad II, became Holy Roman Emperor in 1106 in the midst of a civil war. Hoping to gain complete control over the church inside the Empire, Henry V appointed Adalbert of Saarbrücken as the powerful archbishop of Mainz in 1111. Adalbert began to assert the powers of the Church against secular authorities, that is, the Emperor. This precipitated the \"Crisis of 1111\", part of the long-term Investiture Controversy. In 1137 the magnates turned back to the Hohenstaufen family for a candidate, Conrad III. Conrad III tried to divest Henry the Proud of his two duchies – Bavaria and Saxony – leading to war in southern Germany as the Empire divided into two factions. The first faction called themselves the \"Welfs\" or \"Guelphs\" after Henry the Proud's family, which was the ruling dynasty in Bavaria; the other faction was known as the \"Waiblings.\" In this early period, the Welfs generally represented ecclesiastical independence under the papacy plus \"particularism\" (a strengthening of the local duchies against the central imperial authority). The Waiblings, on the other hand, stood for control of the Church by a strong central Imperial government.\n\nBetween 1152 and 1190, during the reign of Frederick I (Barbarossa), of the Hohenstaufen dynasty, an accommodation was reached with the rival Guelph party by the grant of the duchy of Bavaria to Henry the Lion, duke of Saxony. Austria became a separate duchy by virtue of the Privilegium Minus in 1156. Barbarossa tried to reassert his control over Italy. In 1177 a final reconciliation was reached between the emperor and the Pope in Venice.\n\nIn 1180, Henry the Lion was outlawed; Saxony was divided, and Bavaria was given to Otto of Wittelsbach. (Otto founded the Wittelsbach dynasty, which was to rule Bavaria until 1918.)\n\nFrom 1184 to 1186, the Hohenstaufen empire under Frederick I Barbarossa reached its peak in the \"Reichsfest\" (imperial celebrations) held at Mainz and the marriage of his son Henry in Milan to the Norman princess Constance of Sicily. The power of the feudal lords was undermined by the appointment of \"ministerials\" (unfree servants of the Emperor) as officials. Chivalry and the court life flowered, leading to a development of German culture and literature (see Wolfram von Eschenbach).\n\nBetween 1212 and 1250, Frederick II established a modern, professionally administered state from his base in Sicily. He resumed the conquest of Italy, leading to further conflict with the Papacy. In the Empire, extensive sovereign powers were granted to ecclesiastical and secular princes, leading to the rise of independent territorial states. The struggle with the Pope sapped the Empire's strength, as Frederick II was excommunicated three times. After his death, the Hohenstaufen dynasty fell, followed by an interregnum during which there was no Emperor.\n\nThe failure of negotiations between Emperor Louis IV and the papacy led in 1338 to the declaration at Rhense by six electors to the effect that election by all or the majority of the electors automatically conferred the royal title and rule over the empire, without papal confirmation. As result, the monarch was no longer subject to papal approbation and became increasingly dependent on the favour of the electors. Between 1346 and 1378 Emperor Charles IV of Luxembourg, king of Bohemia, sought to restore the imperial authority. The Golden Bull of 1356 stipulated that in future the emperor was to be chosen by four secular electors and three spiritual electors. The secular electors were the King of Bohemia, the Count Palatine of the Rhine, the Duke of Saxony, and the Margrave of Brandenburg; the three spiritual electors were the Archbishops of Mainz, Trier, and Cologne.\n\nAround 1350 Germany and almost the whole of Europe were ravaged by the Black Death. Jews were persecuted on religious and economic grounds; many fled to Poland. The Black Death is estimated to have killed 30–60 percent of Europe's population[3] in the 14th century.\n\nAfter the disasters of the 14th century – war, plague, and schism – early-modern European society gradually came into being as a result of economic, religious, and political changes. A money economy arose which provoked social discontent among knights and peasants. Gradually, a proto-capitalistic system evolved out of feudalism. The Fugger family gained prominence through commercial and financial activities and became financiers to both ecclesiastical and secular rulers. The knightly classes found their monopoly on arms and military skill undermined by the introduction of mercenary armies and foot soldiers. Predatory activity by \"robber knights\" became common.\n\nFrom 1438 the Habsburgs, who controlled most of the southeast of the Empire (more or less modern-day Austria and Slovenia, and Bohemia and Moravia after the death of King Louis II in 1526), maintained a constant grip on the position of the Holy Roman Emperor until 1806 (with the exception of the years between 1742 and 1745). This situation, however, gave rise to increased disunity among the Holy Roman Empire's territorial rulers and prevented sections of the country from coming together to form nations in the manner of France and England.\n\nDuring his reign from 1493 to 1519, Maximilian I tried to reform the Empire. An Imperial supreme court (\"Reichskammergericht\") was established, imperial taxes were levied, and the power of the Imperial Diet (\"Reichstag\") was increased. The reforms, however, were frustrated by the continued territorial fragmentation of the Empire.\n\nThe German lands had a population of about 5 or 6 million. The great majority were farmers, typically in a state of serfdom under the control of nobles and monasteries. A few towns were starting to emerge. From 1100, new towns were founded around imperial strongholds, castles, bishops' palaces, and monasteries. The towns began to establish municipal rights and liberties (see German town law). Several cities such as Cologne became Imperial Free Cities, which did not depend on princes or bishops, but were immediately subject to the Emperor. The towns were ruled by patricians: merchants carrying on long-distance trade. Craftsmen formed guilds, governed by strict rules, which sought to obtain control of the towns; a few were open to women. Society was divided into sharply demarcated classes: the clergy, physicians, merchants, various guilds of artisans, and peasants; full citizenship was not available to paupers. Political tensions arose from issues of taxation, public spending, regulation of business, and market supervision, as well as the limits of corporate autonomy.\n\nCologne's central location on the Rhine river placed it at the intersection of the major trade routes between east and west and was the basis of Cologne's growth. The economic structures of medieval and early modern Cologne were characterized by the city's status as a major harbor and transport hub upon the Rhine. It was the seat of the archbishops, who ruled the surrounding area and (from 1248 to 1880) built the great Cologne Cathedral, with sacred relics that made it a destination for many worshippers. By 1288 the city had secured its independence from the archbishop (who relocated to Bonn), and was ruled by its burghers.\n\nFrom the early Medieval period and continuing through to the 18th century, Germanic law assigned women to a subordinate and dependent position relative to men. Salic (Frankish) law, from which the laws of the German lands would be based, placed women at a disadvantage with regard to property and inheritance rights. Germanic widows required a male guardian to represent them in court. Unlike Anglo-Saxon law or the Visigothic Code, Salic law barred women from royal succession. Social status was based on military and biological roles, a reality demonstrated in rituals associated with newborns, when female infants were given a lesser value than male infants. The use of physical force against wives was condoned until the 18th century in Bavarian law.\n\nSome women of means asserted their influence during the Middle Ages, typically in royal court or convent settings. Hildegard of Bingen, Gertrude the Great, Elisabeth of Bavaria (1478–1504), and Argula von Grumbach are among the women who pursued independent accomplishments in fields as diverse as medicine, music composition, religious writing, and government and military politics.\n\nBenedictine abbess Hildegard von Bingen (1098–1179) wrote several influential theological, botanical, and medicinal texts, as well as letters, liturgical songs, poems, and arguably the oldest surviving morality play, while supervising brilliant miniature Illuminations. About 100 years later, Walther von der Vogelweide (c. 1170 - c. 1230) became the most celebrated of the Middle High German lyric poets.\n\nAround 1439, Johannes Gutenberg of Mainz, used movable type printing and issued the Gutenberg Bible. He was the global inventor of the printing press, thereby starting the Printing Revolution. Cheap printed books and pamphlets played central roles for the spread of the Reformation and the Scientific Revolution.\n\nAround the transition from the 15th to the 16th century, Albrecht Dürer from Nuremberg established his reputation across Europe as painter, printmaker, mathematician, engraver, and theorist when he was still in his twenties and secured his reputation as one of the most important figures of the Northern Renaissance.\n\nThe addition \"Nationis Germanicæ\" (of German Nation) to the emperor's title appeared first in the 15th century: in a 1486 law decreed by Frederick III and in 1512 in reference to the Imperial Diet in Cologne by Maximilian I. By then, the emperors had lost their influence in Italy and Burgundy. In 1525, the Heilbronn reform plan – the most advanced document of the German Peasants' War (\"Deutscher Bauernkrieg\") – referred to the \"Reich\" as \"von Teutscher Nation\" (of German nation).\n\nIn the early 16th century there was much discontent occasioned by abuses such as indulgences in the Catholic Church, and a general desire for reform.\n\nIn 1517 the Reformation began with the publication of Martin Luther's 95 Theses; he posted them in the town square and gave copies of them to German nobles, but it is debated whether he nailed them to the church door in Wittenberg as is commonly said. The list detailed 95 assertions Luther believed to show corruption and misguidance within the Catholic Church. One often cited example, though perhaps not Luther's chief concern, is a condemnation of the selling of indulgences; another prominent point within the 95 Theses is Luther's disagreement both with the way in which the higher clergy, especially the pope, used and abused power, and with the very idea of the pope.\n\nIn 1521 Luther was outlawed at the Diet of Worms. But the Reformation spread rapidly, helped by the Emperor Charles V's wars with France and the Turks. Hiding in the Wartburg Castle, Luther translated the Bible from Latin to German, establishing the basis of the German language. A curious fact is that Luther spoke a dialect which had minor importance in the German language of that time. After the publication of his Bible, his dialect suppressed the others and evolved into what is now the modern German.\n\nIn 1524 the German Peasants' War broke out in Swabia, Franconia and Thuringia against ruling princes and lords, following the preaching of Reformers. But the revolts, which were assisted by war-experienced noblemen like Götz von Berlichingen and Florian Geyer (in Franconia), and by the theologian Thomas Münzer (in Thuringia), were soon repressed by the territorial princes. As many as 100,000 German peasants were massacred during the revolt. With the protestation of the Lutheran princes at the Imperial Diet of Speyer (1529) and rejection of the Lutheran \"Augsburg Confession\" at Augsburg (1530), a separate Lutheran church emerged.\n\nFrom 1545 the Counter-Reformation began in Germany. The main force was provided by the Jesuit order, founded by the Spaniard Ignatius of Loyola. Central and northeastern Germany were by this time almost wholly Protestant, whereas western and southern Germany remained predominantly Catholic. In 1547, Holy Roman Emperor Charles V defeated the Schmalkaldic League, an alliance of Protestant rulers. The Peace of Augsburg in 1555 brought recognition of the Lutheran faith. But the treaty also stipulated that the religion of a state was to be that of its ruler (Cuius regio, eius religio).\n\nIn 1608/1609 the Protestant Union and the Catholic League were formed.\n\nFrom 1618 to 1648 the Thirty Years' War ravaged in the Holy Roman Empire. The causes were the conflicts between Catholics and Protestants, the efforts by the various states within the Empire to increase their power and the Catholic Emperor's attempt to achieve the religious and political unity of the Empire. The immediate occasion for the war was the uprising of the Protestant nobility of Bohemia against the emperor, but the conflict was widened into a European War by the intervention of King Christian IV of Denmark (1625–29), Gustavus Adolphus of Sweden (1630–48) and France under Cardinal Richelieu. Germany became the main theatre of war and the scene of the final conflict between France and the Habsburgs for predominance in Europe.\n\nThe fighting often was out of control, with marauding bands of hundreds or thousands of starving soldiers spreading plague, plunder, and murder. The armies that were under control moved back and forth across the countryside year after year, levying heavy taxes on cities, and seizing the animals and food stocks of the peasants without payment. The enormous social disruption over three decades caused a dramatic decline in population because of killings, disease, crop failures, declining birth rates and random destruction, and the out-migration of terrified people. One estimate shows a 38% drop from 16 million people in 1618 to 10 million by 1650, while another shows \"only\" a 20% drop from 20 million to 16 million. The Altmark and Württemberg regions were especially hard hit. It took generations for Germany to fully recover.\n\nThe war ended in 1648 with the Peace of Westphalia. Alsace was permanently lost to France, Pomerania was temporarily lost to Sweden, and the Netherlands officially left the Empire. Imperial power declined further as the states' rights were increased.\n\nThe German population reached about twenty million people, the great majority of whom were peasant farmers.\n\nThe Reformation was a triumph of literacy and the new printing press. Luther's translation of the Bible into German was a decisive moment in the spread of literacy, and stimulated as well the printing and distribution of religious books and pamphlets. From 1517 onward religious pamphlets flooded Germany and much of Europe. By 1530 over 10,000 publications are known, with a total of ten million copies. The Reformation was thus a media revolution. Luther strengthened his attacks on Rome by depicting a \"good\" against \"bad\" church. From there, it became clear that print could be used for propaganda in the Reformation for particular agendas. Reform writers used pre-Reformation styles, clichés, and stereotypes and changed items as needed for their own purposes. Especially effective were Luther's \"Small Catechism\", for use of parents teaching their children, and \"Larger Catechism,\" for pastors. Using the German vernacular they expressed the Apostles' Creed in simpler, more personal, Trinitarian language. Illustrations in the newly translated Bible and in many tracts popularized Luther's ideas. Lucas Cranach the Elder (1472–1553), the great painter patronized by the electors of Wittenberg, was a close friend of Luther, and illustrated Luther's theology for a popular audience. He dramatized Luther's views on the relationship between the Old and New Testaments, while remaining mindful of Luther's careful distinctions about proper and improper uses of visual imagery.\n\nLuther's German translation of the Bible was also decisive for the German language and its evolution from Early New High German to Modern Standard. His bible promoted the development of non-local forms of language and exposed all speakers to forms of German from outside their own area.\n\nDecisive scientific developments took place during the 16th and 17th centuries, especially in the fields of astronomy, mathematics and physics. In 1543, astronomer Nicolaus Copernicus from Toruń (Thorn) published his work \"De revolutionibus orbium coelestium\" and became the first person to formulate a comprehensive heliocentric cosmology that displaced the Earth from the center of the universe. Almost 70 years after Copernicus's death and building on his theories, astronomer Johannes Kepler from Stuttgart was a leader in the 17th-century scientific revolution. He is best known for his laws of planetary motion. His works \"Astronomia nova\" and \"Harmonices Mundi\" were further codified by later astronomers. These works also influenced contemporary Italian scientist Galileo Galilei and provided one of the foundations for Englishman Isaac Newton's theory of universal gravitation.\n\nFrom 1640, Brandenburg-Prussia had started to rise under the Great Elector, Frederick William. The Peace of Westphalia in 1648 strengthened it even further, through the acquisition of East Pomerania. From 1713 to 1740, King Frederick William I, also known as the \"Soldier King\", established a highly centralized, militarized state with a heavily rural population of about three million (compared to the nine million in Austria).\n\nIn terms of the boundaries of 1914, Germany in 1700 had a population of 16 million, increasing slightly to 17 million by 1750, and growing more rapidly to 24 million by 1800. Wars continued, but they were no longer so devastating to the civilian population; famines and major epidemics did not occur, but increased agricultural productivity led to a higher birth rate, and a lower death rate.\n\nLouis XIV of France conquered parts of Alsace and Lorraine (1678–1681), and had invaded and devastated the Electorate of the Palatinate (1688–1697) in the War of Palatinian Succession. Louis XIV benefited from the Empire's problems with the Turks, which were menacing Austria. Louis XIV ultimately had to relinquish the Electorate of the Palatinate. Afterwards Hungary was reconquered from the Turks; Austria, under the Habsburgs, developed into a great power.\n\nFrederick II \"the Great\" is best known for his military genius, his reorganization of Prussian armies, his battlefield successes, his enlightened rule, and especially his making Prussia one of the great powers, as well as escaping from almost certain national disaster at the last minute. He was especially a role model for an aggressively expanding Germany down to 1945, and even today retains his heroic image in Germany.\n\nIn the War of Austrian Succession (1740–1748) Maria Theresa fought successfully for recognition of her succession to the throne. But in the Silesian Wars and in the Seven Years' War she had to cede 95 percent of Silesia to Frederick the Great. After the Peace of Hubertsburg in 1763 between Austria, Prussia and Saxony, Prussia won recognition as a great power, thus launching a century-long rivalry with Austria for the leadership of the German peoples.\n\nFrom 1763, against resistance from the nobility and citizenry, an \"enlightened absolutism\" was established in Prussia and Austria, according to which the ruler governed according to the best precepts of the philosophers. The economies developed and legal reforms were undertaken, including the abolition of torture and the improvement in the status of Jews. Emancipation of the peasants slowly began. Compulsory education was instituted.\n\nIn 1772–1795 Prussia took the lead in the partitions of Poland, with Austria and Russia splitting the rest. Prussia occupied the western territories of the former Polish–Lithuanian Commonwealth that surrounded existing Prussian holdings. This occupation led over a century of Polish resistance until Poland again became independent in 1918.\n\nCompletely overshadowed by Prussia and Austria, according to historian Hajo Holborn, the smaller German states were generally characterized by political lethargy and administrative inefficiency, often compounded by rulers who were more concerned with their mistresses and their hunting dogs than with the affairs of state. Bavaria was especially unfortunate in this regard; it was a rural land with very heavy debts and few growth centers. Saxony was in economically good shape, although its government was seriously mismanaged, and numerous wars had taken their toll. During the time when Prussia rose rapidly within Germany, Saxony was distracted by foreign affairs. The house of Wettin concentrated on acquiring and then holding on to the Polish throne which was ultimately unsuccessful. In Württemberg the duke lavished funds on palaces, mistresses, great celebration, and hunting expeditions. Many of the city-states of Germany were run by bishops, who in reality were from powerful noble families and showed scant interest in religion. None developed a significant reputation for good government.\n\nIn Hesse-Kassel, the Landgrave Frederick II, ruled 1760–1785 as an enlightened despot, and raised money by renting soldiers (called \"Hessians\") to Great Britain to help fight the American Revolutionary War. He combined Enlightenment ideas with Christian values, cameralist plans for central control of the economy, and a militaristic approach toward diplomacy.\n\nHanover did not have to support a lavish court—its rulers were also kings of England and resided in London. George III, elector (ruler) from 1760 to 1820, never once visited Hanover. The local nobility who ran the country opened the University of Göttingen in 1737; it soon became a world-class intellectual center. Baden sported perhaps the best government of the smaller states. Karl Friedrich ruled well for 73 years (1738–1811) and was an enthusiast for The Enlightenment; he abolished serfdom in 1783.\n\nThe smaller states failed to form coalitions with each other, and were eventually overwhelmed by Prussia. Between 1807 and 1871, Prussia swallowed up many of the smaller states, with minimal protest, then went on to found the German Empire. In the process, Prussia became too heterogeneous, lost its identity, and by the 1930s had become an administrative shell of little importance.\n\nIn a heavily agrarian society, land ownership played a central role. Germany's nobles, especially those in the East – called Junkers – dominated not only the localities, but also the Prussian court, and especially the Prussian army. Increasingly after 1815, a centralized Prussian government based in Berlin took over the powers of the nobles, which in terms of control over the peasantry had been almost absolute. To help the nobility avoid indebtedness, Berlin set up a credit institution to provide capital loans in 1809, and extended the loan network to peasants in 1849. When the German Empire was established in 1871, the Junker nobility controlled the army and the Navy, the bureaucracy, and the royal court; they generally set governmental policies.\n\nPeasants continued to center their lives in the village, where they were members of a corporate body, and to help manage the community resources and monitor the community life. In the East, they were serfs who were bound permanently to parcels of land. In most of Germany, farming was handled by tenant farmers who paid rents and obligatory services to the landlord, who was typically a nobleman. Peasant leaders supervised the fields and ditches and grazing rights, maintained public order and morals, and supported a village court which handled minor offenses. Inside the family the patriarch made all the decisions, and tried to arrange advantageous marriages for his children. Much of the villages' communal life centered around church services and holy days. In Prussia, the peasants drew lots to choose conscripts required by the army. The noblemen handled external relationships and politics for the villages under their control, and were not typically involved in daily activities or decisions.\n\nThe emancipation of the serfs came in 1770–1830, beginning with Schleswig in 1780. The peasants were now ex-serfs and could own their land, buy and sell it, and move about freely. The nobles approved for now they could buy land owned by the peasants. The chief reformer was Baron vom Stein (1757–1831), who was influenced by The Enlightenment, especially the free market ideas of Adam Smith. The end of serfdom raised the personal legal status of the peasantry. A bank was set up so that landowners could borrow government money to buy land from peasants (the peasants were not allowed to use it to borrow money to buy land until 1850). The result was that the large landowners obtained larger estates, and many peasants became landless tenants, or moved to the cities or to America. The other German states imitated Prussia after 1815. In sharp contrast to the violence that characterized land reform in the French Revolution, Germany handled it peacefully. In Schleswig the peasants, who had been influenced by the Enlightenment, played an active role; elsewhere they were largely passive. Indeed, for most peasants, customs and traditions continued largely unchanged, including the old habits of deference to the nobles whose legal authority remained quite strong over the villagers. Although the peasants were no longer tied to the same land as serfs had been, the old paternalistic relationship in East Prussia lasted into the 20th century.\n\nThe agrarian reforms in northwestern Germany in the era 1770–1870 were driven by progressive governments and local elites. They abolished feudal obligations and divided collectively owned common land into private parcels and thus created a more efficient market-oriented rural economy, which increased productivity and population growth and strengthened the traditional social order because wealthy peasants obtained most of the former common land, while the rural proletariat was left without land; many left for the cities or America. Meanwhile, the division of the common land served as a buffer preserving social peace between nobles and peasants. In the east the serfs were emancipated but the Junker class maintained its large estates and monopolized political power.\n\nAround 1800 the Catholic monasteries, which had large land holdings, were nationalized and sold off by the government. In Bavaria they had controlled 56% of the land.\n\nA major social change 1750-1850, depending on region, was the end of the traditional whole house\" (\"ganzes Haus\") system, in which the owner's family lived together in one large building with the servants and craftsmen he employed. They reorganized into separate living arrangements. No longer did the owner's wife take charge of all the females in the different families in the whole house. In the new system, farm owners became more professionalized and profit-oriented. They managed the fields and the household exterior according to the dictates of technology, science, and economics. Farm wives supervised family care and the household interior, to which strict standards of cleanliness, order, and thrift applied. The result was the spread of formerly urban bourgeois values into rural Germany.\n\nThe lesser families were now living separately on wages. They had to provide for their own supervision, health, schooling, and old-age. At the same time, because of the demographic transition, there were far fewer children, allowing for much greater attention to each child. Increasingly the middle-class family valued its privacy and its inward direction, shedding too-close links with the world of work. Furthermore, the working classes, the middle classes and the upper classes became physically, psychologically and politically more separate. This allowed for the emergence of working-class organizations. It also allowed for declining religiosity among the working-class, who were no longer monitored on a daily basis.\n\nBefore 1750 the German upper classes looked to France for intellectual, cultural and architectural leadership; French was the language of high society. By the mid-18th century the \"Aufklärung\" (The Enlightenment) had transformed German high culture in music, philosophy, science and literature. Christian Wolff (1679–1754) was the pioneer as a writer who expounded the Enlightenment to German readers; he legitimized German as a philosophic language.\n\nJohann Gottfried von Herder (1744–1803) broke new ground in philosophy and poetry, as a leader of the Sturm und Drang movement of proto-Romanticism. Weimar Classicism (\"Weimarer Klassik\") was a cultural and literary movement based in Weimar that sought to establish a new humanism by synthesizing Romantic, classical, and Enlightenment ideas. The movement, from 1772 until 1805, involved Herder as well as polymath Johann Wolfgang von Goethe (1749–1832) and Friedrich Schiller (1759–1805), a poet and historian. Herder argued that every folk had its own particular identity, which was expressed in its language and culture. This legitimized the promotion of German language and culture and helped shape the development of German nationalism. Schiller's plays expressed the restless spirit of his generation, depicting the hero's struggle against social pressures and the force of destiny.\n\nGerman music, sponsored by the upper classes, came of age under composers Johann Sebastian Bach (1685–1750), Joseph Haydn (1732–1809), and Wolfgang Amadeus Mozart (1756–1791).\n\nIn remote Königsberg philosopher Immanuel Kant (1724–1804) tried to reconcile rationalism and religious belief, individual freedom, and political authority. Kant's work contained basic tensions that would continue to shape German thought – and indeed all of European philosophy – well into the 20th century.\n\nThe German Enlightenment won the support of princes, aristocrats, and the middle classes, and it permanently reshaped the culture.\n\nBefore the 19th century, young women lived under the economic and disciplinary authority of their fathers until they married and passed under the control of their husbands. In order to secure a satisfactory marriage, a woman needed to bring a substantial dowry. In the wealthier families, daughters received their dowry from their families, whereas the poorer women needed to work in order to save their wages so as to improve their chances to wed. Under the German laws, women had property rights over their dowries and inheritances, a valuable benefit as high mortality rates resulted in successive marriages. Before 1789, the majority of women lived confined to society’s private sphere, the home.\nThe Age of Reason did not bring much more for women: men, including Enlightenment aficionados, believed that women were naturally destined to be principally wives and mothers. Within the educated classes, there was the belief that women needed to be sufficiently educated to be intelligent and agreeable interlocutors to their husbands. However, the lower-class women were expected to be economically productive in order to help their husbands make ends meet.\n\nGerman reaction to the French Revolution was mixed at first. German intellectuals celebrated the outbreak, hoping to see the triumph of Reason and The Enlightenment. The royal courts in Vienna and Berlin denounced the overthrow of the king and the threatened spread of notions of liberty, equality, and fraternity. By 1793, the execution of the French king and the onset of the Terror disillusioned the Bildungsbürgertum (educated middle classes). Reformers said the solution was to have faith in the ability of Germans to reform their laws and institutions in peaceful fashion.\n\nEurope was racked by two decades of war revolving around France's efforts to spread its revolutionary ideals, and the opposition of reactionary royalty. War broke out in 1792 as Austria and Prussia invaded France, but were defeated at the Battle of Valmy (1792). The German lands saw armies marching back and forth, bringing devastation (albeit on a far lower scale than the Thirty Years' War, almost two centuries before), but also bringing new ideas of liberty and civil rights for the people. Prussia and Austria ended their failed wars with France but (with Russia) partitioned Poland among themselves in 1793 and 1795. The French took control of the Rhineland, imposed French-style reforms, abolished feudalism, established constitutions, promoted freedom of religion, emancipated Jews, opened the bureaucracy to ordinary citizens of talent, and forced the nobility to share power with the rising middle class. Napoleon created the Kingdom of Westphalia (1807–1813) as a model state. These reforms proved largely permanent and modernized the western parts of Germany. When the French tried to impose the French language, German opposition grew in intensity. A Second Coalition of Britain, Russia, and Austria then attacked France but failed. Napoleon established direct or indirect control over most of western Europe, including the German states apart from Prussia and Austria. The old Holy Roman Empire was little more than a farce; Napoleon simply abolished it in 1806 while forming new countries under his control. In Germany Napoleon set up the \"Confederation of the Rhine,\" comprising most of the German states except Prussia and Austria.\n\nPrussia tried to remain neutral while imposing tight controls on dissent, but with German nationalism sharply on the rise, the small nation blundered by going to war with Napoleon in 1806. Its economy was weak, its leadership poor, and the once mighty Prussian army was a hollow shell. Napoleon easily crushed it at the Battle of Jena (1806). Napoleon occupied Berlin, and Prussia paid dearly. Prussia lost its recently acquired territories in western Germany, its army was reduced to 42,000 men, no trade with Britain was allowed, and Berlin had to pay Paris heavy reparations and fund the French army of occupation. Saxony changed sides to support Napoleon and join his Confederation of the Rhine; its elector was rewarded with the title of king and given a slice of Poland taken from Prussia.\n\nAfter Napoleon's fiasco in Russia in 1812, including the deaths of many Germans in his invasion army, Prussia joined with Russia. Major battles followed in quick order, and when Austria switched sides to oppose Napoleon his situation grew tenuous. He was defeated in a great Battle of Leipzig in late 1813, and Napoleon's empire started to collapse. One after another the German states switched to oppose Napoleon, but he rejected peace terms. Allied armies invaded France in early 1814, Paris fell, and in April Napoleon surrendered. He returned for 100 days in 1815, but was finally defeated by the British and German armies at Waterloo. Prussia was the big winner at the Vienna peace conference, gaining extensive territory.\n\nThe German Confederation () was the loose association of 39 states created in 1815 to coordinate the economies of separate German-speaking countries. It acted as a buffer between the powerful states of Austria and Prussia. Britain approved of it because London felt that there was need for a stable, peaceful power in central Europe that could discourage aggressive moves by France or Russia. According to Lee (1985), most historians have judged the Confederation to be weak and ineffective, as well as an obstacle to German nationalist aspirations. It collapsed because of the rivalry between Prussia and Austria (known as German dualism), warfare, the 1848 revolution, and the inability of the multiple members to compromise. It was replaced by the North German Confederation in 1866.\n\nThe population of the German Confederation (excluding Austria) grew 60% from 1815 to 1865, from 21,000,000 to 34,000,000. The era saw the Demographic Transition take place in Germany. It was a transition from high birth rates and high death rates to low birth and death rates as the country developed from a pre-industrial to a modernized agriculture and supported a fast-growing industrialized urban economic system. In previous centuries, the shortage of land meant that not everyone could marry, and marriages took place after age 25. After 1815, increased agricultural productivity meant a larger food supply, and a decline in famines, epidemics, and malnutrition. This allowed couples to marry earlier, and have more children. Arranged marriages became uncommon as young people were now allowed to choose their own marriage partners, subject to a veto by the parents. The high birthrate was offset by a very high rate of infant mortality and emigration, especially after about 1840, mostly to the German settlements in the United States, plus periodic epidemics and harvest failures. The upper and middle classes began to practice birth control, and a little later so too did the peasants.\n\nBefore 1850 Germany lagged far behind the leaders in industrial development – Britain, France, and Belgium. In 1800, Germany's social structure was poorly suited to entrepreneurship or economic development. Domination by France during the era of the French Revolution (1790s to 1815), however, produced important institutional reforms. Reforms included the abolition of feudal restrictions on the sale of large landed estates, the reduction of the power of the guilds in the cities, and the introduction of a new, more efficient commercial law. Nevertheless, traditionalism remained strong in most of Germany. Until mid-century, the guilds, the landed aristocracy, the churches, and the government bureaucracies had so many rules and restrictions that entrepreneurship was held in low esteem, and given little opportunity to develop. From the 1830s and 1840s, Prussia, Saxony, and other states reorganized agriculture. The introduction of sugar beets, turnips, and potatoes yielded a higher level of food production, which enabled a surplus rural population to move to industrial areas. The beginnings of the industrial revolution in Germany came in the textile industry, and was facilitated by eliminating tariff barriers through the Zollverein, starting in 1834.\n\nBy mid-century, the German states were catching up. By 1900 Germany was a world leader in industrialization, along with Britain and the United States. Historian Thomas Nipperdey sums it up:\n\nIndustrialization brought rural Germans to the factories, mines and railways. The population in 1800 was heavily rural, with only 10% of the people living in communities of 5000 or more people, and only 2% living in cities of more than 100,000. After 1815, the urban population grew rapidly, due primarily to the influx of young people from the rural areas. Berlin grew from 172,000 in 1800, to 826,000 in 1870; Hamburg grew from 130,000 to 290,000; Munich from 40,000 to 269,000; and Dresden from 60,000 to 177,000. Offsetting this growth, there was extensive emigration, especially to the United States. Emigration totaled 480,000 in the 1840s, 1,200,000 in the 1850s, and 780,000 in the 1860s.\n\nThe takeoff stage of economic development came with the railroad revolution in the 1840s, which opened up new markets for local products, created a pool of middle managers, increased the demand for engineers, architects and skilled machinists and stimulated investments in coal and iron. Political disunity of three dozen states and a pervasive conservatism made it difficult to build railways in the 1830s. However, by the 1840s, trunk lines did link the major cities; each German state was responsible for the lines within its own borders. Economist Friedrich List summed up the advantages to be derived from the development of the railway system in 1841:\n\nLacking a technological base at first, the Germans imported their engineering and hardware from Britain, but quickly learned the skills needed to operate and expand the railways. In many cities, the new railway shops were the centres of technological awareness and training, so that by 1850, Germany was self-sufficient in meeting the demands of railroad construction, and the railways were a major impetus for the growth of the new steel industry. Observers found that even as late as 1890, their engineering was inferior to Britain’s. However, German unification in 1870 stimulated consolidation, nationalisation into state-owned companies, and further rapid growth. Unlike the situation in France, the goal was support of industrialisation, and so heavy lines crisscrossed the Ruhr and other industrial districts, and provided good connections to the major ports of Hamburg and Bremen. By 1880, Germany had 9,400 locomotives pulling 43,000 passengers and 30,000 tons of freight a day, and forged ahead of France.\n\nA large number of newspapers and magazines flourished; A typical small city had one or two newspapers; Berlin and Leipzig had dozens. The audience was limited to perhaps five percent of the adult men, chiefly from the aristocratic and middle classes, who followed politics. Liberal papers outnumbered conservative ones by a wide margin. Foreign governments bribed editors to guarantee a favorable image. Censorship was strict, and the government issued the political news they were supposed to report. After 1871, strict press laws were used by Bismarck to shut down the Socialist, and to threaten hostile editors. There were no national newspapers. Editors focused on political commentary, but also include in a nonpolitical cultural page, focused on the arts and high culture. Especially popular was the serialized novel, with a new chapter every week. Magazines were politically more influential, and attracted the leading intellectuals as authors.\n\nGerman artists and intellectuals, heavily influenced by the French Revolution and by the great German poet and writer Johann Wolfgang von Goethe (1749–1832), turned to Romanticism after a period of Enlightenment. Philosophical thought was decisively shaped by Immanuel Kant (1724–1804). Ludwig van Beethoven (1770–1827) was the leading composer of Romantic music. His use of tonal architecture in such a way as to allow significant expansion of musical forms and structures was immediately recognized as bringing a new dimension to music. His later piano music and string quartets, especially, showed the way to a completely unexplored musical universe, and influenced Franz Schubert (1797–1828) and Robert Schumann (1810–1856). In opera, a new Romantic atmosphere combining supernatural terror and melodramatic plot in a folkloric context was first successfully achieved by Carl Maria von Weber (1786–1826) and perfected by Richard Wagner (1813–1883) in his Ring Cycle. The Brothers Grimm (1785–1863 & 1786–1859) not only collected folk stories into the popular Grimm's Fairy Tales, but were also linguists, now counted among the founding fathers of German studies. They were commissioned to begin the Deutsches Wörterbuch (\"The German Dictionary\"), which remains the most comprehensive work on the German language.\n\nAt the universities high-powered professors developed international reputations, especially in the humanities led by history and philology, which brought a new historical perspective to the study of political history, theology, philosophy, language, and literature. With Georg Wilhelm Friedrich Hegel (1770–1831) in philosophy, Friedrich Schleiermacher (1768–1834) in theology and Leopold von Ranke (1795–1886) in history, the University of Berlin, founded in 1810, became the world's leading university. Von Ranke, for example, professionalized history and set the world standard for historiography. By the 1830s mathematics, physics, chemistry, and biology had emerged with world class science, led by Alexander von Humboldt (1769–1859) in natural science and Carl Friedrich Gauss (1777–1855) in mathematics. Young intellectuals often turned to politics, but their support for the failed Revolution of 1848 forced many into exile.\n\nTwo main developments reshaped religion in Germany. Across the land, there was a movement to unite the larger Lutheran and the smaller Reformed Protestant churches. The churches themselves brought this about in Baden, Nassau, and Bavaria. However, in Prussia King Frederick William III was determined to handle unification entirely on his own terms, without consultation. His goal was to unify the Protestant churches, and to impose a single standardized liturgy, organization and even architecture. The long-term goal was to have fully centralized royal control of all the Protestant churches. In a series of proclamations over several decades the \"Church of the Prussian Union\" was formed, bringing together the more numerous Lutherans, and the less numerous Reformed Protestants. The government of Prussia now had full control over church affairs, with the king himself recognized as the leading bishop. Opposition to unification came from the \"Old Lutherans\" in Silesia who clung tightly to the theological and liturgical forms they had followed since the days of Luther. The government attempted to crack down on them, so they went underground. Tens of thousands migrated, to South Australia, and especially to the United States, where they formed the Missouri Synod, which is still in operation as a conservative denomination. Finally in 1845 a new king Frederick William IV offered a general amnesty and allowed the Old Lutherans to form a separate church association with only nominal government control.\n\nFrom the religious point of view of the typical Catholic or Protestant, major changes were underway in terms of a much more personalized religiosity that focused on the individual more than the church or the ceremony. The rationalism of the late 19th century faded away, and there was a new emphasis on the psychology and feeling of the individual, especially in terms of contemplating sinfulness, redemption, and the mysteries and the revelations of Christianity. Pietistic revivals were common among Protestants. Among Catholics there was a sharp increase in popular pilgrimages. In 1844 alone, half a million pilgrims made a pilgrimage to the city of Trier in the Rhineland to view the Seamless robe of Jesus, said to be the robe that Jesus wore on the way to his crucifixion. Catholic bishops in Germany had historically been largely independent Of Rome, but now the Vatican exerted increasing control, a new \"ultramontanism\" of Catholics highly loyal to Rome. A sharp controversy broke out in 1837-38 in the largely Catholic Rhineland over the religious education of children of mixed marriages, where the mother was Catholic and the father Protestant. The government passed laws to require that these children always be raised as Protestants, contrary to Napoleonic law that had previously prevailed and allowed the parents to make the decision. It put the Catholic Archbishop under house arrest. In 1840, the new King Frederick William IV sought reconciliation and ended the controversy by agreeing to most of the Catholic demands. However Catholic memories remained deep and led to a sense that Catholics always needed to stick together in the face of an untrustworthy government.\n\nAfter the fall of Napoleon, Europe's statesmen convened in Vienna in 1815 for the reorganisation of European affairs, under the leadership of the Austrian Prince Metternich. The political principles agreed upon at this Congress of Vienna included the restoration, legitimacy and solidarity of rulers for the repression of revolutionary and nationalist ideas.\n\nThe German Confederation () was founded, a loose union of 39 states (35 ruling princes and 4 free cities) under Austrian leadership, with a Federal Diet () meeting in Frankfurt am Main. It was a loose coalition that failed to satisfy most nationalists. The member states largely went their own way, and Austria had its own interests.\n\nIn 1819 a student radical assassinated the reactionary playwright August von Kotzebue, who had scoffed at liberal student organisations. In one of the few major actions of the German Confederation, Prince Metternich called a conference that issued the repressive Carlsbad Decrees, designed to suppress liberal agitation against the conservative governments of the German states. The Decrees terminated the fast-fading nationalist fraternities (), removed liberal university professors, and expanded the censorship of the press. The decrees began the \"persecution of the demagogues\", which was directed against individuals who were accused of spreading revolutionary and nationalist ideas. Among the persecuted were the poet Ernst Moritz Arndt, the publisher Johann Joseph Görres and the \"Father of Gymnastics\" Ludwig Jahn.\nIn 1834 the Zollverein was established, a customs union between Prussia and most other German states, but excluding Austria. As industrialisation developed, the need for a unified German state with a uniform currency, legal system, and government became more and more obvious.\n\nGrowing discontent with the political and social order imposed by the Congress of Vienna led to the outbreak, in 1848, of the March Revolution in the German states. In May the German National Assembly (the Frankfurt Parliament) met in Frankfurt to draw up a national German constitution.\n\nBut the 1848 revolution turned out to be unsuccessful: King Frederick William IV of Prussia refused the imperial crown, the Frankfurt parliament was dissolved, the ruling princes repressed the risings by military force, and the German Confederation was re-established by 1850. Many leaders went into exile, including a number who went to the United States and became a political force there.\n\nThe 1850s were a period of extreme political reaction. Dissent was vigorously suppressed, and many Germans emigrated to America following the collapse of the 1848 uprisings. Frederick William IV became extremely depressed and melancholy during this period, and was surrounded by men who advocated clericalism and absolute divine monarchy. The Prussian people once again lost interest in politics. Prussia not only expanded its territory but began to industrialize rapidly, while maintaining a strong agricultural base.\n\nIn 1857, the king had a stroke and his brother William became regent, then became King William I in 1861. Although conservative, William I was far more pragmatic. His most significant accomplishment was naming Otto von Bismarck as chancellor in 1862. The combination of Bismarck, Defense Minister Albrecht von Roon, and Field Marshal Helmut von Moltke set the stage for victories over Denmark, Austria, and France, and led to the unification of Germany. The obstacle to German unification was Austria, and Bismarck solved the problem with a series of wars that united the German states north of Austria.\n\nIn 1863–64, disputes between Prussia and Denmark grew over Schleswig, which was not part of the German Confederation, and which Danish nationalists wanted to incorporate into the Danish kingdom. The dispute led to the short Second War of Schleswig in 1864. Prussia, joined by Austria, easily defeated Denmark and occupied Jutland. The Danes were forced to cede both the duchy of Schleswig and the duchy of Holstein to Austria and Prussia. In the aftermath, the management of the two duchies caused escalating tensions between Austria and Prussia. The former wanted the duchies to become an independent entity within the German Confederation, while the latter wanted to annex them. The Seven Weeks War between Austria and Prussia broke out in June 1866. In July, the two armies clashed at Sadowa-Königgrätz (Bohemia) in an enormous battle involving half a million men. The Prussian breech-loading needle guns carried the day over the slow muzzle-loading rifles of the Austrians, who lost a quarter of their army in the battle. Austria ceded Venice to Italy, but Bismarck was deliberately lenient with the loser to keep alive a long-term alliance with Austria in a subordinate role. Now the French faced an increasingly strong Prussia.\n\nIn 1866, the German Confederation was dissolved. In its place the North German Federation (German \"Norddeutscher Bund\") was established, under the leadership of Prussia. Austria was excluded, and the Austrian influence in Germany that had begun in the 15th century finally came to an end. The North German Federation was a transitional organisation that existed from 1867 to 1871, between the dissolution of the German Confederation and the founding of the German Empire.\n\nAfter Germany was united by Otto von Bismarck into the \"German Reich\", he determined German politics until 1890. Bismarck tried to foster alliances in Europe, on one hand to contain France, and on the other hand to consolidate Germany's influence in Europe. On the domestic front Bismarck tried to stem the rise of socialism by anti-socialist laws, combined with an introduction of health care and social security. At the same time Bismarck tried to reduce the political influence of the emancipated Catholic minority in the Kulturkampf, literally \"culture struggle\". The Catholics only grew stronger, forming the Center (Zentrum) Party. Germany grew rapidly in industrial and economic power, matching Britain by 1900. Its highly professional army was the best in the world, but the navy could never catch up with Britain's Royal Navy.\n\nIn 1888, the young and ambitious Kaiser Wilhelm II became emperor. He could not abide advice, least of all from the most experienced politician and diplomat in Europe, so he fired Bismarck. The Kaiser opposed Bismarck's careful foreign policy and wanted Germany to pursue colonialist policies, as Britain and France had been doing for decades, as well as build a navy that could match the British. The Kaiser promoted active colonization of Africa and Asia for those areas that were not already colonies of other European powers; his record was notoriously brutal and set the stage for genocide. The Kaiser took a mostly unilateral approach in Europe with as main ally the Austro-Hungarian Empire, and an arms race with Britain, which eventually led to the situation in which the assassination of the Austrian-Hungarian crown prince could spark off World War I.\n\nDisputes between France and Prussia increased. In 1868, the Spanish queen Isabella II was expelled by a revolution, leaving that country's throne vacant. When Prussia tried to put a Hohenzollern candidate, Prince Leopold, on the Spanish throne, the French angrily protested. In July 1870, France declared war on Prussia (the Franco-Prussian War). The debacle was swift. A succession of German victories in northeastern France followed, and one French army was besieged at Metz. After a few weeks, the main army was finally forced to capitulate in the fortress of Sedan. French Emperor Napoleon III was taken prisoner and a republic hastily proclaimed in Paris. The new government, realising that a victorious Germany would demand territorial acquisitions, resolved to fight on. They began to muster new armies, and the Germans settled down to a grim siege of Paris. The starving city surrendered in January 1871, and the Prussian army staged a victory parade in it. France was forced to pay indemnities of 5 billion francs and cede Alsace-Lorraine. It was a bitter peace that would leave the French thirsting for revenge.\n\nDuring the Siege of Paris, the German princes assembled in the Hall of Mirrors of the Palace of Versailles and proclaimed the Prussian King Wilhelm I as the \"German Emperor\" on 18 January 1871. The German Empire was thus founded, with the German states unified into a single economic, political, and administrative unit. The empire comprised 25 states, three of which were Hanseatic free cities. It was dubbed the \"Little German\" solution, since it excluded the Austrian territories and the Habsburgs. Bismarck, again, was appointed to serve as Chancellor.\n\nThe new empire was characterised by a great enthusiasm and vigor. There was a rash of heroic artwork in imitation of Greek and Roman styles, and the nation possessed a vigorous, growing industrial economy, while it had always been rather poor in the past. The change from the slower, more tranquil order of the old Germany was very sudden, and many, especially the nobility, resented being displaced by the new rich. And yet, the nobles clung stubbornly to power, and they, not the bourgeois, continued to be the model that everyone wanted to imitate. In imperial Germany, possessing a collection of medals or wearing a uniform was valued more than the size of one's bank account, and Berlin never became a great cultural center as London, Paris, or Vienna were. The empire was distinctly authoritarian in tone, as the 1871 constitution gave the emperor exclusive power to appoint or dismiss the chancellor. He also was supreme commander-in-chief of the armed forces and final arbiter of foreign policy. But freedom of speech, association, and religion were nonetheless guaranteed by the constitution.\n\nBismarck's domestic policies as Chancellor of Germany were characterised by his fight against perceived enemies of the Protestant Prussian state. In the Kulturkampf (1871–1878), he tried to minimize the influence of the Roman Catholic Church and of its political arm, the Catholic Centre Party, through various measures—like the introduction of civil marriage—but without much success. The Kulturkampf antagonised many Protestants as well as Catholics, and was eventually abandoned. Millions of non-Germans subjects in the German Empire, like the Polish, Danish and French minorities, were discriminated against, and a policy of Germanisation was implemented.\n\nThe new Empire provided rich new opportunities at the top for the nobility of Prussia, and the other states, to fill. They dominated the diplomatic service, the Army, and the civil service. Through their control of the civil service, the aristocracy had a dominant voice in decisions affecting the universities and the churches. In 1914, Germany's diplomats consisted of eight princes 29 counts 20 barons 54 other nobles, and a mere 11 commoners. The commoners were chiefly the sons of leading industrialists or bankers. Almost all the diplomats had been socialized into the feudal student corps at the universities. The consular corps comprised commoners, but they had little decision-making ability. Since the days of Frederick the great, it had been difficult for commoners to achieve high ranking the Army. It was considered a suitable role for young aristocrats. The new Constitution put Military affairs under the direct control of the Emperor, and largely out of reach of the Reichstag. With its large corps of reserve officers across Germany, the military strengthened its role as \"The estate which upheld the nation.\" Historian Hans-Ulrich Wehler says, \"it became an almost separate, self-perpetuating caste.\"\n\nPower increasingly was centralized in the national capital of Berlin (including neighboring Potsdam.) where 7000 aristocrats drew a sharp line between themselves and everyone else. Berlin's rapidly increasing rich middle-class aped and copied the aristocracy and tried to marry into it. The closed system stood in contrast to Britain where the top levels of the elite were far more open with routes available through a public school education, Oxford, and Cambridge, the Inns of Court, appointment to high office, or leadership in the House of Commons. A peerage could permanently boost a rich industrial family into the upper reaches of the establishment. In Germany, the process worked in the other direction as the nobility became industrialists. For example, 221 of the 243 mines in Silesia were owned by nobles or by the King of Prussia himself.\n\nGermany's middle class, based in the cities, grew exponentially, although it never gained the political power it had in France, Britain or the United States. The Bund Deutscher Frauenvereine (Association of German Women's Organizations or BDF) was established in 1894 to encompass the proliferating women's organizations that had sprung up since the 1860s. From the beginning the BDF was a bourgeois organization, its members working toward equality with men in such areas as education, financial opportunities, and political life. Working-class women were not welcome; they were organized by the Socialists.\n\nThe rise of the Socialist Workers' Party (later known as the Social Democratic Party of Germany, SPD), declared its aim to establish peacefully a new socialist order through the transformation of existing political and social conditions. From 1878, Bismarck tried to repress the social democratic movement by outlawing the party's organisation, its assemblies and most of its newspapers. When it finally was allowed to run candidates, the Social Democrats were stronger than ever.\n\nBismarck built on a tradition of welfare programs in Prussia and Saxony that began as early as the 1840s. In the 1880s he introduced old age pensions, accident insurance, medical care, and unemployment insurance that formed the basis of the modern European welfare state. His paternalistic programs won the support of German industry because its goals were to win the support of the working classes for the Empire and reduce the outflow of immigrants to America, where wages were higher but welfare did not exist. Bismarck further won the support of both industry and skilled workers by his high tariff policies, which protected profits and wages from American competition, although they alienated the liberal intellectuals who wanted free trade.\n\nBismarck would not tolerate any power outside Germany—as in Rome—having a say in German affairs. He launched a Kulturkampf (\"culture war\") against the power of the pope and the Catholic Church in 1873, but only in Prussia. This gained strong support from German liberals, who saw the Catholic Church as the bastion of reaction and their greatest enemy. The Catholic element, in turn, saw in the National-Liberals as its worst enemy and formed the Center Party.\n\nCatholics, although nearly a third of the national population, were seldom allowed to hold major positions in the Imperial government, or the Prussian government. After 1871, there was a systematic purge of the remaining Catholics; in the powerful interior ministry, which handled all police affairs, the only Catholic was a messenger boy. Jews were likewise heavily discriminated against.\n\nMost of the Kulturkampf was fought out in Prussia, but Imperial Germany passed the Pulpit Law which made it a crime for any cleric to discuss public issues in a way that displeased the government. Nearly all Catholic bishops, clergy, and laymen rejected the legality of the new laws and defiantly faced the increasingly heavy penalties and imprisonments imposed by Bismarck's government. Historian Anthony Steinhoff reports the casualty totals: \n\nBismarck underestimated the resolve of the Catholic Church and did not foresee the extremes that this struggle would attain. The Catholic Church denounced the harsh new laws as anti-Catholic and mustered the support of its rank and file voters across Germany. In the following elections, the Center Party won a quarter of the seats in the Imperial Diet. The conflict ended after 1879 because Pope Pius IX died in 1878 and Bismarck broke with the Liberals to put his main emphasis on tariffs, foreign policy, and attacking socialists. Bismarck negotiated with the conciliatory new pope Leo XIII. Peace was restored, the bishops returned and the jailed clerics were released. Laws were toned down or taken back (Mitigation Laws 1880-1883 and Peace Laws 1886/87), but the laws concerning education, civil registry of marriages and religious disaffiliation remained in place. The Center Party gained strength and became an ally of Bismarck, especially when he attacked socialism.\n\nBismarck's post-1871 foreign policy was conservative and basically aimed at security and preventing the dreaded scenario of a Franco-Russian alliance, which would trap Germany between the two in a war.\nThe League of Three Emperors (\"Dreikaisersbund\") was signed in 1872 by Russia, Austria, and Germany. It stated that republicanism and socialism were common enemies and that the three powers would discuss any matters concerning foreign policy. Bismarck needed good relations with Russia in order to keep France isolated. In 1877–1878, Russia fought a victorious war with the Ottoman Empire and attempted to impose the Treaty of San Stefano on it. This upset the British in particular, as they were long concerned with preserving the Ottoman Empire and preventing a Russian takeover of the Bosphorus Strait. Germany hosted the Congress of Berlin (1878), whereby a more moderate peace settlement was agreed to. Germany had no direct interest in the Balkans, however, which was largely an Austrian and Russian sphere of influence, although King Carol of Romania was a German prince.\n\nIn 1879, Bismarck formed a Dual Alliance of Germany and Austria-Hungary, with the aim of mutual military assistance in the case of an attack from Russia, which was not satisfied with the agreement reached at the Congress of Berlin. The establishment of the Dual Alliance led Russia to take a more conciliatory stance, and in 1887, the so-called Reinsurance Treaty was signed between Germany and Russia: in it, the two powers agreed on mutual military support in the case that France attacked Germany, or in case of an Austrian attack on Russia. Russia turned its attention eastward to Asia and remained largely inactive in European politics for the next 25 years. In 1882, Italy joined the Dual Alliance to form a Triple Alliance. Italy wanted to defend its interests in North Africa against France's colonial policy. In return for German and Austrian support, Italy committed itself to assisting Germany in the case of a French military attack.\n\nFor a long time, Bismarck had refused to give in to widespread public demands to give Germany \"a place in the sun\" through the acquisition of overseas colonies. In 1880 Bismarck gave way, and a number of colonies were established overseas. In Africa, these were Togo, the Cameroons, German South-West Africa, and German East Africa; in Oceania, they were German New Guinea, the Bismarck Archipelago, and the Marshall Islands. In fact, it was Bismarck himself who helped initiate the Berlin Conference of 1885. He did it to \"establish international guidelines for the acquisition of African territory\" (see Colonisation of Africa). This conference was an impetus for the \"Scramble for Africa\" and \"New Imperialism\".\n\nIn 1888, emperor William I died at the age of 90. His son Frederick III, the hope of German liberals, was already stricken with throat cancer and died three months later. Frederick's son Wilhelm II then became emperor at the age of 29. Having had a problematic relationship with his liberal parents, Wilhelm had early on decided to renew the top level of the state. The two years that Bismarck remained in office feigned continuity, but a difference of opinion on social politics served as an excuse for the young Kaiser to force the chancellor into retirement in March 1890. Following a principle known as \"personal regiment\" (German: \"persönliches Regiment\"), Wilhelm aimed to exercise influence on every government decision.\n\nThe young Kaiser Wilhelm sought aggressively to increase Germany's influence in the world (\"Weltpolitik\"). After the removal of Bismarck, foreign policy was in the hands of the erratic Kaiser, who played an increasingly reckless hand, and the powerful foreign office under the leadership of Friedrich von Holstein. The foreign office argued that: first, a long-term coalition between France and Russia had to fall apart; secondly, Russia and Britain would never get together; and, finally, Britain would eventually seek an alliance with Germany. Germany refused to renew its treaties with Russia. But Russia did form a closer relationship with France in the Dual Alliance of 1894, since both were worried about the possibilities of German aggression. Furthermore, Anglo–German relations cooled as Germany aggressively tried to build a new empire and engaged in a naval race with Britain; London refused to agree to the formal alliance that Germany sought. Berlin's analysis proved mistaken on every point, leading to Germany's increasing isolation and its dependence on the Triple Alliance, which brought together Germany, Austria-Hungary, and Italy. The Triple Alliance was undermined by differences between Austria and Italy, and in 1915 Italy switched sides.\n\nMeanwhile, the German Navy under Admiral Alfred von Tirpitz had ambitions to rival the great British Navy, and dramatically expanded its fleet in the early 20th century to protect the colonies and exert power worldwide. Tirpitz started a programme of warship construction in 1898. In 1890, Germany had gained the island of Heligoland in the North Sea from Britain in exchange for the eastern African island of Zanzibar, and proceeded to construct a great naval base there. This posed a direct threat to British hegemony on the seas, with the result that negotiations for an alliance between Germany and Britain broke down. The British, however, kept well ahead in the naval race by the introduction of the highly advanced new \"Dreadnought\" battleship in 1907.\n\nIn the First Moroccan Crisis of 1905, Germany nearly came to blows with Britain and France when the latter attempted to establish a protectorate over Morocco. The Germans were upset at having not been informed about French intentions, and declared their support for Moroccan independence. William II made a highly provocative speech regarding this. The following year, a conference was held in which all of the European powers except Austria-Hungary (by now little more than a German satellite) sided with France. A compromise was brokered by the United States where the French relinquished some, but not all, control over Morocco.\n\nThe Second Moroccan Crisis of 1911 saw another dispute over Morocco erupt when France tried to suppress a revolt there. Germany, still smarting from the previous quarrel, agreed to a settlement whereby the French ceded some territory in central Africa in exchange for Germany's renouncing any right to intervene in Moroccan affairs. This confirmed French control over Morocco, which became a full protectorate of that country in 1912.\n\nThe economy continued to industrialize and urbanize, with heavy industry – especially coal and steel – becoming important in the Ruhr, and manufacturing growing in the cities, the Ruhr, and Silesia. Perkins (1981) argues that more important than Bismarck's new tariff on imported grain was the introduction of the sugar beet as a main crop. Farmers quickly abandoned traditional, inefficient practices in favor of modern methods, including use of new fertilizers and new tools. The knowledge and tools gained from the intensive farming of sugar and other root crops made Germany the most efficient agricultural producer in Europe by 1914. Even so, farms were small in size, and women did much of the field work. An unintended consequence was the increased dependence on migratory, especially foreign, labor.\nBased on its leadership in chemical research in the universities and industrial laboratories, Germany became dominant in the world's chemical industry in the late 19th century. At first, the production of dyes was critical.\n\nGermany became Europe's leading steel-producing nation in the 1890s, thanks in large part to the protection from American and British competition afforded by tariffs and cartels. The leading firm was \"Friedrich Krupp AG Hoesch-Krupp,\" run by the Krupp family. The merger of several major firms into the \"Vereinigte Stahlwerke\" (United Steel Works) in 1926 was modeled on the U.S. Steel corporation in the United States. The new company emphasized rationalization of management structures and modernization of the technology; it employed a multi-divisional structure and used return on investment as its measure of success. By 1913, American and German exports dominated the world steel market, as Britain slipped to third place.\n\nIn machinery, iron and steel, and other industries, German firms avoided cut-throat competition and instead relied on trade associations. Germany was a world leader because of its prevailing \"corporatist mentality\", its strong bureaucratic tradition, and the encouragement of the government. These associations regulate competition and allowed small firms to function in the shadow of much larger companies.\n\nGermany's unification process after 1871 was heavily dominated by men and give priority to the \"Fatherland\" theme and related male issues, such as military prowess. Nevertheless, middle class women enrolled in the \"Bund Deutscher Frauenvereine\", the Union of German Feminist Organizations (BDF). Founded in 1894, it grew to include 137 separate women's rights groups from 1907 until 1933, when the Nazi regime disbanded the organization. The BDF gave national direction to the proliferating women's organizations that had sprung up since the 1860s. From the beginning the BDF was a bourgeois organization, its members working toward equality with men in such areas as education, financial opportunities, and political life. Working-class women were not welcome; they were organized by the Socialists.\n\nFormal organizations for promoting women's rights grew in numbers during the Wilhelmine period. German feminists began to network with feminists from other countries, and participated in the growth of international organizations.\n\nBy the 1890s, German colonial expansion in Asia and the Pacific (Kiauchau in China, the Marianas, the Caroline Islands, Samoa) led to frictions with Britain, Russia, Japan and the United States. The construction of the Baghdad Railway, financed by German banks, was designed to eventually connect Germany with the Turkish Empire and the Persian Gulf, but it also collided with British and Russian geopolitical interests.\n\nThe largest colonial enterprises were in Africa. The harsh treatment of the Nama and Herero in what is now Namibia in Africa in 1906–07 led to charges of genocide against the Germans. Historians are examining the links and precedents between the Herero and Namaqua Genocide and the Holocaust of the 1940s.\n\nEthnic demands for nation states upset the balance between the empires that dominated Europe, leading to World War I, which started in August 1914. Germany stood behind its ally Austria in a confrontation with Serbia, but Serbia was under the protection of Russia, which was allied to France. Germany was the leader of the Central Powers, which included Austria-Hungary, the Ottoman Empire, and later Bulgaria; arrayed against them were the Allies, consisting chiefly of Russia, France, Britain, and in 1915 Italy.\n\nIn explaining why neutral Britain went to war with Germany, Kennedy (1980) recognized it was critical for war that Germany become economically more powerful than Britain, but he downplays the disputes over economic trade imperialism, the Baghdad Railway, confrontations in Central and Eastern Europe, high-charged political rhetoric and domestic pressure-groups. Germany's reliance time and again on sheer power, while Britain increasingly appealed to moral sensibilities, played a role, especially in seeing the invasion of Belgium as a necessary military tactic or a profound moral crime. The German invasion of Belgium was not important because the British decision had already been made and the British were more concerned with the fate of France (pp. 457–62). Kennedy argues that by far the main reason was London's fear that a repeat of 1870 — when Prussia and the German states smashed France — would mean that Germany, with a powerful army and navy, would control the English Channel and northwest France. British policy makers insisted that would be a catastrophe for British security.\n\nIn the west, Germany sought a quick victory by encircling Paris using the Schlieffen Plan. But it failed due to Belgian resistance, Berlin's diversion of troops, and very stiff French resistance on the Marne, north of Paris.\n\nThe Western Front became an extremely bloody battleground of trench warfare. The stalemate lasted from 1914 until early 1918, with ferocious battles that moved forces a few hundred yards at best along a line that stretched from the North Sea to the Swiss border. The British imposed a tight naval blockade in the North Sea which lasted until 1919, sharply reducing Germany's overseas access to raw materials and foodstuffs. Food scarcity became a serious problem by 1917.\n\nThe United States joined with the Allies in April 1917. The entry of the United States into the war – following Germany's declaration of unrestricted submarine warfare – marked a decisive turning-point against Germany.\n\nMore wide open was the fighting on the Eastern Front. In the east, there were decisive victories against the Russian army, the trapping and defeat of large parts of the Russian contingent at the Battle of Tannenberg, followed by huge Austrian and German successes. The breakdown of Russian forces – exacerbated by internal turmoil caused by the 1917 Russian Revolution – led to the Treaty of Brest-Litovsk the Bolsheviks were forced to sign on 3 March 1918 as Russia withdrew from the war. It gave Germany control of Eastern Europe. Spencer Tucker says, \"The German General Staff had formulated extraordinarily harsh terms that shocked even the German negotiator.\" When Germany later complained that the Treaty of Versailles of 1919 was too harsh on them, the Allies responded that it was more benign than Brest-Litovsk.\n\nBy defeating Russia in 1917 Germany was able to bring hundreds of thousands of combat troops from the east to the Western Front, giving it a numerical advantage over the Allies. By retraining the soldiers in new storm-trooper tactics, the Germans expected to unfreeze the Battlefield and win a decisive victory before the American army arrived in strength. However, the spring offensives all failed, as the Allies fell back and regrouped, and the Germans lacked the reserves necessary to consolidate their gains. In the summer, with the Americans arriving at 10,000 a day, and the German reserves exhausted, it was only a matter of time before multiple Allied offenses destroyed the German army.\n\nUnexpectedly Germany plunged into World War I (1914–1918). It rapidly mobilized its civilian economy for the war effort, the economy was handicapped by the British blockade that cut off food supplies.\nMeanwhile, conditions deteriorated rapidly on the home front, with severe food shortages reported in all urban areas. Causes involved the transfer of many farmers and food workers into the military, an overburdened railroad system, shortages of coal, and the British blockade that cut off imports from abroad. The winter of 1916–1917 was known as the \"turnip winter,\" because that vegetable, usually fed to livestock, was used by people as a substitute for potatoes and meat, which were increasingly scarce. Thousands of soup kitchens were opened to feed the hungry people, who grumbled that the farmers were keeping the food for themselves. Even the army had to cut the rations for soldiers. Morale of both civilians and soldiers continued to sink.\n\n1918 was also the year of the deadly 1918 Spanish Flu pandemic which struck hard at a population weakened by years of malnutrition.\n\nThe end of October 1918, in Wilhelmshaven, in northern Germany, saw the beginning of the German Revolution of 1918–19. Units of the German Navy refused to set sail for a last, large-scale operation in a war which they saw as good as lost, initiating the uprising. On 3 November, the revolt spread to other cities and states of the country, in many of which workers' and soldiers' councils were established. Meanwhile, Hindenburg and the senior commanders had lost confidence in the Kaiser and his government. The Kaiser and all German ruling princes abdicated. On 9 November 1918, the Social Democrat Philipp Scheidemann proclaimed a Republic.\nOn 11 November, the Compiègne armistice was signed, ending the war. The Treaty of Versailles was signed on 28 June 1919. Germany was to cede Alsace-Lorraine to France. Eupen-Malmédy would temporarily be ceded to Belgium, with a plebiscite to be held to allow the people the choice of the territory either remaining with Belgium or being returned to German control. Following a plebiscite, the territory was allotted to Belgium on 20 September 1920. The future of North Schleswig was to be decided by plebiscite. In the Schleswig Plebiscites, the Danish-speaking population in the north voted for Denmark and the southern, German speaking populace, part voted for Germany. Schleswig was thus partitioned. Holstein remained German without a referendum. Memel was ceded to the Allied and Associated powers, to decide the future of the area. On 9 January 1923, Lithuanian forces invaded the territory. Following negotiations, on 8 May 1924, the League of Nations ratified the annexation on the grounds that Lithuania accepted the Memel Statute, a power-sharing arrangement to protect non-Lithuanians in the territory and its autonomous status. Until 1929, German-Lithuanian co-operation increased and this power sharing arrangement worked. Poland was restored and most of the provinces of Posen and West Prussia, and some areas of Upper Silesia were reincorporated into the reformed country after plebiscites and independence uprisings. All German colonies were to be handed over to League of Nations, who then assigned them as Mandates to Australia, France, Japan, New Zealand, Portugal, and the United Kingdom. The new owners were required to act as a disinterested trustee over the region, promoting the welfare of its inhabitants in a variety of ways until they were able to govern themselves. The left and right banks of the Rhine were to be permanently demilitarised. The industrially important Saarland was to be governed by the League of Nations for 15 years and its coalfields administered by France. At the end of that time a plebiscite was to determine the Saar's future status. To ensure execution of the treaty's terms, Allied troops would occupy the left (German) bank of the Rhine for a period of 5–15 years. The German army was to be limited to 100,000 officers and men; the general staff was to be dissolved; vast quantities of war material were to be handed over and the manufacture of munitions rigidly curtailed. The navy was to be similarly reduced, and no military aircraft were allowed. Germany was also required to pay reparations for all civilian damage caused during the war.\n\nThe humiliating peace terms in the Treaty of Versailles provoked bitter indignation throughout Germany, and seriously weakened the new democratic regime. The greatest enemies of democracy had already been constituted. In December 1918, the Communist Party of Germany (KPD) was founded, and in 1919 it tried and failed to overthrow the new republic. Adolf Hitler in 1919 took control of the new National Socialist German Workers' Party (NSDAP), which failed in a coup in Munich in 1923. Both parties, as well as parties supporting the republic, built militant auxiliaries that engaged in increasingly violent street battles. Electoral support for both parties increased after 1929 as the Great Depression hit the economy hard, producing many unemployed men who became available for the paramilitary units. The Nazis, with a mostly rural and lower middle class base, overthrew the Weimar regime and ruled Germany in 1933–1945; the KPD, with a mostly urban and working class base, came to power (in the East) in 1945–1989.\n\nOn 11 August 1919 the Weimar constitution came into effect, with Friedrich Ebert as first President.\n\nOn 30 December 1918, the Communist Party of Germany was founded by the Spartacus League, who had split from the Social Democratic Party during the war. It was headed by Rosa Luxemburg and Karl Liebknecht, and rejected the parliamentary system. In 1920, about 300,000 members from the Independent Social Democratic Party of Germany joined the party, transforming it into a mass organization. The Communist Party had a following of about 10% of the electorate.\n\nIn the first months of 1920, the Reichswehr was to be reduced to 100,000 men, in accordance with the Treaty of Versailles. This included the dissolution of many Freikorps – units made up of volunteers. In an attempt at a coup d'état in March 1920, the Kapp Putsch, extreme right-wing politician Wolfgang Kapp let Freikorps soldiers march on Berlin and proclaimed himself Chancellor of the Reich. After four days the coup d'état collapsed, due to popular opposition and lack of support by the civil servants and the officers. Other cities were shaken by strikes and rebellions, which were bloodily suppressed.\n\nGermany was the first state to establish diplomatic relations with the new Soviet Union. Under the Treaty of Rapallo, Germany accorded the Soviet Union \"de jure\" recognition, and the two signatories mutually cancelled all pre-war debts and renounced war claims.\n\nWhen Germany defaulted on its reparation payments, French and Belgian troops occupied the heavily industrialised Ruhr district (January 1923). The German government encouraged the population of the Ruhr to passive resistance: shops would not sell goods to the foreign soldiers, coal-mines would not dig for the foreign troops, trams in which members of the occupation army had taken seat would be left abandoned in the middle of the street. The passive resistance proved effective, insofar as the occupation became a loss-making deal for the French government. But the Ruhr fight also led to hyperinflation, and many who lost all their fortune would become bitter enemies of the Weimar Republic, and voters of the anti-democratic right. See 1920s German inflation.\n\nIn September 1923, the deteriorating economic conditions led Chancellor Gustav Stresemann to call an end to the passive resistance in the Ruhr. In November, his government introduced a new currency, the Rentenmark (later: Reichsmark), together with other measures to stop the hyperinflation. In the following six years the economic situation improved. In 1928, Germany's industrial production even regained the pre-war levels of 1913.\n\nThe national elections of 1924 led to a swing to the right. Field Marshal Paul von Hindenburg was elected President in 1925.\n\nIn October 1925 the Treaty of Locarno was signed by Germany, France, Belgium, Britain and Italy; it recognised Germany's borders with France and Belgium. Moreover, Britain, Italy and Belgium undertook to assist France in the case that German troops marched into the demilitarised Rheinland. Locarno paved the way for Germany's admission to the League of Nations in 1926.\n\nThe actual amount of reparations that Germany was obliged to pay out was not the 132 billion marks decided in the London Schedule of 1921 but rather the 50 million marks stipulated in the A and B Bonds. Historian Sally Marks says the 112 billion marks in \"C bonds\" were entirely chimerical—a device to fool the public into thinking Germany would pay much more. The actual total payout from 1920 to 1931 (when payments were suspended indefinitely) was 20 billion German gold marks, worth about $5 billion US dollars or £1 billion British pounds. 12.5 billion was cash that came mostly from loans from New York bankers. The rest was goods like coal and chemicals, or from assets like railway equipment. The reparations bill was fixed in 1921 on the basis of a German capacity to pay, not on the basis of Allied claims. The highly publicized rhetoric of 1919 about paying for all the damages and all the veterans' benefits was irrelevant for the total, but it did determine how the recipients spent their share. Germany owed reparations chiefly to France, Britain, Italy and Belgium; the US received $100 million.\n\nThe Wall Street Crash of 1929 marked the beginning of the worldwide Great Depression, which hit Germany as hard as any nation. In July 1931, the \"Darmstätter und Nationalbank\" – one of the biggest German banks – failed. In early 1932, the number of unemployed had soared to more than 6,000,000.\n\nOn top of the collapsing economy came a political crisis: the political parties represented in the \"Reichstag\" were unable to build a governing majority in the face of escalating extremism from the far right (the Nazis, NSDAP) and the far left (the Communists, KPD). In March 1930, President Hindenburg appointed Heinrich Brüning Chancellor. To push through his package of austerity measures against a majority of Social Democrats, Communists and the NSDAP (Nazis), Brüning made use of emergency decrees and dissolved Parliament. In March and April 1932, Hindenburg was re-elected in the German presidential election of 1932.\n\nThe Nazi Party was the largest party in the national elections of 1932. On 31 July 1932 it received 37.3% of the votes, and in the election on 6 November 1932 it received less, but still the largest share, 33.1%, making it the biggest party in the \"Reichstag\". The Communist KPD came third, with 15%. Together, the anti-democratic parties of far right and far left were now able to hold the majority of seats in Parliament, but they were at sword's point with each other, fighting it out in the streets. The Nazis were particularly successful among Protestants, among unemployed young voters, among the lower middle class in the cities and among the rural population. It was weakest in Catholic areas and in large cities. On 30 January 1933, pressured by former Chancellor Franz von Papen and other conservatives, President Hindenburg appointed Hitler as Chancellor.\n\nThe Weimar years saw a flowering of German science and high culture, before the Nazi regime resulted in a decline in the scientific and cultural life in Germany and forced many renowned scientists and writers to flee.\nGerman recipients dominated the Nobel prizes in science. Germany dominated the world of physics before 1933, led by Hermann von Helmholtz, Joseph von Fraunhofer, Daniel Gabriel Fahrenheit, Wilhelm Conrad Röntgen, Albert Einstein, Max Planck and Werner Heisenberg. Chemistry likewise was dominated by German professors and researchers at the great chemical companies such as BASF and Bayer and persons like Fritz Haber. Theoretical mathematicians included Carl Friedrich Gauss in the 19th century and David Hilbert in the 20th century. Carl Benz, the inventor of the automobile, was one of the pivotal figures of engineering.\n\nAmong the most important German writers were Thomas Mann (1875–1955), Hermann Hesse (1877–1962) and Bertolt Brecht (1898–1956). The pessimistic historian Oswald Spengler wrote \"The Decline of the West\" (1918–23) on the inevitable decay of Western Civilization, and influenced intellectuals in Germany such as Martin Heidegger, Max Scheler, and the Frankfurt School, as well as intellectuals around the world.\n\nAfter 1933, Nazi proponents of \"Aryan physics,\" led by the Nobel Prize-winners Johannes Stark and Philipp Lenard, attacked Einstein's theory of relativity as a degenerate example of Jewish materialism in the realm of science. Many scientists and humanists emigrated; Einstein moved permanently to the U.S. but some of the others returned after 1945.\n\nThe Nazi regime restored economic prosperity and ended mass unemployment using heavy spending on the military, while suppressing labor unions and strikes. The return of prosperity gave the Nazi Party enormous popularity, with only minor, isolated and subsequently unsuccessful cases of resistance among the German population over the 12 years of rule. The Gestapo (secret police) under Heinrich Himmler destroyed the political opposition and persecuted the Jews, trying to force them into exile, while taking their property. The Party took control of the courts, local government, and all civic organizations except the Protestant and Catholic churches. All expressions of public opinion were controlled by Hitler's propaganda minister, Joseph Goebbels, who made effective use of film, mass rallies, and Hitler's hypnotic speaking. The Nazi state idolized Hitler as its Führer (leader), putting all powers in his hands. Nazi propaganda centered on Hitler and was quite effective in creating what historians called the \"Hitler Myth\"—that Hitler was all-wise and that any mistakes or failures by others would be corrected when brought to his attention. In fact Hitler had a narrow range of interests and decision making was diffused among overlapping, feuding power centers; on some issues he was passive, simply assenting to pressures from whoever had his ear. All top officials reported to Hitler and followed his basic policies, but they had considerable autonomy on a daily basis.\n\nIn order to secure a majority for his Nazi Party in the \"Reichstag\", Hitler called for new elections. On the evening of 27 February 1933, a fire was set in the \"Reichstag\" building. Hitler swiftly blamed an alleged Communist uprising, and convinced President Hindenburg to sign the Reichstag Fire Decree. This decree, which would remain in force until 1945, repealed important political and human rights of the Weimar constitution. Communist agitation was banned, but at this time not the Communist Party itself.\n\nEleven thousand Communists and Socialists were arrested and brought into hastily prepared Nazi concentration camps such as Kemna concentration camp, where they were at the mercy of the Gestapo, the newly established secret police force (9,000 were found guilty and most executed). Communist \"Reichstag\" deputies were taken into protective custody (despite their constitutional privileges).\n\nDespite the terror and unprecedented propaganda, the last free General Elections of 5 March 1933, while resulting in 43.9% failed to bring the majority for the NSDAP that Hitler had hoped for. Together with the German National People's Party (DNVP), however, he was able to form a slim majority government. With accommodations to the Catholic Centre Party, Hitler succeeded in convincing a required two-thirds of a rigged Parliament to pass the Enabling act of 1933 which gave his government full legislative power. Only the Social Democrats voted against the Act. The Enabling Act formed the basis for the dictatorship, dissolution of the Länder; the trade unions and all political parties other than the Nazi Party were suppressed. A centralised totalitarian state was established, no longer based on the liberal Weimar constitution. Germany left the League of Nations. The coalition parliament was rigged on this fateful 23 March 1933 by defining the absence of arrested and murdered deputies as voluntary and therefore cause for their exclusion as wilful absentees. Subsequently, in July the Centre Party was voluntarily dissolved in a \"quid pro quo\" with the Pope under the \"anti-communist\" Pope Pius XI for the Reichskonkordat; and by these manoeuvres Hitler achieved movement of these Catholic voters into the Nazi party, and a long-awaited international diplomatic acceptance of his regime. It is interesting to note, however, that according to Professor Dick Geary the Nazis gained a larger share of their vote in Protestant areas than in Catholic areas, in the elections held between 1928 and November 1932. The Communist Party was proscribed in April 1933. On the weekend of 30 June 1934, he gave order to the SS to seize Röhm and his lieutenants, and to execute them without trial (known as the Night of the Long Knives). Upon Hindenburg's death on 2 August 1934, Hitler's cabinet passed a law proclaiming the presidency to be vacant and transferred the role and powers of the head of state to Hitler as Führer (Leader) and Chancellor.\nHowever, many leaders of the Nazi SA were disappointed. The Chief of Staff of the SA, Ernst Röhm, was pressing for the SA to be incorporated into the army. Hitler had long been at odds with Röhm and felt increasingly threatened by these plans and in the \"Night of the Long Knives\" in 1934 killed Röhm and the top SA leaders using their notorious homosexuality as an excuse.\n\nThe SS became an independent organisation under the command of the \"Reichsführer SS\" Heinrich Himmler. He would become the supervisor of the \"Gestapo\" and of the concentration camps, soon also of the ordinary police. Hitler also established the Waffen-SS as a separate troop.\n\nThe Nazi regime was particularly hostile towards Jews, who became the target of unending antisemitic propaganda attacks. The Nazis attempted to convince the German people to view and treat Jews as \"subhumans\" and immediately after winning almost 44% of parliamentary seats in the 1933 federal elections the Nazis imposed a nationwide boycott of Jewish businesses. On March 20, 1933 the first Nazi concentration camp was established at Dachau in Bavaria and from 1933 to 1935 the Nazi regime consolidated their power and imposed the Nuremberg Laws of 1935 which banned all Jews from civil service and academics positions. Jews lost their German citizenship, and a ban on sexual relations between people classified as \"Aryans\" and \"non-Aryans\" was created. Jews continued to suffer persecution under the Nazi regime, exemplified by the Kristallnacht pogrom of 1938, and about half of Germany's 500,000 Jews fled the country before 1939, after which escape became almost impossible.\n\nIn 1941, the Nazi leadership decided to implement a plan that they called the \"Final Solution\" which came to be known as the Holocaust. Under the plan, Jews and other \"lesser races\" along with political opponents from Germany as well as occupied countries were systematically murdered at murder sites, Nazi concentration camps, and starting in 1942, at extermination camps. Between 1941 and 1945 Jews, Gypsies, Slavs, communists, homosexuals, the mentally and physically disabled and members of other groups were targeted and methodically murdered in the largest genocide of the 20th century. In total approximately 11 million people were killed during the Holocaust including 1.1 million children.\n\nHitler re-established the Luftwaffe (air force) and reintroduced universal military service. This was in breach of the Treaty of Versailles; Britain, France and Italy issued notes of protest. Hitler had the officers swear their personal allegiance to him. In 1936 German troops marched into the demilitarised Rhineland. Britain and France did not intervene. The move strengthened Hitler's standing in Germany. His reputation swelled further with the 1936 Summer Olympics, which were held in the same year in Berlin, and which proved another great propaganda success for the regime as orchestrated by master propagandist Joseph Goebbels.\n\nHistorians have paid special attention to the efforts by Nazi Germany to reverse the gains women made before 1933, especially in the relatively liberal Weimar Republic. It appears the role of women in Nazi Germany changed according to circumstances. Theoretically the Nazis believed that women must be subservient to men, avoid careers, devote themselves to childbearing and child-rearing, and be a helpmate of the traditional dominant father in the traditional family. However, before 1933, women played important roles in the Nazi organization and were allowed some autonomy to mobilize other women. After Hitler came to power in 1933, the activist women were replaced by bureaucratic women who emphasized feminine virtues, marriage, and childbirth. As Germany prepared for war, large numbers were incorporated into the public sector and with the need for full mobilization of factories by 1943, all women were required to register with the employment office. Women's wages remained unequal and women were denied positions of leadership or control.\n\nIn 1944-45 more than 500,000 women were volunteer uniformed auxiliaries in the German armed forces (Wehrmacht). About the same number served in civil aerial defense, 400,000 volunteered as nurses, and many more replaced drafted men in the wartime economy. In the Luftwaffe they served in combat roles helping to operate the anti—aircraft systems that shot down Allied bombers.\n\nHitler's diplomatic strategy in the 1930s was to make seemingly reasonable demands, threatening war if they were not met. When opponents tried to appease him, he accepted the gains that were offered, then went to the next target. That aggressive strategy worked as Germany pulled out of the League of Nations (1933), rejected the Versailles Treaty and began to re-arm (1935), won back the Saar (1935), remilitarized the Rhineland (1936), formed an alliance (\"axis\") with Mussolini's Italy (1936), sent massive military aid to Franco in the Spanish Civil War (1936–39), seized Austria (1938), took over Czechoslovakia after the British and French \"appeasement\" of the Munich Agreement of 1938, formed a peace pact with Joseph Stalin's Soviet Union in August 1939, and finally invaded Poland in September 1939. Britain and France declared war and World War II began – somewhat sooner than the Nazis expected or were ready for.\n\nAfter establishing the \"Rome-Berlin axis\" with Benito Mussolini, and signing the Anti-Comintern Pact with Japan – which was joined by Italy a year later in 1937 – Hitler felt able to take the offensive in foreign policy. On 12 March 1938, German troops marched into Austria, where an attempted Nazi coup had been unsuccessful in 1934. When Austrian-born Hitler entered Vienna, he was greeted by loud cheers. Four weeks later, 99% of Austrians voted in favour of the annexation (Anschluss) of their country Austria to the German Reich. After Austria, Hitler turned to Czechoslovakia, where the 3.5 million-strong Sudeten German minority was demanding equal rights and self-government. At the Munich Conference of September 1938, Hitler, the Italian leader Benito Mussolini, British Prime Minister Neville Chamberlain and French Prime Minister Édouard Daladier agreed upon the cession of Sudeten territory to the German Reich by Czechoslovakia. Hitler thereupon declared that all of German Reich's territorial claims had been fulfilled. However, hardly six months after the Munich Agreement, in March 1939, Hitler used the smoldering quarrel between Slovaks and Czechs as a pretext for taking over the rest of Czechoslovakia as the Protectorate of Bohemia and Moravia. In the same month, he secured the return of Memel from Lithuania to Germany. Chamberlain was forced to acknowledge that his policy of appeasement towards Hitler had failed.\n\nAt first Germany's military moves were brilliantly successful, as in the \"blitzkrieg\" invasions of Poland (1939), Norway (1940), the Low Countries (1940), and above all the stunningly successful invasion and quick conquest of France in 1940. Hitler probably wanted peace with Britain in late 1940, but Prime Minister Winston Churchill, standing alone, was dogged in his defiance. Churchill had major financial, military, and diplomatic help from President Franklin D. Roosevelt in the U.S., another implacable foe of Hitler. Hitler's emphasis on maintaining high living standards postponed the full mobilization of the national economy until 1942, years after the great rivals Britain, Russia, and the U.S. had fully mobilized. Germany invaded the Soviet Union in June 1941 – weeks behind schedule – but swept forward until it reached the gates of Moscow.\nThe tide turned in December 1941, when the invasion of Russia stalled in cold weather and the United States joined the war. After surrender in North Africa and losing the Battle of Stalingrad in 1942–43, the Germans were on the defensive. By late 1944, the United States, Canada, France, and Great Britain were closing in on Germany in the West, while the Soviets were closing from the East. Overy estimated in 2014 that in all about 353,000 civilians were killed by British and American strategic bombing of German cities, and nine million left homeless.\n\nNazi Germany collapsed as Berlin was taken by the Red Army in a fight to the death on the city streets. Hitler committed suicide on 30 April 1945. Final German surrender was signed on 8 May 1945.\n\nBy September 1945, the Third Reich (which lasted only 12 years) and its Axis partners (Italy and Japan) had been defeated, chiefly by the forces of the Soviet Union, the United States, and Great Britain. Much of Europe lay in ruins, over 60 million people had been killed (most of them civilians), including approximately 6 million Jews and 5 million non-Jews in what became known as the Holocaust. World War II resulted in the destruction of Germany's political and economic infrastructure and led directly to its partition, considerable loss of territory (especially in the east), and historical legacy of guilt and shame.\n\nAs a consequence of the defeat of Nazi Germany in 1945 and the onset of the Cold War in 1947, the country was split between the two global blocs in the East and West, a period known as the division of Germany. Millions of refugees from Central and Eastern Europe moved west, most of them to West Germany. Two states emerged: West Germany was a parliamentary democracy, a NATO member, a founding member of what since became the European Union and one of the world's largest economies, while East Germany was a totalitarian Communist dictatorship that was a satellite of Moscow. With the collapse of Communism in 1989, reunion on West Germany's terms followed.\n\nNo one doubted Germany's economic and engineering prowess; the question was how long bitter memories of the war would cause Europeans to distrust Germany, and whether Germany could demonstrate it had rejected totalitarianism and militarism and embraced democracy and human rights.\n\nThe total of German war dead was 8% to 10% out of a prewar population of 69,000,000, or between 5.5 million and 7 million people. This included 4.5 million in the military, and between 1 and 2 million civilians. There was chaos as 11 million foreign workers and POWs left, while 14 million displaced refugees from the east and soldiers returned home. During the Cold War, the West German government estimated a death toll of 2.2 million civilians due to the flight and expulsion of Germans and through forced labour in the Soviet Union. This figure remained unchallenged until the 1990s, when some historians put the death toll at 500,000–600,000 confirmed deaths. In 2006 the German government reaffirmed its position that 2.0–2.5 million deaths occurred.\nAt the Potsdam Conference, Germany was divided into four military occupation zones by the Allies and did not regain independence until 1949. The provinces east of the Oder and Neisse rivers (the Oder-Neisse line) were transferred to Poland, Lithuania, and Russia (Kaliningrad oblast); the 6.7 million Germans living in Poland and the 2.5 million in Czechoslovakia were forced to move west, although most had already left when the war ended.\n\nDenazification removed, imprisoned, or executed most top officials of the old regime, but most middle and lower ranks of civilian officialdom were not seriously affected. In accordance with the Allied agreement made at the Yalta conference millions of POWs were used as forced labor by the Soviet Union and other European countries.\n\nIn the East, the Soviets crushed dissent and imposed another police state, often employing ex-Nazis in the dreaded Stasi. The Soviets extracted about 23% of the East German GNP for reparations, while in the West reparations were a minor factor.\n\nIn 1945–46 housing and food conditions were bad, as the disruption of transport, markets, and finances slowed a return to normal. In the West, bombing had destroyed the fourth of the housing stock, and over 10 million refugees from the east had crowded in, most living in camps. Food production in 1946–48 was only two-thirds of the prewar level, while grain and meat shipments – which usually supplied 25% of the food – no longer arrived from the East. Furthermore, the end of the war brought the end of large shipments of food seized from occupied nations that had sustained Germany during the war. Coal production was down 60%, which had cascading negative effects on railroads, heavy industry, and heating. Industrial production fell more than half and reached prewar levels only at the end of 1949.\n\nAllied economic policy originally was one of industrial disarmament plus building the agricultural sector. In the western sectors, most of the industrial plants had minimal bomb damage and the Allies dismantled 5% of the industrial plants for reparations.\n\nHowever, deindustrialization became impractical and the U.S. instead called for a strong industrial base in Germany so it could stimulate European economic recovery. The U.S. shipped food in 1945–47 and made a $600 million loan in 1947 to rebuild German industry. By May 1946 the removal of machinery had ended, thanks to lobbying by the U.S. Army. The Truman administration finally realised that economic recovery in Europe could not go forward without the reconstruction of the German industrial base on which it had previously been dependent. Washington decided that an \"orderly, prosperous Europe requires the economic contributions of a stable and productive Germany.\"\n\nIn 1945 the occupying powers took over all newspapers in Germany and purged them of Nazi influence. The American occupation headquarters, the Office of Military Government, United States (OMGUS) began its own newspaper based in Munich, \"Die Neue Zeitung.\" It was edited by German and Jewish émigrés who fled to the United States before the war. Its mission was to encourage democracy by exposing Germans to how American culture operated. The paper was filled with details on American sports, politics, business, Hollywood, and fashions, as well as international affairs.\n\nIn 1949 the Soviet zone became the \"Deutsche Demokratische Republik\" – \"DDR\" (\"German Democratic Republic\" – \"GDR\", simply often \"East Germany\"), under control of the Socialist Unity Party. Neither country had a significant army until the 1950s, but East Germany built the Stasi into a powerful secret police that infiltrated every aspect of the society.\n\nEast Germany was an Eastern bloc state under political and military control of the Soviet Union through her occupation forces and the Warsaw Treaty. Political power was solely executed by leading members (\"Politburo\") of the communist-controlled Socialist Unity Party (SED). A Soviet-style command economy was set up; later the GDR became the most advanced Comecon state. While East German propaganda was based on the benefits of the GDR's social programs and the alleged constant threat of a West German invasion, many of her citizens looked to the West for political freedoms and economic prosperity.\n\nWalter Ulbricht (1893–1973) was the party boss from 1950 to 1971. In 1933, Ulbricht had fled to Moscow, where he served as a Comintern agent loyal to Stalin. As World War II was ending, Stalin assigned him the job of designing the postwar German system that would centralize all power in the Communist Party. Ulbricht became deputy prime minister in 1949 and secretary (chief executive) of the Socialist Unity (Communist) party in 1950. Some 2.6 million people had fled East Germany by 1961 when he built the Berlin Wall to stop them — shooting those who attempted it. What the GDR called the \"Anti-Fascist Protective Wall\" was a major embarrassment for the program during the Cold War, but it did stabilize East Germany and postpone its collapse. Ulbricht lost power in 1971, but was kept on as a nominal head of state. He was replaced because he failed to solve growing national crises, such as the worsening economy in 1969–70, the fear of another popular uprising as had occurred in 1953, and the disgruntlement between Moscow and Berlin caused by Ulbricht's détente policies toward the West.\n\nThe transition to Erich Honecker (General Secretary from 1971 to 1989) led to a change in the direction of national policy and efforts by the Politburo to pay closer attention to the grievances of the proletariat. Honecker's plans were not successful, however, with the dissent growing among East Germany's population.\n\nIn 1989, the socialist regime collapsed after 40 years, despite its omnipresent secret police, the Stasi. Main reasons for the collapse include severe economic problems and growing emigration towards the West.\n\nEast Germany's culture was shaped by Communism and particularly Stalinism. It was characterized by East German psychoanalyst Hans-Joachim Maaz in 1990 as having produced a \"Congested Feeling\" among Germans in the East as a result of Communist policies criminalizing personal expression that deviates from government approved ideals, and through the enforcement of Communist principals by physical force and intellectual repression by government agencies, particularly the Stasi. Critics of the East German state have claimed that the state's commitment to communism was a hollow and cynical tool of a ruling elite. This argument has been challenged by some scholars who claim that the Party was committed to the advance of scientific knowledge, economic development, and social progress. However, the vast majority regarded the state's Communist ideals to be nothing more than a deceptive method for government control.\n\nAccording to German historian Jürgen Kocka (2010):\n\nIn 1949, the three western occupation zones (American, British, and French) were combined into the Federal Republic of Germany (FRG, West Germany). The government was formed under Chancellor Konrad Adenauer and his conservative CDU/CSU coalition. The CDU/CSU was in power during most of the period since 1949. The capital was Bonn until it was moved to Berlin in 1990. In 1990 FRG absorbed East Germany and gained full sovereignty over Berlin. At all points West Germany was much larger and richer than East Germany, which became a dictatorship under the control of the Communist Party and was closely monitored by Moscow. Germany, especially Berlin, was a cockpit of the Cold War, with NATO and the Warsaw Pact assembling major military forces in west and east. However, there was never any combat.\n\nWest Germany enjoyed prolonged economic growth beginning in the early 1950s (\"Wirtschaftswunder\" or \"Economic Miracle\"). Industrial production doubled from 1950 to 1957, and gross national product grew at a rate of 9 or 10% per year, providing the engine for economic growth of all of Western Europe. Labor union supported the new policies with postponed wage increases, minimized strikes, support for technological modernization, and a policy of co-determination (\"Mitbestimmung\"), which involved a satisfactory grievance resolution system as well as requiring representation of workers on the boards of large corporations. The recovery was accelerated by the currency reform of June 1948, U.S. gifts of $1.4 billion as part of the Marshall Plan, the breaking down of old trade barriers and traditional practices, and the opening of the global market. West Germany gained legitimacy and respect, as it shed the horrible reputation Germany had gained under the Nazis.\n\nWest Germany played a central role in the creation of European cooperation; it joined NATO in 1955 and was a founding member of the European Economic Community in 1958.\n\nThe most dramatic and successful policy event was the currency reform of 1948. Since the 1930s, prices and wages had been controlled, but money had been plentiful. That meant that people had accumulated large paper assets, and that official prices and wages did not reflect reality, as the black market dominated the economy and more than half of all transactions were taking place unofficially. On 21 June 1948, the Western Allies withdrew the old currency and replaced it with the new Deutsche Mark at the rate of 1 new per 10 old. This wiped out 90% of government and private debt, as well as private savings. Prices were decontrolled, and labor unions agreed to accept a 15% wage increase, despite the 25% rise in prices. The result was that prices of German export products held steady, while profits and earnings from exports soared and were poured back into the economy. The currency reforms were simultaneous with the $1.4 billion in Marshall Plan money coming in from the United States, which was used primarily for investment.\n\nIn addition, the Marshall Plan forced German companies, as well as those in all of Western Europe, to modernize their business practices and take account of the international market. Marshall Plan funding helped overcome bottlenecks in the surging economy caused by remaining controls (which were removed in 1949), and Marshall Plan business reforms opened up a greatly expanded market for German exports. Overnight, consumer goods appeared in the stores, because they could be sold for realistic prices, emphasizing to Germans that their economy had turned a corner.\n\nThe success of the currency reform angered the Soviets, who cut off all road, rail, and canal links between the western zones and West Berlin. This was the Berlin Blockade, which lasted from 24 June 1948 to 12 May 1949. In response, the U.S. and Britain launched an airlift of food and coal and distributed the new currency in West Berlin as well. The city thereby became economically integrated into West Germany.\n\nKonrad Adenauer (1876–1967) was the dominant leader in West Germany. He was the first chancellor (top official) of the FRG, 1949–63, and until his death was the founder and leader of the Christian Democratic Union (CDU), a coalition of conservatives, ordoliberals, and adherents of Protestant and Catholic social teaching that dominated West Germany politics for most of its history. During his chancellorship, the West Germany economy grew quickly, and West Germany established friendly relations with France, participated in the emerging European Union, established the country's armed forces (the \"Bundeswehr\"), and became a pillar of NATO as well as firm ally of the United States. Adenauer's government also commenced the long process of reconciliation with the Jews and Israel after the Holocaust.\n\nLudwig Erhard (1897–1977) was in charge of economic policy as economics director for the British and American occupation zones and was Adenauer's long-time economics minister. Erhard's decision to lift many price controls in 1948 (despite opposition from both the social democratic opposition and Allied authorities), plus his advocacy of free markets, helped set the Federal Republic on its strong growth from wartime devastation. Norbert Walter, a former chief economist at Deutsche Bank, argues that \"Germany owes its rapid economic advance after World War II to the system of the Social Market Economy, established by Ludwig Erhard.\" Erhard was politically less successful when he served as the CDU Chancellor from 1963 until 1966. Erhard followed the concept of a social market economy, and was in close touch with professional economists. Erhard viewed the market itself as social and supported only a minimum of welfare legislation. However, Erhard suffered a series of decisive defeats in his effort to create a free, competitive economy in 1957; he had to compromise on such key issues as the anti-cartel legislation. Thereafter, the West German economy evolved into a conventional west European welfare state.\n\nMeanwhile, in adopting the Godesberg Program in 1959, the Social Democratic Party of Germany (SPD) largely abandoned Marxism ideas and embraced the concept of the market economy and the welfare state. Instead it now sought to move beyond its old working class base to appeal the full spectrum of potential voters, including the middle class and professionals. Labor unions cooperated increasingly with industry, achieving labor representation on corporate boards and increases in wages and benefits.\n\nIn 1966 Erhard lost support and Kurt Kiesinger (1904–1988) was elected as Chancellor by a new CDU/CSU-SPD alliance combining the two largest parties. Socialist (SPD) leader Willy Brandt was Deputy Federal Chancellor and Foreign Minister. The Grand Coalition lasted 1966–69 and is best known for reducing tensions with the Soviet bloc nations and establishing diplomatic relations with Czechoslovakia, Romania and Yugoslavia.\n\nWith a booming economy short of unskilled workers, especially after the Berlin Wall cut off the steady flow of East Germans, the FRG negotiated migration agreements with Italy (1955), Spain (1960), Greece (1960), and Turkey (1961) that brought in hundreds of thousands of temporary guest workers, called \"Gastarbeiter\". In 1968 the FRG signed a guest worker agreement with Yugoslavia that employed additional guest workers. \"Gastarbeiter\" were young men who were paid full-scale wages and benefits, but were expected to return home in a few years.\n\nThe agreement with Turkey ended in 1973 but few workers returned because there were few good jobs in Turkey. By 2010 there were about 4 million people of Turkish descent in Germany. The generation born in Germany attended German schools, but had a poor command of either German or Turkish, and had either low-skilled jobs or were unemployed.\n\nWilly Brandt (1913–1992) was the leader of the Social Democratic Party in 1964–87 and West German Chancellor in 1969–1974. Under his leadership, the German government sought to reduce tensions with the Soviet Union and improve relations with the German Democratic Republic, a policy known as the \"Ostpolitik\". Relations between the two German states had been icy at best, with propaganda barrages in each direction. The heavy outflow of talent from East Germany prompted the building of the Berlin Wall in 1961, which worsened Cold War tensions and prevented East Germans from travel. Although anxious to relieve serious hardships for divided families and to reduce friction, Brandt's \"Ostpolitik\" was intent on holding to its concept of \"two German states in one German nation.\"\n\n\"Ostpolitik\" was opposed by the conservative elements in Germany, but won Brandt an international reputation and the Nobel Peace Prize in 1971. In September 1973, both West and East Germany were admitted to the United Nations. The two countries exchanged permanent representatives in 1974, and, in 1987, East Germany's leader Erich Honecker paid an official state visit to West Germany.\n\nAfter 1973, Germany was hard hit by a worldwide economic crisis, soaring oil prices, and stubbornly high unemployment, which jumped from 300,000 in 1973 to 1.1 million in 1975. The Ruhr region was hardest hit, as its easy-to-reach coal mines petered out, and expensive German coal was no longer competitive. Likewise the Ruhr steel industry went into sharp decline, as its prices were undercut by lower-cost suppliers such as Japan. The welfare system provided a safety net for the large number of unemployed workers, and many factories reduce their labor force and began to concentrate on high-profit specialty items. After 1990 the Ruhr moved into service industries and high technology. Cleaning up the heavy air and water pollution became a major industry in its own right. Meanwhile, formerly rural Bavaria became a high-tech center of industry.\n\nA spy scandal forced Brandt to step down as Chancellor while remaining as party leader. He was replaced by Helmut Schmidt (b. 1918), of the SPD, who served as Chancellor in 1974–1982. Schmidt continued the \"Ostpolitik\" with less enthusiasm. He had a PhD in economics and was more interested in domestic issues, such as reducing inflation. The debt grew rapidly as he borrowed to cover the cost of the ever more expensive welfare state. After 1979, foreign policy issues grew central as the Cold War turned hot again. The German peace movement mobilized hundreds of thousands of demonstrators to protest against American deployment in Europe of new medium-range ballistic missiles. Schmidt supported the deployment but was opposed by the left wing of the SPD and by Brandt.\n\nThe pro-business Free Democratic Party (FDP) had been in coalition with the SPD, but now it changed direction. Led by Finance Minister Otto Graf Lambsdorff (1926–2009) the FDP adopted the market-oriented \"Kiel Theses\" in 1977; it rejected the Keynesian emphasis on consumer demand, and proposed to reduce social welfare spending, and try to introduce policies to stimulate production and facilitate jobs. Lambsdorff argued that the result would be economic growth, which would itself solve both the social problems and the financial problems. As a consequence, the FDP switched allegiance to the CDU and Schmidt lost his parliamentary majority in 1982. For the only time in West Germany's history, the government fell on a vote of no confidence.\n\nHelmut Kohl (b. 1930) brought the conservatives back to power with a CDU/CSU-FDP coalition in 1982, and served as Chancellor until 1998. After repeated victories in 1983, 1987, 1990 and 1994 he was finally defeated by a landslide that was the biggest on record, for the left in the 1998 federal elections, and was succeeded as Chancellor by Gerhard Schröder of the SPD. Kohl is best known for orchestrating reunification with the approval of all the Four Powers from World War II, who still had a voice in German affairs.\n\nDuring the summer of 1989, rapid changes known as \"peaceful revolution\" or \"Die Wende\" took place in East Germany, which quickly led to German reunification. Growing numbers of East Germans emigrated to West Germany, many via Hungary after Hungary's reformist government opened its borders. Thousands of East Germans also tried to reach the West by staging sit-ins at West German diplomatic facilities in other East European capitals, most notably in Prague. The exodus generated demands within East Germany for political change, and mass demonstrations in several cities continued to grow.\n\nUnable to stop the growing civil unrest, Erich Honecker was forced to resign in October, and on 9 November, East German authorities unexpectedly allowed East German citizens to enter West Berlin and West Germany. Hundreds of thousands of people took advantage of the opportunity; new crossing points were opened in the Berlin Wall and along the border with West Germany. This led to the acceleration of the process of reforms in East Germany that ended with the German reunification that came into force on 3 October 1990.\n\nThe SPD in coalition with the Greens won the elections of 1998. SPD leader Gerhard Schröder positioned himself as a centrist \"Third Way\" candidate in the mold of Britain's Tony Blair and America's Bill Clinton.\n\nSchröder, in March 2003, reversed his position and proposed a significant downsizing of the welfare state, known as Agenda 2010. He had enough support to overcome opposition from the trade unions and the SPD's left wing. Agenda 2010 had five goals: tax cuts; labor market deregulation, especially relaxing rules protecting workers from dismissal and setting up Hartz concept job training; modernizing the welfare state by reducing entitlements; decreasing bureaucratic obstacles for small businesses; and providing new low-interest loans to local governments.\n\nFrom 2005 to 2009, Germany was ruled by a grand coalition led by the CDU's Angela Merkel as chancellor. Since the 2009 elections, Merkel has headed a centre-right government of the CDU/CSU and FDP.\n\nTogether with France and other EU states, Germany has played the leading role in the European Union. Germany (especially under Chancellor Helmut Kohl) was one of the main supporters of admitting many East European countries to the EU. Germany is at the forefront of European states seeking to exploit the momentum of monetary union to advance the creation of a more unified and capable European political, defence and security apparatus. German Chancellor Schröder expressed an interest in a permanent seat for Germany in the UN Security Council, identifying France, Russia, and Japan as countries that explicitly backed Germany's bid. Germany formally adopted the Euro on 1 January 1999 after permanently fixing the Deutsche Mark rate on 21 December 1998.\n\nSince 1990, the German Bundeswehr has participated in a number of peacekeeping and disaster relief operations abroad. Since 2002, German troops formed part of the International Security Assistance Force in the war in Afghanistan, resulting in the first German casualties in combat missions since World War II.\n\nIn the worldwide economic recession that began in 2008, Germany did relatively well. However, the economic instability of Greece and several other EU nations in 2010–11 forced Germany to reluctantly sponsor a massive financial rescue.\n\nIn the wake of the disaster to the nuclear industry in Japan following its 2011 earthquake and tsunami, German public opinion turned sharply against nuclear power in Germany, which produces a fourth of the electricity supply. In response Merkel has announced plans to close down the nuclear system over the next decade, and to rely even more heavily on wind and other alternative energy sources, in addition to coal and natural gas. For further information, see Germany in 2011.\n\nA major historiographical debate about the German history concerns the \"Sonderweg\", the alleged \"special path\" that separated German history from the normal course of historical development, and whether or not Nazi Germany was the inevitable result of the \"Sonderweg\". Proponents of the \"Sonderweg\" theory such as Fritz Fischer point to such events of the Revolution of 1848, the authoritarianism of the Second Empire and the continuation of the Imperial elite into the Weimar and Nazi periods. Opponents such as Gerhard Ritter of the \"Sonderweg\" theory argue that proponents of the theory are guilty of seeking selective examples, and there was much contingency and chance in German history. In addition, there was much debate within the supporters of the \"Sonderweg\" concept as for the reasons for the \"Sonderweg\", and whether or not the \"Sonderweg\" ended in 1945. Was there a Sonderweg? Winkler says:\n\n\n\n\n\n\n\n\n\n\n\n", "id": "13224", "title": "History of Germany"}
{"url": "https://en.wikipedia.org/wiki?curid=13225", "text": "Hades\n\nHades (; or , \"Háidēs\") was the ancient Greek chthonic god of the underworld, which eventually took his name.\n\nIn Greek mythology, Hades was regarded as the oldest son of Cronus and Rhea, although the last son regurgitated by his father. He and his brothers Zeus and Poseidon defeated their father's generation of gods, the Titans, and claimed rulership over the cosmos. Hades received the underworld, Zeus the sky, and Poseidon the sea, with the solid earth—long the province of Gaia—available to all three concurrently. Hades was often portrayed with his three-headed guard dog Cerberus.\n\nThe Etruscan god Aita and Roman gods Dis Pater and Orcus were eventually taken as equivalent to the Greek Hades and merged as Pluto, a Latinization of his euphemistic Greek name Plouton.\n\nThe origin of Hades' name is uncertain, but has generally been seen as meaning \"The Unseen One\" since antiquity. An extensive section of Plato's dialogue \"Cratylus\" is devoted to the etymology of the god's name, in which Socrates is arguing for a folk etymology not from \"unseen\" but from \"his knowledge (\"eidenai\") of all noble things\". Modern linguists have proposed the Proto-Greek form *\"Awides\" (\"unseen\"). The earliest attested form is \"Aḯdēs\" (), which lacks the proposed digamma. West argues instead for an original meaning of \"the one who presides over meeting up\" from the universality of death.\n\nIn Homeric and Ionic Greek, he was known as \"Áïdēs\". Other poetic variations of the name include \"Aïdōneús\" () and the inflected forms \"Áïdos\" (, gen.), \"Áïdi\" (, dat.), and \"Áïda\" (, acc.), whose reconstructed nominative case *\"Áïs\" () is, however, not attested. The name as it came to be known in classical times was \"Háidēs\" (). Later the iota became silent, then a subscript marking (), and finally omitted entirely (). \n\nPerhaps from fear of pronouncing his name, around the 5th century BC, the Greeks started referring to Hades as Pluto (, \"Ploútōn\"), with a root meaning \"wealthy\", considering that from the abode below (i.e., the soil) come riches (e.g., fertile crops, metals and so on). Plouton became the Roman god who both rules the underworld and distributed riches from below. This deity was a mixture of the Greek god Hades and the Eleusinian icon Ploutos, and from this he also received a priestess, which was not previously practiced in Greece. More elaborate names of the same genre were \"Ploutodótēs\" () or \"Ploutodotḗr\" () meaning \"giver of wealth\". Epithets of Hades include \"Agesander\" () and \"Agesilaos\" (), both from \"ágō\" (, \"lead\", \"carry\" or \"fetch\") and \"anḗr\" (, \"man\") or \"laos\" (, \"men\" or \"people\"), describing Hades as the god who carries away all. Nicander uses the form \"Hegesilaus\" (). He was also referred to as \"Zeus Katachthonios (\"Ζευς καταχθονιος), meaning \"the Zeus of the Underworld\", by those avoiding his actual name, as he had complete control over the Underworld.\n\nIn Greek mythology, Hades the god of the underworld, was a son of the Titans Cronus and Rhea. He had three sisters, Demeter, Hestia, and Hera, as well as two brothers, Zeus, the youngest of the three, and Poseidon.\nUpon reaching adulthood, Zeus managed to force his father to disgorge his siblings. After their release, the six younger gods, along with allies they managed to gather, challenged the elder gods for power in the Titanomachy, a divine war. The war lasted for ten years and ended with the victory of the younger gods. Following their victory, according to a single famous passage in the \"Iliad\" (xv.187–93), Hades and his two brothers, Poseidon and Zeus, drew lots for realms to rule. Zeus received the sky, Poseidon received the seas, and Hades received the underworld, the unseen realm to which the souls of the dead go upon leaving the world as well as any and all things beneath the earth. Some myths suggest that Hades was dissatisfied with his turnout, but had no choice and moved to his new realm.\n\nHades obtained his wife and queen, Persephone, through abduction at the behest of Zeus. This myth is the most important one Hades takes part in; it also connected the Eleusinian Mysteries with the Olympian pantheon, particularly as represented in the \"Homeric Hymn to Demeter\", which is the oldest story of the abduction, most likely dating back to the beginning of the 6th Century BC. Helios told the grieving Demeter that Hades was not unworthy as a consort for Persephone:\n\n\"Aidoneus, the Ruler of Many, is no unfitting husband among the deathless gods for your child, being your own brother and born of the same stock: also, for honor, he has that third share which he received when division was made at the first, and is appointed lord of those among whom he dwells.\"\n\nDespite modern connotations of death as evil, Hades was actually more altruistically inclined in mythology. Hades was often portrayed as passive rather than evil; his role was often maintaining relative balance. However he was depicted as cold, stern, and gave all his subjects equal treatment in regards to his laws. Any other individual aspects of his personality are not given, as Greeks refrained from giving him much thought to avoid attracting his attention. \n\nHades ruled the dead, assisted by others over whom he had complete authority. The House of Hades was described as full of \"guests,\" though he rarely left the Underworld. He cared little about what happened in the Upperworld, as his primary attention was ensuring none of his subjects ever left. He strictly forbade his subjects to leave his domain and would become quite enraged when anyone tried to leave, or if someone tried to steal the souls from his realm. His wrath was equally terrible for anyone who tried to cheat death or otherwise crossed him, as Sisyphus and Pirithous found out to their sorrow. While usually indifferent to his subjects, Hades was very focused on the punishment of these two people; particularly Pirithous, as he entered the underworld in an attempt to steal Persephone for himself, and consequently was forced onto the \"Chair of Forgetfulness\". Another myth is about the Roman god Asclepius who was originally a demigod, fathered by Apollo and birthed by Coronis, a Thessalian princess. During his lifetime, he became a famous and talented physician, who eventually was able to bring the dead back to life. Feeling cheated, Plouton persuaded Zeus to kill him with a thunderbolt. After his death, he was brought to Olympus where he became a god. Hades was only depicted outside of the Underworld once in myth, and even that is believed to have been an instance where he had just left the gates of the Underworld, which was when Heracles shot him with an arrow as Hades was attempting to defend the city of Plyus. After he was shot, however, he traveled to Olympus to heal. Besides Heracles, the only other living people who ventured to the Underworld were all heroes: Odysseus, Aeneas (accompanied by the Sibyl), Orpheus, who Hades showed uncharacteristic mercy towards at Persephone's persuasion, who was moved by Orpheus' music, Theseus with Pirithous, and, in a late romance, Psyche. None of them were pleased with what they witnessed in the realm of the dead. In particular, the Greek war hero Achilles, whom Odysseus conjured with a blood libation, said:\n\"O shining Odysseus, never try to console me for dying.<br>\nI would rather follow the plow as thrall to another<br>\nman, one with no land allotted to him and not much to live on,<br>\nthan be a king over all the perished dead.\"\n\nHades, as the god of the dead, was a fearsome figure to those still living; in no hurry to meet him, they were reluctant to swear oaths in his name, and averted their faces when sacrificing to him. Since to many, simply to say the word \"Hades\" was frightening, euphemisms were pressed into use. Since precious minerals come from under the earth (i.e., the \"underworld\" ruled by Hades), he was considered to have control of these as well, and was referred to as Πλούτων (\"Plouton\", related to the word for \"wealth\"), Latinized as Pluto. Sophocles explained referring to Hades as \"the rich one\" with these words: \"the gloomy Hades enriches himself with our sighs and our tears.\" In addition, he was called Clymenus (\"notorious\"), Polydegmon (\"who receives many\"), and perhaps Eubuleus (\"good counsel\" or \"well-intentioned\"), all of them euphemisms for a name that was unsafe to pronounce, which evolved into epithets.\n\nHe spent most of the time in his dark realm. Formidable in battle, he proved his ferocity in the famous Titanomachy, the battle of the Olympians versus the Titans, which established the rule of Zeus.\n\nFeared and loathed, Hades embodied the inexorable finality of death: \"Why do we loathe Hades more than any god, if not because he is so adamantine and unyielding?\" The rhetorical question is Agamemnon's. He was not, however, an evil god, for although he was stern, cruel, and unpitying, he was still just. Hades ruled the Underworld and was therefore most often associated with death and feared by men, but he was not Death itself — the actual embodiment of Death was Thanatos.\n\nWhen the Greeks propitiated Hades, they banged their hands on the ground to be sure he would hear them. Black animals, such as sheep, were sacrificed to him, and the very vehemence of the rejection of human sacrifice expressed in myth suggests an unspoken memory of some distant past. The blood from all chthonic sacrifices including those to propitiate Hades dripped into a pit or cleft in the ground. The person who offered the sacrifice had to avert his face.\n\nOne ancient source says that he possessed the Cap of invisibility. His chariot, drawn by four black horses, made for a fearsome and impressive sight. His other ordinary attributes were the narcissus and cypress plants, the Key of Hades and Cerberus, the three-headed dog.\n\nThe philosopher Heraclitus, unifying opposites, declared that Hades and Dionysus, the very essence of indestructible life \"(zoë)\", are the same god. Among other evidence Kerényi notes that the grieving goddess Demeter refused to drink wine, which is the gift of Dionysus, after Persephone's abduction, because of this association, and suggests that Hades may in fact have been a \"cover name\" for the underworld Dionysus. He suggests that this dual identity may have been familiar to those who came into contact with the Mysteries. One of the epithets of Dionysus was \"Chthonios\", meaning \"the subterranean\".\n\n Hades was depicted so infrequently in artwork, as well as mythology, because the Greeks were so afraid of him. His artistic representations, which are generally found in Archaic pottery, are not even concretely thought of as the deity; however at this point in time it is heavily believed that the figures illustrated are indeed Hades. He was later presented in the classical arts in the depictions of the Rape of Persephone. Within these illustrations, Hades was often young, yet he was also shown as varying ages in other works. Due to this lack of depictions, there weren't very strict guidelines when representing the deity. On pottery, he has a dark beard and is presented as a stately figure on an \"ebony throne.\" His attributes in art include a scepter, cornucopia, rooster. and a key, which both represented his control over the underworld and acted as a reminder that the gates of the Underworld were always locked so that souls could not leave. Even if the doors were open, Cerberus, the three-headed guard dog of the Underworld, ensured that while all souls were allowed to enter into The Underworld freely, none could ever escape. The dog is often portrayed next to the god as a means of easy identification, since no other deity relates to it so directly. Sometimes, artists painted Hades as looking away from the other gods, as he was disliked by them as well as humans.\n\nAs Plouton, he was regarded in a more positive light. He holds a cornucopia, representing the gifts he bestows upon people as well as fertility, which he becomes connected to.\nThe consort of Hades was Persephone, represented by the Greeks as the beautiful daughter of Demeter.\n\nPersephone did not submit to Hades willingly, but was abducted by him while picking flowers in the fields of Nysa. In protest of his act, Demeter cast a curse on the land and there was a great famine; though, one by one, the gods came to request she lift it, lest mankind perish, she asserted that the earth would remain barren until she saw her daughter again. Finally, Zeus intervened; via Hermes, he requested that Hades return Persephone. Hades complied,\n\"But he on his part secretly gave her sweet pomegranate seed to eat, taking care for himself that she might not remain continually with grave, dark-robed Demeter.\"\n\nDemeter questioned Persephone on her return to light and air:\n\n\"...but if you have tasted food, you must go back again beneath the secret places of the earth, there to dwell a third part of the seasons every year: yet for the two parts you shall be with me and the other deathless gods.\"\n\nThis bound her to Hades and the Underworld, much to the dismay of Demeter. It is not clear whether Persephone was accomplice to the ploy. Zeus proposed a compromise, to which all parties agreed: of the year, Persephone would spend one third with her husband.\n\nIt is during this time that winter casts on the earth \"an aspect of sadness and mourning.\"\n\nTheseus and Pirithous pledged to kidnap and marry daughters of Zeus. Theseus chose Helen and together they kidnapped her and decided to hold onto her until she was old enough to marry. Pirithous chose Persephone. They left Helen with Theseus' mother, Aethra and traveled to the Underworld. Hades knew of their plan to capture his wife, so he pretended to offer them hospitality and set a feast; as soon as the pair sat down, snakes coiled around their feet and held them there. Theseus was eventually rescued by Heracles but Pirithous remained trapped as punishment for daring to seek the wife of a god for his own.\n\nHeracles' final labour was to capture Cerberus. First, Heracles went to Eleusis to be initiated into the Eleusinian Mysteries. He did this to absolve himself of guilt for killing the centaurs and to learn how to enter and exit the underworld alive. He found the entrance to the underworld at Taenarum. Athena and Hermes helped him through and back from Hades. Heracles asked Hades for permission to take Cerberus. Hades agreed as long as Heracles didn't harm Cerberus. When Heracles dragged the dog out of Hades, he passed through the cavern Acherusia.\n\nThe nymph Minthe, associated with the river Cocytus, loved by Hades, was turned into the mint plant, by a jealous Persephone.\n\nIn older Greek myths, the realm of Hades is the misty and gloomy abode of the dead (also called Erebus), where all mortals go. Very few mortals could leave Hades once they entered. The exceptions, Heracles and Theseus, are heroic. Even Odysseus in his \"Nekyia\" (\"Odyssey\", xi) calls up the spirits of the departed, rather than descend to them. Later Greek philosophy introduced the idea that all mortals are judged after death and are either rewarded or cursed.\n\nThere were several sections of the realm of Hades, including Elysium, the Asphodel Meadows, and Tartarus. Greek mythographers were not perfectly consistent about the geography of the afterlife. A contrasting myth of the afterlife concerns the Garden of the Hesperides, often identified with the Isles of the Blessed, where the blessed heroes may dwell.\n\nIn Roman mythology, the entrance to the Underworld located at Avernus, a crater near Cumae, was the route Aeneas used to descend to the realm of the dead. By synecdoche, \"Avernus\" could be substituted for the underworld as a whole. The \"di inferi\" were a collective of underworld divinities.\n\nFor Hellenes, the deceased entered the underworld by crossing the Styx, ferried across by Charon kair'-on), who charged an \"obolus,\" a small coin for passage placed in the mouth of the deceased by pious relatives. Paupers and the friendless gathered for a hundred years on the near shore according to Book VI of Vergil's Aeneid. Greeks offered propitiatory libations to prevent the deceased from returning to the upper world to \"haunt\" those who had not given them a proper burial. The far side of the river was guarded by Cerberus, the three-headed dog defeated by Heracles (Roman Hercules). Passing beyond Cerberus, the shades of the departed entered the land of the dead to be judged.\n\nThe five rivers of the realm of Hades, and their symbolic meanings, are Acheron (the river of sorrow, or woe), Cocytus (lamentation), Phlegethon (fire), Lethe (oblivion), and Styx (hate), the river upon which even the gods swore and in which Achilles was dipped to render him invincible. The Styx forms the boundary between the upper and lower worlds. See also Eridanos.\n\nThe first region of Hades comprises the Fields of Asphodel, described in \"Odyssey\" xi, where the shades of heroes wander despondently among lesser spirits, who twitter around them like bats. Only libations of blood offered to them in the world of the living can reawaken in them for a time the sensations of humanity.\n\nBeyond lay Erebus, which could be taken for a euphonym of Hades, whose own name was dread. There were two pools, that of Lethe, where the common souls flocked to erase all memory, and the pool of Mnemosyne (\"memory\"), where the initiates of the Mysteries drank instead. In the forecourt of the palace of Hades and Persephone sit the three judges of the Underworld: Minos, Rhadamanthus, and Aeacus. There at the trivium sacred to Hecate, where three roads meet, souls are judged, returned to the Fields of Asphodel if they are neither virtuous nor evil, sent by the road to Tartarus if they are impious or evil, or sent to Elysium (Islands of the Blessed) with the \"blameless\" heroes.\n\nIn the Sibylline oracles, a curious hodgepodge of Greco-Roman and Judaeo-Christian elements, Hades again appears as the abode of the dead, and by way of folk etymology, it even derives \"Hades\" from the name Adam (the first man), saying it is because he was the first to enter there. Owing to its appearance in the New Testament of the Bible, \"Hades\" also has a distinct meaning in Christianity.\n\n\n", "id": "13225", "title": "Hades"}
{"url": "https://en.wikipedia.org/wiki?curid=13236", "text": "GNU Hurd\n\nGNU Hurd (usually referred to as The Hurd or just Hurd) is the multiserver microkernel written as part of GNU. It has been under development since 1990 by the GNU Project of the Free Software Foundation, designed as a replacement for the Unix kernel, and released as free software under the GNU General Public License.\n\nGNU Hurd consists of a set of protocols and server processes (or daemons, in Unix terminology) that run on the GNU Mach microkernel. The Hurd aims to surpass the Unix kernel in functionality, security, and stability, while remaining largely compatible with it. The GNU Project chose the multiserver microkernel for the operating system, due to perceived advantages over the traditional Unix monolithic kernel architecture.\n\nIn December 1991 the primary architect of the Hurd described the name as a mutually recursive acronym:\nAs both \"hurd\" and \"hird\" are homophones of the English word \"herd\", the full name \"GNU Hurd\" is also a play on the words \"herd of gnus\", reflecting how the kernel works. The logo is called the \"Hurd boxes\" and it also reflects on architecture. The logo is a graph where nodes represent the Hurd kernel's servers and directed edges are IPC messages.\n\nRichard Stallman founded the GNU project in September 1983 with an aim to create a free GNU operating system. Initially the components required for kernel development were written: editors, shell, compiler and all the others. By 1989, the GNU GPL came into being and the only major component missing was the kernel.\n\nDevelopment on the Hurd began in 1990 after an abandoned kernel attempt in 1986, based on the research TRIX operating system developed by Professor Steve Ward and his group at MIT's Laboratory for Computer Science (LCS). According to Thomas Bushnell, the initial Hurd architect, their early plan was to adapt the 4.4BSD-Lite kernel and, in hindsight, \"It is now perfectly obvious to me that this would have succeeded splendidly and the world would be a very different place today\". In 1987 Richard Stallman proposed using the Mach microkernel developed at Carnegie Mellon University. Work on this was delayed for three years due to uncertainty over whether CMU would release the Mach code under a suitable license.\n\nWith the release of the Linux kernel in 1991, the primary user of GNU's userland components soon became operating systems based on the Linux kernel (Linux distributions), prompting the coining of the term \"GNU/Linux\".\n\nDevelopment of the Hurd has proceeded slowly. Despite an optimistic announcement by Stallman in 2002 predicting a release of GNU/Hurd later that year, the Hurd is still not considered suitable for production environments. Development in general has not met expectations, and there are still a significant number of bugs and missing features. This has resulted in a poorer product than many (including Stallman) had expected. In 2010, after twenty years under development, Stallman said that he was \"not very optimistic about the GNU Hurd. It makes some progress, but to be really superior it would require solving a lot of deep problems\", but added that \"finishing it is not crucial\" for the GNU system because a free kernel already existed (Linux), and completing Hurd would not address the main remaining problem for a free operating system: device support.\n\nThe Debian project, among others, have worked on the Hurd project to produce binary distributions of Hurd-based GNU operating systems for IBM PC compatible systems.\n\nOn August 20, 2015, amid the Google Summer of Code, it was announced that GNU Guix had been ported to GNU Hurd, making it the first native package manager on the Hurd.\n\nUnlike most Unix-like kernels, the Hurd uses a server–client architecture, built on a microkernel that is responsible for providing the most basic kernel services – coordinating access to the hardware: the CPU (through process management and scheduling), RAM (via memory management), and other various input/output devices (via I/O scheduling) for sound, graphics, mass storage, etc. In theory the microkernel design would allow for all device drivers to be built as servers working in user space, but today most drivers of this kind are still contained in the GNU Mach kernel space.\n\nAccording to Hurd developers the main advantage of microkernel-based design is the ability to extend the system: developing a new module would not require in depth knowledge of the rest of the kernel and a bug in one module would not crash the entire system. Hurd provides a concept of \"translators\", a framework of modules used to extend a file system functionality.\n\nFrom early on, the Hurd was developed to use GNU Mach as the microkernel. This was a technical decision made by Richard Stallman, who thought it would speed up the work by saving a large part of it. He has admitted that he was wrong about that. Other Unix-like systems working on the Mach microkernel include OSF/1, Lites, and MkLinux. macOS and NeXTSTEP use hybrid kernels based on Mach.\n\nFrom 2004 onward, various efforts were launched to port the Hurd to more modern microkernels. The L4 microkernel was the original choice in 2004, but progress slowed to a halt. Nevertheless, during 2005, Hurd developer Neal Walfield finished the initial memory management framework for the L4/Hurd port, and Marcus Brinkmann ported essential parts of glibc; namely, getting the process startup code working, allowing programs to run, thus allowing the first user programs (trivial ones such as the hello world program) in C to run.\n\nSince 2005 Brinkmann and Walfield started researching Coyotos as a new kernel for HURD. In 2006, Brinkmann met with Jonathan Shapiro (a primary architect of the Coyotos Operating System) to aid in and discuss the use of the Coyotos kernel for GNU/Hurd. In further discussion HURD developers realised that Coyotos (as well as other similar kernels) are not suitable for HURD.\n\nIn 2007, Hurd developers Neal Walfield and Marcus Brinkmann gave a critique of the Hurd architecture, known as \"the critique\", and a proposal for how a future system may be designed, known as \"the position paper\". In 2008, Neal Walfield began working on the Viengoos microkernel as a modern native kernel for HURD. , development on Viengoos is paused due to Walfield lacking time to work on it.\n\nIn the meantime, others have continued working on the Mach variant of Hurd.\n\nA number of traditional Unix concepts are replaced or extended in the Hurd.\n\nUnder Unix, every running program has an associated user id, which normally corresponds to the user that started the process. This id largely dictates the actions permitted to the program. No outside process can change the user id of a running program. A Hurd process, on the other hand, runs under a \"set\" of user ids, which can contain multiple ids, one, or none. A sufficiently privileged process can add and remove ids to another process. For example, there is a password server that will hand out ids in return for a correct login password.\n\nRegarding the file system, a suitable program can be designated as a \"translator\" for a single file or a whole directory hierarchy. Every access to the translated file, or files below a hierarchy in the second case, is in fact handled by the program. For example, a file translator may simply redirect read and write operations to another file, like a Unix symbolic link. The effect of Unix \"mounting\" is achieved by setting up a filesystem translator (using the \"settrans\" command). Translators can also be used to provide services to the user. For example, the ftpfs translator allows a user to encapsulate remote FTP sites within a directory. Then, standard tools such as ls, cp, and rm can be used to manipulate files on the remote system. Even more powerful translators are ones such as UnionFS, which allows a user to unify multiple directories into one; thus listing the unified directory reveals the contents of all the directories.\n\nThe Hurd requires a multiboot-compliant boot loader, such as GRUB.\n\nAccording to the Debian documentation there are 24 servers (18 core servers and 6 file system servers) named as follows:\n\n\n\nThe servers collectively implement the POSIX API, with each server implementing a part of the interface. For instance, the various filesystem servers each implement the filesystem calls. The storage server will work as a wrapping layer, similar to the block layer of Linux. The equivalent of VFS of Linux is achieved by libdiskfs and libpager libraries.\n\nHurd-based GNU distributions include:\n\n\n", "id": "13236", "title": "GNU Hurd"}
{"url": "https://en.wikipedia.org/wiki?curid=13240", "text": "Hollywood cycles\n\nIn the classic era of the cinema of the United States (1930 – 1945) \"cycles\" or \ngenres matured. They were called cycles, which was a short term for stories that were similar. While we would recognize many of the genres as Westerns, gangsters, musicals, etc., often the cycles were significantly more specific. Instead of \"romantic comedy\" it might be \"Boy-meets-girl-boy-loses-girl-boy-gets-girl\" cycle.\n\n", "id": "13240", "title": "Hollywood cycles"}
{"url": "https://en.wikipedia.org/wiki?curid=13250", "text": "Health care reform\n\nHealth care reform is a general rubric used for discussing major health policy creation or changes—for the most part, governmental policy that affects health care delivery in a given place. Health care reform typically attempts to:\n\nIn the United States, the debate regarding health care reform includes questions of a right to health care, access, fairness, sustainability, quality and amounts spent by government. The mixed public-private health care system in the United States is the most expensive in the world, with health care costing more per person than in any other nation, and a greater portion of gross domestic product (GDP) is spent on it than in any other United Nations member state except for East Timor (Timor-Leste). A study of international health care spending levels in the year 2000, published in the health policy journal \"Health Affairs\", found that while the U.S. spends more on health care than other countries in the Organization for Economic Co-operation and Development (OECD), the use of health care services in the U.S. is below the OECD median by most measures. The authors of the study concluded that the prices paid for health care services are much higher in the U.S.\n\nIn spite of the amount spent on health care in the U.S., according to a 2008 Commonwealth Fund report, the United States ranks last in the quality of health care among developed countries. The World Health Organization (WHO), in 2000, ranked the US health care system 37th in overall performance and 72nd by overall level of health (among 191 member nations included in the study). International comparisons that could lead to conclusions about the quality of the health care received by Americans are subject to debate. The US pays twice as much yet lags other wealthy nations in such measures as infant mortality and life expectancy, which are among the most widely collected, hence easily compared, international statistics. Many people are underinsured, for example, in Colorado \"of those with insurance for a full year, 36.3% were underinsured.\" About 10.7 million insured Americans spend more than a quarter of their annual paychecks on health care because of the high deductible polices.\n\nThe Patient Protection and Affordable Care Act (Public Law 111-148) was signed into law by President Barack Obama on March 23, 2010. Along with the Health Care and Education Reconciliation Act of 2010 (signed March 30), the Act is a product of the health care reform efforts of the Democratic 111th Congress and the Obama administration. The law includes health-related provisions to take effect over the next four years, including expanding Medicaid eligibility for people making up to 133% of the federal poverty level (FPL), subsidizing insurance premiums for people making up to 400% of the FPL ($88,000 for family of 4 in 2010) so their maximum \"out-of-pocket\" payment for annual premiums will be from 2% to 9.5% of income, providing incentives for businesses to provide health care benefits, prohibiting denial of coverage and denial of claims based on pre-existing conditions, establishing health insurance exchanges, prohibiting insurers from establishing annual coverage caps, and support for medical research. According to White House and Congressional Budget Office figures, the maximum share of income that enrollees would have to pay for the would vary depending on their income relative to the federal poverty level, as follows: for families with income 133–150% of FPL will be 3-4% of income, for families with income of 150–200% of FPL will be 4-6.3% of income, for families with income 200–250% of FPL will be 6.3-8.05% of income, for families with income 250-300% of FPL will be 8.05-9.5% of income, for families with income from 300 to 400% of FPL will be 9.5% of income.\n\nThe costs of these provisions are offset by a variety of taxes, fees, and cost-saving measures, such as new Medicare taxes for those in high-income brackets, taxes on indoor tanning, cuts to the Medicare Advantage program in favor of traditional Medicare, and fees on medical devices and pharmaceutical companies; there is also a tax penalty for those who do not obtain health insurance, unless they are exempt due to low income or other reasons. The Congressional Budget Office estimates that the net effect of both laws will be a reduction in the federal deficit by $143 billion over the first decade.\n\nThe universal health care proposal pending in the U.S. Congress is called the United States National Health Care Act (H.R. 676, formerly the \"Medicare for All Act.\") The Congressional Budget Office and related government agencies scored the cost of a universal health care system several times since 1991, and have uniformly predicted cost savings, probably because of the 40% cost savings associated with universal preventative care and elimination of insurance company overhead costs.\n\nIn 2009, the Health Information Technology for Economic and Clinical Health Act (HITECH) offered monetary incentives from 2011 to 2015 for adopting EHR technology to decrease the length of time for hospitals and other healthcare facilities to move from paper records to an electronic health record system. The technology, while not without its pitfalls, should allow easier documentation and storage, the ability to access the information from a bedside, and the ability to sync prescriptions with a bar code.\n\nThe Affordable Care Act was enacted with the goals of increasing the quality and affordability of health insurance, lowering the uninsured rate by expanding public and private insurance coverage, and reducing the costs of healthcare for individuals and the government. Health care providers receive payment more frequently as the number of insured people increases and the number of uninsured patients unable to pay out of pocket declines. Competition between insurers in the new health insurance marketplace has increased pressure on insurance companies to reduce premium rates, leading to reduced compensation rates to providers in some plans.\n\nMany healthcare facilities are struggling to break even since the cost of providing health services has increased, due to wages, technology, and resources. Medicare reimbursement payments to health providers for orthopaedic procedures such as total knee arthroplasty, lumbar spine repair, open rotator cuff repair, and open ankle fracture repair, declined from 1992-2010 which means the providers must rely on self-pay patients and patients with commercial insurances to make up the difference. The changes in regulations regarding risk pool assessment and the inclusion of 10 essential health benefits to every insurance plan have also contributed to the rise in cost of insurance premiums. \n\nBoth Hawaii and Massachusetts have implemented some incremental reforms in health care, but neither state has complete coverage of its citizens. For example, data from the Kaiser Family Foundation shows that 5% of Massachusetts and 8% of Hawaii residents are uninsured. To date, The U.S. Uniform Law Commission, sponsored by the National Conference of Commissioners on Uniform State Laws has not submitted a uniform act or model legislation regarding health care insurance or health care reform.\n\nThe United States spends more on health care than any other country in the world, and, yet, has poorer health status by many measures. In 2007, the United States spent $7,290 per capita on health care. The average among peer nations in the Organisation for Economic Cooperation and Development (OECD) is $3075, just 42 percent of U.S. spending. Health spending is concentrated on a few consumers. In 2006, almost half of all health care spending was used to treat just 5 percent of the population, according to the Kaiser Family Foundation. More than half of bankruptcy filings are related to health care expenses, and sixty-eight percent of these cases are filed by people who have health insurance. According to the White House Council of Economic Advisors, the average family income will be $2,600 lower by 2020, if the growth in the cost of health care is not slowed by at least 1.5 percent. The cost of health insurance premiums more than doubled between 1999 and 2008 while workers' earnings stagnated. In 2008, the average annual cost for family insurance coverage was $12,700. 6\n\nAn estimated 52 million people - more than 15 percent of the people in the United States - are currently without health insurance or access to a government health care program. About 4 million people lost their health insurance during the current recession. That's more than 10,000 people every day. Nationally, 77 percent of the people who are uninsured are workers or are dependents of someone who works. In 2008, employees of small businesses contributed an average of $4,101 for family coverage, compared to $2,982 paid by employees in large firms. About 59 percent of employees with incomes below the poverty level ($18,310 for a family of three)11 do not have health insurance. At income levels twice to three times the poverty level, about 34 percent lack insurance. Half as many lack insurance at four times the poverty level.\n\nHealthcare was reformed in 1948 after the Second World War, broadly along the lines of the 1942 Beveridge Report, with the creation of the National Health Service or NHS. It was originally established as part of a wider reform of social services and funded by a system of National Insurance, though receipt of healthcare was never contingent upon making contributions towards the National Insurance Fund. Private health care was not abolished but had to compete with the NHS. About 15% of all spending on health in the UK is still privately funded but this includes the patient contributions towards NHS provided prescription drugs, so private sector healthcare in the UK is quite small. As part of a wider reform of social provision it was originally thought that the focus would be as much about the prevention of ill-health as it was about curing disease. The NHS for example would distribute baby formula milk fortified with vitamins and minerals in an effort to improve the health of children born in the post war years as well as other supplements such as cod liver oil and malt. Many of the common childhood diseases such as measles, mumps, and chicken pox were mostly eradicated with a national program of vaccinations.\n\nThe NHS has been through many reforms since 1974. The Conservative Thatcher administrations attempted to bring competition into the NHS by developing a supplier/buyer role between hospitals as suppliers and health authorities as buyers. This necessitated the detailed costing of activities, something which the NHS had never had to do in such detail, and some felt was unnecessary. The Labour Party generally opposed these changes, although after the party became New Labour, the Blair government retained elements of competition and even extended it, allowing private health care providers to bid for NHS work. Some treatment and diagnostic centres are now run by private enterprise and funded under contract. However, the extent of this privatisation of NHS work is still small, though remains controversial. The administration committed more money to the NHS raising it to almost the same level of funding as the European average and as a result, there was large expansion and modernisation programme and waiting times improved.\n\nThe government of Gordon Brown proposed new reforms for care in England. One is to take the NHS back more towards health prevention by tackling issues that are known to cause long term ill health. The biggest of these is obesity and related diseases such as diabetes and cardio-vascular disease. The second reform is to make the NHS a more personal service, and it is negotiating with doctors to provide more services at times more convenient to the patient, such as in the evenings and at weekends. This personal service idea would introduce regular health check-ups so that the population is screened more regularly. Doctors will give more advice on ill-health prevention (for example encouraging and assisting patients to control their weight, diet, exercise more, cease smoking etc.) and so tackle problems before they become more serious. Waiting times, which fell considerably under Blair (median wait time is about 6 weeks for elective non-urgent surgery) are also in focus. A target was set from December 2008, to ensure that no person waits longer than 18 weeks from the date that a patient is referred to the hospital to the time of the operation or treatment. This 18 week period thus includes the time to arrange a first appointment, the time for any investigations or tests to determine the cause of the problem and how it should be treated. An NHS Constitution was published which lays out the legal rights of patients as well as promises (not legally enforceable) the NHS strives to keep in England.\n\nNumerous healthcare reforms in Germany were legislative interventions to stabilise the public health insurance since 1983. 9 out of 10 citizens are publicly insured, only 8% privately. Health care in Germany, including its industry and all services, is one of the largest sectors of the German economy. The total expenditure in health economics of Germany was about 287.3 billion euro in 2010, equivalent to 11.6 percent of the gross domestic product (GDP) this year and about 3,510 euro per capita. Direct inpatient and outpatient care equal just about a quarter of the entire expenditure - depending on the perspective. Expenditure on pharmaceutical drugs is almost twice the amount of those for the entire hospital sector. Pharmaceutical drug expenditure grew by an annual average of 4.1% between 2004 and 2010.\n\nThese developments have caused numerous healthcare reforms since the 1980s. An actual example of 2010 and 2011: First time since 2004 the drug expenditure fell from 30.2 billion euro in 2010, to 29.1 billion Euro in 2011, i. e. minus 1.1 billion Euro or minus 3.6%. That was caused by restructuring the Social Security Code: manufacturer discount 16% instead of 6%, price moratorium, increasing discount contracts, increasing discount by wholesale trade and pharmacies.\n\nThe Netherlands has introduced a new system of health care insurance based on risk equalization through a risk equalization pool. In this way, a compulsory insurance package is available to all citizens at affordable cost without the need for the insured to be assessed for risk by the insurance company. Furthermore, health insurers are now willing to take on high risk individuals because they receive compensation for the higher risks.\n\nA 2008 article in the journal Health Affairs suggested that the Dutch health system, which combines mandatory universal coverage with competing private health plans, could serve as a model for reform in the US.\n\nFollowing the collapse of the Soviet Union, Russia embarked on a series of reforms intending to deliver better healthcare by compulsory medical insurance with privately owned providers in addition to the state run institutions. According to the OECD none of 1991-93 reforms worked out as planned and the reforms had in many respects made the system worse. Russia has more physicians, hospitals, and healthcare workers than almost any other country in the world on a per capita basis, but since the collapse of the Soviet Union, the health of the Russian population has declined considerably as a result of social, economic, and lifestyle changes. However, after Putin became president in 2000 there was significant growth in spending for public healthcare and in 2006 it exceed the pre-1991 level in real terms. Also life expectancy increased from 1991-93 levels, infant mortality rate dropped from 18.1 in 1995 to 8.4 in 2008. Russian Prime Minister Vladimir Putin announced a large-scale health care reform in 2011 and pledged to allocate more than 300 billion rubles ($10 billion) in the next few years to improve health care in the country.\n\nTaiwan changed its healthcare system in 1995 to a National Health Insurance model similar to the US Medicare system for seniors. As a result, the 40% of Taiwanese people who had previously been uninsured are now covered. It is said to deliver universal coverage with free choice of doctors and hospitals and no waiting lists. Polls in 2005 are reported to have shown that 72.5% of Taiwanese are happy with the system, and when they are unhappy, it's with the cost of premiums (equivalent to less than US$20 a month).\n\nEmployers and the self-employed are legally bound to pay National Health Insurance (NHI) premiums which are similar to social security contributions in other countries. However, the NHI is a pay-as-you-go system. The aim is for the premium income to pay costs. The system is also subsidized by a tobacco tax surcharge and contributions from the national lottery.\n\nAs evidenced by the large variety of different healthcare systems seen across the world, there are several different pathways that a country could take when thinking about reform. In comparison to the UK, physicians in Germany have more bargaining power through professional organizations (i.e., physician associations); this ability to negotiate affects reform efforts. Germany makes use of sickness funds, which citizens are obliged to join but are able to opt out if they have a very high income (Belien 87). The Netherlands used a similar system but the financial threshold for opting out was lower (Belien 89). The Swiss, on the other hand use more of a privately based health insurance system where citizens are risk-rated by age and sex, among other factors (Belien 90). The United States government provides healthcare to just over 25% of its citizens through various agencies, but otherwise does not employ a system. Healthcare is generally centered around regulated private insurance methods.\n\nOne key component to healthcare reform is the reduction of healthcare fraud and abuse. In the U.S. and the EU, it is estimated that as much as 10 percent of all healthcare transactions and expenditures may be fraudulent. See Terry L. Leap, \"Phantom Billing, Fake Prescriptions, and the High Cost of Medicine: Health Care Fraud and What to do about It\" (Cornell University Press, 2011).\n\nAlso interesting to notice is the oldest healthcare system in the world and its advantages and disadvantages, see Health in Germany.\n\n", "id": "13250", "title": "Health care reform"}
{"url": "https://en.wikipedia.org/wiki?curid=13253", "text": "Henry Mayhew\n\nHenry Mayhew (25 November 1812 – 25 July 1887) was an English social researcher, journalist, playwright and advocate of reform. He was one of the co-founders of the satirical and humorous magazine \"Punch\" in 1841, and was the magazine's joint-editor, with Mark Lemon, in its early days. He is also known for his work as a social researcher, publishing an extensive series of newspaper articles in the \"Morning Chronicle\" that was later compiled into the book series \"London Labour and the London Poor\" (1851), a groundbreaking and influential survey of the city's poor.\n\nHe was born in London, one of seventeen children of Joshua Mayhew. He was educated at Westminster School before running away from his studies to sea. He then served with the East India Company as a midshipman on a ship bound for Calcutta. He returned after several years, in 1829, becoming a trainee lawyer in Wales. He left this and became a freelance journalist. He contributed to \"The Thief\", a readers' digest, followed quickly by editing a weekly journal – \"Figaro in London\". Mayhew reputedly fled his creditors and holed up at The Erwood Inn, a small public house in the village of Erwood, south of Builth Wells in Wales.\n\nIn 1835 Mayhew found himself in a state of debt and, along with a fellow writer, escaped to Paris to avoid his creditors. He spent his time writing and in the company of other writers including William Thackeray and Douglas Jerrold. Mayhew spent over ten years in Paris returning to England in the 1850s whereby he was involved in several literary adventures, mostly the writing of plays. Two of his plays – \"But, However\" and the \"Wandering Minstrel\" – were successful, whilst his early work \"Figaro in London\" was less successful.\n\nOn 17 July 1841 Mayhew cofounded Punch magazine. At its founding the magazine was jointly edited by Mayhew and Mark Lemon. The two men hired a group of writers and also illustrators to aid them. These included Douglas Jerrold, Angus Reach, John Leech, Richard Doyle and Shirley Brooks. Initially it was subtitled \"The London Charivari\", this being a reference to a satirical humour magazine published in France under the title \"Le Charivari\" (a work read often whilst Mayhew was in Paris). Reflecting their satiric and humorous intent, the two editors took for their name and masthead the anarchic glove puppet Mr. Punch.\n\n\"Punch\" was an unexpected success, selling about 6,000 copies a week in the early years. However, sales of as many as 10,000 issues a week were required to cover all costs of the magazine. In December 1842, the magazine was sold to Bradbury and Evans; Mayhew resigned as joint editor, and he continued at the magazine as \"suggestor in chief\" with Mark Lemon reappointed as editor. Mayhew eventually severed his connection with the magazine, writing his last article in February 1845. His brother Horace stayed on the board of Punch until his own death.\n\nThe \"Punch\" years gave Mayhew the opportunity to meet talented illustrators who he later employed to work from daguerreotypes on \"London Labour and the London Poor\". Following \"Punch\" magazine, Mayhew new launched \"Iron Times\", a railway magazine. However this venture lost Mayhew so much money that he was forced to appear in a Court of Bankruptcy in 1846.\n\nIn 1842 Mayhew contributed to the pioneering Illustrated London News. By this time Mayhew had become reasonably secure financially, had settled his debts and married Jane Jerrold, the daughter of his friend Douglas Jerrold. She lived until 1880.\n\nThe articles comprising \"London Labour and the London Poor\" were initially collected into three volumes in 1851; the 1861 edition included a fourth volume, co-written with Bracebridge Hemyng, John Binny and Andrew Halliday, on the lives of prostitutes, thieves and beggars. This Extra Volume took a more general and statistical approach to its subject than Volumes 1 to 3.\n\nMayhew wrote in volume one: \"\"I shall consider the whole of the metropolitan poor under three separate phases, according as they \"will\" work, they \"can't\" work, and they \"won't\" work\"\". He interviewed everyone—beggars, street-entertainers (such as Punch and Judy men), market traders, prostitutes, labourers, sweatshop workers, even down to the \"mudlarks\" who searched the stinking mud on the banks of the River Thames for wood, metal, rope and coal from passing ships, and the \"pure-finders\" who gathered dog faeces to sell to tanners. He described their clothes, how and where they lived, their entertainments and customs, and made detailed estimates of the numbers and incomes of those practising each trade. The books show how marginal and precarious many people's lives were, in what, at that time, was the richest city in the world.\n\nMayhew's richly detailed descriptions give an impression of what the street markets of his day were like. An example from Volume 1:\n\nSome of the London street traders didn't like the way Mayhew wrote about them. In spring/summer 1851 they established a \"Street Trader's Protection Association\" to guard themselves against the journalist.\n\nMayhew was the grandfather of Audrey Mayhew Allen (b. 1870), an author of a number of children's stories published in various periodicals, and of \"Gladys in Grammarland\", an imitation of Lewis Carroll's \"Wonderland\" books.\n\nMayhew's work was embraced by and was an influence on the Christian Socialists, such as Thomas Hughes, Charles Kingsley, and F. D. Maurice. Radicals also published sizeable excerpts from the reports in the Northern Star, the Red Republican, and other newspapers. The often sympathetic investigations, with their immediacy and unswerving eye for detail, offered unprecedented insights into the condition of the Victorian poor. Alongside the earlier work of Edwin Chadwick, they are also regarded as a decisive influence on the thinking of Charles Dickens.\n\nMayhew's work inspired the script of director Christine Edzard's 1990 film \"The Fool\". Mayhew has appeared as a character in television and radio histories of Victorian London ; he was played by Timothy West in the documentary \"London\" (2004), and David Haig in the Afternoon Play \"A Chaos of Wealth and Want\" (2010). In the 2012 novel \"Dodger\" by Terry Pratchett, Mayhew and his wife appear as fictionalised versions of themselves, and he is mentioned in the dedication.\n\n\n", "id": "13253", "title": "Henry Mayhew"}
{"url": "https://en.wikipedia.org/wiki?curid=13255", "text": "Hydrogen\n\nHydrogen is a chemical element with chemical symbol H and atomic number 1. With an atomic weight of , hydrogen is the lightest element on the periodic table. Its monatomic form (H) is the most abundant chemical substance in the Universe, constituting roughly 75% of all baryonic mass. Non-remnant stars are mainly composed of hydrogen in the plasma state. The most common isotope of hydrogen, termed \"protium\" (name rarely used, symbol H), has one proton and no neutrons.\n\nThe universal emergence of atomic hydrogen first occurred during the recombination epoch. At standard temperature and pressure, hydrogen is a colorless, odorless, tasteless, non-toxic, nonmetallic, highly combustible diatomic gas with the molecular formula H. Since hydrogen readily forms covalent compounds with most nonmetallic elements, most of the hydrogen on Earth exists in molecular forms such as water or organic compounds. Hydrogen plays a particularly important role in acid–base reactions because most acid-base reactions involve the exchange of protons between soluble molecules. In ionic compounds, hydrogen can take the form of a negative charge (i.e., anion) when it is known as a hydride, or as a positively charged (i.e., cation) species denoted by the symbol H. The hydrogen cation is written as though composed of a bare proton, but in reality, hydrogen cations in ionic compounds are always more complex. As the only neutral atom for which the Schrödinger equation can be solved analytically, study of the energetics and bonding of the hydrogen atom has played a key role in the development of quantum mechanics.\n\nHydrogen gas was first artificially produced in the early 16th century by the reaction of acids on metals. In 1766–81, Henry Cavendish was the first to recognize that hydrogen gas was a discrete substance, and that it produces water when burned, the property for which it was later named: in Greek, hydrogen means \"water-former\".\n\nIndustrial production is mainly from steam reforming natural gas, and less often from more energy-intensive methods such as the electrolysis of water. Most hydrogen is used near the site of its production site, the two largest uses being fossil fuel processing (e.g., hydrocracking) and ammonia production, mostly for the fertilizer market. Hydrogen is a concern in metallurgy as it can embrittle many metals, complicating the design of pipelines and storage tanks.\n\nHydrogen gas (dihydrogen or molecular hydrogen) is highly flammable and will burn in air at a very wide range of concentrations between 4% and 75% by volume. The enthalpy of combustion is −286 kJ/mol:\n\nHydrogen gas forms explosive mixtures with air in concentrations from 4–74% and with chlorine at 5–95%. The explosive reactions may be triggered by spark, heat, or sunlight. The hydrogen autoignition temperature, the temperature of spontaneous ignition in air, is . Pure hydrogen-oxygen flames emit ultraviolet light and with high oxygen mix are nearly invisible to the naked eye, as illustrated by the faint plume of the Space Shuttle Main Engine, compared to the highly visible plume of a Space Shuttle Solid Rocket Booster, which uses an ammonium perchlorate composite. The detection of a burning hydrogen leak may require a flame detector; such leaks can be very dangerous. Hydrogen flames in other conditions are blue, resembling blue natural gas flames.\n\nThe destruction of the Hindenburg airship was a notorious example of hydrogen combustion and the cause is still debated. The visible orange flames in that incident were the result of a rich mixture of hydrogen to oxygen combined with carbon compounds from the airship skin.\n\nH reacts with every oxidizing element. Hydrogen can react spontaneously and violently at room temperature with chlorine and fluorine to form the corresponding hydrogen halides, hydrogen chloride and hydrogen fluoride, which are also potentially dangerous acids.\n\nThe ground state energy level of the electron in a hydrogen atom is −13.6 eV, which is equivalent to an ultraviolet photon of roughly 91 nm wavelength.\n\nThe energy levels of hydrogen can be calculated fairly accurately using the Bohr model of the atom, which conceptualizes the electron as \"orbiting\" the proton in analogy to the Earth's orbit of the Sun. However, the atomic electron and proton are held together by electromagnetic force, while planets and celestial objects are held by gravity. Because of the discretization of angular momentum postulated in early quantum mechanics by Bohr, the electron in the Bohr model can only occupy certain allowed distances from the proton, and therefore only certain allowed energies.\n\nA more accurate description of the hydrogen atom comes from a purely quantum mechanical treatment that uses the Schrödinger equation, Dirac equation or even the Feynman path integral formulation to calculate the probability density of the electron around the proton. The most complicated treatments allow for the small effects of special relativity and vacuum polarization. In the quantum mechanical treatment, the electron in a ground state hydrogen atom has no angular momentum at all—illustrating how the \"planetary orbit\" differs from electron motion.\nThere exist two different spin isomers of hydrogen diatomic molecules that differ by the relative spin of their nuclei. In the orthohydrogen form, the spins of the two protons are parallel and form a triplet state with a molecular spin quantum number of 1 (+); in the parahydrogen form the spins are antiparallel and form a singlet with a molecular spin quantum number of 0 (–). At standard temperature and pressure, hydrogen gas contains about 25% of the para form and 75% of the ortho form, also known as the \"normal form\". The equilibrium ratio of orthohydrogen to parahydrogen depends on temperature, but because the ortho form is an excited state and has a higher energy than the para form, it is unstable and cannot be purified. At very low temperatures, the equilibrium state is composed almost exclusively of the para form. The liquid and gas phase thermal properties of pure parahydrogen differ significantly from those of the normal form because of differences in rotational heat capacities, as discussed more fully in \"spin isomers of hydrogen\". The ortho/para distinction also occurs in other hydrogen-containing molecules or functional groups, such as water and methylene, but is of little significance for their thermal properties.\n\nThe uncatalyzed interconversion between para and ortho H increases with increasing temperature; thus rapidly condensed H contains large quantities of the high-energy ortho form that converts to the para form very slowly. The ortho/para ratio in condensed H is an important consideration in the preparation and storage of liquid hydrogen: the conversion from ortho to para is exothermic and produces enough heat to evaporate some of the hydrogen liquid, leading to loss of liquefied material. Catalysts for the ortho-para interconversion, such as ferric oxide, activated carbon, platinized asbestos, rare earth metals, uranium compounds, chromic oxide, or some nickel compounds, are used during hydrogen cooling.\n\n\nWhile H is not very reactive under standard conditions, it does form compounds with most elements. Hydrogen can form compounds with elements that are more electronegative, such as halogens (e.g., F, Cl, Br, I), or oxygen; in these compounds hydrogen takes on a partial positive charge. When bonded to fluorine, oxygen, or nitrogen, hydrogen can participate in a form of medium-strength noncovalent bonding with the hydrogen of other similar molecules, a phenomenon called hydrogen bonding that is critical to the stability of many biological molecules. Hydrogen also forms compounds with less electronegative elements, such as metals and metalloids, where it takes on a partial negative charge. These compounds are often known as hydrides.\n\nHydrogen forms a vast array of compounds with carbon called the hydrocarbons, and an even vaster array with heteroatoms that, because of their general association with living things, are called organic compounds. The study of their properties is known as organic chemistry and their study in the context of living organisms is known as biochemistry. By some definitions, \"organic\" compounds are only required to contain carbon. However, most of them also contain hydrogen, and because it is the carbon-hydrogen bond which gives this class of compounds most of its particular chemical characteristics, carbon-hydrogen bonds are required in some definitions of the word \"organic\" in chemistry. Millions of hydrocarbons are known, and they are usually formed by complicated synthetic pathways that seldom involve elementary hydrogen.\n\nCompounds of hydrogen are often called hydrides, a term that is used fairly loosely. The term \"hydride\" suggests that the H atom has acquired a negative or anionic character, denoted H, and is used when hydrogen forms a compound with a more electropositive element. The existence of the hydride anion, suggested by Gilbert N. Lewis in 1916 for group 1 and 2 salt-like hydrides, was demonstrated by Moers in 1920 by the electrolysis of molten lithium hydride (LiH), producing a stoichiometry quantity of hydrogen at the anode. For hydrides other than group 1 and 2 metals, the term is quite misleading, considering the low electronegativity of hydrogen. An exception in group 2 hydrides is , which is polymeric. In lithium aluminium hydride, the anion carries hydridic centers firmly attached to the Al(III).\n\nAlthough hydrides can be formed with almost all main-group elements, the number and combination of possible compounds varies widely; for example, more than 100 binary borane hydrides are known, but only one binary aluminium hydride. Binary indium hydride has not yet been identified, although larger complexes exist.\n\nIn inorganic chemistry, hydrides can also serve as bridging ligands that link two metal centers in a coordination complex. This function is particularly common in group 13 elements, especially in boranes (boron hydrides) and aluminium complexes, as well as in clustered carboranes.\n\nOxidation of hydrogen removes its electron and gives H, which contains no electrons and a nucleus which is usually composed of one proton. That is why is often called a proton. This species is central to discussion of acids. Under the Bronsted-Lowry theory, acids are proton donors, while bases are proton acceptors.\n\nA bare proton, , cannot exist in solution or in ionic crystals because of its unstoppable attraction to other atoms or molecules with electrons. Except at the high temperatures associated with plasmas, such protons cannot be removed from the electron clouds of atoms and molecules, and will remain attached to them. However, the term 'proton' is sometimes used loosely and metaphorically to refer to positively charged or cationic hydrogen attached to other species in this fashion, and as such is denoted \"\" without any implication that any single protons exist freely as a species.\n\nTo avoid the implication of the naked \"solvated proton\" in solution, acidic aqueous solutions are sometimes considered to contain a less unlikely fictitious species, termed the \"hydronium ion\" (). However, even in this case, such solvated hydrogen cations are more realistically conceived as being organized into clusters that form species closer to H. Other oxonium ions are found when water is in acidic solution with other solvents.\n\nAlthough exotic on Earth, one of the most common ions in the universe is the ion, known as protonated molecular hydrogen or the trihydrogen cation.\n\nHydrogen has three naturally occurring isotopes, denoted , and . Other, highly unstable nuclei ( to ) have been synthesized in the laboratory but not observed in nature.\n\nHydrogen is the only element that has different names for its isotopes in common use today. During the early study of radioactivity, various heavy radioactive isotopes were given their own names, but such names are no longer used, except for deuterium and tritium. The symbols D and T (instead of and ) are sometimes used for deuterium and tritium, but the corresponding symbol for protium, P, is already in use for phosphorus and thus is not available for protium. In its nomenclatural guidelines, the International Union of Pure and Applied Chemistry allows any of D, T, , and to be used, although and are preferred.\n\nThe exotic atom muonium (symbol Mu), composed of an antimuon and an electron, is also sometimes considered as a light radioisotope of hydrogen, due to the mass difference between the antimuon and the electron. which was discovered in 1960 During the muon's lifetime, muonium can enter into compounds such as muonium chloride (MuCl) or sodium muonide (NaMu), analogous to hydrogen chloride and sodium hydride respectively.\n\nIn 1671, Robert Boyle discovered and described the reaction between iron filings and dilute acids, which results in the production of hydrogen gas. In 1766, Henry Cavendish was the first to recognize hydrogen gas as a discrete substance, by naming the gas from a metal-acid reaction \"inflammable air\". He speculated that \"inflammable air\" was in fact identical to the hypothetical substance called \"phlogiston\" and further finding in 1781 that the gas produces water when burned. He is usually given credit for the discovery of hydrogen as an element. In 1783, Antoine Lavoisier gave the element the name hydrogen (from the Greek ὑδρο- \"hydro\" meaning \"water\" and -γενής \"genes\" meaning \"creator\") when he and Laplace reproduced Cavendish's finding that water is produced when hydrogen is burned.\n\nLavoisier produced hydrogen for his experiments on mass conservation by reacting a flux of steam with metallic iron through an incandescent iron tube heated in a fire. Anaerobic oxidation of iron by the protons of water at high temperature can be schematically represented by the set of following reactions:\n\nMany metals such as zirconium undergo a similar reaction with water leading to the production of hydrogen.\n\nHydrogen was liquefied for the first time by James Dewar in 1898 by using regenerative cooling and his invention, the vacuum flask. He produced solid hydrogen the next year. Deuterium was discovered in December 1931 by Harold Urey, and tritium was prepared in 1934 by Ernest Rutherford, Mark Oliphant, and Paul Harteck. Heavy water, which consists of deuterium in the place of regular hydrogen, was discovered by Urey's group in 1932. François Isaac de Rivaz built the first de Rivaz engine, an internal combustion engine powered by a mixture of hydrogen and oxygen in 1806. Edward Daniel Clarke invented the hydrogen gas blowpipe in 1819. The Döbereiner's lamp and limelight were invented in 1823.\n\nThe first hydrogen-filled balloon was invented by Jacques Charles in 1783. Hydrogen provided the lift for the first reliable form of air-travel following the 1852 invention of the first hydrogen-lifted airship by Henri Giffard. German count Ferdinand von Zeppelin promoted the idea of rigid airships lifted by hydrogen that later were called Zeppelins; the first of which had its maiden flight in 1900. Regularly scheduled flights started in 1910 and by the outbreak of World War I in August 1914, they had carried 35,000 passengers without a serious incident. Hydrogen-lifted airships were used as observation platforms and bombers during the war.\n\nThe first non-stop transatlantic crossing was made by the British airship \"R34\" in 1919. Regular passenger service resumed in the 1920s and the discovery of helium reserves in the United States promised increased safety, but the U.S. government refused to sell the gas for this purpose. Therefore, H was used in the \"Hindenburg\" airship, which was destroyed in a midair fire over New Jersey on 6 May 1937. The incident was broadcast live on radio and filmed. Ignition of leaking hydrogen is widely assumed to be the cause, but later investigations pointed to the ignition of the aluminized fabric coating by static electricity. But the damage to hydrogen's reputation as a lifting gas was already done.\n\nIn the same year the first hydrogen-cooled turbogenerator went into service with gaseous hydrogen as a coolant in the rotor and the stator in 1937 at Dayton, Ohio, by the Dayton Power & Light Co.; because of the thermal conductivity of hydrogen gas, this is the most common type in its field today.\n\nThe nickel hydrogen battery was used for the first time in 1977 aboard the U.S. Navy's Navigation technology satellite-2 (NTS-2). For example, the ISS, Mars Odyssey and the Mars Global Surveyor are equipped with nickel-hydrogen batteries. In the dark part of its orbit, the Hubble Space Telescope is also powered by nickel-hydrogen batteries, which were finally replaced in May 2009, more than 19 years after launch and 13 years beyond their design life.\n\nBecause of its simple atomic structure, consisting only of a proton and an electron, the hydrogen atom, together with the spectrum of light produced from it or absorbed by it, has been central to the development of the theory of atomic structure. Furthermore, study of the corresponding simplicity of the hydrogen molecule and the corresponding cation brought understanding of the nature of the chemical bond, which followed shortly after the quantum mechanical treatment of the hydrogen atom had been developed in the mid-1920s.\n\nOne of the first quantum effects to be explicitly noticed (but not understood at the time) was a Maxwell observation involving hydrogen, half a century before full quantum mechanical theory arrived. Maxwell observed that the specific heat capacity of H unaccountably departs from that of a diatomic gas below room temperature and begins to increasingly resemble that of a monatomic gas at cryogenic temperatures. According to quantum theory, this behavior arises from the spacing of the (quantized) rotational energy levels, which are particularly wide-spaced in H because of its low mass. These widely spaced levels inhibit equal partition of heat energy into rotational motion in hydrogen at low temperatures. Diatomic gases composed of heavier atoms do not have such widely spaced levels and do not exhibit the same effect.\n\nAntihydrogen () is the antimatter counterpart to hydrogen. It consists of an antiproton with a positron. Antihydrogen is the only type of antimatter atom to have been produced as of 2015.\n\nHydrogen, as atomic H, is the most abundant chemical element in the universe, making up 75% of normal matter by mass and more than 90% by number of atoms. (Most of the mass of the universe, however, is not in the form of chemical-element type matter, but rather is postulated to occur as yet-undetected forms of mass such as dark matter and dark energy.) This element is found in great abundance in stars and gas giant planets. Molecular clouds of H are associated with star formation. Hydrogen plays a vital role in powering stars through the proton-proton reaction and the CNO cycle nuclear fusion.\n\nThroughout the universe, hydrogen is mostly found in the atomic and plasma states, with properties quite different from those of molecular hydrogen. As a plasma, hydrogen's electron and proton are not bound together, resulting in very high electrical conductivity and high emissivity (producing the light from the Sun and other stars). The charged particles are highly influenced by magnetic and electric fields. For example, in the solar wind they interact with the Earth's magnetosphere giving rise to Birkeland currents and the aurora. Hydrogen is found in the neutral atomic state in the interstellar medium. The large amount of neutral hydrogen found in the damped Lyman-alpha systems is thought to dominate the cosmological baryonic density of the Universe up to redshift \"z\"=4.\n\nUnder ordinary conditions on Earth, elemental hydrogen exists as the diatomic gas, H. However, hydrogen gas is very rare in the Earth's atmosphere (1 ppm by volume) because of its light weight, which enables it to escape from Earth's gravity more easily than heavier gases. However, hydrogen is the third most abundant element on the Earth's surface, mostly in the form of chemical compounds such as hydrocarbons and water. Hydrogen gas is produced by some bacteria and algae and is a natural component of flatus, as is methane, itself a hydrogen source of increasing importance.\n\nA molecular form called protonated molecular hydrogen () is found in the interstellar medium, where it is generated by ionization of molecular hydrogen from cosmic rays. This charged ion has also been observed in the upper atmosphere of the planet Jupiter. The ion is relatively stable in the environment of outer space due to the low temperature and density. is one of the most abundant ions in the Universe, and it plays a notable role in the chemistry of the interstellar medium. Neutral triatomic hydrogen H can exist only in an excited form and is unstable. By contrast, the positive hydrogen molecular ion () is a rare molecule in the universe.\n\n is produced in chemistry and biology laboratories, often as a by-product of other reactions; in industry for the hydrogenation of unsaturated substrates; and in nature as a means of expelling reducing equivalents in biochemical reactions.\n\nHydrogen can be prepared in several different ways, but economically the most important processes involve removal of hydrogen from hydrocarbons, as about 95% of hydrogen production came from steam reforming around year 2000. Commercial bulk hydrogen is usually produced by the steam reforming of natural gas. At high temperatures (1000–1400 K, 700–1100 °C or 1300–2000 °F), steam (water vapor) reacts with methane to yield carbon monoxide and .\n\nThis reaction is favored at low pressures but is nonetheless conducted at high pressures (2.0  MPa, 20 atm or 600 inHg). This is because high-pressure is the most marketable product and pressure swing adsorption (PSA) purification systems work better at higher pressures. The product mixture is known as \"synthesis gas\" because it is often used directly for the production of methanol and related compounds. Hydrocarbons other than methane can be used to produce synthesis gas with varying product ratios. One of the many complications to this highly optimized technology is the formation of coke or carbon:\n\nConsequently, steam reforming typically employs an excess of . Additional hydrogen can be recovered from the steam by use of carbon monoxide through the water gas shift reaction, especially with an iron oxide catalyst. This reaction is also a common industrial source of carbon dioxide:\n\nOther important methods for production include partial oxidation of hydrocarbons:\n\nand the coal reaction, which can serve as a prelude to the shift reaction above:\n\nHydrogen is sometimes produced and consumed in the same industrial process, without being separated. In the Haber process for the production of ammonia, hydrogen is generated from natural gas. Electrolysis of brine to yield chlorine also produces hydrogen as a co-product.\n\nIn the laboratory, is usually prepared by the reaction of dilute non-oxidizing acids on some reactive metals such as zinc with Kipp's apparatus.\n\nAluminium can also produce upon treatment with bases:\n\nThe electrolysis of water is a simple method of producing hydrogen. A low voltage current is run through the water, and gaseous oxygen forms at the anode while gaseous hydrogen forms at the cathode. Typically the cathode is made from platinum or another inert metal when producing hydrogen for storage. If, however, the gas is to be burnt on site, oxygen is desirable to assist the combustion, and so both electrodes would be made from inert metals. (Iron, for instance, would oxidize, and thus decrease the amount of oxygen given off.) The theoretical maximum efficiency (electricity used vs. energetic value of hydrogen produced) is in the range 80–94%.\n\nAn alloy of aluminium and gallium in pellet form added to water can be used to generate hydrogen. The process also produces alumina, but the expensive gallium, which prevents the formation of an oxide skin on the pellets, can be re-used. This has important potential implications for a hydrogen economy, as hydrogen can be produced on-site and does not need to be transported.\n\nThere are more than 200 thermochemical cycles which can be used for water splitting, around a dozen of these cycles such as the iron oxide cycle, cerium(IV) oxide–cerium(III) oxide cycle, zinc zinc-oxide cycle, sulfur-iodine cycle, copper-chlorine cycle and hybrid sulfur cycle are under research and in testing phase to produce hydrogen and oxygen from water and heat without using electricity. A number of laboratories (including in France, Germany, Greece, Japan, and the USA) are developing thermochemical methods to produce hydrogen from solar energy and water.\n\nUnder anaerobic conditions, iron and steel alloys are slowly oxidized by the protons of water concomitantly reduced in molecular hydrogen (). The anaerobic corrosion of iron leads first to the formation of ferrous hydroxide (green rust) and can be described by the following reaction:\n\nIn its turn, under anaerobic conditions, the ferrous hydroxide ( ) can be oxidized by the protons of water to form magnetite and molecular hydrogen.\nThis process is described by the Schikorr reaction:\n\nThe well crystallized magnetite () is thermodynamically more stable than the ferrous hydroxide ( ).\n\nThis process occurs during the anaerobic corrosion of iron and steel in oxygen-free groundwater and in reducing soils below the water table.\n\nIn the absence of atmospheric oxygen (), in deep geological conditions prevailing far away from Earth atmosphere, hydrogen () is produced during the process of serpentinization by the anaerobic oxidation by the water protons (H) of the ferrous (Fe) silicate present in the crystal lattice of the fayalite (, the olivine iron-endmember). The corresponding reaction leading to the formation of magnetite (), quartz (Si) and hydrogen () is the following:\n\nThis reaction closely resembles the Schikorr reaction observed in the anaerobic oxidation of the ferrous hydroxide in contact with water.\n\nFrom all the fault gases formed in power transformers, hydrogen is the most common and is generated under most fault conditions; thus, formation of hydrogen is an early indication of serious problems in the transformer's life cycle.\n\nLarge quantities of are needed in the petroleum and chemical industries. The largest application of is for the processing (\"upgrading\") of fossil fuels, and in the production of ammonia. The key consumers of in the petrochemical plant include hydrodealkylation, hydrodesulfurization, and hydrocracking. has several other important uses. is used as a hydrogenating agent, particularly in increasing the level of saturation of unsaturated fats and oils (found in items such as margarine), and in the production of methanol. It is similarly the source of hydrogen in the manufacture of hydrochloric acid. is also used as a reducing agent of metallic ores.\n\nHydrogen is highly soluble in many rare earth and transition metals and is soluble in both nanocrystalline and amorphous metals. Hydrogen solubility in metals is influenced by local distortions or impurities in the crystal lattice. These properties may be useful when hydrogen is purified by passage through hot palladium disks, but the gas's high solubility is a metallurgical problem, contributing to the embrittlement of many metals, complicating the design of pipelines and storage tanks.\n\nApart from its use as a reactant, has wide applications in physics and engineering. It is used as a shielding gas in welding methods such as atomic hydrogen welding. H is used as the rotor coolant in electrical generators at power stations, because it has the highest thermal conductivity of any gas. Liquid H is used in cryogenic research, including superconductivity studies. Because is lighter than air, having a little more than of the density of air, it was once widely used as a lifting gas in balloons and airships.\n\nIn more recent applications, hydrogen is used pure or mixed with nitrogen (sometimes called forming gas) as a tracer gas for minute leak detection. Applications can be found in the automotive, chemical, power generation, aerospace, and telecommunications industries. Hydrogen is an authorized food additive (E 949) that allows food package leak testing among other anti-oxidizing properties.\n\nHydrogen's rarer isotopes also each have specific applications. Deuterium (hydrogen-2) is used in nuclear fission applications as a moderator to slow neutrons, and in nuclear fusion reactions. Deuterium compounds have applications in chemistry and biology in studies of reaction isotope effects. Tritium (hydrogen-3), produced in nuclear reactors, is used in the production of hydrogen bombs, as an isotopic label in the biosciences, and as a radiation source in luminous paints.\n\nThe triple point temperature of equilibrium hydrogen is a defining fixed point on the ITS-90 temperature scale at 13.8033 kelvins.\n\nHydrogen is commonly used in power stations as a coolant in generators due to a number of favorable properties that are a direct result of its light diatomic molecules. These include low density, low viscosity, and the highest specific heat and thermal conductivity of all gases.\n\nHydrogen is not an energy resource, except in the hypothetical context of commercial nuclear fusion power plants using deuterium or tritium, a technology presently far from development. The Sun's energy comes from nuclear fusion of hydrogen, but this process is difficult to achieve controllably on Earth. Elemental hydrogen from solar, biological, or electrical sources require more energy to make it than is obtained by burning it, so in these cases hydrogen functions as an energy carrier, like a battery. Hydrogen may be obtained from fossil sources (such as methane), but these sources are unsustainable.\n\nThe energy density per unit \"volume\" of both liquid hydrogen and compressed hydrogen gas at any practicable pressure is significantly less than that of traditional fuel sources, although the energy density per unit fuel \"mass\" is higher. Nevertheless, elemental hydrogen has been widely discussed in the context of energy, as a possible future \"carrier\" of energy on an economy-wide scale. For example, sequestration followed by carbon capture and storage could be conducted at the point of production from fossil fuels. Hydrogen used in transportation would burn relatively cleanly, with some NO emissions, but without carbon emissions. However, the infrastructure costs associated with full conversion to a hydrogen economy would be substantial. Fuel cells can convert hydrogen and oxygen directly to electricity more efficiently than internal combustion engines.\n\nHydrogen is employed to saturate broken (\"dangling\") bonds of amorphous silicon and amorphous carbon that helps stabilizing material properties. It is also a potential electron donor in various oxide materials, including ZnO, SnO, CdO, MgO, ZrO, HfO, LaO, YO, TiO, SrTiO, LaAlO, SiO, AlO, ZrSiO, HfSiO, and SrZrO.\n\nH is a product of some types of anaerobic metabolism and is produced by several microorganisms, usually via reactions catalyzed by iron- or nickel-containing enzymes called hydrogenases. These enzymes catalyze the reversible redox reaction between H and its component two protons and two electrons. Creation of hydrogen gas occurs in the transfer of reducing equivalents produced during pyruvate fermentation to water. The natural cycle of hydrogen production and consumption by organisms is called the hydrogen cycle.\n\nWater splitting, in which water is decomposed into its component protons, electrons, and oxygen, occurs in the light reactions in all photosynthetic organisms. Some such organisms, including the alga \"Chlamydomonas reinhardtii\" and cyanobacteria, have evolved a second step in the dark reactions in which protons and electrons are reduced to form H gas by specialized hydrogenases in the chloroplast. Efforts have been undertaken to genetically modify cyanobacterial hydrogenases to efficiently synthesize H gas even in the presence of oxygen. Efforts have also been undertaken with genetically modified alga in a bioreactor.\n\nHydrogen poses a number of hazards to human safety, from potential detonations and fires when mixed with air to being an asphyxiant in its pure, oxygen-free form. In addition, liquid hydrogen is a cryogen and presents dangers (such as frostbite) associated with very cold liquids. Hydrogen dissolves in many metals, and, in addition to leaking out, may have adverse effects on them, such as hydrogen embrittlement, leading to cracks and explosions. Hydrogen gas leaking into external air may spontaneously ignite. Moreover, hydrogen fire, while being extremely hot, is almost invisible, and thus can lead to accidental burns.\n\nEven interpreting the hydrogen data (including safety data) is confounded by a number of phenomena. Many physical and chemical properties of hydrogen depend on the parahydrogen/orthohydrogen ratio (it often takes days or weeks at a given temperature to reach the equilibrium ratio, for which the data is usually given). Hydrogen detonation parameters, such as critical detonation pressure and temperature, strongly depend on the container geometry.\n\n\n\n", "id": "13255", "title": "Hydrogen"}
{"url": "https://en.wikipedia.org/wiki?curid=13256", "text": "Helium\n\nHelium is a chemical element with symbol He and atomic number 2. It is a colorless, odorless, tasteless, non-toxic, inert, monatomic gas, the first in the noble gas group in the periodic table. Its boiling point is the lowest among all the elements.\n\nAfter hydrogen, helium is the second lightest and second most abundant element in the observable universe, being present at about 24% of the total elemental mass, which is more than 12 times the mass of all the heavier elements combined. Its abundance is similar to this figure in the Sun and in Jupiter. This is due to the very high nuclear binding energy (per nucleon) of helium-4 with respect to the next three elements after helium. This helium-4 binding energy also accounts for why it is a product of both nuclear fusion and radioactive decay. Most helium in the universe is helium-4, and is believed to have been formed during the Big Bang. Large amounts of new helium are being created by nuclear fusion of hydrogen in stars.\n\nHelium is named for the Greek god of the Sun, Helios. It was first detected as an unknown yellow spectral line signature in sunlight during a solar eclipse in 1868 by French astronomer Jules Janssen. Janssen is jointly credited with detecting the element along with Norman Lockyer. Janssen observed during the solar eclipse of 1868 while Lockyer observed from Britain. Lockyer was the first to propose that the line was due to a new element, which he named. The formal discovery of the element was made in 1895 by two Swedish chemists, Per Teodor Cleve and Nils Abraham Langlet, who found helium emanating from the uranium ore cleveite. In 1903, large reserves of helium were found in natural gas fields in parts of the United States, which is by far the largest supplier of the gas today.\n\nLiquid helium is used in cryogenics (its largest single use, absorbing about a quarter of production), particularly in the cooling of superconducting magnets, with the main commercial application being in MRI scanners. Helium's other industrial uses—as a pressurizing and purge gas, as a protective atmosphere for arc welding and in processes such as growing crystals to make silicon wafers—account for half of the gas produced. A well-known but minor use is as a lifting gas in balloons and airships. As with any gas whose density differs from that of air, inhaling a small volume of helium temporarily changes the timbre and quality of the human voice. In scientific research, the behavior of the two fluid phases of helium-4 (helium I and helium II) is important to researchers studying quantum mechanics (in particular the property of superfluidity) and to those looking at the phenomena, such as superconductivity, produced in matter near absolute zero.\n\nOn Earth it is relatively rare—5.2 ppm by volume in the atmosphere. Most terrestrial helium present today is created by the natural radioactive decay of heavy radioactive elements (thorium and uranium, although there are other examples), as the alpha particles emitted by such decays consist of helium-4 nuclei. This radiogenic helium is trapped with natural gas in concentrations as great as 7% by volume, from which it is extracted commercially by a low-temperature separation process called fractional distillation. Previously, terrestrial helium—a non-renewable resource, because once released into the atmosphere it readily escapes into space—was thought to be in increasingly short supply. However, recent studies suggest that helium produced deep in the earth by radioactive decay can collect in natural gas reserves in larger than expected quantities, in some cases having been released by volcanic activity.\n\nThe first evidence of helium was observed on August 18, 1868, as a bright yellow line with a wavelength of 587.49 nanometers in the spectrum of the chromosphere of the Sun. The line was detected by French astronomer Jules Janssen during a total solar eclipse in Guntur, India. This line was initially assumed to be sodium. On October 20 of the same year, English astronomer Norman Lockyer observed a yellow line in the solar spectrum, which he named the D Fraunhofer line because it was near the known D and D lines of sodium. He concluded that it was caused by an element in the Sun unknown on Earth. Lockyer and English chemist Edward Frankland named the element with the Greek word for the Sun, ἥλιος (\"helios\").\n\nIn 1882, Italian physicist Luigi Palmieri detected helium on Earth for the first time through its D spectral line, when he analyzed the lava of Mount Vesuvius.\n\nOn March 26, 1895, Scottish chemist Sir William Ramsay isolated helium on Earth by treating the mineral cleveite (a variety of uraninite with at least 10% rare earth elements) with mineral acids. Ramsay was looking for argon but, after separating nitrogen and oxygen from the gas liberated by sulfuric acid, he noticed a bright yellow line that matched the D line observed in the spectrum of the Sun. These samples were identified as helium by Lockyer and British physicist William Crookes. It was independently isolated from cleveite in the same year by chemists Per Teodor Cleve and Abraham Langlet in Uppsala, Sweden, who collected enough of the gas to accurately determine its atomic weight. Helium was also isolated by the American geochemist William Francis Hillebrand prior to Ramsay's discovery when he noticed unusual spectral lines while testing a sample of the mineral uraninite. Hillebrand, however, attributed the lines to nitrogen. His letter of congratulations to Ramsay offers an interesting case of discovery and near-discovery in science.\n\nIn 1907, Ernest Rutherford and Thomas Royds demonstrated that alpha particles are helium nuclei by allowing the particles to penetrate the thin glass wall of an evacuated tube, then creating a discharge in the tube to study the spectra of the new gas inside. In 1908, helium was first liquefied by Dutch physicist Heike Kamerlingh Onnes by cooling the gas to less than one kelvin. He tried to solidify it by further reducing the temperature but failed because helium does not solidify at atmospheric pressure. Onnes' student Willem Hendrik Keesom was eventually able to solidify 1 cm of helium in 1926 by applying additional external pressure.\n\nIn 1938, Russian physicist Pyotr Leonidovich Kapitsa discovered that helium-4 has almost no viscosity at temperatures near absolute zero, a phenomenon now called superfluidity. This phenomenon is related to Bose–Einstein condensation. In 1972, the same phenomenon was observed in helium-3, but at temperatures much closer to absolute zero, by American physicists Douglas D. Osheroff, David M. Lee, and Robert C. Richardson. The phenomenon in helium-3 is thought to be related to pairing of helium-3 fermions to make bosons, in analogy to Cooper pairs of electrons producing superconductivity.\n\nAfter an oil drilling operation in 1903 in Dexter, Kansas, produced a gas geyser that would not burn, Kansas state geologist Erasmus Haworth collected samples of the escaping gas and took them back to the University of Kansas at Lawrence where, with the help of chemists Hamilton Cady and David McFarland, he discovered that the gas consisted of, by volume, 72% nitrogen, 15% methane (a combustible percentage only with sufficient oxygen), 1% hydrogen, and 12% an unidentifiable gas. With further analysis, Cady and McFarland discovered that 1.84% of the gas sample was helium. This showed that despite its overall rarity on Earth, helium was concentrated in large quantities under the American Great Plains, available for extraction as a byproduct of natural gas.\n\nThis enabled the United States to become the world's leading supplier of helium. Following a suggestion by Sir Richard Threlfall, the United States Navy sponsored three small experimental helium plants during World War I. The goal was to supply barrage balloons with the non-flammable, lighter-than-air gas. A total of of 92% helium was produced in the program even though less than a cubic meter of the gas had previously been obtained. Some of this gas was used in the world's first helium-filled airship, the U.S. Navy's C-7, which flew its maiden voyage from Hampton Roads, Virginia, to Bolling Field in Washington, D.C., on December 1, 1921, nearly two years before the Navy's first \"rigid\" helium-filled airship, the Naval Aircraft Factory-built \"USS Shenandoah\", flew in September 1923.\n\nAlthough the extraction process, using low-temperature gas liquefaction, was not developed in time to be significant during World War I, production continued. Helium was primarily used as a lifting gas in lighter-than-air craft. During World War II, the demand increased for helium for lifting gas and for shielded arc welding. The helium mass spectrometer was also vital in the atomic bomb Manhattan Project.\n\nThe government of the United States set up the National Helium Reserve in 1925 at Amarillo, Texas, with the goal of supplying military airships in time of war and commercial airships in peacetime. Because of the Helium Control Act (1927), which banned the export of scarce helium on which the US then had a production monopoly, together with the prohibitive cost of the gas, the Hindenburg, like all German Zeppelins, was forced to use hydrogen as the lift gas. The helium market after World War II was depressed but the reserve was expanded in the 1950s to ensure a supply of liquid helium as a coolant to create oxygen/hydrogen rocket fuel (among other uses) during the Space Race and Cold War. Helium use in the United States in 1965 was more than eight times the peak wartime consumption.\n\nAfter the \"Helium Acts Amendments of 1960\" (Public Law 86–777), the U.S. Bureau of Mines arranged for five private plants to recover helium from natural gas. For this \"helium conservation\" program, the Bureau built a pipeline from Bushton, Kansas, to connect those plants with the government's partially depleted Cliffside gas field near Amarillo, Texas. This helium-nitrogen mixture was injected and stored in the Cliffside gas field until needed, at which time it was further purified.\n\nBy 1995, a billion cubic meters of the gas had been collected and the reserve was US$1.4 billion in debt, prompting the Congress of the United States in 1996 to phase out the reserve. The resulting \"Helium Privatization Act of 1996\" (Public Law 104–273) directed the United States Department of the Interior to empty the reserve, with sales starting by 2005.\n\nHelium produced between 1930 and 1945 was about 98.3% pure (2% nitrogen), which was adequate for airships. In 1945, a small amount of 99.9% helium was produced for welding use. By 1949, commercial quantities of Grade A 99.95% helium were available.\n\nFor many years, the United States produced more than 90% of commercially usable helium in the world, while extraction plants in Canada, Poland, Russia, and other nations produced the remainder. In the mid-1990s, a new plant in Arzew, Algeria, producing 17 million cubic meters (600 million cubic feet) began operation, with enough production to cover all of Europe's demand. Meanwhile, by 2000, the consumption of helium within the U.S. had risen to more than 15 million kg per year. In 2004–2006, additional plants in Ras Laffan, Qatar, and Skikda, Algeria were built. Algeria quickly became the second leading producer of helium. Through this time, both helium consumption and the costs of producing helium increased. From 2002 to 2007 helium prices doubled.\n\nAs of 2012, the United States National Helium Reserve accounted for 30 percent of the world's helium. The reserve was expected to run out of helium in 2018. Despite that, a proposed bill in the United States Senate would allow the reserve to continue to sell the gas. Other large reserves were in the Hugoton in Kansas, United States, and nearby gas fields of Kansas and the panhandles of Texas and Oklahoma. New helium plants were scheduled to open in 2012 in Qatar, Russia, and the US state of Wyoming, but they were not expected to ease the shortage.\n\nIn 2013, Qatar started up the world's largest helium unit. 2014 was widely acknowledged to be a year of over-supply in the helium business, following years of renowned shortages. Nasdaq reported (2015) that for Air Products, an international corporation that sells gases for industrial use, helium volumes remain under pressure due to feedstock supply constraints.\n\nIn the perspective of quantum mechanics, helium is the second simplest atom to model, following the hydrogen atom. Helium is composed of two electrons in atomic orbitals surrounding a nucleus containing two protons and (usually) two neutrons. As in Newtonian mechanics, no system that consists of more than two particles can be solved with an exact analytical mathematical approach (see 3-body problem) and helium is no exception. Thus, numerical mathematical methods are required, even to solve the system of one nucleus and two electrons. Such computational chemistry methods have been used to create a quantum mechanical picture of helium electron binding which is accurate to within < 2% of the correct value, in a few computational steps. Such models show that each electron in helium partly screens the nucleus from the other, so that the effective nuclear charge \"Z\" which each electron sees, is about 1.69 units, not the 2 charges of a classic \"bare\" helium nucleus.\n\nThe nucleus of the helium-4 atom is identical with an alpha particle. High-energy electron-scattering experiments show its charge to decrease exponentially from a maximum at a central point, exactly as does the charge density of helium's own electron cloud. This symmetry reflects similar underlying physics: the pair of neutrons and the pair of protons in helium's nucleus obey the same quantum mechanical rules as do helium's pair of electrons (although the nuclear particles are subject to a different nuclear binding potential), so that all these fermions fully occupy 1s orbitals in pairs, none of them possessing orbital angular momentum, and each cancelling the other's intrinsic spin. Adding another of any of these particles would require angular momentum and would release substantially less energy (in fact, no nucleus with five nucleons is stable). This arrangement is thus energetically extremely stable for all these particles, and this stability accounts for many crucial facts regarding helium in nature.\n\nFor example, the stability and low energy of the electron cloud state in helium accounts for the element's chemical inertness, and also the lack of interaction of helium atoms with each other, producing the lowest melting and boiling points of all the elements.\n\nIn a similar way, the particular energetic stability of the helium-4 nucleus, produced by similar effects, accounts for the ease of helium-4 production in atomic reactions that involve either heavy-particle emission or fusion. Some stable helium-3 (2 protons and 1 neutron) is produced in fusion reactions from hydrogen, but it is a very small fraction compared to the highly favorable helium-4.\nThe unusual stability of the helium-4 nucleus is also important cosmologically: it explains the fact that in the first few minutes after the Big Bang, as the \"soup\" of free protons and neutrons which had initially been created in about 6:1 ratio cooled to the point that nuclear binding was possible, almost all first compound atomic nuclei to form were helium-4 nuclei. So tight was helium-4 binding that helium-4 production consumed nearly all of the free neutrons in a few minutes, before they could beta-decay, and also leaving few to form heavier atoms such as lithium, beryllium, or boron. Helium-4 nuclear binding per nucleon is stronger than in any of these elements (see nucleogenesis and binding energy) and thus, once helium had been formed, no energetic drive was available to make elements 3, 4 and 5. It was barely energetically favorable for helium to fuse into the next element with a lower energy per nucleon, carbon. However, due to lack of intermediate elements, this process requires three helium nuclei striking each other nearly simultaneously (see triple alpha process). There was thus no time for significant carbon to be formed in the few minutes after the Big Bang, before the early expanding universe cooled to the temperature and pressure point where helium fusion to carbon was no longer possible. This left the early universe with a very similar ratio of hydrogen/helium as is observed today (3 parts hydrogen to 1 part helium-4 by mass), with nearly all the neutrons in the universe trapped in helium-4.\n\nAll heavier elements (including those necessary for rocky planets like the Earth, and for carbon-based or other life) have thus been created since the Big Bang in stars which were hot enough to fuse helium itself. All elements other than hydrogen and helium today account for only 2% of the mass of atomic matter in the universe. Helium-4, by contrast, makes up about 23% of the universe's ordinary matter—nearly all the ordinary matter that is not hydrogen.\n\nHelium is the second least reactive noble gas after neon, and thus the second least reactive of all elements. It is inert and monatomic in all standard conditions. Because of helium's relatively low molar (atomic) mass, its thermal conductivity, specific heat, and sound speed in the gas phase are all greater than any other gas except hydrogen. For these reasons and the small size of helium monatomic molecules, helium diffuses through solids at a rate three times that of air and around 65% that of hydrogen.\n\nHelium is the least water-soluble monatomic gas, and one of the least water-soluble of any gas (CF, SF, and CF have lower mole fraction solubilities: 0.3802, 0.4394, and 0.2372 x/10, respectively, versus helium's 0.70797 x/10), and helium's index of refraction is closer to unity than that of any other gas. Helium has a negative Joule-Thomson coefficient at normal ambient temperatures, meaning it heats up when allowed to freely expand. Only below its Joule-Thomson inversion temperature (of about 32 to 50 K at 1 atmosphere) does it cool upon free expansion. Once precooled below this temperature, helium can be liquefied through expansion cooling.\n\nMost extraterrestrial helium is found in a plasma state, with properties quite different from those of atomic helium. In a plasma, helium's electrons are not bound to its nucleus, resulting in very high electrical conductivity, even when the gas is only partially ionized. The charged particles are highly influenced by magnetic and electric fields. For example, in the solar wind together with ionized hydrogen, the particles interact with the Earth's magnetosphere, giving rise to Birkeland currents and the aurora.\n\nUnlike any other element, helium will remain liquid down to absolute zero at normal pressures. This is a direct effect of quantum mechanics: specifically, the zero point energy of the system is too high to allow freezing. Solid helium requires a temperature of 1–1.5 K (about −272 °C or −457 °F) and about 25 bar (2.5 MPa) of pressure. It is often hard to distinguish solid from liquid helium since the refractive index of the two phases are nearly the same. The solid has a sharp melting point and has a crystalline structure, but it is highly compressible; applying pressure in a laboratory can decrease its volume by more than 30%. With a bulk modulus of about 27 MPa it is ~100 times more compressible than water. Solid helium has a density of 0.214 ± 0.006 g/cm at 1.15 K and 66 atm; the projected density at 0 K and 25 bar (2.5 MPa) is 0.187 ± 0.009 g/cm.\n\nBelow its boiling point of 4.22 kelvins and above the lambda point of 2.1768 kelvins, the isotope helium-4 exists in a normal colorless liquid state, called \"helium I\". Like other cryogenic liquids, helium I boils when it is heated and contracts when its temperature is lowered. Below the lambda point, however, helium does not boil, and it expands as the temperature is lowered further. \n\nHelium I has a gas-like index of refraction of 1.026 which makes its surface so hard to see that floats of Styrofoam are often used to show where the surface is. This colorless liquid has a very low viscosity and a density of 0.145–0.125 g/mL (between about 0 and 4 K), which is only one-fourth the value expected from classical physics. Quantum mechanics is needed to explain this property and thus both states of liquid helium (helium I and helium II) are called \"quantum fluids\", meaning they display atomic properties on a macroscopic scale. This may be an effect of its boiling point being so close to absolute zero, preventing random molecular motion (thermal energy) from masking the atomic properties.\n\nLiquid helium below its lambda point (called \"helium II\") exhibits very unusual characteristics. Due to its high thermal conductivity, when it boils, it does not bubble but rather evaporates directly from its surface. Helium-3 also has a superfluid phase, but only at much lower temperatures; as a result, less is known about the properties of the isotope.\nHelium II is a superfluid, a quantum mechanical state (see: macroscopic quantum phenomena) of matter with strange properties. For example, when it flows through capillaries as thin as 10 to 10 m it has no measurable viscosity. However, when measurements were done between two moving discs, a viscosity comparable to that of gaseous helium was observed. Current theory explains this using the \"two-fluid model\" for helium II. In this model, liquid helium below the lambda point is viewed as containing a proportion of helium atoms in a ground state, which are superfluid and flow with exactly zero viscosity, and a proportion of helium atoms in an excited state, which behave more like an ordinary fluid.\n\nIn the \"fountain effect\", a chamber is constructed which is connected to a reservoir of helium II by a sintered disc through which superfluid helium leaks easily but through which non-superfluid helium cannot pass. If the interior of the container is heated, the superfluid helium changes to non-superfluid helium. In order to maintain the equilibrium fraction of superfluid helium, superfluid helium leaks through and increases the pressure, causing liquid to fountain out of the container.\n\nThe thermal conductivity of helium II is greater than that of any other known substance, a million times that of helium I and several hundred times that of copper. This is because heat conduction occurs by an exceptional quantum mechanism. Most materials that conduct heat well have a valence band of free electrons which serve to transfer the heat. Helium II has no such valence band but nevertheless conducts heat well. The flow of heat is governed by equations that are similar to the wave equation used to characterize sound propagation in air. When heat is introduced, it moves at 20 meters per second at 1.8 K through helium II as waves in a phenomenon known as \"second sound\".\n\nHelium II also exhibits a creeping effect. When a surface extends past the level of helium II, the helium II moves along the surface, against the force of gravity. Helium II will escape from a vessel that is not sealed by creeping along the sides until it reaches a warmer region where it evaporates. It moves in a 30 nm-thick film regardless of surface material. This film is called a Rollin film and is named after the man who first characterized this trait, Bernard V. Rollin. As a result of this creeping behavior and helium II's ability to leak rapidly through tiny openings, it is very difficult to confine liquid helium. Unless the container is carefully constructed, the helium II will creep along the surfaces and through valves until it reaches somewhere warmer, where it will evaporate. Waves propagating across a Rollin film are governed by the same equation as gravity waves in shallow water, but rather than gravity, the restoring force is the van der Waals force. These waves are known as \"third sound\".\n\nThere are nine known isotopes of helium, but only helium-3 and helium-4 are stable. In the Earth's atmosphere, one atom is for every million that are . Unlike most elements, helium's isotopic abundance varies greatly by origin, due to the different formation processes. The most common isotope, helium-4, is produced on Earth by alpha decay of heavier radioactive elements; the alpha particles that emerge are fully ionized helium-4 nuclei. Helium-4 is an unusually stable nucleus because its nucleons are arranged into complete shells. It was also formed in enormous quantities during Big Bang nucleosynthesis.\n\nHelium-3 is present on Earth only in trace amounts; most of it since Earth's formation, though some falls to Earth trapped in cosmic dust. Trace amounts are also produced by the beta decay of tritium. Rocks from the Earth's crust have isotope ratios varying by as much as a factor of ten, and these ratios can be used to investigate the origin of rocks and the composition of the Earth's mantle. is much more abundant in stars as a product of nuclear fusion. Thus in the interstellar medium, the proportion of to is about 100 times higher than on Earth. Extraplanetary material, such as lunar and asteroid regolith, have trace amounts of helium-3 from being bombarded by solar winds. The Moon's surface contains helium-3 at concentrations on the order of 10 ppb, much higher than the approximately 5 ppt found in the Earth's atmosphere. A number of people, starting with Gerald Kulcinski in 1986, have proposed to explore the moon, mine lunar regolith, and use the helium-3 for fusion.\n\nLiquid helium-4 can be cooled to about 1 kelvin using evaporative cooling in a 1-K pot. Similar cooling of helium-3, which has a lower boiling point, can achieve about in a helium-3 refrigerator. Equal mixtures of liquid and below separate into two immiscible phases due to their dissimilarity (they follow different quantum statistics: helium-4 atoms are bosons while helium-3 atoms are fermions). Dilution refrigerators use this immiscibility to achieve temperatures of a few millikelvins.\n\nIt is possible to produce exotic helium isotopes, which rapidly decay into other substances. The shortest-lived heavy helium isotope is helium-5 with a half-life of . Helium-6 decays by emitting a beta particle and has a half-life of 0.8 second. Helium-7 also emits a beta particle as well as a gamma ray. Helium-7 and helium-8 are created in certain nuclear reactions. Helium-6 and helium-8 are known to exhibit a nuclear halo.\n\nHelium has a valence of zero and is chemically unreactive under all normal conditions. It is an electrical insulator unless ionized. As with the other noble gases, helium has metastable energy levels that allow it to remain ionized in an electrical discharge with a voltage below its ionization potential. Helium can form unstable compounds, known as excimers, with tungsten, iodine, fluorine, sulfur, and phosphorus when it is subjected to a glow discharge, to electron bombardment, or reduced to plasma by other means. The molecular compounds HeNe, HgHe, and WHe, and the molecular ions , , , and have been created this way. HeH is also stable in its ground state, but is extremely reactive—it is the strongest Brønsted acid known, and therefore can exist only in isolation, as it will protonate any molecule or counteranion it contacts. This technique has also produced the neutral molecule He, which has a large number of band systems, and HgHe, which is apparently held together only by polarization forces.\n\nVan der Waals compounds of helium can also be formed with cryogenic helium gas and atoms of some other substance, such as LiHe and He.\n\nTheoretically, other true compounds may be possible, such as helium fluorohydride (HHeF) which would be analogous to HArF, discovered in 2000. Calculations show that two new compounds containing a helium-oxygen bond could be stable. Two new molecular species, predicted using theory, CsFHeO and N(CH)FHeO, are derivatives of a metastable FHeO anion first theorized in 2005 by a group from Taiwan. If confirmed by experiment, the only remaining element with no known stable compounds would be neon.\n\nHelium atoms have been inserted into the hollow carbon cage molecules (the fullerenes) by heating under high pressure. The endohedral fullerene molecules formed are stable at high temperatures. When chemical derivatives of these fullerenes are formed, the helium stays inside. If helium-3 is used, it can be readily observed by helium nuclear magnetic resonance spectroscopy. Many fullerenes containing helium-3 have been reported. Although the helium atoms are not attached by covalent or ionic bonds, these substances have distinct properties and a definite composition, like all stoichiometric chemical compounds.\n\nUnder high pressures helium can form compounds with various other elements. Helium-nitrogen clathrate (He(N)) crystals have been grown at room temperature at pressures ca. 10 GPa in a diamond anvil cell. At 130 GPa NaHe is thermodynamically stable with a fluorite structure.\n\nAlthough it is rare on Earth, helium is the second most abundant element in the known Universe (after hydrogen), constituting 23% of its baryonic mass. The vast majority of helium was formed by Big Bang nucleosynthesis one to three minutes after the Big Bang. As such, measurements of its abundance contribute to cosmological models. In stars, it is formed by the nuclear fusion of hydrogen in proton-proton chain reactions and the CNO cycle, part of stellar nucleosynthesis.\n\nIn the Earth's atmosphere, the concentration of helium by volume is only 5.2 parts per million. The concentration is low and fairly constant despite the continuous production of new helium because most helium in the Earth's atmosphere escapes into space by several processes. In the Earth's heterosphere, a part of the upper atmosphere, helium and other lighter gases are the most abundant elements.\n\nMost helium on Earth is a result of radioactive decay. Helium is found in large amounts in minerals of uranium and thorium, including cleveite, pitchblende, carnotite and monazite, because they emit alpha particles (helium nuclei, He) to which electrons immediately combine as soon as the particle is stopped by the rock. In this way an estimated 3000 metric tons of helium are generated per year throughout the lithosphere. In the Earth's crust, the concentration of helium is 8 parts per billion. In seawater, the concentration is only 4 parts per trillion. There are also small amounts in mineral springs, volcanic gas, and meteoric iron. Because helium is trapped in the subsurface under conditions that also trap natural gas, the greatest natural concentrations of helium on the planet are found in natural gas, from which most commercial helium is extracted. The concentration varies in a broad range from a few ppm to more than 7% in a small gas field in San Juan County, New Mexico.\n\nAs of 2011 the world's helium reserves were estimated at 40 billion cubic meters, with a quarter of that being in the South Pars / North Dome Gas-Condensate field owned jointly by Qatar and Iran.\n\nFor large-scale use, helium is extracted by fractional distillation from natural gas, which can contain as much as 7% helium. Since helium has a lower boiling point than any other element, low temperature and high pressure are used to liquefy nearly all the other gases (mostly nitrogen and methane). The resulting crude helium gas is purified by successive exposures to lowering temperatures, in which almost all of the remaining nitrogen and other gases are precipitated out of the gaseous mixture. Activated charcoal is used as a final purification step, usually resulting in 99.995% pure Grade-A helium. The principal impurity in Grade-A helium is neon. In a final production step, most of the helium that is produced is liquefied via a cryogenic process. This is necessary for applications requiring liquid helium and also allows helium suppliers to reduce the cost of long distance transportation, as the largest liquid helium containers have more than five times the capacity of the largest gaseous helium tube trailers.\n\nIn 2008, approximately 169 million standard cubic meters (SCM) of helium were extracted from natural gas or withdrawn from helium reserves with approximately 78% from the United States, 10% from Algeria, and most of the remainder from Russia, Poland and Qatar. By 2013, increases in helium production in Qatar (under the company RasGas managed by Air Liquide) had increased Qatar's fraction of world helium production to 25%, and made it the second largest exporter after the United States. \nAn estimated of helium was detected in Tanzania in 2016.\n\nIn the United States, most helium is extracted from natural gas of the Hugoton and nearby gas fields in Kansas, Oklahoma, and the Panhandle Field in Texas. Much of this gas was once sent by pipeline to the National Helium Reserve, but since 2005 this reserve is being depleted and sold off, and is expected under present law to be largely depleted by 2021.\n\nDiffusion of crude natural gas through special semipermeable membranes and other barriers is another method to recover and purify helium. In 1996, the U.S. had \"proven\" helium reserves, in such gas well complexes, of about 147 billion standard cubic feet (4.2 billion SCM). At rates of use at that time (72 million SCM per year in the U.S.; see pie chart below) this would have been enough helium for about 58 years of U.S. use, and less than this (perhaps 80% of the time) at world use rates, although factors in saving and processing impact effective reserve numbers.\n\nHelium must be extracted from natural gas because it is present in air at only a fraction of that of neon, yet the demand for it is far higher. It is estimated that if all neon production were retooled to save helium, that 0.1% of the world's helium demands would be satisfied. Similarly, only 1% of the world's helium demands could be satisfied by re-tooling all air distillation plants. Helium can be synthesized by bombardment of lithium or boron with high-velocity protons, but this process is a completely uneconomic method of production.\n\nHelium is commercially available in either liquid or gaseous form. As a liquid, it can be supplied in small insulated containers called dewars which hold as much as 1,000 liters of helium, or in large ISO containers which have nominal capacities as large as 42 m (around 11,000 U.S. gallons). In gaseous form, small quantities of helium are supplied in high-pressure cylinders holding as much as 8 m (approx. 282 standard cubic feet), while large quantities of high-pressure gas are supplied in tube trailers which have capacities of as much as 4,860 m (approx. 172,000 standard cubic feet).\n\nAccording to helium conservationists like Nobel laureate physicist Robert Coleman Richardson, the free market price of helium has contributed to \"wasteful\" usage (e.g. for helium balloons). Prices in the 2000s have been lowered by U.S. Congress' decision to sell off the country's large helium stockpile by 2015. According to Richardson, the current price needs to be multiplied by 20 to eliminate the excessive wasting of helium. In their book, the \"Future of helium as a natural resource\" (Routledge, 2012), Nuttall, Clarke & Glowacki (2012) also proposed to create an International Helium Agency (IHA) to build a sustainable market for this precious commodity.\n\nWhile balloons are perhaps the best known use of helium, they are a minor part of all helium use. Helium is used for many purposes that require some of its unique properties, such as its low boiling point, low density, low solubility, high thermal conductivity, or inertness. Of the 2014 world helium total production of about 32 million kg (180 million standard cubic meters) helium per year, the largest use (about 32% of the total in 2014) is in cryogenic applications, most of which involves cooling the superconducting magnets in medical MRI scanners and NMR spectrometers. Other major uses were pressurizing and purging systems, welding, maintenance of controlled atmospheres, and leak detection. Other uses by category were relatively minor fractions.\n\nHelium is used as a protective gas in growing silicon and germanium crystals, in titanium and zirconium production, and in gas chromatography, because it is inert. Because of its inertness, thermally and calorically perfect nature, high speed of sound, and high value of the heat capacity ratio, it is also useful in supersonic wind tunnels and impulse facilities.\n\nHelium is used as a shielding gas in arc welding processes on materials that at welding temperatures are contaminated and weakened by air or nitrogen. A number of inert shielding gases are used in gas tungsten arc welding, but helium is used instead of cheaper argon especially for welding materials that have higher heat conductivity, like aluminium or copper.\n\nOne industrial application for helium is leak detection. Because helium diffuses through solids three times faster than air, it is used as a tracer gas to detect leaks in high-vacuum equipment (such as cryogenic tanks) and high-pressure containers. The tested object is placed in a chamber, which is then evacuated and filled with helium. The helium that escapes through the leaks is detected by a sensitive device (helium mass spectrometer), even at the leak rates as small as 10 mbar·L/s (10 Pa·m/s). The measurement procedure is normally automatic and is called helium integral test. A simpler procedure is to fill the tested object with helium and to manually search for leaks with a hand-held device.\n\nHelium leaks through cracks should not be confused with gas permeation through a bulk material. While helium has documented permeation constants (thus a calculable permeation rate) through glasses, ceramics, and synthetic materials, inert gases such as helium will not permeate most bulk metals.\n\nBecause it is lighter than air, airships and balloons are inflated with helium for lift. While hydrogen gas is more buoyant, and escapes permeating through a membrane at a lower rate, helium has the advantage of being non-flammable, and indeed fire-retardant. Another minor use is in rocketry, where helium is used as an ullage medium to displace fuel and oxidizers in storage tanks and to condense hydrogen and oxygen to make rocket fuel. It is also used to purge fuel and oxidizer from ground support equipment prior to launch and to pre-cool liquid hydrogen in space vehicles. For example, the Saturn V rocket used in the Apollo program needed about 370,000 m (13 million cubic feet) of helium to launch.\n\nHelium as a breathing gas has no narcotic properties, so helium mixtures such as trimix, heliox and heliair are used for deep diving to reduce the effects of narcosis, which worsen with increasing depth. As pressure increases with depth, the density of the breathing gas also increases, and the low molecular weight of helium is found to considerably reduce the effort of breathing by lowering the density of the mixture. This reduces the Reynolds number of flow, leading to a reduction of turbulent flow and an increase in laminar flow, which requires less work of breathing. At depths below divers breathing helium–oxygen mixtures begin to experience tremors and a decrease in psychomotor function, symptoms of high-pressure nervous syndrome. This effect may be countered to some extent by adding an amount of narcotic gas such as hydrogen or nitrogen to a helium–oxygen mixture.\n\nHelium–neon lasers, a type of low-powered gas laser producing a red beam, had various practical applications which included barcode readers and laser pointers, before they were almost universally replaced by cheaper diode lasers.\n\nFor its inertness and high thermal conductivity, neutron transparency, and because it does not form radioactive isotopes under reactor conditions, helium is used as a heat-transfer medium in some gas-cooled nuclear reactors.\n\nHelium, mixed with a heavier gas such as xenon, is useful for thermoacoustic refrigeration due to the resulting high heat capacity ratio and low Prandtl number. The inertness of helium has environmental advantages over conventional refrigeration systems which contribute to ozone depletion or global warming.\n\nHelium is also used in some hard disk drives.\n\nThe use of helium reduces the distorting effects of temperature variations in the space between lenses in some telescopes, due to its extremely low index of refraction. This method is especially used in solar telescopes where a vacuum tight telescope tube would be too heavy.\n\nHelium is a commonly used carrier gas for gas chromatography.\n\nThe age of rocks and minerals that contain uranium and thorium can be estimated by measuring the level of helium with a process known as helium dating.\n\nHelium at low temperatures is used in cryogenics, and in certain cryogenics applications. As examples of applications, liquid helium is used to cool certain metals to the extremely low temperatures required for superconductivity, such as in superconducting magnets for magnetic resonance imaging. The Large Hadron Collider at CERN uses 96 metric tons of liquid helium to maintain the temperature at 1.9 kelvin.\n\nNeutral helium at standard conditions is non-toxic, plays no biological role and is found in trace amounts in human blood.\nThe speed of sound in helium is nearly three times the speed of sound in air. Because the fundamental frequency of a gas-filled cavity is proportional to the speed of sound in the gas, when helium is inhaled there is a corresponding increase in the resonant frequencies of the vocal tract. The fundamental frequency (sometimes called pitch) does not change, since this is produced by direct vibration of the vocal folds, which is unchanged. However, the higher resonant frequencies cause a change in timbre, resulting in a reedy, duck-like vocal quality. The opposite effect, lowering resonant frequencies, can be obtained by inhaling a dense gas such as sulfur hexafluoride or xenon.\n\nInhaling helium can be dangerous if done to excess, since helium is a simple asphyxiant and so displaces oxygen needed for normal respiration. Fatalities have been recorded, including a youth who suffocated in Vancouver in 2003 and two adults who suffocated in South Florida in 2006. In 1998, an Australian girl (her age is not known) from Victoria fell unconscious and temporarily turned blue after inhaling the entire contents of a party balloon.\nInhaling helium directly from pressurized cylinders or even balloon filling valves is extremely dangerous, as high flow rate and pressure can result in barotrauma, fatally rupturing lung tissue.\n\nDeath caused by helium is rare. The first media-recorded case was that of a 15-year-old girl from Texas who died in 1998 from helium inhalation at a friend's party; the exact type of helium death is unidentified.\n\nIn the United States only two fatalities were reported between 2000 and 2004, including a man who died in North Carolina of barotrauma in 2002. A youth asphyxiated in Vancouver during 2003, and a 27-year-old man in Australia had an embolism after breathing from a cylinder in 2000. Since then two adults asphyxiated in South Florida in 2006, and there were cases in 2009 and 2010, one a Californian youth who was found with a bag over his head, attached to a helium tank, and another teenager in Northern Ireland died of asphyxiation. At Eagle Point, Oregon a teenage girl died in 2012 from barotrauma at a party. A girl from Michigan died from hypoxia later in the year.\n\nOn February 4, 2015 it was revealed that during the recording of their main TV show on January 28, a 12-year-old member (name withheld) of Japanese all-girl singing group 3B Junior suffered from air embolism, losing consciousness and falling in a coma as a result of air bubbles blocking the flow of blood to the brain, after inhaling huge quantities of helium as part of a game. The incident was not made public until a week later. The staff of TV Asahi held an emergency press conference to communicate that the member had been taken to the hospital and is showing signs of rehabilitation such as moving eyes and limbs, but her consciousness has not been sufficiently recovered as of yet. Police have launched an investigation due to a neglect of safety measures.\n\nThe safety issues for cryogenic helium are similar to those of liquid nitrogen; its extremely low temperatures can result in cold burns, and the liquid-to-gas expansion ratio can cause explosions if no pressure-relief devices are installed. Containers of helium gas at 5 to 10 K should be handled as if they contain liquid helium due to the rapid and significant thermal expansion that occurs when helium gas at less than 10 K is warmed to room temperature.\n\nAt high pressures (more than about 20 atm or two MPa), a mixture of helium and oxygen (heliox) can lead to high-pressure nervous syndrome, a sort of reverse-anesthetic effect; adding a small amount of nitrogen to the mixture can alleviate the problem.\n\n\n\nGeneral\n\nMore detail\n\nMiscellaneous\n\nHelium shortage\n", "id": "13256", "title": "Helium"}
{"url": "https://en.wikipedia.org/wiki?curid=13257", "text": "Hydrocarbon\n\nIn organic chemistry, a hydrocarbon is an organic compound consisting entirely of hydrogen and carbon, and thus are group 14 hydrides. Hydrocarbons from which one hydrogen atom has been removed are functional groups, called hydrocarbyls.\nAromatic hydrocarbons (arenes), alkanes, alkenes, cycloalkanes and alkyne-based compounds are different types of hydrocarbons.\n\nThe majority of hydrocarbons found on Earth naturally occur in crude oil, where decomposed organic matter provides an abundance of carbon and hydrogen which, when bonded, can catenate to form seemingly limitless chains.\n\nThe classifications for hydrocarbons, defined by IUPAC nomenclature of organic chemistry are as follows:\n\nHydrocarbons can be gases (e.g. methane and propane), liquids (e.g. hexane and benzene), waxes or low melting solids (e.g. paraffin wax and naphthalene) or polymers (e.g. polyethylene, polypropylene and polystyrene).\n\nBecause of differences in molecular structure, the empirical formula remains different between hydrocarbons; in linear or \"straight-run\" alkanes, alkenes and alkynes, the amount of bonded hydrogen lessens in alkenes and alkynes due to the \"self-bonding\" or catenation of carbon preventing entire saturation of the hydrocarbon by the formation of double or triple bonds.\n\nThis inherent ability of hydrocarbons to bond to themselves is known as catenation, and allows hydrocarbons to form more complex molecules, such as cyclohexane, and in rarer cases, arenes such as benzene. This ability comes from the fact that the bond character between carbon atoms is entirely non-polar, in that the distribution of electrons between the two elements is somewhat even due to the same electronegativity values of the elements (~0.30), and does not result in the formation of an electrophile.\n\nGenerally, with catenation comes the loss of the total amount of bonded hydrocarbons and an increase in the amount of energy required for bond cleavage due to strain exerted upon the molecule; in molecules such as cyclohexane, this is referred to as ring strain, and occurs due to the \"destabilized\" spatial electron configuration of the atom.\n\nIn simple chemistry, as per valence bond theory, the carbon atom must follow the \"\"4-hydrogen rule\"\", which states that the maximum number of atoms available to bond with carbon is equal to the number of electrons that are attracted into the outer shell of carbon. In terms of shells, carbon consists of an incomplete outer shell, which comprises 4 electrons, and thus has 4 electrons available for covalent or dative bonding.\n\nHydrocarbons are hydrophobic like lipids.\n\nSome hydrocarbons also are abundant in the solar system. Lakes of liquid methane and ethane have been found on Titan, Saturn's largest moon, confirmed by the Cassini-Huygens Mission. Hydrocarbons are also abundant in nebulae forming polycyclic aromatic hydrocarbon (PAH) compounds.\n\nHydrocarbons are a primary energy source for current civilizations. The predominant use of hydrocarbons is as a combustible fuel source. In their solid form, hydrocarbons take the form of asphalt (bitumen).\n\nMixtures of volatile hydrocarbons are now used in preference to the chlorofluorocarbons as a propellant for aerosol sprays, due to chlorofluorocarbons' impact on the ozone layer.\n\nMethane (CH) and ethane (CH) are gaseous at ambient temperatures and cannot be readily liquefied by pressure alone. Propane (CH) is however easily liquefied, and exists in 'propane bottles' mostly as a liquid. Butane (CH) is so easily liquefied that it provides a safe, volatile fuel for small pocket lighters. Pentane (CH) is a clear liquid at room temperature, commonly used in chemistry and industry as a powerful nearly odorless solvent of waxes and high molecular weight organic compounds, including greases. Hexane (CH) is also a widely used non-polar, non-aromatic solvent, as well as a significant fraction of common gasoline.\nThe C through C alkanes, alkenes and isomeric cycloalkanes are the top components of gasoline, naphtha, jet fuel and specialized industrial solvent mixtures. With the progressive addition of carbon units, the simple non-ring structured hydrocarbons have higher viscosities, lubricating indices, boiling points, solidification temperatures, and deeper color. At the opposite extreme from methane lie the heavy tars that remain as the \"lowest fraction\" in a crude oil refining retort. They are collected and widely utilized as roofing compounds, pavement composition, wood preservatives (the creosote series) and as extremely high viscosity shear-resisting liquids.\n\nHydrocarbon use is also prevalent in nature. Some eusocial arthropods, such as the Brazilian stingless bee \"Schwarziana quadripunctata\", use unique hydrocarbon \"scents\" in order to determine kin from non-kin. The chemical hydrocarbon composition varies between age, sex, nest location, and hierarchal position.\n\nHydrocarbon poisoning such as that of benzene and petroleum usually occurs accidentally by inhalation or ingestion of these cytotoxic chemical compounds. Intravenous or subcutaneous injection of petroleum compounds with intent of suicide or abuse is an extraordinary event that can result in local damage or systemic toxicity such as tissue necrosis, abscess formation, respiratory system failure and partial damage to the kidneys, the brain and the nervous system. Moaddab and Eskandarlou report a case of chest wall necrosis and empyema resulting from attempting suicide by injection of petroleum into the pleural cavity.\n\nThere are three main types of reactions:\n\n\nSubstitution reactions only occur in saturated hydrocarbons (single carbon–carbon bonds). In this reaction, an alkane reacts with a chlorine molecule. One of the chlorine atoms displace an hydrogen atom. This forms hydrochloric acid as well as the hydrocarbon with one chlorine atom.\nall the way to CCl (carbon tetrachloride)\n\nall the way to CCl (hexachloroethane)\n\nAddition reactions involve alkenes and alkynes. In this reaction a halogen molecule breaks the double or triple bond in the hydrocarbon and forms a bond.\n\nHydrocarbons are currently the main source of the world's electric energy and heat sources (such as home heating) because of the energy produced when burnt. Often this energy is used directly as heat such as in home heaters, which use either petroleum or natural gas. The hydrocarbon is burnt and the heat is used to heat water, which is then circulated. A similar principle is used to create electric energy in power plants.\n\nCommon properties of hydrocarbons are the facts that they produce steam, carbon dioxide and heat during combustion and that oxygen is required for combustion to take place. The simplest hydrocarbon, methane, burns as follows:\n\nIn inadequate supply of air, carbon monoxide gas and water vapour are formed:\n\nAnother example of this reaction is propane:\n\nBurning of hydrocarbons is an example of an exothermic chemical reaction.\n\nHydrocarbons can also be burned with elemental fluorine, resulting in carbon tetrafluoride and hydrogen fluoride products.\n\nExtracted hydrocarbons in a liquid form are referred to as petroleum (literally \"rock oil\") or mineral oil, whereas hydrocarbons in a gaseous form are referred to as natural gas. Petroleum and natural gas are found in the Earth's subsurface with the tools of petroleum geology and are a significant source of fuel and raw materials for the production of organic chemicals.\n\nThe extraction of liquid hydrocarbon fuel from sedimentary basins is integral to modern energy development. Hydrocarbons are mined from oil sands and oil shale, and potentially extracted from sedimentary methane hydrates. These reserves require distillation and upgrading to produce synthetic crude and petroleum.\n\nOil reserves in sedimentary rocks are the source of hydrocarbons for the energy, transport and petrochemical industries.\n\nEconomically important hydrocarbons include fossil fuels such as coal, petroleum and natural gas, and its derivatives such as plastics, paraffin, waxes, solvents and oils. Hydrocarbons – along with NO and sunlight – contribute to the formation of tropospheric ozone and greenhouse gases.\n\nBacteria in the gabbroic layer of the ocean's crust can degrade hydrocarbons; but the extreme environment makes research difficult. Other bacteria such as \"Lutibacterium anuloederans\" can also degrade hydrocarbons.\nMycoremediation or breaking down of hydrocarbon by mycellium and mushroom is possible.\n\nMany hydrocarbons are highly flammable, therefore, care should be taken to prevent injury. Benzene and many aromatic compounds are possible carcinogens, and proper safety equipment must be worn to prevent these harmful compounds from entering the body. If hydrocarbons undergo combustion in tight areas, toxic carbon monoxide can form. Hydrocarbons should be kept away from fluorine compounds due to the high probability of forming toxic hydrofluoric acid.\n\n\n\n", "id": "13257", "title": "Hydrocarbon"}
{"url": "https://en.wikipedia.org/wiki?curid=13258", "text": "Halogen\n\nThe halogens or halogen elements () are a group in the periodic table consisting of five chemically related elements: fluorine (F), chlorine (Cl), bromine (Br), iodine (I), and astatine (At). The artificially created element 117 (tennessine, Ts) may also be a halogen. In the modern IUPAC nomenclature, this group is known as group 17. The symbol X is often used generically to refer to any halogen.\n\nThe name 'halogen' means 'salt-producing'. When halogens react with metals they produce a wide range of salts, including calcium fluoride, sodium chloride (common table salt), silver bromide and potassium iodide.\n\nThe group of halogens is the only periodic table group that contains elements in three of the four main states of matter at standard temperature and pressure. All of the halogens form acids when bonded to hydrogen. Most halogens are typically produced from minerals or salts. The middle halogens, that is chlorine, bromine and iodine, are often used as disinfectants. Organobromides are the most important class of flame retardants. Elemental halogens are dangerously to potentially lethally toxic.\nThe fluorine mineral fluorospar was known as early as 1529. Early chemists realized that fluorine compounds contain an undiscovered element, but were unable to isolate it. In 1869, George Gore, an English chemist, ran a current of electricity through hydrofluoric acid and discovered fluorine, but he was unable to prove his results at the time. In 1886, Henri Moissan, a chemist in Paris, performed electrolysis on potassium bifluoride dissolved in waterless hydrofluoric acid, and successfully produced fluorine.\n\nHydrochloric acid was known to alchemists and early chemists. However, elemental chlorine was not produced until 1774, when Carl Wilhelm Scheele heated hydrochloric acid with manganese dioxide. Scheele called the element \"dephlogisticated muriatic acid\", which is how chlorine was known for 33 years. In 1807, Humphry Davy investigated chlorine and discovered that it is an actual element. Chlorine was used as a poison gas during World War I.\n\nBromine was discovered in the 1820s by Antoine-Jérôme Balard. Balard discovered bromine by passing chlorine gas through a sample of brine. He originally proposed the name \"muride\" for the new element, but the French Academy changed the element's name to bromine.\n\nIodine was discovered by Bernard Courtois, who was using seaweed ash as part of a process for saltpeter manufacture. Courtois typically boiled the seaweed ash with water to generate potassium chloride. However, in 1811, Courtois added sulfuric acid to his process, and found that his process produced purple fumes that condensed into black crystals. Suspecting that these crystals were a new element, Courtois sent samples to other chemists for investigation. Iodine was proven to be a new element by Joseph Gay-Lussac.\n\nIn 1931, Fred Allison claimed to have discovered element 85 with a magneto-optical machine, and named the element Alabamine, but was mistaken. In 1937, Jajendralal De claimed to have discovered element 85 in minerals, and called the element dakine, but he was also mistaken. An attempt at discovering element 85 in 1939 by Horia Hulublei and Yvette Cauchois via spectroscopy was also unsuccessful, as was an attempt in the same year by Walter Minder, who discovered an iodine-like element resulting from beta decay of radium. Element 85, now named astatine, was produced successfully in 1940 by Dale R. Corson, K.R. Mackenzie, and Emilio G. Segrè, who bombarded bismuth with alpha particles.\n\nIn 1842, the Swedish chemist Baron Jöns Jakob Berzelius proposed the term \"halogen\" – ἅλς (\"háls\"), \"salt\" or \"sea\", and γεν- (\"gen-\"), \"to produce\" – for the four elements (fluorine, chlorine, bromine, and iodine) that produce a sea-salt-like substance when they form a compound with a metal. The word \"halogen\" had actually first been proposed in 1811 by Johann Salomo Christoph Schweigger as a name for the newly discovered element chlorine, but Davy's proposed term for this element eventually won out, and Schweigger's term was kept at Berzelius' suggestion as the term for the element group that contains chlorine.\n\nFluorine's name comes from the Latin word \"fluere\", meaning \"to flow\". Chlorine's name comes from the Greek word \"chloros\", meaning \"greenish-yellow\". Bromine's name comes from the Greek word \"bromos\", meaning \"stench\". Iodine's name comes from the Greek word \"iodes\", meaning \"violet\". Astatine's name comes from the Greek word \"astatos\", meaning \"unstable\". Tennessine is named after the US state of Tennessee.\n\nThe halogens show trends in chemical bond energy moving from top to bottom of the periodic table column with fluorine deviating slightly. (It follows trend in having the highest bond energy in compounds with other atoms, but it has very weak bonds within the diatomic F molecule.) This means, as you go down the periodic table, the reactivity of the element will decrease because of the increasing size of the atoms.\n\nHalogens are highly reactive, and as such can be harmful or lethal to biological organisms in sufficient quantities. This high reactivity is due to the high electronegativity of the atoms due to their high effective nuclear charge. Because the halogens have seven valence electrons in their outermost energy level, they can gain an electron by reacting with atoms of other elements to satisfy the octet rule. Fluorine is one of the most reactive elements, attacking otherwise-inert materials such as glass, and forming compounds with the usually inert noble gases. It is a corrosive and highly toxic gas. The reactivity of fluorine is such that, if used or stored in laboratory glassware, it can react with glass in the presence of small amounts of water to form silicon tetrafluoride (SiF). Thus, fluorine must be handled with substances such as Teflon (which is itself an organofluorine compound), extremely dry glass, or metals such as copper or steel, which form a protective layer of fluoride on their surface.\n\nThe high reactivity of fluorine allows paradoxically some of the strongest bonds possible, especially to carbon. For example, Teflon is fluorine bonded with carbon and is extremely resistant to thermal and chemical attack and has a high melting point.\n\nThe halogens form homonuclear diatomic molecules (not proven for astatine).\nDue to relatively weak intermolecular forces, chlorine and fluorine form part of the group known as \"elemental gases\".\n\nThe elements become less reactive and have higher melting points as the atomic number increases. The higher melting points are caused by stronger London dispersion forces resulting from more electrons.\n\nAll of the halogens have been observed to react with hydrogen to form hydrogen halides. For fluorine, chlorine, and bromine, this reaction is in the form of:\n\nHowever, hydrogen iodide and hydrogen astatide can split back into their constituent elements.\n\nThe hydrogen-halogen reactions get gradually less reactive toward the heavier halogens. A fluorine-hydrogen reaction is explosive even when it is dark and cold. A chlorine-hydrogen reaction is also explosive, but only in the presence of light and heat. A bromine-hydrogen reaction is even less explosive; it is explosive only when exposed to flames. Iodine and astatine only partially react with hydrogen, forming equilibria.\n\nAll halogens form binary compounds with hydrogen known as the hydrogen halides: hydrogen fluoride (HF), hydrogen chloride (HCl), hydrogen bromide (HBr), hydrogen iodide (HI), and hydrogen astatide (HAt). All of these compounds form acids when mixed with water. Hydrogen fluoride is the only hydrogen halide that forms hydrogen bonds. Hydrochloric acid, hydrobromic acid, hydroiodic acid, and hydroastatic acid are all strong acids, but hydrofluoric acid is a weak acid.\n\nAll of the hydrogen halides are irritants. Hydrogen fluoride and hydrogen chloride are highly acidic. Hydrogen fluoride is used as an industrial chemical, and is highly toxic, causing pulmonary edema and damaging cells. Hydrogen chloride is also a dangerous chemical. Breathing in gas with more than fifty parts per million of hydrogen chloride can cause death in humans. Hydrogen bromide is even more toxic and irritating than hydrogen chloride. Breathing in gas with more than thirty parts per million of hydrogen bromide can be lethal to humans. Hydrogen iodide, like other hydrogen halides, is toxic.\n\nAll the halogens are known to react with sodium to form sodium fluoride, sodium chloride, sodium bromide, sodium iodide, and sodium astatide. Heated sodium's reaction with halogens produces bright-orange flames. Sodium's reaction with chlorine is in the form of:\n\nIron reacts with fluorine, chlorine, and bromine to form Iron(III) halides. These reactions are in the form of:\n\nHowever, when iron reacts with iodine, it forms only iron(II) iodide.\n\nIron wool can react rapidly with fluorine to form the white compound iron(III) fluoride even in cold temperatures. When chlorine comes into contact with heated iron, they react to form the black iron (III) chloride. However, if the reaction conditions are moist, this reaction will instead result in a reddish-brown product. Iron can also react with bromine to form iron(III) bromide. This compound is reddish-brown in dry conditions. Iron's reaction with bromine is less reactive than its reaction with fluorine or chlorine. Hot iron can also react with iodine, but it forms iron(II) iodide. This compound may be gray, but the reaction is always contaminated with excess iodine, so it is not known for sure. Iron's reaction with iodine is less vigorous than its reaction with the lighter halogens.\n\nInterhalogen compounds are in the form of XY where X and Y are halogens and n is one, three, five, or seven. Interhalogen compounds contain at most two different halogens. Large interhalogens, such as can be produced by a reaction of a pure halogen with a smaller interhalogen such as . All interhalogens except can be produced by directly combining pure halogens in various conditions.\n\nInterhalogens are typically more reactive than all diatomic halogen molecules except F because interhalogen bonds are weaker. However, the chemical properties of interhalogens are still roughly the same as those of diatomic halogens. Many interhalogens consist of one or more atoms of fluorine bonding to a heavier halogen. Chlorine can bond with up to 3 fluorine atoms, bromine can bond with up to five fluorine atoms, and iodine can bond with up to seven fluorine atoms. Most interhalogen compounds are covalent gases. However, there are some interhalogens that are liquids, such as BrF, and many iodine-containing interhalogens are solids.\n\nMany synthetic organic compounds such as plastic polymers, and a few natural ones, contain halogen atoms; these are known as \"halogenated\" compounds or organic halides. Chlorine is by far the most abundant of the halogens in seawater, and the only one needed in relatively large amounts (as chloride ions) by humans. For example, chloride ions play a key role in brain function by mediating the action of the inhibitory transmitter GABA and are also used by the body to produce stomach acid. Iodine is needed in trace amounts for the production of thyroid hormones such as thyroxine. Organohalogens are also synthesized through the nucleophilic abstraction reaction.\n\nPolyhalogenated compounds are industrially created compounds substituted with multiple halogens. Many of them are very toxic and bioaccumulate in humans, and have a very wide application range. They include PCBs, PBDEs, and perfluorinated compounds (PFCs), as well as numerous other compounds.\n\nFluorine reacts vigorously with water to produce oxygen (O) and hydrogen fluoride (HF):\n\nChlorine has maximum solubility of ca. 7.1 g Cl per kg of water at ambient temperature (21 °C). Dissolved chlorine reacts to form hydrochloric acid (HCl) and hypochlorous acid, a solution that can be used as a disinfectant or bleach:\n\nBromine has a solubility of 3.41 g per 100 g of water, but it slowly reacts to form hydrogen bromide (HBr) and hypobromous acid (HBrO):\n\nIodine, however, is minimally soluble in water (0.03 g/100 g water at 20 °C) and does not react with it. However, iodine will form an aqueous solution in the presence of iodide ion, such as by addition of potassium iodide (KI), because the triiodide ion is formed.\n\nThe table below is a summary of the key physical and atomic properties of the halogens. Data marked with question marks are either uncertain or are estimations partially based on periodic trends rather than observations.\n\nFluorine has one stable and naturally occurring isotope, fluorine-19. However, there are trace amounts in nature of the radioactive isotope fluorine-23, which occurs via cluster decay of protactinium-231. A total of eighteen isotopes of fluorine have been discovered, with atomic masses ranging from 14 to 31. Chlorine has two stable and naturally occurring isotopes, chlorine-35 and chlorine-37. However, there are trace amounts in nature of the isotope chlorine-36, which occurs via spallation of argon-36. A total of 24 isotopes of chlorine have been discovered, with atomic masses ranging from 28 to 51.\n\nThere are two stable and naturally occurring isotopes of bromine, bromine-79 and bromine-81. A total of 32 isotopes of bromine have been discovered, with atomic masses ranging 67 to 98. There is one stable and naturally occurring isotope of iodine, iodine-127. However, there are trace amounts in nature of the radioactive isotope iodine-129, which occurs via spallation and from the radioactive decay of uranium in ores. Several other radioactive isotopes of iodine have also been created naturally via the decay of uranium. A total of 38 isotopes of iodine have been discovered, with atomic masses ranging from 108 to 145.\n\nThere are no stable isotopes of astatine. However, there are three naturally occurring radioactive isotopes of astatine produced via radioactive decay of uranium, neptunium, and plutonium. These isotopes are astatine-215, astatine-217, and astatine-219. A total of 31 isotopes of astatine have been discovered, with atomic masses ranging from 193 to 223.\n\nApproximately six million metric tons of the fluorine mineral fluorite are produced each year. Four hundred-thousand metric tons of hydrofluoric acid are made each year. Fluorine gas is made from hydrofluoric acid produced as a by-product in phosphoric acid manufacture. Approximately 15,000 metric tons of fluorine gas are made per year.\n\nThe mineral halite is the mineral that is most commonly mined for chlorine, but the minerals carnallite and sylvite are also mined for chlorine. Forty million metric tons of chlorine are produced each year by the electrolysis of brine.\n\nApproximately 450,000 metric tons of bromine are produced each year. Fifty percent of all bromine produced is produced in the United States, 35% in Israel, and most of the remainder in China. Historically, bromine was produced by adding sulfuric acid and bleaching powder to natural brine. However, in modern times, bromine is produced by electrolysis, a method invented by Herbert Dow. It is also possible to produce bromine by passing chlorine through seawater and then passing air through the seawater.\n\nIn 2003, 22,000 metric tons of iodine were produced. Chile produces 40% of all iodine produced, Japan produces 30%, and smaller amounts are produced in Russia and the United States. Until the 1950s, iodine was extracted from kelp. However, in modern times, iodine is produced in other ways. One way that iodine is produced is by mixing sulfur dioxide with nitrate ores, which contain some iodates. Iodine is also extracted from natural gas fields.\n\nEven though astatine is naturally occurring, it is usually produced by bombarding bismuth with alpha particles.\n\nBoth chlorine and bromine are used as disinfectants for drinking water, swimming pools, fresh wounds, spas, dishes, and surfaces. They kill bacteria and other potentially harmful microorganisms through a process known as sterilization. Their reactivity is also put to use in bleaching. Sodium hypochlorite, which is produced from chlorine, is the active ingredient of most fabric bleaches, and chlorine-derived bleaches are used in the production of some paper products. Chlorine also reacts with sodium to create sodium chloride, which is table salt.\n\nHalogen lamps are a type of incandescent lamp using a tungsten filament in bulbs that have a small amounts of a halogen, such as iodine or bromine added. This enables the production of lamps that are much smaller than non-halogen incandescent lightbulbs at the same wattage. The gas reduces the thinning of the filament and blackening of the inside of the bulb resulting in a bulb that has a much greater life. Halogen lamps glow at a higher temperature (2800 to 3400 Kelvin) with a whiter color than other incandescent bulbs. However, this requires bulbs to be manufactured from fused quartz rather than silica glass to reduce breakage.\n\nIn drug discovery, the incorporation of halogen atoms into a lead drug candidate results in analogues that are usually more lipophilic and less water-soluble. As a consequence, halogen atoms are used to improve penetration through lipid membranes and tissues. It follows that there is a tendency for some halogenated drugs to accumulate in adipose tissue.\n\nThe chemical reactivity of halogen atoms depends on both their point of attachment to the lead and the nature of the halogen. Aromatic halogen groups are far less reactive than aliphatic halogen groups, which can exhibit considerable chemical reactivity. For aliphatic carbon-halogen bonds, the C-F bond is the strongest and usually less chemically reactive than aliphatic C-H bonds. The other aliphatic-halogen bonds are weaker, their reactivity increasing down the periodic table. They are usually more chemically reactive than aliphatic C-H bonds. As a consequence, the most common halogen substitutions are the less reactive aromatic fluorine and chlorine groups.\n\nFluoride anions are found in ivory, bones, teeth, blood, eggs, urine, and hair of organisms. Fluoride anions in very small amounts may be essential for humans. There are 0.5 milligrams of fluorine per liter of human blood. Human bones contain 0.2 to 1.2% fluorine. Human tissue contains approximately 50 parts per billion of fluorine. A typical 70-kilogram human contains 3 to 6 grams of fluorine.\n\nChloride anions are essential to a large number of species, humans included. The concentration of chlorine in the dry weight of cereals is 10 to 20 parts per million, while in potatoes the concentration of chloride is 0.5%. Plant growth is adversely affected by chloride levels in the soil falling below 2 parts per million. Human blood contains an average of 0.3% chlorine. Human bone typically contains 900 parts per million of chlorine. Human tissue contains approximately 0.2 to 0.5% chlorine. There is a total of 95 grams of chlorine in a typical 70-kilogram human.\n\nSome bromine in the form of the bromide anion is present in all organisms. A biological role for bromine in humans has not been proven, but some organisms contain organobromine compounds. Humans typically consume 1 to 20 milligrams of bromine per day. There are typically 5 parts per million of bromine in human blood, 7 parts per million of bromine in human bones, and 7 parts per million of bromine in human tissue. A typical 70-kilogram human contains 260 milligrams of bromine.\n\nHumans typically consume less than 100 micrograms of iodine per day. Iodine deficiency can cause intellectual disability. Organoiodine compounds occur in humans in some of the glands, especially the thyroid gland, as well as the stomach, epidermis, and immune system. Foods containing iodine include cod, oysters, shrimp, herring, lobsters, sunflower seeds, seaweed, and mushrooms. However, iodine is not known to have a biological role in plants. There are typically 0.06 milligrams per liter of iodine in human blood, 300 parts per billion of iodine in human bones, and 50 to 700 parts per billion of iodine in human tissue. There are 10 to 20 milligrams of iodine in a typical 70-kilogram human.\n\nAstatine has no biological role.\n\nThe halogens tend to decrease in toxicity towards the heavier halogens.\n\nFluorine gas is extremely toxic; breathing fluorine gas at a concentration of 0.1% for several minutes is lethal. Hydrofluoric acid is also toxic, being able to penetrate skin and cause highly painful burns. In addition, fluoride anions are toxic, but not as toxic as pure fluorine. Fluoride can be lethal in amounts of 5 to 10 grams. Prolonged consumption of fluoride above concentrations of 1.5 mg/L is associated with a risk of dental fluorosis, an aesthetic condition of the teeth. At concentrations above 4 mg/L, there is an increased risk of developing skeletal fluorosis, a condition in which bone fractures become more common due to the hardening of bones. Current recommended levels in water fluoridation, a way to prevent dental caries, range from 0.7 to 1.2 mg/L to avoid the detrimental effects of fluoride while at the same time reaping the benefits. People with levels between normal levels and those required for skeletal fluorosis tend to have symptoms similar to arthritis.\n\nChlorine gas is highly toxic. Breathing in chlorine at a concentration of 3 parts per million can rapidly cause a toxic reaction. Breathing in chlorine at a concentration of 50 parts per million is highly dangerous. Breathing in chlorine at a concentration of 500 parts per million for a few minutes is lethal. Breathing in chlorine gas is highly painful. Hydrochloric acid is a dangerous chemical.\n\nPure bromine is somewhat toxic, but less toxic than fluorine and chlorine. One hundred milligrams of bromine is lethal. Bromide anions are also toxic, but less so than bromine. Bromide has a lethal dose of 30 grams.\n\nIodine is somewhat toxic, being able to irritate the lungs and eyes, with a safety limit of 1 milligram per cubic meter. When taken orally, 3 grams of iodine can be lethal. Iodide anions are mostly nontoxic, but these can also be deadly if ingested in large amounts.\n\nAstatine is very radioactive and thus highly dangerous, but it has not been produced in macroscopic quantities and hence it is most unlikely that its toxicity will be of much relevance to the average individual.\n\nCertain aluminium clusters have superatom properties. These aluminium clusters are generated as anions ( with \"n\" = 1, 2, 3, ... ) in helium gas and reacted with a gas containing iodine. When analyzed by mass spectrometry one main reaction product turns out to be .<ref name=\"bergeron/2004\"></ref> These clusters of 13 aluminium atoms with an extra electron added do not appear to react with oxygen when it is introduced in the same gas stream. Assuming each atom liberates its 3 valence electrons, this means 40 electrons are present, which is one of the magic numbers for sodium and implies that these numbers are a reflection of the noble gases.\n\nCalculations show that the additional electron is located in the aluminium cluster at the location directly opposite from the iodine atom. The cluster must therefore have a higher electron affinity for the electron than iodine and therefore the aluminium cluster is called a superhalogen (i.e., the vertical electron detachment energies of the moieties that make up the negative ions are larger than those of any halogen atom). The cluster component in the ion is similar to an iodide ion or a bromide ion. The related cluster is expected to behave chemically like the triiodide ion.<ref name=\"bergeron/2005\"></ref>\n\n", "id": "13258", "title": "Halogen"}
{"url": "https://en.wikipedia.org/wiki?curid=13259", "text": "Home page\n\nA home page or a start page is the initial or main web page of a website or a browser. The initial page of a website is sometimes called main page as well.\n\nA home page is generally the main page a visitor navigating to a website from a web search engine will see, and it may also serve as a landing page to attract visitors. The home page is used to facilitate navigation to other pages on the site by providing links to prioritized and recent articles and pages, and possibly a search box. For example, a news website may present headlines and first paragraphs of top stories, with links to full articles, in a dynamic web page that reflects the popularity and recentness of stories. Meanwhile, other websites utilize the homepage to attract users to create an account. Once they are logged in, the homepage may be redirected to their profile page. This may in turn be referred to as the \"personal home page\".\n\nA website may have multiple home pages, although most have one. Wikipedia, for example, has a home page at wikipedia.org, as well as language-specific home pages, such as en.wikipedia.org and de.wikipedia.org.\n\nThe majority of websites have a home page with underlying content pages, although some websites contain only a single page.\n\nThe uniform resource locator (URL) of a home page is most often the base-level domain name, such as https://wikipedia.org. Historically it may also be found at <nowiki>http://domain.tld/index.html</nowiki> or <nowiki>http://domain.tld/default.html</nowiki>, where \"tld\" refers to the top-level domain used by the website.\n\nIf a home page has not been created for a web site, many web servers will default to display a list of files located in the site's directory, if the security settings of the directory permit. This list will include hyperlinks to the files, allowing for simple file sharing without maintaining a separate HTML file.\n\nA home page also refers to the first page that appears upon opening a web browser, sometimes called the start page, although the home page of a website can be used as a start page. This start page can be a website, or it can be a page with various browser functions such as the display of thumbnails of frequently visited websites. Multiple websites can be set as a start page, to open in different tabs. Some websites are intended to be used as start pages, such as iGoogle (now defunct), My Yahoo!, and MSN.com, and provide links to commonly used services such as webmail and online weather forecasts.\n\nIn the early days of the World Wide Web in the first half of the 1990s, an important part of web pages belonged to students or teachers with a UNIX account in their university. System administrators of such systems installed an HTTP server pointing its root directory to the directory containing the users accounts. On UNIX, the base directory of an account is called \"home\", and the codice_1 environment variable contains its path (for example codice_2). The URL of the home page is usually has the format codice_3. Thus the term home page appeared and then spread to its current usage.\n\nA personal home page historically has served as a means of self-portrayal, job-related presentation, and pure enjoyment, giving way to professional advancement and social interaction. Owing to the rise of social media sites, personal home pages are no longer as common as during the mid-late 1990s and early-2000s.\n\nA personal web page is also commonly called a home page, although such websites can contain many pages. In Germany the term \"homepage\" is often used as a synonym for the term \"website\".\n\nA home page can also be used outside the context of web browsers, such as to refer to the principal screen of a user interface, frequently referred to as a home screen on mobile devices such as mobile phones.\n\n\n", "id": "13259", "title": "Home page"}
{"url": "https://en.wikipedia.org/wiki?curid=13260", "text": "Hee Haw\n\nHee Haw was an American television variety show featuring country music and humor with fictional rural \"Kornfield Kounty\" as a backdrop. It aired on CBS from 1969–1971 followed by a 21-year run in local syndication. The show was inspired by \"Rowan & Martin's Laugh-In\", the major difference being that \"Hee Haw\" was far less topical, and was centered on country music and rural culture. Hosted by country artists Buck Owens and Roy Clark for most of the series' run, the show was equally well known for its voluptuous, scantily clad women in stereotypical farmer's daughter outfits and country-style minidresses (a group that came to be known as the \"Hee Haw Honeys\"), and its corn pone humor.\n\n\"Hee Haw\"'s appeal, however, was not limited to a rural audience. It was successful in all of the major markets, including New York, Los Angeles, Boston, and Chicago. Other niche programs such as \"The Lawrence Welk Show\" (which targeted older audiences) and \"Soul Train\" (which targeted black audiences) also rose to prominence in syndication during the era. Like \"Laugh-In\", the show minimized production costs by taping all of the recurring sketches for a season in batches, setting up for the Cornfield one day, the Joke Fence on another day, etc. At the height of its popularity, an entire season's worth of shows would be taped in two separate week-long sessions, then individual shows were assembled from edited sections. Only musical performances were taped with a live audience; a laugh track was added to all other segments.\n\nThe series was taped for CBS at its network affiliate WLAC-TV (now WTVF) in downtown Nashville, and later at Opryland USA in the Donelson area of Nashville. The show was produced by Yongestreet Productions through the mid-1980s; it was later produced by Gaylord Entertainment, which distributed the show in syndication. The show's name was coined by show business talent manager and producer Bernie Brillstein and derives from a common English onomatopoeia used to describe the braying sound that a donkey makes.\n\nMuch of \"Hee Haw's\" origin was Canadian. The series' creators, comedy writers Frank Peppiatt and John Aylesworth, were from Canada. From 1969 until the late 1980s, \"Hee Haw\" was produced by Yongestreet Productions, named after Yonge Street, a major thoroughfare in Toronto. Gordie Tapp and Don Harron, both writer/performers on the show, were also Canadian.\n\n\"Hee Haw\" premiered on CBS as a summer 1969 replacement for \"The Smothers Brothers Comedy Hour\". Though the show had respectable ratings (it sat at #16 for the 1970-71 season), it was dropped in July 1971 by CBS as part of the so-called \"Rural Purge\" (along with fellow country-themed shows \"The Beverly Hillbillies\", \"Mayberry R.F.D.\", and \"Green Acres\"). The success of \"Hee Haw\" and other country-themed shows was the source of a heated dispute in CBS's corporate offices; Michael Dann, although he personally disliked the shows, considered total viewership the benchmark of success and encouraged the shows to stay on the air, while Fred Silverman believed certain demographics—the ones in which \"Hee Haw\" and the others performed poorly—could draw more advertising dollars. Silverman's view won out, and CBS canceled the rural shows in summer 1971.\n\nUndaunted, the producers put together a syndication deal for the show, which continued in roughly the same format for 20 more years (though Owens departed in 1986). After Owens left, Clark was assisted each week by a country music celebrity co-host.\n\nDuring the show's peak in popularity, \"Hee Haw\" often competed in syndication against \"The Lawrence Welk Show\", a long-running ABC program which had also been canceled in 1971, also in an attempt to purge the networks of older demographic-leaning programs. Like \"Hee Haw\", \"Lawrence Welk\" was picked up for syndication in the fall of 1971, and there were some markets where the same station aired both programs. (The success of \"Hee Haw\" and \"Lawrence Welk\" in syndication, and the network decisions that led to their respective cancellations, were the inspiration for a novelty song called \"The Lawrence Welk-Hee Haw Counter-Revolution Polka,\" performed by Clark; the song became a top 10 hit on the \"Billboard\" Hot Country Singles chart in the fall of 1972.) \"Welk\" and \"Hee Haw\" also competed against another music-oriented niche program that moved to syndication in 1971: \"Soul Train\", a black-oriented program (originally a local program based in Chicago) that also went on to a very long run in syndication.\n\nMirroring the long downward trend in the popularity of variety shows in general that had taken place in the 1970s, ratings began to decline for \"Hee Haw\" by the mid-1980s, a trend that continued into the early 1990s. In the fall of 1991, in an attempt to win back viewers and attract a younger audience, the show's format and setting underwent a dramatic overhaul. The changes included a new title (\"The Hee Haw Show\"), more pop-oriented country music, and the barnyard-cornfield setting replaced by a city street and shopping mall set. The first of the new shows aired in January 1992.\n\nDespite the attempt to keep the show fresh, the changes alienated many of its longtime viewers while failing to gain the hoped-for younger viewers, and the ratings continued their decline.\n\nDuring the summer of 1992, a decision was made to end first-run production, and instead air highlights of the show's earlier years in a revamped program called \"Hee Haw Silver\" (as part of celebrating the show's 25th season). Under the new format, Clark hosted a mixture of classic clips and new footage.\n\nThe \"Hee Haw Silver\" episodes spotlighted many of their classic sketches and moments from the show, with a series of retrospective looks at performers who had since died, such as David \"Stringbean\" Akeman, Archie Campbell, Junior Samples, and Kenny Price. According to the show's producer, Sam Lovullo, the ratings showed improvement with these classic reruns; however, the series was finally canceled in 1993 at the conclusion of its 25th season. \"Hee Haw\" continued to pop up in reruns (see below for details) throughout the 1990s and later during the following decade, in a series of successful DVD releases from Time Life.\n\nAfter the show's syndication run ended, reruns aired on The Nashville Network from 1993 until 1996. Upon the cancellation of reruns in 1996 the program resurfaced, in reruns, the following year for a limited run on the same network. Its 21 years in TV syndication (1971–1992) was the record for the longest-running U.S. syndicated TV program, until \"Soul Train\" surpassed it in 1993; \"Hee Haw\" remains the fifth longest-running syndicated American TV program, though the longest-running of its genre.\n\nDuring the 2006–07 season CMT aired a series of reruns and TV Land also recognized the series with an award presented by k.d. lang; in attendance were Roy Clark, Gunilla Hutton, Barbi Benton, the Hager twins, Linda Thompson, Misty Rowe, and others. It was during this point, roughly between the years of 2004 and 2007, that Time Life began selling selected episodes of the show on DVD. Among the DVD content offered was the 1978 10th anniversary special that hadn't been seen since its original airing. CMT sporadically aired the series, usually in graveyard slots, and primarily held the rights in order to be able to air the musical performances as part of their music video library (such as during the \"Pure Vintage\" block on CMT Pure Country).\n\nReruns of \"Hee Haw\" began airing on RFD-TV in September 2008, where it currently remains, anchoring the network's Sunday night lineup, although beginning in January 2014 an episode airs on Saturday afternoon and the same episode is rerun the following Sunday night. In 2011 the network began re-airing the earliest episodes from 1969–70 on Thursday evenings. In the summer of 2011 a lot of the surviving cast and an ensemble of country artists taped a \"Country's Family Reunion\" special, entitled \"Salute to the Kornfield\", which aired on RFD-TV in January 2012. The special is also part of \"Country's Family Reunion's\" DVD series. Concurrent with the special was the unveiling of a \"Hee Haw\" exhibit, titled \"Pickin' and Grinnin\"', at the Oklahoma History Center in Oklahoma City.\n\nTwo rural-style comedians, already well known in their native Canada, gained their first major U.S. exposure: Gordie Tapp and Don Harron (whose KORN Radio character, newscaster Charlie Farquharson, had been a fixture of Canadian television since 1952 and later appeared on \"The Red Green Show\").\n\nOther cast members over the years included, but were not limited to:\nRoy Acuff,\nCathy Baker (as the show's emcee),\nBilly Jim Baker,\nBarbi Benton,\nKelly Billingsley,\nVicki Bird,\nJennifer Bishop,\nArchie Campbell,\nPhil Campbell,\nHarry Cole (Weeping Willie),\nMackenzie Colt,\nJohn Henry Faulk,\nTennessee Ernie Ford,\nMarianne Gordon (Rogers),\nJim and Jon Hager,\nVictoria Hallman,\nDiana Goodman,\nGunilla Hutton,\nLinda Johnson,\nGrandpa Jones,\nZella Lehr (the \"unicycle girl\"),\nGeorge Lindsey (reprising his \"Goober\" character from \"The Andy Griffith Show\"),\nJimmy Little,\nIrlene Mandrell,\nCharlie McCoy,\nDawn McKinley,\nPatricia McKinnon,\nSherry Miles,\nRev. Grady Nutt,\nMinnie Pearl,\nClaude \"Jackie\" Phelps,\nSlim Pickens,\nKenny Price,\nAnne Randall,\nChase Randolph,\nSusan Raye,\nJimmie Riddle,\nJeannine Riley,\nAlice Ripley,\nLulu Roman,\nMisty Rowe,\nJunior Samples,\nRay Sanders,\nTerry Sanders,\nGailard Sartain,\nDiana Scott,\nGerald Smith (the \"Georgia Quacker\"),\nJeff Smith,\nDonna Stokes,\nDennis Stone,\nRoni Stoneman,\nMary Taylor,\nNancy Taylor,\nLinda Thompson,\nLisa Todd,\nPedro Tomas,\nNancy Traylor, \nBuck Trent,\nJackie Waddell, \nPat Woodell, and\nJonathan Winters, among many others.\n\nThe Buckaroos (Buck Owens' band) initially served as the house band on the show and consisted of members Don Rich, Jim Shaw, Jerry Brightman, Jerry Wiggins, Rick Taylor, Doyle Singer (Doyle Curtsinger), Don Lee, Ronnie Jackson, Terry Christoffersen, Doyle Holly, and in later seasons fiddle player Jana Jae, and Victoria Hallman, who replaced Don Rich on harmony vocals (Rich was killed in a motorcycle accident in 1974). In later seasons, harmonica player Charlie McCoy joined the cast and became the show's music director, forming the \"Hee Haw Band\", which became the house band for the remainder of the series' run. The Nashville Edition, a four-member (two male, two female) singing group, served as the background singers for most of the musical performances.\n\nSome of the cast members made national headlines: Lulu Roman was twice charged with drug possession in 1971, David \"Stringbean\" Akeman and his wife were murdered in November 1973 during a robbery at their home; and as mentioned above, Buck Owens' lead guitarist and harmony singer Don Rich of the Buckaroos was killed in a motorcycle crash in 1974.\n\nSome cast members, such as Charlie McCoy and Tennessee Ernie Ford, originally appeared on the show as guest stars.\n\nAfter Buck Owens left the show, a different country music artist would accompany Roy Clark as a guest co-host each week until the final season (\"Hee Haw Silver\"), which Clark hosted alone.\n\nSome of the most popular sketches and segments on \"Hee Haw\" included, but were not limited to:\n\n\n\n\nGuest stars often participated in some of the sketches (mostly the \"PFFT! You Was Gone\" and \"The Cornfield\" sketches); however, this did not occur until later seasons.\n\nHee Haw was a premiere showcase on commercial television during the 1970s and early 1980s for country, bluegrass, gospel, and other styles of American traditional music, featuring hundreds of elite musical performances that were paramount to the success, popularity and legacy of the series for a broad audience of Southern, rural and purely music fans alike. Although country music was the primary genre of music featured on the show, guest stars and cast members alike also performed music from other genres, such as oldies and pop standards.\n\nSome of the most popular music-based segments on the show (other than guest stars' performances) included:\n\nLovullo also has made the claim the show presented \"what were, in reality, the first musical videos.\" Lovullo said his videos were conceptualized by having the show's staff go to nearby rural areas and film animals and farmers, before editing the footage to fit the storyline of a particular song. \"The video material was a very workable production item for the show,\" he wrote. \"It provided picture stories for songs. However, some of our guests felt the videos took attention away from their live performances, which they hoped would promote record sales. If they had a hit song, they didn't want to play it under comic barnyard footage.\" The concept's mixed reaction eventually spelled an end to the \"video\" concept on \"Hee Haw\". However, several of co-host Owens' songs – including \"Tall, Dark Stranger,\" \"Big in Vegas\", and \"I Wouldn't Live in New York City (If They Gave Me the Whole Dang Town)\" – aired on the series and have since aired on Great American Country and CMT as part of their classic country music programming blocks.\n\n\"Hee Haw\" featured at least two, and sometimes three or four, guest celebrities each week. While most of the guest stars were country music artists, a wide range of other famous luminaries were featured. Also, several clogging groups frequently performed on the show, and occasionally the show featured child singers who would perform top country songs of the day.\n\nSheb Wooley, one of the original cast members, wrote the show's theme song. After filming the initial 13 episodes, other professional demands caused him to leave the show, but he returned from time to time as a guest.\n\nLoretta Lynn was the first guest star of \"Hee Haw\" and made more guest appearances than any other artist. She also co-hosted the show more than any other guest co-host and therefore appears on more of the DVD releases for retail sale than any other guest star.\n\nFrom 1990–92, country megastar Garth Brooks appeared on the show four times. In 1992, producer Sam Lovullo tried unsuccessfully to contact Brooks because he wanted him for the final show. Brooks then surprised Lovullo by showing up at the last minute, ready to don his overalls and perform for the final episode.\n\nA barn interior set was used as the main stage for most of the musical performances from the show's premiere until the debut of the \"Hee Haw Honky Tonk\" sketch in the early 1980s. Afterwards, the \"Hee Haw Honky Tonk\" set would serve as the main stage for the remainder of the series' run. Buck Owens then began using the barn interior set for his performances after it was replaced by the \"Hee Haw Honky Tonk\" set and was named \"Buck's Place\" (as a nod to one of Owens' hits, \"Sam's Place\"). Other settings for the musical performances throughout the series' run included a haystack (where the entire cast performed songs), the living room of a Victorian house, the front porch and lawn of the Samuel B. Sternwheeler home, a grist mill (where Roy Clark performed many of his songs in earlier seasons), and a railroad depot, where Buck Owens performed many of his songs in earlier seasons.\n\nElvis Presley was a fan of \"Hee Haw\" and wanted to appear as a guest on the program, but Presley was afraid that his manager, Colonel Tom Parker, would not allow him to do so. Two of the Hee Haw Honeys dated Presley long before they joined the cast: Most notably Linda Thompson in the mid-1970s, whom Presley also had a long-lasting, steady relationship with after his divorce from Priscilla; and Diana Goodman shortly afterwards. Shortly after Presley's death, his father, Vernon Presley, made a cameo appearance on the show and paid tribute to his late son, noting how much he enjoyed watching the show.\n\nAt the end of the show, hosts Clark and Owens, backed by the entire cast, sang the original closing song with the following lyrics:\n\nAnd then (spoken):\n\n\n\"Hee Haw\" produced a short-lived spin-off series, \"Hee Haw Honeys\" (not to be confused with \"Hee Haw's\" female cast members), for the 1979 television season. The musical sitcom starred Kathie Lee Johnson (Gifford) along with \"Hee Haw\" regulars Misty Rowe, Gailard Sartain, Lulu Roman, and Kenny Price as a family who owned a truck stop restaurant (likely inspired by the \"Lulu's Truck Stop\" sketch on \"Hee Haw\"). Their restaurant included a bandstand, where guest country artists would perform a couple of their hits of the day, sometimes asking the cast to join them. Cast members would also perform songs occasionally; and the Nashville Edition, \"Hee Haw's\" backup singing group, frequently appeared on the show, portraying regular patrons of the restaurant.\n\nThe Hee Haw Theater opened in Branson, Missouri, in 1981 and operated through 1983. It featured live shows using the cast of the television series, as well as guests and other talent. The format was similar with a country variety show-type family theme.\n\n\"Hee Haw\" continues to remain beloved and popular with its long-time fans and those who've discovered the program through DVD releases or its reruns on RFD-TV. In spite of the loving support of the series by its fans, the program has never been a favorite of television critics or reviewers.\n\nOn at least four episodes of the animated Fox series \"Family Guy\", when the storyline hits a dead-end, a cutaway to Conway Twitty performing a song is inserted. The handoff is done in \"Hee Haw\" style, and often uses actual footage of Twitty performing on the show.\n\nLulu Roman released a new album titled \"At Last\" on January 15, 2013. The album features Lulu's versions of 12 classics and standards including guest appearances by Dolly Parton, T. Graham Brown, Linda Davis, and Georgette Jones (daughter of George Jones and Tammy Wynette).\n\n", "id": "13260", "title": "Hee Haw"}
{"url": "https://en.wikipedia.org/wiki?curid=13263", "text": "Hexadecimal\n\nIn mathematics and computing, hexadecimal (also base , or hex) is a positional numeral system with a radix, or base, of 16. It uses sixteen distinct symbols, most often the symbols 0–9 to represent values zero to nine, and A, B, C, D, E, F (or alternatively a, b, c, d, e, f) to represent values ten to fifteen. \n\nHexadecimal numerals are widely used by computer system designers and programmers. As each hexadecimal digit represents four binary digits (bits), it allows a human-friendly representation of binary-coded values. One hexadecimal digit represents a nibble (4 bits), which is half of an octet or byte (8 bits). For example, a single byte can have values ranging from 00000000 to 11111111, in binary, but this is more conveniently represented as 00 to FF in hexadecimal. \n\nSeveral different notations are used to represent hexadecimal constants in computing languages; the prefix \"0x\" is widespread due to its use in Unix and C (and related operating systems and languages). Alternatively, some authors denote hexadecimal values using a suffix or subscript. For example, one could write 0x2AF3 or 2AF3, depending on the choice of notation.\n\nIn contexts where the base is not clear, hexadecimal numbers can be ambiguous and confused with numbers expressed in other bases. There are several conventions for expressing values unambiguously. A numerical subscript (itself written in decimal) can give the base explicitly: 159 is decimal 159; 159 is hexadecimal 159, which is equal to 345. Some authors prefer a text subscript, such as 159 and 159, or 159 and 159.\n\nIn linear text systems, such as those used in most computer programming environments, a variety of methods have arisen:\n\nThere is no universal convention to use lowercase or uppercase for the letter digits, and each is prevalent or preferred in particular environments by community standards or convention.\n\nThe use of the letters \"A\" through \"F\" to represent the digits above 9 was not universal in the early history of computers.\n\nThere are no traditional numerals to represent the quantities from ten to fifteen — letters are used as a substitute — and most European languages lack non-decimal names for the numerals above ten. Even though English has names for several non-decimal powers (\"pair\" for the first binary power, \"score\" for the first vigesimal power, \"dozen\", \"gross\" and \"great gross\" for the first three duodecimal powers), no English name describes the hexadecimal powers (decimal 16, 256, 4096, 65536, ... ). Some people read hexadecimal numbers digit by digit like a phone number, or using the NATO phonetic alphabet, the Joint Army/Navy Phonetic Alphabet, or a similar ad hoc system.\nSystems of counting on digits have been devised for both binary and hexadecimal.\nArthur C. Clarke suggested using each finger as an on/off bit, allowing finger counting from zero to 1023 on ten fingers. Another system for counting up to FF (255) is illustrated on the right.\n\nThe hexadecimal system can express negative numbers the same way as in decimal: −2A to represent −42 and so on.\n\nHexadecimal can also be used to express the exact bit patterns used in the processor, so a sequence of hexadecimal digits may represent a signed or even a floating point value. This way, the negative number −42 can be written as FFFF FFD6 in a 32-bit CPU register (in two's-complement), as C228 0000 in a 32-bit FPU register or C045 0000 0000 0000 in a 64-bit FPU register (in the IEEE floating-point standard).\n\nJust as decimal numbers can be represented in exponential notation, so too can hexadecimal. By convention, the letter \"P\" (or \"p\", for \"power\") represents \"times two raised to the power of\", whereas \"E\" (or \"e\") serves a similar purpose in decimal as part of the E notation. The number after the \"P\" is \"decimal\" and represents the \"binary\" exponent.\n\nUsually the number is normalised so that the leading hexadecimal digit is 1 (unless the value is exactly 0).\n\nExample: 1.3DEp42 represents .\n\nThis notation can be used for floating-point literals in the C99 edition of the C programming language.\nUsing the \"%a\" or \"%A\" conversion specifiers, this notation can be produced by implementations of the \"printf\" family of functions following the C99 specification and\nSingle Unix Specification\nPOSIX\nstandard. Hexadecimal exponential notation is required by the IEEE 754-2008 binary floating-point standard.\n\nMost computers manipulate binary data, but it is difficult for humans to work with the large number of digits for even a relatively small binary number. Although most humans are familiar with the base 10 system, it is much easier to map binary to hexadecimal than to decimal because each hexadecimal digit maps to a whole number of bits (4).\nThis example converts 1111 to base ten. Since each position in a binary numeral can contain either a 1 or a 0, its value may be easily determined by its position from the right:\nTherefore:\n\nWith little practice, mapping 1111 to F in one step becomes easy: see table in Written representation. The advantage of using hexadecimal rather than decimal increases rapidly with the size of the number. When the number becomes large, conversion to decimal is very tedious. However, when mapping to hexadecimal, it is trivial to regard the binary string as 4-digit groups and map each to a single hexadecimal digit.\n\nThis example shows the conversion of a binary number to decimal, mapping each digit to the decimal value, and adding the results.\n\nCompare this to the conversion to hexadecimal, where each group of four digits can be considered independently, and converted directly:\n\nThe conversion from hexadecimal to binary is equally direct.\n\nThe octal system can also be useful as a tool for people who need to deal directly with binary computer data. Octal represents data as three bits per character, rather than four.\n\nAs with all bases there is a simple algorithm for converting a representation of a number to hexadecimal by doing integer division and remainder operations in the source base. In theory, this is possible from any base, but for most humans only decimal and for most computers only binary (which can be converted by far more efficient methods) can be easily handled with this method.\n\nLet d be the number to represent in hexadecimal, and the series hh...hh be the hexadecimal digits representing the number.\n\n\n\"16\" may be replaced with any other base that may be desired.\n\nThe following is a JavaScript implementation of the above algorithm for converting any number to a hexadecimal in String representation. Its purpose is to illustrate the above algorithm. To work with data seriously, however, it is much more advisable to work with bitwise operators.\n\nIt is also possible to make the conversion by assigning each place in the source base the hexadecimal representation of its place value and then performing multiplication and addition to get the final representation.\nThat is, to convert the number B3AD to decimal one can split the hexadecimal number into its digits: B (11), 3 (3), A (10) and D (13), and then get the final result by multiplying each decimal representation by 16, where \"p\" is the corresponding hex digit position, counting from right to left, beginning with 0. In this case we have , which is 45997 base 10.\n\nMost modern computer systems with graphical user interfaces provide a built-in calculator utility, capable of performing conversions between various radices, in general including hexadecimal.\n\nIn Microsoft Windows, the Calculator utility can be set to Scientific mode (called Programmer mode in some versions), which allows conversions between radix 16 (hexadecimal), 10 (decimal), 8 (octal) and 2 (binary), the bases most commonly used by programmers. In Scientific Mode, the on-screen numeric keypad includes the hexadecimal digits A through F, which are active when \"Hex\" is selected. In hex mode, however, the Windows Calculator supports only integers.\n\nAs with other numeral systems, the hexadecimal system can be used to represent rational numbers, although repeating expansions are common since sixteen (10) has only a single prime factor (two):\n\nwhere an overline denotes a recurring pattern.\n\nFor any base, 0.1 (or \"1/10\") is always equivalent to one divided by the representation of that base value in its own number system. Thus, whether dividing one by two for binary or dividing one by sixteen for hexadecimal, both of these fractions are written as codice_47. Because the radix 16 is a perfect square (4), fractions expressed in hexadecimal have an odd period much more often than decimal ones, and there are no cyclic numbers (other than trivial single digits). Recurring digits are exhibited when the denominator in lowest terms has a prime factor not found in the radix; thus, when using hexadecimal notation, all fractions with denominators that are not a power of two result in an infinite string of recurring digits (such as thirds and fifths). This makes hexadecimal (and binary) less convenient than decimal for representing rational numbers since a larger proportion lie outside its range of finite representation.\n\nAll rational numbers finitely representable in hexadecimal are also finitely representable in decimal, duodecimal and sexagesimal: that is, any hexadecimal number with a finite number of digits has a finite number of digits when expressed in those other bases. Conversely, only a fraction of those finitely representable in the latter bases are finitely representable in hexadecimal. For example, decimal 0.1 corresponds to the infinite recurring representation 0.199999999999... in hexadecimal. However, hexadecimal is more efficient than bases 12 and 60 for representing fractions with powers of two in the denominator (e.g., decimal one sixteenth is 0.1 in hexadecimal, 0.09 in duodecimal, 0;3,45 in sexagesimal and 0.0625 in decimal).\n\nThe table below gives the expansions of some common irrational numbers in decimal and hexadecimal.\nPowers of two have very simple expansions in hexadecimal. The first sixteen powers of two are shown below.\n\nThe word \"hexadecimal\" is composed of \"hexa-\", derived from the Greek έξ (hex) for \"six\", and \"-decimal\", derived from the Latin for \"tenth\". Webster's Third New International online derives \"hexadecimal\" as an alteration of the all-Latin \"sexadecimal\" (which appears in the earlier Bendix documentation). The earliest date attested for \"hexadecimal\" in Merriam-Webster Collegiate online is 1954, placing it safely in the category of international scientific vocabulary (ISV). It is common in ISV to mix Greek and Latin combining forms freely. The word \"sexagesimal\" (for base 60) retains the Latin prefix. Donald Knuth has pointed out that the etymologically correct term is \"senidenary\" (or possibly, \"sedenary\"), from the Latin term for \"grouped by 16\". (The terms \"binary\", \"ternary\" and \"quaternary\" are from the same Latin construction, and the etymologically correct terms for \"decimal\" and \"octal\" arithmetic are \"denary\" and \"octonary\", respectively.) Alfred B. Taylor used \"senidenary\" in his mid-1800s work on alternative number bases, although he rejected base 16 because of its \"incommodious number of digits\". Schwartzman notes that the expected form from usual Latin phrasing would be \"sexadecimal\", but computer hackers would be tempted to shorten that word to \"sex\". The etymologically proper Greek term would be \"hexadecadic\" / \"εξαδεκαδικός\" / \"exadekadikos\" (although in Modern Greek, \"decahexadic\" / \"δεκαεξαδικός\" / \"dekaexadikos\" is more commonly used).\n\nThe traditional Chinese units of weight were base-16. For example, one jīn (斤) in the old system equals sixteen taels. The suanpan (Chinese abacus) could be used to perform hexadecimal calculations.\n\nAs with the duodecimal system, there have been occasional attempts to promote hexadecimal as the preferred numeral system. These attempts often propose specific pronunciation and symbols for the individual numerals. Some proposals unify standard measures so that they are multiples of 16.\n\nAn example of unified standard measures is hexadecimal time, which subdivides a day by 16 so that there are 16 \"hexhours\" in a day.\n\nSimple key for notations used in article:\n\nBase16 or hex (not to be confused with Intel HEX and the like) is one of the simplest binary-to-text encodings, which stores each byte as a pair of hexadecimal digits. Many variations of such format are possible, for example either uppercase (A-F) or lowercase (a-f) letters may be used for digits greater than 9; spaces, line breaks or other separators may be added between digit groups of different lengths; header and/or footer with metainformation may be added.\n\n", "id": "13263", "title": "Hexadecimal"}
{"url": "https://en.wikipedia.org/wiki?curid=13264", "text": "Hex\n\nHex or HEX may refer to:\n\n\n\n\n\n\n\n", "id": "13264", "title": "Hex"}
{"url": "https://en.wikipedia.org/wiki?curid=13265", "text": "Hitler (disambiguation)\n\nAdolf Hitler (1889–1945) was the authoritarian Chancellor of Germany from 1933 to 1945.\n\nHitler may also refer to:\n\n\n\n\n", "id": "13265", "title": "Hitler (disambiguation)"}
{"url": "https://en.wikipedia.org/wiki?curid=13266", "text": "Histogram\n\nA histogram shows history representation of the distribution of numerical data. It is an estimate of the probability distribution of a continuous variable (quantitative variable) and was first introduced by Karl Pearson. To construct a histogram, the first step is to \"bin\" the range of values—that is, divide the entire range of values into a series of intervals—and then count how many values fall into each interval. The bins are usually specified as consecutive, non-overlapping intervals of a variable. The bins (intervals) must be adjacent, and are often (but are not required to be) of equal size.\n\nIf the bins are of equal size, a rectangle is erected over the bin with height proportional to the frequency — the number of cases in each bin. A histogram may also be normalized to display \"relative\" frequencies. It then shows the proportion of cases that fall into each of several categories, with the sum of the heights equaling 1.\n\nHowever, bins need not be of equal width; in that case, the erected rectangle is defined to have its \"area\" proportional to the frequency of cases in the bin. The vertical axis is then not the frequency but \"frequency density\" — the number of cases per unit of the variable on the horizontal axis. Examples of variable bin width are displayed on Census bureau data below.\n\nAs the adjacent bins leave no gaps, the rectangles of a histogram touch each other to indicate that the original variable is continuous.\n\nHistograms give a rough sense of the density of the underlying distribution of the data, and often for density estimation: estimating the probability density function of the underlying variable. The total area of a histogram used for probability density is always normalized to 1. If the length of the intervals on the \"x\"-axis are all 1, then a histogram is identical to a relative frequency plot.\n\nA histogram can be thought of as a simplistic kernel density estimation, which uses a kernel to smooth frequencies over the bins. This yields a smoother probability density function, which will in general more accurately reflect distribution of the underlying variable. The density estimate could be plotted as an alternative to the histogram, and is usually drawn as a curve rather than a set of boxes.\n\nAnother alternative is the average shifted histogram,\nwhich is fast to compute and gives a smooth curve estimate of the density without using kernels.\n\nThe histogram is one of the seven basic tools of quality control.\n\nHistograms are sometimes confused with bar charts. A histogram is used for continuous data, where the bins represent ranges of data, while a bar chart is a plot of categorical variables. Some authors recommend that bar charts have gaps between the rectangles to clarify the distinction.\n\nThe etymology of the word \"histogram\" is uncertain. Sometimes it is said to be derived from the Ancient Greek (\"histos\") – \"anything set upright\" (as the masts of a ship, the bar of a loom, or the vertical bars of a histogram); and (\"gramma\") – \"drawing, record, writing\". It is also said that Karl Pearson, who introduced the term in 1891, derived the name from \"historical diagram\".\n\nThis is a toy example:\n\nThe words used to describe the patterns in a histogram are: \"symmetric\", \"skewed left\" or \"right\", \"unimodal\", \"bimodal\" or \"multimodal\".\n\nIt is a good idea to plot the data using several different bin widths to learn more about it. Here is an example on tips given in a restaurant.\n\nHere are a couple more examples:\nThe U.S. Census Bureau found that there were 124 million people who work outside of their homes. Using their data on the time occupied by travel to work, the table below shows the absolute number of people who responded with travel times \"at least 30 but less than 35 minutes\" is higher than the numbers for the categories above and below it. This is likely due to people rounding their reported journey time. The problem of reporting values as somewhat arbitrarily rounded numbers is a common phenomenon when collecting data from people.\n\nThis histogram shows the number of cases per unit interval as the height of each block, so that the area of each block is equal to the number of people in the survey who fall into its category. The area under the curve represents the total number of cases (124 million). This type of histogram shows absolute numbers, with Q in thousands.\n\nThis histogram differs from the first only in the vertical scale. The area of each block is the fraction of the total that each category represents, and the total area of all the bars is equal to 1 (the fraction meaning \"all\"). The curve displayed is a simple density estimate. This version shows proportions, and is also known as a unit area histogram.\nIn other words, a histogram represents a frequency distribution by means of rectangles whose widths represent class intervals and whose areas are proportional to the corresponding frequencies: the height of each is the average frequency density for the interval. The intervals are placed together in order to show that the data represented by the histogram, while exclusive, is also contiguous. (E.g., in a histogram it is possible to have two connecting intervals of 10.5–20.5 and 20.5–33.5, but not two connecting intervals of 10.5–20.5 and 22.5–32.5. Empty intervals are represented as empty and not skipped.)\n\nIn a more general mathematical sense, a histogram is a function \"m\" that counts the number of observations that fall into each of the disjoint categories (known as \"bins\"), whereas the graph of a histogram is merely one way to represent a histogram. Thus, if we let \"n\" be the total number of observations and \"k\" be the total number of bins, the histogram \"m\" meets the following conditions:\n\nA cumulative histogram is a mapping that counts the cumulative number of observations in all of the bins up to the specified bin. That is, the cumulative histogram \"M\" of a histogram \"m\" is defined as:\n\nThere is no \"best\" number of bins, and different bin sizes can reveal different features of the data. Grouping data is at least as old as Graunt's work in the 17th century, but no systematic guidelines were given until Sturges's work in 1926.\n\nUsing wider bins where the density is low reduces noise due to sampling randomness; using narrower bins where the density is high (so the signal drowns the noise) gives greater precision to the density estimation. Thus varying the bin-width within a histogram can be beneficial. Nonetheless, equal-width bins are widely used.\n\nSome theoreticians have attempted to determine an optimal number of bins, but these methods generally make strong assumptions about the shape of the distribution. Depending on the actual data distribution and the goals of the analysis, different bin widths may be appropriate, so experimentation is usually needed to determine an appropriate width. There are, however, various useful guidelines and rules of thumb.\n\nThe number of bins \"k\" can be assigned directly or can be calculated from a suggested bin width \"h\" as:\n\nThe braces indicate the ceiling function.\n\n\nwhich takes the square root of the number of data points in the sample (used by Excel histograms and many others).\n\n\nSturges' formula is derived from a binomial distribution and implicitly assumes an approximately normal distribution.\n\nIt implicitly bases the bin sizes on the range of the data and can perform poorly if \"n\" < 30, because the number of bins will be small—less than seven—and unlikely to show trends in the data well. It may also perform poorly if the data are not normally distributed.\n\n\nThe Rice Rule is presented as a simple alternative to Sturges's rule.\n\nDoane's formula is a modification of Sturges' formula which attempts to improve its performance with non-normal data.\n\nwhere formula_8 is the estimated 3rd-moment-skewness of the distribution and\n\n\nwhere formula_11 is the sample standard deviation. Scott's normal reference rule is optimal for random samples of normally distributed data, in the sense that it minimizes the integrated mean squared error of the density estimate.\n\nThis approach of minimizing integrated mean squared error can be generalized beyond Normal distributions:\n\nHere, formula_13 is the number of datapoints in the \"k\"th bin, and choosing the value of \"h\" that minimizes \"J\" will minimize integrated mean squared error.\n\n\nThe Freedman–Diaconis rule is:\n\nwhich is based on the interquartile range, denoted by IQR. It replaces 3.5σ of Scott's rule with 2 IQR, which is less sensitive than the standard deviation to outliers in data.\n\n\nwhere formula_16 and formula_17 are mean and biased variance of a histogram with bin-width formula_18, formula_19 and formula_20.\n\n\nA good reason why the number of bins should be inversely proportional to formula_21 is the following: suppose that\nthe data are obtained as formula_22 independent realizations of a bounded probability distribution with smooth density.\nThen the histogram remains equally »rugged« as formula_22 tends to infinity. If formula_24 is the »width« of the\ndistribution (e. g., the standard deviation or the inter-quartile range), then the number of units in a bin (the frequency) is\nof order formula_25 and the \"relative\" standard error is of order formula_26.\nComparing to the next bin, the relative change of the frequency is of order formula_27 provided that the\nderivative of the density is non-zero. These two are of the same order if formula_28 is of order formula_29,\nso that formula_30 is of order formula_21.\n\nThis simple cubic root choice can also be applied to bins with non-constant width.\n\n\n\n", "id": "13266", "title": "Histogram"}
{"url": "https://en.wikipedia.org/wiki?curid=13269", "text": "Hilter\n\nHilter is a municipality in the district Osnabrück, Lower Saxony, Germany. It is located in the hills of the Teutoburg Forest.\n\nAs of 2002 it has a population of 10,178, and covers an area of 52.61 km². Highest elevation is the Hohnangel with 262 m above sea level.\n\nThe municipality was united on July 14, 1972, by merging the municipalities Borgloh, Hankenberge and Hilter. Already in 1977 the municipalities Allendorf, Borgloh-Wellendorf, Ebbendorf, Eppendorf and Uphöfen were joined into the \"Einheitsgemeinde\" Borgloh.\n\nHilter was well known for mining \"Hilter Gold\" ochre as well as its big margarine factory which owned one of the largest whaling fleets in the early 20th century.\n\n", "id": "13269", "title": "Hilter"}
{"url": "https://en.wikipedia.org/wiki?curid=13270", "text": "Hawaii\n\nHawaii ( ; locally, ; ) is the 50th and most recent state to have joined the United States of America, having received statehood on August 21, 1959. Hawaii is the only U.S. state located in Oceania and the only one composed entirely of islands. It is the northernmost island group in Polynesia, occupying most of an archipelago in the central Pacific Ocean. Hawaii is the only U.S. state not located in the Americas.\n\nThe state encompasses nearly the entire volcanic Hawaiian archipelago, which comprises hundreds of islands spread over . At the southeastern end of the archipelago, the eight main islands are—in order from northwest to southeast: Niihau, Kauai, Oahu, Molokai, Lānai, Kahoolawe, Maui and the Island of Hawaii. The last is the largest island in the group; it is often called the \"Big Island\" or \"Hawaii Island\" to avoid confusion with the state or archipelago. The archipelago is physiographically and ethnologically part of the Polynesian subregion of Oceania.\n\nHawaii's diverse natural scenery, warm tropical climate, abundance of public beaches, oceanic surroundings, and active volcanoes make it a popular destination for tourists, surfers, biologists, and volcanologists. Because of its central location in the Pacific and 19th-century labor migration, Hawaii's culture is strongly influenced by North American and Asian cultures, in addition to its indigenous Hawaiian culture. Hawaii has over a million permanent residents, along with many visitors and U.S. military personnel. Its capital is Honolulu on the island of Oahu.\n\nHawaii is the 8th-smallest and the 11th-least populous, but the 13th-most densely populated of the fifty U.S. states. It is the only state with an Asian plurality. The state's coastline is about long, the fourth longest in the U.S. after the coastlines of Alaska, Florida and California.\n\nThe Hawaiian sovereignty movement, which generally views the overthrow of Kingdom of Hawaii in 1893 and its subsequent annexation by the United States as illegal, seeks some form of greater autonomy for Hawaii, such as free association or independence from the United States.\n\nThe state of Hawaii derives its name from the name of its largest island, Hawaii. A common Hawaiian explanation of the name of Hawaii is that was named for Hawaiiloa, a legendary figure from Hawaiian myth. He is said to have discovered the islands when they were first settled.\n\nThe Hawaiian language word \"Hawaii\" is very similar to Proto-Polynesian *\"Sawaiki\", with the reconstructed meaning \"homeland\". Cognates of \"Hawaii\" are found in other Polynesian languages, including Māori (\"Hawaiki\"), Rarotongan (\"ʻAvaiki\") and Samoan (\"Savaii\") . According to linguists Pukui and Elbert, \"[e]lsewhere in Polynesia, Hawaii or a cognate is the name of the underworld or of the ancestral home, but in Hawaii, the name has no meaning\".\n\nA somewhat divisive political issue arose in 1978 when the Constitution of the State of Hawaii added Hawaiian as a second official state language. The title of the state constitution is \"The Constitution of the State of Hawaii\". ArticleXV, Section1 of the Constitution uses \"The State of Hawaii\". Diacritics were not used because the document, drafted in 1949, predates the use of the okina () and the kahakō in modern Hawaiian orthography. The exact spelling of the state's name in the Hawaiian language is \"Hawaii\". In the Hawaii Admission Act that granted Hawaiian statehood, the federal government recognized \"Hawaii\" as the official state name. Official government publications, department and office titles, and the Seal of Hawaii use the traditional spelling with no symbols for glottal stops or vowel length. In contrast, the National and State Parks Services, the University of Hawaii and some private enterprises implement these symbols. No precedent for changes to U.S. state names exists since the adoption of the United States Constitution in 1789. However, the Constitution of Massachusetts formally changed the \"Province of Massachusetts Bay\" to the Commonwealth of Massachusetts in 1780, and in the 1819 the Territory of Arkansaw was created but was later admitted to statehood as State of Arkansas.\n\nThere are eight main Hawaiian islands, seven of which are permanently inhabited. The island of Niihau is privately managed by brothers Bruce and Keith Robinson; access is restricted to those who have permission from the island's owners.\n\nThe Hawaiian archipelago is located southwest of the contiguous United States. Hawaii is the southernmost U.S. state and the second westernmost after Alaska. Hawaii, along with Alaska, does not border any other U.S. state. It is the only U.S. state that is not geographically located in North America, the only state completely surrounded by water and that is entirely an archipelago, and the only state in which coffee is cultivable.\n\nIn addition to the eight main islands, the state has many smaller islands and islets. Kaula is a small island near Niihau that is often overlooked. The Northwest Hawaiian Islands is a group of nine small, older islands to the northwest of Kauai that extend from Nihoa to Kure Atoll; these are remnants of once much larger volcanic mountains. Across the archipelago are around 130 small rocks and islets, such as Molokini, which are either volcanic, marine sedimentary or erosional in origin.\n\nHawaii's tallest mountain Mauna Kea is above mean sea level; it is taller than Mount Everest if measured from the base of the mountain, which lies on the floor of the Pacific Ocean and rises about .\n\nThe Hawaiian islands were formed by volcanic activity initiated at an undersea magma source called the Hawaii hotspot. The process is continuing to build islands; the tectonic plate beneath much of the Pacific Ocean continually moves northwest and the hot spot remains stationary, slowly creating new volcanoes. Because of the hotspot's location, all currently active land volcanoes are located on the southern half of Hawaii Island. The newest volcano, Lōihi Seamount, is located south of the coast of Hawaii Island.\n\nThe last volcanic eruption outside Hawaii Island occurred at Haleakalā on Maui before the late 18thcentury, though it could have been hundreds of years earlier. In 1790, Kīlauea exploded; it was the deadliest eruption known to have occurred in the modern era in what is now the United States. Up to 5,405 warriors and their families marching on Kīlauea were killed by the eruption. Volcanic activity and subsequent erosion have created impressive geological features. Hawaii Island has the third-highest point among the world's islands.\n\nOn the flanks of the volcanoes, slope instability has generated damaging earthquakes and related tsunamis, particularly in 1868 and 1975. Steep cliffs have been created by catastrophic debris avalanches on the submerged flanks of ocean island volcanoes.\n\nBecause the islands of Hawaii are distant from other land habitats, life is thought to have arrived there by wind, waves (i.e. by ocean currents) and wings (i.e. birds, insects, and any seeds they may have carried on their feathers). This isolation, in combination with the diverse environment (including extreme altitudes, tropical climates, and arid shorelines), produced an array of endemic flora and fauna. Hawaii has more endangered species and has lost a higher percentage of its endemic species than any other U.S. state. One endemic plant, \"Brighamia\", now requires hand-pollination because its natural pollinator is presumed to be extinct. The two species of \"Brighamia\"—\"B. rockii\" and \"B. insignis\"—are represented in the wild by around 120 individual plants. To ensure these plants set seed, biologists rappel down cliffs to brush pollen onto their stigmas.\n\nThe extant main islands of the archipelago have been above the surface of the ocean for fewer than 10million years; a fraction of the time biological colonization and evolution have occurred there. The islands are well known for the environmental diversity that occurs on high mountains within a trade winds field. On a single island, the climate around the coasts can range from dry tropical (less than annual rainfall) to wet tropical; on the slopes, environments range from tropical rainforest (more than per year), through a temperate climate, to alpine conditions with a cold, dry climate. The rainy climate impacts soil development, which largely determines ground permeability, affecting the distribution of streams and wetlands.\n\nSeveral areas in Hawaii are under the protection of the National Park Service. Hawaii has two national parks: Haleakalā National Park located near Kula on the island of Maui, which features the dormant volcano Haleakalā that formed east Maui, and Hawaii Volcanoes National Park in the southeast region of the Hawaii Island, which includes the active volcano Kīlauea and its rift zones.\n\nThere are three national historical parks; Kalaupapa National Historical Park in Kalaupapa, Molokai, the site of a former leper colony; Kaloko-Honokōhau National Historical Park in Kailua-Kona on Hawaii Island; and Puuhonua o Hōnaunau National Historical Park, an ancient place of refuge on Hawaii Island's west coast. Other areas under the control of the National Park Service include Ala Kahakai National Historic Trail on Hawaii Island and the USS \"Arizona\" Memorial at Pearl Harbor on Oahu.\n\nThe Papahānaumokuākea Marine National Monument was proclaimed by President George W. Bush on June 15, 2006. The monument covers roughly of reefs, atolls, and shallow and deep sea out to offshore in the Pacific Ocean—an area larger than all of the national parks in the U.S. combined.\n\nHawaii's climate is typical for the tropics, although temperatures and humidity tend to be less extreme because of near-constant trade winds from the east. Summer highs usually reach around during the day, with the temperature reaching a low of at night. Winter day temperatures are usually around ; at low elevation they seldom dip below at night. Snow, not usually associated with the tropics, falls at on Mauna Kea and Mauna Loa on Hawaii Island in some winter months. Snow rarely falls on Haleakalā. Mount Waialeale on Kauai has the second-highest average annual rainfall on Earth, about per year. Most of Hawaii experiences only two seasons; the dry season runs from May to October and the wet season is from October to April.\n\nThe warmest temperature recorded in the state, in Pahala on April 27, 1931, is , making it tied with Alaska as the lowest record high temperature observed in a U.S. state. Hawaii's record low temperature is observed in May1979 on the summit of Mauna Kea. Hawaii is the only state to have never recorded sub-zero Fahrenheit temperatures.\n\nClimates vary considerably on each island; they can be divided into windward and leeward (\"koolau\" and \"kona\", respectively) areas based upon location relative to the higher mountains. Windward sides face cloud cover.\n\nHawaii is one of four U.S. states—apart from the original thirteen—the Vermont Republic (1791), the Republic of Texas (1845), and the California Republic (1846)—that were independent nations prior to statehood. Along with Texas, Hawaii had formal, international diplomatic recognition as a nation.\n\nThe Kingdom of Hawaii was sovereign from 1810 until 1893 when the monarchy was overthrown by resident American and European capitalists and landholders in a \"coup d'état\". Hawaii was an independent republic from 1894 until August 12, 1898, when it officially became a territory of the United States. Hawaii was admitted as a U.S. state on August 21, 1959.\n\nBased on archaeological evidence, the earliest habitation of the Hawaiian Islands dates to around 300 CE, probably by Polynesian settlers from the Marquesas Islands. A second wave of migration from Raiatea and Bora Bora took place in the century. The date of the human discovery and habitation of the Hawaiian Islands is the subject of academic debate. Some archaeologists and historians believe there was an early settlement from the Marquesas. They think it was a later wave of immigrants from Tahiti around 1000 CE who introduced a new line of high chiefs, the kapu system, the practice of human sacrifice, and the building of \"heiau\". This later immigration is detailed in Hawaiian mythology (\"moolelo\") about Paao. Other authors say there is no archaeological or linguistic evidence for a later influx of Tahitian settlers and that Paao must be regarded as a myth.\n\nThe history of the islands is marked by a slow, steady growth in population and the size of the chiefdoms, which grew to encompass whole islands. Local chiefs, called alii, ruled their settlements, and launched wars to extend their influence and defend their communities from predatory rivals. Ancient Hawaii was a caste-based society, much like that of Hindus in India.\n\nIt is more than just \"possible\" that Spanish explorers arrived in the Hawaiian Islands in the 16th century—200 years before Captain James Cook's first documented visit in 1778. Ruy López de Villalobos commanded a fleet of six ships that left Acapulco in 1542 bound for the Philippines with a Spanish sailor named Juan Gaetano aboard as pilot. Depending on the interpretation, Gaetano's reports describe an encounter with either Hawaii or the Marshall Islands. If de Villalobos' crew spotted Hawaii, Gaetano would be considered the first European to see the islands. Some scholars have dismissed these claims due to a lack of credibility.\n\nSpanish archives contain a chart that depicts islands at the same latitude as Hawaii but with a longitude ten degrees east of the islands. In this manuscript, the island of Maui is named \"La Desgraciada\" (The Unfortunate Island), and what appears to be Hawaii Island is named \"La Mesa\" (The Table). Islands resembling Kahoolawe, Lanai, and Molokai are named \"Los Monjes\" (The Monks). For two-and-a-half centuries, Spanish galleons crossed the Pacific from Mexico along a route that passed south of Hawaii on their way to Manila. The exact route was kept secret to protect the Spanish trade monopoly against competing powers.\n\nThe 1778 arrival of British explorer James Cook was the first documented contact by a European explorer with Hawaii. Cook named the archipelago as the Sandwich Islands in honor of his sponsor John Montagu, 4th Earl of Sandwich. Cook published the islands' location and rendered the native name as \"Owyhee\". This spelling lives on in Owyhee County, Idaho. It was named after three native Hawaiian members of a trapping party who went missing in that area. The Owyhee Mountains were also named for them.\nCook visited the Hawaiian Islands twice. As he prepared for departure after his second visit in 1779, a quarrel ensued as Cook took temple idols and fencing as \"firewood\", and a minor chief and his men took a ship's boat. Cook abducted the King of Hawaii Island, Kalaniōpuu, and held him for ransom aboard his ship in order to gain return of Cook's boat. This tactic had worked in Tahiti and other islands. Instead, Kalaniōpuu's supporters fought back, killing Cook and four marines as Cook's party retreated along the beach to their ship. They departed without the ship's boat.\n\nAfter Cook's visit and the publication of several books relating his voyages, the Hawaiian islands attracted many European visitors: explorers, traders, and eventually whalers, who found the islands to be a convenient harbor and source of supplies. Early British influence can be seen in the design of the flag of Hawaii, which bears the Union Jack in the top-left corner. These visitors introduced diseases to the once-isolated islands, causing the Hawaiian population to drop precipitously. Native Hawaiians had no resistance to Eurasian diseases, such as influenza, smallpox and measles. By 1820, disease, famine and wars between the chiefs killed more than half of the Native Hawaiian population. During the 1850s, measles killed a fifth of Hawaii's people.\n\nHistorical records indicated the earliest Chinese immigrants to Hawaii originated from Guangdong Province; a few sailors arrived in 1778 with Captain Cook's journey and more arrived in 1789 with an American trader, who settled in Hawaii in the late 18th century. It appears that leprosy was introduced by Chinese workers by 1830; as with the other new infectious diseases, it proved damaging to the Hawaiians.\n\nDuring the 1780s and 1790s, chiefs often fought for power. After a series of battles that ended in 1795, all inhabited islands were subjugated under a single ruler, who became known as King Kamehameha the Great. He established the House of Kamehameha, a dynasty that ruled the kingdom until 1872.\n\nAfter Kamehameha II inherited the throne in 1819, American Protestant missionaries to Hawaii converted many Hawaiians to Christianity. They used their influence to end many traditional practices of the people. The islands' first Christian king was Kamehameha III. Hiram Bingham I, a prominent Protestant missionary, was a trusted adviser to the monarchy during this period. Other missionaries and their descendants became active in commercial and political affairs, leading to conflicts between the monarchy and its restive American subjects. Catholic and Mormon missionaries were also active in the kingdom, but they converted a minority of the Native Hawaiian population. Missionaries from each major group administered to the leper colony at Kalaupapa on Molokai, which was established in 1866 and operated well into the 20th century. The best known were Father Damien and Mother Marianne Cope, both of whom were canonized in the early 21st century as Roman Catholic saints.\n\nThe death of the bachelor King Kamehameha V—who did not name an heir—resulted in the popular election of Lunalilo over Kalākaua. Lunalilo died the next year, also without naming an heir. In 1874, the election was contested within the legislature between Kalākaua and Emma, Queen Consort of Kamehameha IV. After riots broke out, the United States and Britain landed troops on the islands to restore order. Governance passed to the House of Kalākaua.\n\nIn 1887, Kalākaua was forced to sign the 1887 Constitution of the Kingdom of Hawaii. Drafted by white businessmen and lawyers, the document stripped the king of much of his authority. It established a property qualification for voting that effectively disenfranchised most Hawaiians and immigrant laborers and favored the wealthier, white elite. Resident whites were allowed to vote but resident Asians were not. Because the 1887 Constitution was signed under threat of violence, it is known as the Bayonet Constitution. King Kalākaua, reduced to a figurehead, reigned until his death in 1891. His sister, Queen Liliuokalani, succeeded him; she was the last monarch of Hawaii.\n\nIn 1893, Queen Liliuokalani announced plans for a new constitution. On January 14, 1893, a group of mostly Euro-American business leaders and residents formed the Committee of Safety to stage a coup d'état against the kingdom and seek annexation by the United States. United States Government Minister John L. Stevens, responding to a request from the Committee of Safety, summoned a company of U.S. Marines. According to historian William Russ, these troops effectively rendered the monarchy unable to protect itself.\n\nIn January 1893, Queen Liliuokalani was overthrown and replaced by a provisional government composed of members of the American Committee of Safety. American lawyer Sanford B. Dole became President of the Republic when the Provisional Government of Hawaii ended on July 4, 1894. Controversy ensued in the following years as the Queen tried to regain her throne. The administration of President Grover Cleveland commissioned the Blount Report, which concluded that the removal of Liliuokalani had been illegal. The U.S. government first demanded that Queen Liliuokalani be reinstated, but the Provisional Government refused.\n\nCongress conducted an independent investigation, and on February 26, 1894, submitted the Morgan Report, which found all parties, including Minister Stevens—with the exception of the Queen—\"not guilty\" and not responsible for the coup. Partisans on both sides of the debate questioned the accuracy and impartiality of both the Blount and Morgan reports over the events of 1893.\n\nIn 1993, the US Congress passed a joint Apology Resolution regarding the overthrow; it was signed by President Bill Clinton. The resolution apologized for the overthrow of the Hawaiian Kingdom and acknowledged that the United States had annexed Hawaii unlawfully.\n\nAfter William McKinley won the 1896 U.S. presidential election, advocates pressed to annex the Republic of Hawaii. The previous president, Grover Cleveland, was a friend of Queen Liliuokalani. McKinley was open to persuasion by U.S. expansionists and by annexationists from Hawaii. He met with three annexationists: Lorrin A. Thurston, Francis March Hatch and William Ansel Kinney. After negotiations in June 1897, Secretary of State John Sherman agreed to a treaty of annexation with these representatives of the Republic of Hawaii. The U.S. Senate never ratified the treaty. Despite the opposition of most native Hawaiians, the Newlands Resolution was used to annex the Republic to the U.S.; it became the Territory of Hawaii. The Newlands Resolution was passed by the House on June 15, 1898, by 209 votes in favor to 91 against, and by the Senate on July 6, 1898, by a vote of 42 to 21.\n\nIn 1900, Hawaii was granted self-governance and retained Iolani Palace as the territorial capitol building. Despite several attempts to become a state, Hawaii remained a territory for sixty years. Plantation owners and capitalists, who maintained control through financial institutions such as the Big Five, found territorial status convenient because they remained able to import cheap, foreign labor. Such immigration and labor practices were prohibited in many states.\n\nPuerto Rican immigration to Hawaii began in 1899 when Puerto Rico's sugar industry was devastated by two hurricanes, causing a worldwide shortage of sugar and a huge demand for sugar from Hawaii. Hawaiian sugarcane plantation owners began to recruit experienced, unemployed laborers in Puerto Rico. Two waves of Korean immigration to Hawaii occurred in the 20th century. The first wave arrived between 1903 and 1924; the second wave began in 1965 after President Lyndon B. Johnson signed the Immigration and Nationality Act of 1965 which removed racial and national barriers and resulted in significantly altering the demographic mix in the U.S.\n\nOahu was the target of a surprise attack on Pearl Harbor by Imperial Japan on December 7, 1941. The attack on Pearl Harbor and other military and naval installations, carried out by aircraft and by midget submarines, brought the United States into World War II.\n\nIn the 1950s, the power of the plantation owners was broken by the descendants of immigrant laborers, who were born in the incorporated U.S. territory and were U.S. citizens. They voted against the Hawaii Republican Party, strongly supported by plantation owners. The new majority voted for the Democratic Party of Hawaii, which dominated territorial and state politics for more than 40 years. Eager to gain full voting rights, Hawaii's residents actively campaigned for statehood. There was concern from both political parties in the U.S. that Hawaii would be a permanent Republican Party stronghold so the admission of Alaska, thought to be a permanent Democratic Party stronghold, was to happen the same year. These predictions turned out to be inaccurate; today, Hawaii votes Democratic predominately, and Alaska votes Republican.\n\nIn March 1959, Congress passed the Hawaii Admission Act, which U.S. President Dwight D. Eisenhower signed into law. The act excluded Palmyra Atoll from statehood; it had been part of the Kingdom and Territory of Hawaii. On June 27, 1959, a referendum asked residents of Hawaii to vote on the statehood bill; 94.3% voted in favor of statehood and 5.7% opposed it. The referendum asked voters to choose between accepting the Act and remaining a U.S. territory. The United Nations' Special Committee on Decolonization later removed Hawaii from its list of non-self-governing territories.\n\nAfter attaining statehood, Hawaii quickly modernized through construction and a rapidly growing tourism economy. Later, state programs promoted Hawaiian culture. The Hawaii State Constitutional Convention of 1978 created institutions such as the Office of Hawaiian Affairs to promote indigenous language and culture.\n\nAfter the arrival of Europeans and Americans, the population of Hawaii fell dramatically until an influx of primarily Asian settlers arrived as migrant laborers at the end of the 19thcentury.\n\nThe United States Census Bureau estimates the population of Hawaii was 1,431,603 on July 1, 2015; an increase of 5.24% since the 2010 United States Census. , Hawaii had an estimated population of 1,431,603; an increase of 12,042 from the previous year and an increase of 71,302 (5.24%) since 2010. This includes a natural increase of 48,111 (96,028 births minus 47,917 deaths) and an increase due to net migration of 16,956 people into the state. Immigration from outside the United States resulted in a net increase of 30,068; migration within the country produced a net loss of 13,112 people. The center of population of Hawaii is located between the two islands of O'ahu and Moloka'i. Large numbers of Native Hawaiians have moved to Las Vegas, which has been called the \"ninth island\" of Hawaii.\n\nHawaii has a \"de facto\" population of over 1.4million, due in part to a large number of military personnel and tourist residents. O'ahu is the most populous island; it has the highest population density with a resident population of just under one million in , about 1,650 people per square mile. Hawaii's 1.4million residents, spread across of land, results in an average population density of 188.6 persons per square mile. The state has a lower population density than Ohio and Illinois.\n\nThe average projected lifespan of people born in Hawaii in 2000 is 79.8 years; 77.1 years if male, 82.5 if female—longer than the average lifespan of any other U.S. state. the U.S. military reported it had 42,371 personnel on the islands.\n\nAccording to the 2010 United States Census, Hawaii had a population of 1,360,301. The state's population identified as 38.6% Asian; 24.7% White (22.7% Non-Hispanic White Alone); 23.6% from two or more races; 10.0% Native Hawaiians and other Pacific Islanders; 8.9% Hispanics and Latinos of any race; 1.6% Black or African American; 1.2% from some other race; and 0.3% Native American and Alaska Native.\n\nHawaii has the highest percentage of Asian Americans and multiracial Americans and the lowest percentage of White Americans of any state. It is the only state where Asian Americans identify as the largest ethnic group. In 2011, 14.5% of births were to white, non-Hispanic parents. Hawaii's Asian population consists mainly of 198,000 (14.6%) Filipino Americans, 185,000 (13.6%) Japanese Americans, roughly 55,000 (4.0%) Chinese Americans, and 24,000 (1.8%) Korean Americans. There are over 80,000 Indigenous Hawaiians—5.9% of the population. Including those with partial ancestry, Samoan Americans constitute 2.8% of Hawaii's population, and Tongan Americans constitute 0.6%.\n\nOver 120,000 (8.8%) of Hispanic and Latino Americans live in Hawaii. Mexican Americans number over 35,000 (2.6%); Puerto Ricans exceed 44,000 (3.2%). Multiracial Americans constitute almost 25% of Hawaii's population, exceeding 320,000 people. Eurasian Americans are a prominent mixed-race group, numbering about 66,000 (4.9%). The Non-Hispanic White population numbers around 310,000—just over 20% of the population. The multi-racial population outnumbers the non-Hispanic white population by about 10,000 people. In 1970, the Census Bureau reported Hawaii's population was 38.8% white and 57.7% Asian and Pacific Islander.\n\nThe five largest European ancestries in Hawaii are German (7.4%), Irish (5.2%), English (4.6%), Portuguese (4.3%) and Italian (2.7%). About 82.2% of the state's residents were born in the United States. Roughly 75% of foreign-born residents originate in Asia. Hawaii is a majority-minority state. It is expected to be one of three states that will not have a non-Hispanic white plurality in 2014; the other two are California and New Mexico.\n\nThe third group of foreigners to arrive in Hawaii were from China. Chinese workers on Western trading ships settled in Hawaii starting in 1789. In 1820, the first American missionaries arrived to preach Christianity and teach the Hawaiians Western ways. , a large proportion of Hawaii's population have Asian ancestry—especially Filipino, Japanese and Chinese. Many are descendants of immigrants brought to work on the sugarcane plantations in the mid-to-late 19th century. The first 153 Japanese immigrants arrived in Hawaii on June 19, 1868. They were not approved by the then-current Japanese government because the contract was between a broker and the Tokugawa shogunate—by then replaced by the Meiji Restoration. The first Japanese current-government-approved immigrants arrived on February 9, 1885, after Kalākaua's petition to Emperor Meiji when Kalākaua visited Japan in 1881.\n\nAlmost 13,000 Portuguese migrants had arrived by 1899; they also worked on the sugarcane plantations. By 1901, over 5,000 Puerto Ricans were living in Hawaii.\n\nEnglish (General American) and Hawaiian are listed as Hawaii's \"official languages\" in the state's 1978 constitution. Article XV, Section 4 specifies that \"Hawaiian shall be required for public acts and transactions only as provided by law\". Hawaii Creole English, locally referred to as \"Pidgin\", is the native language of many native residents and is a second language for many others.\n\nAs of the 2000 Census, 73.44% of Hawaii residents aged five and older exclusively speak English at home. According to the 2008 American Community Survey, 74.6% of Hawaii's residents over the age of five speak only English at home. In their homes, 21.0% of state residents speak an additional Asian language, 2.6% speak Spanish, 1.6% speak other Indo-European languages and 0.2% speak another language.\n\nAfter English, other languages popularly spoken in the state are Tagalog, Japanese and Ilokano. Significant numbers of European immigrants and their descendants also speak their native languages; the most numerous are German, Portuguese, Italian and French. 5.37% of residents speak Tagalog—which includes non-native speakers of Filipino language, the national, co-official, Tagalog-based language; 4.96% speak Japanese and 4.05% speak Ilokano; 1.2% speak Chinese, 1.68% speak Hawaiian; 1.66% speak Spanish; 1.61% speak Korean; and 1.01% speak Samoan.\n\nFinally, Hawai'i Sign Language is spoken on the islands, but is dwindling in numbers due to American Sign Language supplanting HSL through schooling and various other domains.\n\nThe keyboard layout used for Hawaiian is QWERTY.\n\nThe Hawaiian language has about 2,000 native speakers, less than 0.1% of the total population. According to the United States Census, there were over 24,000 total speakers of the language in Hawaii in 2006–2008. Hawaiian is a Polynesian member of the Austronesian language family. It is closely related to other Polynesian languages, such as Marquesan, Tahitian, Māori, Rapa Nui (the language of Easter Island), and less closely to Samoan and Tongan.\n\nAccording to Schütz, the Marquesans colonized the archipelago in roughly 300 CE and were later followed by waves of seafarers from the Society Islands, Samoa and Tonga.\n\nThese Polynesians remained in the islands; they eventually became the Hawaiian people and their languages evolved into the Hawaiian language. Kimura and Wilson say, \"[l]inguists agree that Hawaiian is closely related to Eastern Polynesian, with a particularly strong link in the Southern Marquesas, and a secondary link in Tahiti, which may be explained by voyaging between the Hawaiian and Society Islands\". Before the arrival of Captain James Cook, the Hawaiian language had no written form. That form was developed mainly by American Protestant |missionaries between 1820 and 1826. They assigned to the Hawaiian phonemes letters from the Latin alphabet.\n\nInterest in Hawaiian increased significantly in the late 20th century. With the help of the Office of Hawaiian Affairs, specially designated immersion schools in which all subjects would be taught in Hawaiian were established. The University of Hawaii developed a Hawaiian language graduate studies program. Municipal codes were altered to favor Hawaiian place and street names for new civic developments. A sign language for the deaf, based on the Hawaiian language, has been in use in the islands since the early 1800s. Hawaiʻi Sign Language is now nearly extinct.\n\nHawaiian distinguishes between long and short vowel sounds. In modern practice, vowel length is indicated with a macron (\"kahakō\"). Hawaiian-language newspapers (\"nūpepa\") published from 1834 to 1948 and traditional native speakers of Hawaiian generally omit the marks in their own writing. The okina and kahakō are intended to help non-native speakers. The Hawaiian language uses the glottal stop (\"okina\") as a consonant. It is written as a symbol similar to the apostrophe or left-hanging (opening) single quotation mark.\n\nSome residents of Hawaii speak Hawaii Creole English (HCE), endonymically called \"pidgin\" or \"pidgin English\". The lexicon of HCE derives mainly from English but also uses words that have derived from Hawaiian, Chinese, Japanese, Portuguese, Ilocano and Tagalog. During the 19th century, the increase in immigration—mainly from China, Japan, Portugal—especially from the Azores and Madeira, and Spain—catalyzed the development of a hybrid variant of English known to its speakers as \"pidgin\". By the early 20th century, pidgin speakers had children who acquired it as their first language. HCE speakers use some Hawaiian words without those words being considered archaic. Most place names are retained from Hawaiian, as are some names for plants and animals. For example, tuna fish is often called by its Hawaiian name, \"ahi\".\n\nHCE speakers have modified the meanings of some English words. For example, \"aunty\" and \"uncle\" may either refer to any adult who is a friend or be used to show respect to an elder. Syntax and grammar follow distinctive rules different from those of General American English. For example, instead of \"it is hot today, isn't it?\", an HCE speaker would say simply \"stay hot, eh?\" The term \"da kine\" is used as a filler; a substitute for virtually any word or phrase. During the surfing boom in Hawaii, HCE was influenced by surfer slang. Some HCE expressions, such as \"brah\" and \"da kine\", have found their ways elsewhere through surfing communities.\n\nChristianity is the most widespread religion in Hawaii. It is mainly represented by various Protestants, Catholics and Mormons. Buddhism is the second most popular religion, especially among the archipelago's Japanese community. Unaffilliated account for one-quarter of the population.\n\nThe largest denominations by number of adherents were the Catholic Church with 249,619 adherents in 2010 and the Church of Jesus Christ of Latter-day Saints with 68,128 adherents in 2009. The third-largest religious group includes all non-denominational churches, with 128 congregations and 32,000 members. The third-largest denominational group is the United Church of Christ, with 115 congregations and 20,000 members. The Southern Baptist Convention has 108 congregations and 18,000 members in Hawaii.\n\nAccording to data provided by religious establishments, religion in Hawaii in 2000 was distributed as follows:\n\n\nA Pew poll found that the religious composition was as follows:\n\nHawaii has had a long history of queer identities. \"Māhū\" people, who often traversed gender as defined by Western standards, were a respected group of pre-colonization people who were widely known in society as healers. Another Hawaiian word, \"aikāne\", referred to same-sex relationships. According to journals written by Captain Cook's crew, it is widely believed that many \"alii\" engaged in \"aikāne\" relationships. Hawaiian scholar Lilikalā Kameeleihiwa said, \"If you didn't sleep with a man, how could you trust him when you went into battle? How would you know if he was going to be the warrior that would protect you at all costs, if he wasn't your lover?\"\n\nA 2012 poll by Gallup found that Hawaii had the largest proportion of lesbian, gay, bisexual and transgender (LGBT) adults in the U.S., at 5.1%, comprising an estimated adult LGBT population of 53,966 individuals. The number of same-sex couple households in 2010 was 3,239; a 35.45% increase of figures from a decade earlier. In 2013, Hawaii became the fifteenth U.S. state to legalize same-sex marriage; a University of Hawaii researcher said the law may boost tourism by $217 million.\n\nThe history of Hawaii's economy can be traced through a succession of dominant industries; sandalwood, whaling, sugarcane, pineapple, the military, tourism and education. Since statehood in 1959, tourism has been the largest industry, contributing 24.3% of the gross state product (GSP) in 1997, despite efforts to diversify. The state's gross output for 2003 was billion; per capita income for Hawaii residents in 2014 was . Hawaiian exports include food and clothing. These industries play a small role in the Hawaiian economy, due to the shipping distance to viable markets, such as the West Coast of the contiguous U.S. The state's food exports include coffee, macadamia nuts, pineapple, livestock, sugarcane and honey.\n\nBy weight, honey bees may be the state's most valuable export. According to the Hawaii Agricultural Statistics Service, agricultural sales were million from diversified agriculture, million from pineapple, and million from sugarcane. Hawaii's relatively consistent climate has attracted the seed industry, which is able to test three generations of crops per year on the islands, compared with one or two on the mainland. Seeds yielded million in 2012, supporting 1,400 workers.\n\nAs of December 2015, the state's unemployment rate was 3.2%. In 2009, the United States military spent billion in Hawaii, accounting for 18% of spending in the state for that year. 75,000 United States Department of Defense personnel live in Hawaii. According to a 2013 study by Phoenix Marketing International, Hawaii had the fourth-largest number of millionaires per capita in the United States, with a ratio of 7.18%.\n\nHawaii residents pay the most per person in state taxes in the United States. Millions of tourists pay general excise tax and hotel room tax.\n\nThe Hawaii Tax Foundation considers the state's tax burden too high, which it says contributes to higher prices and the perception of an unfriendly business climate.\n\nState Senator Sam Slom says state taxes are comparatively higher than other states because the state government handles education, health care, and social services that are usually handled at a county or municipal level in most other states.\n\nThe cost of living in Hawaii, specifically Honolulu, is high compared to that of most major U.S. cities. However, the cost of living in Honolulu is 6.7% lower than in New York City and 3.6% lower than in San Francisco. These numbers may not take some costs, such as increased travel costs for flights, additional shipping fees, and the loss of promotional participation opportunities for customers outside the contiguous U.S., into account. While some online stores offer free shipping on orders to Hawaii, many merchants exclude Hawaii, Alaska, Puerto Rico and certain other U.S. territories.\n\nHawaiian Electric Industries, a privately owned company, provides 95% of the state's population with electricity, mostly from fossil-fuel power stations. Average electricity prices in October 2014 () were nearly three times the national average () and 80% higher than the second-highest state, Connecticut.\n\nThe median home value in Hawaii in the 2000 U.S. Census was , while the national median home value was . Hawaii home values were the highest of all states, including California with a median home value of . Research from the National Association of Realtors places the 2010 median sale price of a single family home in Honolulu, Hawaii, at and the U.S. median sales price at . The sale price of single family homes in Hawaii was the highest of any U.S. city in 2010, just above that of the Silicon Valley area of California ().\n\nHawaii's very high cost of living is the result of several interwoven factors of the global economy in addition to domestic U.S. government trade policy. Like other regions with desirable weather throughout the year, such as areas of California, Arizona and Florida, Hawaii's residents can be considered to be subject to a \"Sunshine tax\". This situation is further exacerbated by the natural factors of geography and world distribution that lead to higher prices for goods due to increased shipping costs, a problem which many island states and territories suffer from as well. The situation is compounded even further by what could possibly be the single largest contributor to the high costs of living in Hawaii, a U.S. trade law known as the Jones Act, or the Merchant Marine Act of 1920. This trade regulation prohibits any foreign-flagged ships from carrying cargo between two American ports—a practice known as cabotage. Most consumer goods in the United States are manufactured by outsourced labor in East Asia, then transported by container ships to ports on the U.S. mainland, and Hawaii also receives the same goods. Being located in the central Pacific Ocean, right between major Pacific shipping lanes, it would be very economical to unload Hawaiian-bound goods in Honolulu, before continuing on to the mainland. However, this would effectively make the second leg of the voyage between Hawaii and the mainland a domestic route between two American ports. Because most large cargo ships operate under foreign \"flags of convenience\" such as Liberia, Vanuatu or Papua New Guinea, allowing them to avoid the more stringent, and thus more costly, regulations of developed nations' ports, the domestic leg of the voyage would be disallowed by the Jones Act. Instead, those cargo ships must proceed directly to the West Coast, where distributors break bulk and transport the Hawaiian-bound, Asian-manufactured goods back across the ocean by U.S.-flagged ships and increasing the length of the voyage by more than 50%. This highly-inefficient system of shipping Hawaii's consumer cargo comes at a very hefty price for the average Hawaiian citizen, and makes the cost of living in Hawaii much, much higher than it would otherwise be.\n\nHawaiian consumers ultimately bear the expense of transporting goods imposed by the Jones Act. This law makes Hawaii less competitive than West Coast ports as a shopping destination for tourists from countries with much higher taxes like Japan, even though prices for Asian-manufactured goods should be cheaper because Hawaii is much closer than mainland states to Asia.\n\nThe aboriginal culture of Hawaii is Polynesian. Hawaii represents the northernmost extension of the vast Polynesian Triangle of the south and central Pacific Ocean. While traditional Hawaiian culture remains as vestiges in modern Hawaiian society, there are re-enactments of the ceremonies and traditions throughout the islands. Some of these cultural influences, including the popularity (in greatly modified form) of \"lūau\" and \"hula\", are strong enough to affect the wider United States.\n\nThe cuisine of Hawaii is a fusion of many foods brought by immigrants to the Hawaiian Islands, including the earliest Polynesians and Native Hawaiian cuisine, and American, Chinese, Filipino, Japanese, Korean, Polynesian and Portuguese origins. Plant and animal food sources are imported from around the world for agricultural use in Hawaii. \"Poi\", a starch made by pounding taro, is one of the traditional foods of the islands. Many local restaurants serve the ubiquitous plate lunch, which features two scoops of rice, a simplified version of American macaroni salad and a variety of toppings including hamburger patties, a fried egg, and gravy of a \"loco moco\", Japanese style \"tonkatsu\" or the traditional lūau favorites, including \"kālua\" pork and \"laulau\". \"Spam musubi\" is an example of the fusion of ethnic cuisine that developed on the islands among the mix of immigrant groups and military personnel. In the 1990s, a group of chefs developed Hawaii regional cuisine as a contemporary fusion cuisine.\n\nSome key customs and etiquette in Hawaii are as follows: when visiting a home, it is considered good manners to bring a small gift for one's host (for example, a dessert). Thus, parties are usually in the form of potlucks. Most locals take their shoes off before entering a home. It is customary for Hawaiian families, regardless of ethnicity, to hold a luau to celebrate a child's first birthday. It is also customary at Hawaiian weddings, especially at Filipino weddings, for the bride and groom to do a money dance (also called the pandanggo). Print media and local residents recommend that one refer to non-Hawaiians as \"locals of Hawaii\" or \"people of Hawaii\".\n\nHawaiian mythology comprises the legends, historical tales, and sayings of the ancient Hawaiian people. It is considered a variant of a more general Polynesian mythology that developed a unique character for several centuries before about 1800. It is associated with the Hawaiian religion, which was officially suppressed in the 19th century but was kept alive by some practitioners to the modern day. Prominent figures and terms include Aumakua, the spirit of an ancestor or family god and Kāne, the highest of the four major Hawaiian deities.\n\nPolynesian mythology is the oral traditions of the people of Polynesia, a grouping of Central and South Pacific Ocean island archipelagos in the Polynesian triangle together with the scattered cultures known as the Polynesian outliers. Polynesians speak languages that descend from a language reconstructed as Proto-Polynesian that was probably spoken in the area around Tonga and Samoa in around 1000 BCE.\n\nPrior to the 15th century, Polynesian people migrated east to the Cook Islands, and from there to other island groups such as Tahiti and the Marquesas. Their descendants later discovered the islands Tahiti, Rapa Nui and later the Hawaiian Islands and New Zealand.\n\nThe Polynesian languages are part of the Austronesian language family. Many are close enough in terms of vocabulary and grammar to be mutually intelligible. There are also substantial cultural similarities between the various groups, especially in terms of social organization, childrearing, horticulture, building and textile technologies. Their mythologies in particular demonstrate local reworkings of commonly shared tales. The Polynesian cultures each have distinct but related oral traditions; legends or myths are traditionally considered to recount ancient history (the time of \"pō\") and the adventures of gods (\"atua\") and deified ancestors.\n\nThere are many Hawaiian state parks. \n\nThe literature of Hawaii is diverse and includes authors Kiana Davenport, Lois-Ann Yamanaka, and Kaui Hart Hemmings. Hawaiian magazines include \"Hana Hou!\", \"Hawaii Business Magazine\" and \"Honolulu\", among others.\n\nThe music of Hawaii includes traditional and popular styles, ranging from native Hawaiian folk music to modern rock and hip hop. Hawaii's musical contributions to the music of the United States are out of proportion to the state's small size. Styles such as slack-key guitar are well-known worldwide, while Hawaiian-tinged music is a frequent part of Hollywood soundtracks. Hawaii also made a major contribution to country music with the introduction of the steel guitar.\n\nTraditional Hawaiian folk music is a major part of the state's musical heritage. The Hawaiian people have inhabited the islands for centuries and have retained much of their traditional musical knowledge. Their music is largely religious in nature, and includes chanting and dance music. Hawaiian music has had an enormous impact on the music of other Polynesian islands; according to Peter Manuel, the influence of Hawaiian music a \"unifying factor in the development of modern Pacific musics\".\n\nTourism is an important part of the Hawaiian economy. In 2003, according to state government data, there were over 6.4 million visitors, with expenditures of over $10 billion, to the Hawaiian Islands. Due to the mild year-round weather, tourist travel is popular throughout the year. The major holidays are the most popular times for outsiders to visit, especially in the winter months. Substantial numbers of Japanese tourists still visit the islands but have now been surpassed by Chinese and Koreans due to the collapse of the value of the Yen and the weak Japanese economy. The average Japanese stays only 5 days while other Asians spend over 9.5 days and spend 25% more.\n\nHawaii hosts numerous cultural events. The annual Merrie Monarch Festival is an international Hula competition. The Hawaii International Film Festival is the premier film festival for Pacific rim cinema. Honolulu hosts the state's long-running LGBT film festival, the Rainbow Film Festival.\n\n, Hawaii's health care system insures 92% of residents. Under the state's plan, businesses are required to provide insurance to employees who work more than twenty hours per week. Heavy regulation of insurance companies helps reduce the cost to employers. Due in part to heavy emphasis on preventive care, Hawaiians require hospital treatment less frequently than the rest of the United States, while total health care expenses measured as a percentage of state GDP are substantially lower. Proponents of universal health care elsewhere in the U.S. sometimes use Hawaii as a model for proposed federal and state health care plans.\n\nHawaii has the only school system within the U.S. that is unified statewide. Policy decisions are made by the fourteen-member state Board of Education, which sets policy and hires the superintendent of schools, who oversees the state Department of Education. The Department of Education is divided into seven districts; four on Oahu and one for each of the other three counties. The main rationale for centralization is to combat inequalities between highly populated Oahu and the more rural Neighbor Islands, and between lower-income and more affluent areas. In most of the U.S., schools are funded from local property taxes. Educators struggle with children of non-native-English-speaking immigrants, whose cultures are different from those of the mainland, where most course materials and testing standards originate.\n\nPublic elementary, middle and high school test scores in Hawaii are below national averages on tests mandated under the No Child Left Behind Act. The Hawaii Board of Education requires all eligible students to take these tests and report all student test scores; some other states—Texas and Michigan, for example—do not. This may have unbalanced the results that reported in August 2005 that of 282 schools across the state, 185 failed to reach federal minimum performance standards in mathematics and reading. The ACT college placement tests show that in 2005, seniors scored slightly above the national average (21.9 compared with 20.9), but in the widely accepted SAT examinations, Hawaii's college-bound seniors tend to score below the national average in all categories except mathematics.\n\nHawaii has the highest rates of private school attendance in the nation. During the 2011–2012 school year, Hawaii public and charter schools had an enrollment of 181,213, while private schools had 37,695. Private schools educated over 17% of students in Hawaii that school year, nearly three times the approximate national average of 6%. It has four of the largest independent schools; Iolani School, Kamehameha Schools, Mid-Pacific Institute and Punahou School. Pacific Buddhist Academy, the second Buddhist high school in the U.S. and first such school in Hawaii, was founded in 2003. The first native controlled public charter school was the Kanu O Ka Aina New Century Charter School.\n\nIndependent and charter schools can select their students, while the public schools are open to all students in their district. The Kamehameha Schools are the only schools in the U.S. that openly grant admission to students based on ancestry; collectively, they are one of the wealthiest schools in the United States, if not the world, having over eleven billion US dollars in estate assets. In 2005, Kamehameha enrolled 5,398 students, 8.4% of the Native Hawaiian children in the state.\n\nGraduates of secondary schools in Hawaii often enter directly into the workforce. Some attend colleges and universities on the mainland or other countries, and the rest attend an institution of higher learning in Hawaii. The largest is the University of Hawaii System, which consists of: the research university at Mānoa, two comprehensive campuses at Hilo and West Oahu, and seven community colleges. Private universities include Brigham Young University–Hawaii, Chaminade University of Honolulu, Hawaii Pacific University, and Wayland Baptist University. Saint Stephen Diocesan Center is a seminary of the Roman Catholic Diocese of Honolulu. Kona hosts the University of the Nations, which is not an accredited university.\n\nFirst opened in 1984 illegally in Kekaha, Kaua'i, the Pūnana Leo or \"Language Nest\" (lit. \"Nest of Voices\") were the first indigenous language immersion schools in the United States. Modelled after the Māori language Kōhanga reo of New Zealand, they provide preschool aged children the opportunity to engage in early education through a Hawaiian language medium, generally taught by elders. Graduates from the Pūnana Leo schools have achieved several measures of academic success in later life. As of 2006, there were a total of eleven Pūnana Leo preschools, with locations on five of the islands.\n\nA system of state highways encircles each main island. Only Oahu has federal highways, and is the only area outside the contiguous 48 states to have signed Interstate highways. Narrow, winding roads and congestion in populated places can slow traffic. Each major island has a public bus system.\n\nHonolulu International Airport (IATA:HNL), which shares runways with the adjacent Hickam Field (IATA:HIK), is the major commercial aviation hub of Hawaii. The commercial aviation airport offers intercontinental service to North America, Asia, Australia and Oceania. Hawaiian Airlines, Mokulele Airlines and go! use jets to provide services between the large airports in Honolulu, Līhue, Kahului, Kona and Hilo. Island Air and Pacific Wings serve smaller airports. These airlines also provide air freight services between the islands.\n\nUntil air passenger services began in the 1920s, private boats were the sole means of traveling between the islands. Seaflite operated hydrofoils between the major islands in the mid-1970s.\n\nThe Hawaii Superferry operated between Oahu and Maui between December 2007 and March 2009, with additional routes planned for other islands. Protests and legal problems over environmental impact statements ended the service, though the company operating Superferry has expressed a wish to recommence ferry services in the future. Currently there are passenger ferry services in Maui County between Molokai and Maui, and between Lanai and Maui, though neither of these take vehicles. Currently Norwegian Cruise Lines and Princess Cruises provide passenger cruise ship services between the larger islands.\n\nAt one time Hawaii had a network of railroads on each of the larger islands that transported farm commodities and passengers. Most were narrow gauge systems but there were some gauge on some of the smaller islands. The standard gauge in the U.S. is . By far the largest railroad was the Oahu Railway and Land Company (OR&L) that ran lines from Honolulu across the western and northern part of Oahu.\n\nThe OR&L was important for moving troops and goods during World War II. Traffic on this line was busy enough for signals to be used to facilitate movement of trains and to require wigwag signals at some railroad crossings for the protection of motorists. The main line was officially abandoned in 1947, although part of it was bought by the U.S. Navy and operated until 1970. of track remain; preservationists occasionally run trains over a portion of this line. The Honolulu High-Capacity Transit Corridor Project aims to add elevated passenger rail on Oahu to relieve highway congestion.\n\nThe movement of the Hawaiian royal family from Hawaii Island to Maui, and subsequently to Oahu, explains the modern-day distribution of population centers. Kamehameha III chose the largest city, Honolulu, as his capital because of its natural harbor—the present-day Honolulu Harbor. Now the state capital, Honolulu is located along the southeast coast of Oahu. The previous capital was Lahaina, Maui, and before that Kailua-Kona, Hawaii. Some major towns are Hilo; Kāneohe; Kailua; Pearl City; Waipahu; Kahului; Kailua-Kona. Kīhei; and Līhue.\n\nHawaii comprises five counties: the City and County of Honolulu, Hawaii County, Maui County, Kauai County, and Kalawao County.\n\nHawaii has the fewest local governments among U.S. states. Unique to this state is the lack of municipal governments. All local governments are generally administered at the county level. The only incorporated area in the state is Honolulu County, a consolidated city–county that governs the entire island of Oahu. County executives are referred to as mayors; these are the Mayor of Hawaii County, Mayor of Honolulu, Mayor of Kauai, and the Mayor of Maui. The mayors are all elected in nonpartisan elections. Kalawao County has no elected government, and as mentioned above there are no local school districts and instead all local public education is administered at the state level by the Hawaii Department of Education. The remaining local governments are special districts.\n\nThe state government of Hawaii is modeled after the federal government with adaptations originating from the kingdom era of Hawaiian history. As codified in the Constitution of Hawaii, there are three branches of government: executive, legislative and judicial. The executive branch is led by the Governor of Hawaii, who is assisted by the Lieutenant Governor of Hawaii, both of whom are elected on the same ticket. The governor is the only state public official elected statewide; all others are appointed by the governor. The lieutenant governor acts as the Secretary of State. The governor and lieutenant governor oversee twenty agencies and departments from offices in the State Capitol. The official residence of the governor is Washington Place. \n\nThe legislative branch consists of the bicameral Hawaii State Legislature, which is composed of the 51-member Hawaii House of Representatives led by the Speaker of the House, and the 25-member Hawaii Senate led by the President of the Senate. The Legislature meets at the State Capitol. The unified judicial branch of Hawaii is the Hawaii State Judiciary. The state's highest court is the Supreme Court of Hawaii, which uses Aliiōlani Hale as its chambers.\n\nHawaii is represented in the United States Congress by two senators and two representatives. , all four seats are held by Democrats. Colleen Hanabusa won a special election for the 1st congressional district representing southeastern Oahu, including central Honolulu, on November 8, 2016 to finish the term of Rep. Mark Takai who died July 20, 2016. Tulsi Gabbard represents the 2nd congressional district, representing the rest of the state, which is largely rural and semi-rural. \n\nBrian Schatz is the senior United States Senator from Hawaii. He was appointed to the office on December 26, 2012, by Governor Neil Abercrombie, following the death of former senator Daniel Inouye. The state's junior senator is Mazie Hirono, the former representative from the second congressional district. Hirono is the first female Asian American senator and the first Buddhist senator. Hawaii incurred the biggest seniority shift between the 112th and 113th Congresses. The state went from a delegation consisting of senators who were first and twenty-first in seniority to their respective replacements, relative newcomers Schatz and Hirono.\n\nFederal officials in Hawaii are based at the Prince Kūhiō Federal Building near the Aloha Tower and Honolulu Harbor. The Federal Bureau of Investigation, Internal Revenue Service and the Secret Service maintain their offices there; the building is also the site of the federal District Court for the District of Hawaii and the United States Attorney for the District of Hawaii.\n\nSince gaining statehood and participating in its first election in1960, Hawaii has supported Democrats in all but two presidential elections; 1972 and1984, both of which were landslide victories for Republicans Richard Nixon and Ronald Reagan respectively. In Hawaii's statehood tenure, only Minnesota has supported Republican candidates fewer times in presidential elections. \n\nHawaii hasn't elected a Republican to represent the state in the U.S. Senate since Hiram Fong in 1970; since 1977, both of the state's U.S. Senators have been Democrats.\n\nIn 2004, John Kerry won the state's four electoral votes by a margin of nine percentage points with 54% of the vote. Every county supported the Democratic candidate. In 1964, favorite son candidate senator Hiram Fong of Hawaii sought the Republican presidential nomination, while Patsy Mink ran in the Oregon primary in 1972. \n\nHonolulu-born Barack Obama, then serving as United States Senator from Illinois, was elected the 44th President of the United States on November 4, 2008 and was re-elected for a second term on November 6, 2012. Obama had won the Hawaii Democratic caucus on February 19, 2008, with 76% of the vote. He was the third Hawaii-born candidate to seek the nomination of a major party and the first presidential nominee from Hawaii.\n\nWhile Hawaii is internationally recognized as a state of the United States while also being broadly accepted as such in mainstream understanding, the legality of this status has been raised in U.S. District Court, the U.N., and other international forums. Domestically, the debate is a topic covered in the Kamehameha Schools curriculum. On September 29, 2015 the Department of the Interior announced a procedure to recognize a Native Hawaiian government.\n\nPolitical organizations seeking some form of sovereignty for Hawaii have been active since the 1880s. Generally, their focus is on self-determination and self-governance, either for Hawaii as an independent nation (in many proposals, for \"Hawaiian nationals\" descended from subjects of the Hawaiian Kingdom or declaring themselves as such by choice), or for people of whole or part native Hawaiian ancestry in an indigenous \"\"nation to nation\"\" relationship akin to tribal sovereignty with US federal recognition of Native Hawaiians. A 2005 Grassroot Institute poll found the majority of Hawaiian residents opposed the Akaka Bill.\n\nSome groups also advocate some form of redress from the United States for the 1893 overthrow of Queen Liliuokalani, and for what is described as a prolonged military occupation beginning with the 1898 annexation. The movement generally views both the overthrow and annexation as illegal, with the Apology Resolution passed by US Congress in 1993 cited as a major impetus by the movement for Hawaiian sovereignty. The sovereignty movement considers Hawaii to be an illegally occupied nation.\n\n\n\n", "id": "13270", "title": "Hawaii"}
{"url": "https://en.wikipedia.org/wiki?curid=13274", "text": "Hearse\n\nA hearse is a funeral vehicle used to carry a coffin/casket/urn from a church or funeral home to a cemetery. In the funeral trade, hearses are often called funeral coaches.\n\nOriginally considered public transportation, an elaborate framework would be erected over a coffin or tomb to which memorial verses or epitaphs were attached. It was then put on the top of horse-drawn carriages, looking much like a luggage rack. Today, the original hearse remains acknowledged by the bit of scroll work or stretched-out \"S\" on the side of a funeral coach, called Landau bars.\n\nHearses were originally horse-drawn, but silent electric motorized carts were introduced as horses began to be phased out as transportation. Examples that were used in Paris were reported in the pages of \"Scientific American\" May 1907 and petrol-driven hearses began to be produced from 1909 in the United States. Motorized hearses became more widely accepted in the 1920s. The vast majority of hearses since then have been based on larger, more powerful car chassis, generally retaining the front end up to and possibly including the front doors but with custom bodywork to the rear to contain the coffin. Some early hearses also served as ambulances, owing to the large cargo capacity in the rear of the vehicle. A few cities experimented with funeral trolley cars and/or subway cars to carry both the casket and mourners to cemeteries, but these were not popular. The only exception was Chicago, Illinois which operated 3 different funeral trolley cars over the elevated tracks in downtown Chicago to outlying cemeteries in the western suburbs. A special funeral bureau handled the funeral trains which sometimes operated 3–4 funeral trains a week over the 'L'.\n\nUsually more luxurious automobile brands are used as a base for funeral cars; the vast majority of hearses in the United States and Canada are Cadillacs, and less frequently, Lincolns. In Europe, Mercedes-Benz, Daimler, Jaguar, Opel, Ford, Vauxhall Motors and Volvo are or were common contemporary bases, and in the past even used Rolls-Royce cars were converted, though their cost is generally considered prohibitive.\n\nCadillac produced what it termed a \"commercial chassis\". This was a longer and strengthened version of the long-wheelbase Fleetwood limousine frame to carry the extra weight of bodywork, rear deck and cargo. Designed for professional car use, the rear of the Cadillac commercial chassis was considerably lower than the passenger car frame, thereby lowering the rear deck height as well for ease of loading and unloading. They were shipped as incomplete cars to coachbuilders for final assembly. A Cadillac commercial chassis typically consisted of the car's front end sheet metal with lighting and trim, dashboard and controls. Rear quarter panels and sometimes the front door shells were shipped with the chassis for use in the finished coachwork. Today, most hearses are made from converted sedans on stretched wheelbases. The fleet division of Ford Motor Company sells a Lincoln Town Car with a special \"hearse package\" strictly to coachbuilders. Shipped without rear seat, rear interior trim, rear window or decklid, the hearse package also features a heavy-duty suspension, brakes, charging system and tires and was once offered on a modified Ford Expedition SUV chassis with the Triton V10 truck engine.\n\nHearses and other funeral service vehicles in the U.S. are often equipped with purple or orange light bars and other flashing lights similar to those found in emergency vehicles in order to increase the visibility of the vehicle while in processions. \n\nIn Europe, most hearses are based on commercial vans. In the past, all medium-sized vans could be converted into hearses. Today, Mercedes-Benz vans are common in modern fleets. It is common to keep old fleets since they have little wear.\n\nSince the working life of a hearse is generally one of light duty and short, sedate drives, hearses often remain serviceable for a long time; hearses 30 years old or more may still be in service, although some funeral directors replace them once, or twice a decade. , a new hearse in the USA usually costs in the range of $60,000 to $85,000.\n\nTwo styles of hearse bodywork are common. The older style is the limousine style; these have narrow pillars and lots of glass. These are more popular in the United Kingdom, among others. More popular in the United States is the landau style, with a heavily-padded leather or (later) vinyl roof, and long blind rear quarters, similarly covered, and decorated with large metal S-shaped bars designed to resemble those used to lower the tops on some horse-drawn coaches. It is common practice in the USA for the windows to be curtained, while in the UK the windows are normally left unobscured. Hearses resemble station wagons strictly because of the shape of the rear ends of conventional ones.\n\nUntil the late 1970s, it was common for hearses in the USA to be \"combination coaches\" which also could serve in the ambulance role; these were common in rural areas. Car-based ambulances and combination coaches were unable to meet stricter Federal specifications for such vehicles and were discontinued after 1979.\n\nDue to the costs of owning an expensive custom vehicle that sits idle \"80 to 90 percent of the week\", individual funeral homes reduce costs by renting or utilizing a shared motor pool.\n\nIn Japan, hearses, called , can come in two styles: \"Foreign\" style, which is similar in build and style to an American hearse, or a \"Japanese\" style, in which the rear area of the vehicle is modified to resemble a small, ornate Buddhist temple. This generally requires the rear of the vehicle to be extensively altered; commonly, the rear roof is cut away from the front windows back and all interior parts are removed from the rear as well. The ornate Buddhist-style rear area, generally constructed of wood and in which the casket or urn is placed, is built on top of this empty cavity and most often is wider than the base of the vehicle, so that it sticks out on the sides, over the rear body panels. Popular bases for these are not limited to large sedans, but also minivans and even pickup trucks by companies like Nissan and Toyota.\n\nThere are regional differences of ornaments. Nagoya style decorates not only the upper half of the body, but the lower half as well.\nKansai style has a relatively modest decorations unpainted.\nKanazawa style (other styles mostly have black bodies) with gilded ornaments.\nTokyo style, found anywhere else in Japan, features painted/gilded ornaments on the upper half of the body.\n\n\"Foreign\" style hearses are mostly similar in appearance to their US counterparts, although their exterior dimensions and interiors reflect the Japanese preference for smaller, less ornate caskets (this in light of the national preference for cremation). This means that, in contrast to American hearses, the rear quarter panels require less, and sometimes no, alteration. These are generally built from station wagons such as the Nissan Stagea, or from executive sedans such as the Toyota Celsior (Lexus LS in the US) and Nissan Cima (Infiniti Q45 in the US). Interestingly, American market vehicles such as the Lincoln Town Car and Cadillac DeVille, which are otherwise fairly uncommon in Japan, are often converted to hearses in both styles.\n\nIn Hong Kong, light goods vehicles of Isuzu, Volkswagen and Ford are used as hearses by most of the privately operated funeral homes.\n\nThe motorcycle hearse has become popular and is often used during the funeral of motorcycle enthusiasts.\nThis type of hearse is either a motorcycle with a special sidecar built to carry a casket or an urn at the side of the rider, or it is a trike that carries the casket behind the rider.\n\nIn recent decades, high capacity funeral homes have implemented designated \"first-call\" vehicles, used exclusively to transport the deceased to the funeral home. These vehicles are often converted full-size station wagons that may or may not feature a traditional landau roof and bars, although in recent years, following the end of the full-size station wagon era, the preference has shifted towards minivans or sport utility vehicles with slide-over landau bar panels for the third row windows. Many first-call vehicles have the appearance of a hearse, but will not accommodate a full-sized casket in length or height. The blue Mercury in the gallery is a retired first-call vehicle (?).\n\nPerhaps owing to the morbid nature of the hearse, its luxurious accommodations for the driver, or both, the hearse has a number of enthusiasts who own and drive retired hearses. There are several hearse clubs.\n\nAmongst enthusiasts, the 1959 Cadillac Miller-Meteor hearse is considered one of the most desirable due to its especially ornate styling and appearances in feature films, notably an ambulance version (Ecto-1) in the motion picture \"Ghostbusters\".\n\nIn the 1971 film \"Harold and Maude\" the character Harold, played by Bud Cort, drives two hearses: originally a 1959 Cadillac Superior 3-way; and then later a custom hearse he makes from a 1971 Jaguar XK-E 4.2 Series II. The Cadillac hearse is now privately owned in central California and is preserved, looking essentially identical to the way it did in the film. Only one Jaguar \"hearse\" was built and was destroyed as part of the film's storyline. Several \"Harold and Maude\" fans have since built similar hearses from E-Types and photos of them can be found online. Jane Goldman, wife of British TV and radio personality Jonathan Ross, owns a similar style \"hearse\" built from a Jaguar XK8 convertible.\n\nThe Rogues prowl around in a graffitied 1955 Cadillac Hearse in the cult classic film \"The Warriors\".\n\nCelebrity hearse enthusiasts include rock singer Neil Young and three-time NASCAR Sprint Cup Champion Tony Stewart, who had his hearse customised for a television show. Sam the Sham of the Pharaohs (known for Wooly Bully and Lil' Red Riding Hood) was known for transporting all his equipment in a 1952 Packard hearse.\n\nIn the HBO television show \"Six Feet Under\", which dealt with death every week, premieres with the Fisher family patriarch Nathaniel, a funeral director, killed in an accident involving his new hearse. His daughter Claire also owned and drove a hearse. In the popular Canadian television program \"\", character Eli Goldsworthy, a 'death obsessed' 16-year-old, drives a 1960s era vintage hearse, affectionately nicknamed Morty. Cleve Hall, of the Syfy television show Monster Man, drives a 1980 Superior, with added coach lights on each side, in the 1st season of the show. He now drives a 1963 Miller Meteor named \"Lucy\".\n\nIn Singapore, the grand hearse is built with a lorry chassis.\n\nIn the traditional Holy Week services of the Roman Catholic Church and some Anglican churches, a candelabrum with 15 candles on it is used for the service of Tenebrae. This candlestick is referred to as a \"hearse\".\n\n", "id": "13274", "title": "Hearse"}
{"url": "https://en.wikipedia.org/wiki?curid=13275", "text": "Hungary\n\nHungary (; ) is a unitary parliamentary republic in Central Europe. It covers an area of , situated in the Carpathian Basin and bordered by Slovakia to the north, Romania to the east, Serbia to the south, Croatia to the southwest, Slovenia to the west, Austria to the northwest, and Ukraine to the northeast. With about 10 million inhabitants, Hungary is a medium-sized member state of the European Union. The official language is Hungarian, which is the most widely spoken uralic language in the world. Hungary's capital and largest metropolis is Budapest, a significant economic hub, classified as an Alpha- global city. Major urban areas include Debrecen, Szeged, Miskolc, Pécs and Győr.\n\nFollowing centuries of successive habitation by Celts, Romans, Slavs, Gepids and Avars, the foundation of Hungary was laid in the late 9th century by the Hungarian grand prince Árpád in the conquest of the Carpathian Basin. His great-grandson Stephen I ascended to the throne in 1000, converting the country to a Christian kingdom. By the 12th century, Hungary became a middle power within the Western world, reaching a golden age by the 15th century. Following the Battle of Mohács in 1526 and about 150 years of partial Ottoman occupation (1541–1699), Hungary came under Habsburg rule, and later formed the great power Austro–Hungarian Empire together with Austria.\n\nHungary's current borders were established in 1920 by the Treaty of Trianon after World War I, when the country lost 71% of its territory, 58% of its population, and 32% of ethnic Hungarians. Following the interwar period, Hungary joined the Axis Powers in World War II, suffering significant damage and casualties. Hungary became a satellite state of the Soviet Union, which contributed to the establishment of a four-decade-long communist dictatorship (1947–1989). The country gained widespread international attention regarding the Revolution of 1956 and the seminal opening of its previously-restricted border with Austria in 1989, which accelerated the collapse of the Eastern Bloc. On 23 October 1989, Hungary became again a democratic parliamentary republic.\n\nIn the 21st century, Hungary is a middle power and has the world's 57th largest economy by nominal GDP, as well as the 58th largest by PPP, out of 188 countries measured by the IMF. As a substantial actor in several industrial and technological sectors, it is both the world's 36th largest exporter and importer of goods. Hungary is a high-income economy with a very high standard of living. It keeps up a social security and universal health care system, and a tuition-free university education. Hungary performs well in international rankings, it is 20th in Quality of life, 25th in inequality-adjusted human development, 32nd in Social Progress Index and ranks as the 19th safest country in the world.\n\nHungary joined the European Union in 2004 and part of the Schengen Area since 2007. Hungary is a member of the United Nations, NATO, WTO, World Bank, the AIIB, the Council of Europe and Visegrád Group. It is well known for its rich cultural history, Hungary has been contributed significantly to arts, music, literature, sports and science and technology. Hungary is the 11th most popular country as tourist destination in Europe, attracting 14.3 million international tourists in 2015. It is home to the largest thermal water cave system, the second-largest thermal lake in the world, the largest lake in Central Europe, and the largest natural grasslands in Europe.\nThe \"H\" in the name of Hungary (and Latin \"Hungaria\") is most likely due to early historical associations with the Huns, who had settled Hungary prior to the Avars. The rest of the word comes from the Latinized form of Medieval Greek \"Oungroi\" (Οὔγγροι). According to an explanation the Greek name was borrowed from Proto-Slavic \"Ǫgǔri\" (Ѫгъри), in turn borrowed from Oghur-Turkic \"Onogur\" ('ten [tribes of the] Ogurs'). \"Onogur\" was the collective name for the tribes who later joined the Bulgar tribal confederacy that ruled the eastern parts of Hungary after the Avars. The Hungarians likely belonged to the Onogur tribal alliance and it is quite possible they became its ethnic majority.\n\nThe Hungarian endonym is \"Magyarország\", composed of \"magyar\" ('Hungarian') and \"ország\" ('country'). The word \"magyar\" is taken from the name of one of the seven major semi-nomadic Hungarian tribes, \"magyeri\". The first element \"magy\" is likely from Proto-Ugric *\"mäńć-\" 'man, person', also found in the name of the Mansi people (\"mäńćī, mańśi, måńś\"). The second element \"eri\", 'man, men, lineage', survives in Hungarian \"férj\" 'husband', and is cognate with Mari \"erge\" 'son', Finnish archaic \"yrkä\" 'young man'.\n\nThe Roman Empire conquered the territory west of the Danube between 35 and 9 BC. From 9 BC to the end of the 4th century, Pannonia was part of the Roman Empire, located within part of later Hungary's territory. Here, a 600-strong Roman legion created the settlement Aquincum in 41–54 CE. A civil city grew gradually in the neighborhood of the military settlement, and in 106 CE Aquincum became the focal point of the commercial life of this area and the capital city of the Pannonian Inferior region. This area now corresponds to the Óbuda district of Budapest, with the Roman ruins now forming part of the modern Aquincum museum. Later came the Huns, who built a powerful empire. After Hunnish rule, the Germanic Ostrogoths, Lombards, and Gepids, and the polyethnic Avars, had a presence in the Carpathian Basin.\n\nIn the 9th century, East Francia, the First Bulgarian Empire and Great Moravia ruled the territory of the Carpathian Basin. The land was inhabited mainly by Avars. The Magyars advancing through the Carpathian Basin encountered the Hungarian-speaking Székely people who inhabited the land at that time. Both contemporary sources and a growing amount of archaeological evidence suggests that groups of the Avars survived the disintegration of their empire.\n\nThe freshly unified Hungarians led by Árpád settled in the Carpathian Basin starting in 895. According to linguistic evidence, they originated from an ancient Uralic-speaking population that formerly inhabited the forested area between the Volga River and the Ural Mountains.\n\nAs a federation of united tribes, Hungary was established in 895, some 50 years after the division of the Carolingian Empire at the Treaty of Verdun in 843, before the unification of the Anglo-Saxon kingdoms. Initially, the rising Principality of Hungary (\"Western Tourkia\" in medieval Greek sources) was a state consisting of a semi-nomadic people. It accomplished an enormous transformation into a Christian realm during the 10th century.\n\nThis state was well-functioning and the nation's military power allowed the Hungarians to conduct successful fierce campaigns and raids from Constantinople to as far as today's Spain. The Hungarians defeated no fewer than three major East Frankish Imperial Armies between 907 and 910. A later defeat at the Battle of Lechfeld in 955 signaled a provisory end to most campaigns on foreign territories, at least towards the West.\n\nThe year 972 marked the date when the ruling prince () Géza of the Árpád dynasty officially started to integrate Hungary into the Christian Western Europe. His first-born son, Saint Stephen I, became the first King of Hungary after defeating his pagan uncle Koppány, who also claimed the throne. Under Stephen, Hungary was recognized as a Catholic Apostolic Kingdom. Applying to Pope Sylvester II, Stephen received the insignia of royalty (including probably a part of the Holy Crown of Hungary, currently kept in the Hungarian Parliament) from the papacy.\n\nBy 1006, Stephen had consolidated his power, and started sweeping reforms to convert Hungary into a Western feudal state. The country switched to using the Latin language, and until as late as 1844, Latin remained the official language of Hungary. Hungary became a powerful kingdom. Ladislaus I extended Hungary's frontier in Transylvania and invaded Croatia in 1091. The Croatian campaign culminated in the Battle of Gvozd Mountain in 1097 and a personal union of Croatia and Hungary in 1102, ruled by Coloman i.e. Könyves Kálmán.\n\nThe most powerful and wealthiest king of the Árpád dynasty was Béla III, who disposed of the equivalent of 23 tonnes of pure silver a year. This exceeded the income of the French king (estimated at 17 tonnes) and was double the receipts of the English Crown.\n\nAndrew II issued the Diploma Andreanum which secured the special privileges of the Transylvanian Saxons and is considered the first Autonomy law in the world. He led the Fifth Crusade to the Holy Land in 1217, setting up the largest royal army in the history of Crusades. His Golden Bull of 1222 was the first constitution in Continental Europe. The lesser nobles also began to present Andrew with grievances, a practice that evolved into the institution of the parliament (\"parlamentum publicum\").\n\nIn 1241–1242, the kingdom received a major blow with the Mongol (Tatar) Invasion. Up to half of Hungary's then population of 2,000,000 were victims of the invasion. King Béla IV let Cumans and Jassic people into the country, who were fleeing the Mongols. Over the centuries, they were fully assimilated into the Hungarian population.\n\nAs a consequence, after the Mongols retreated, King Béla ordered the construction of hundreds of stone castles and fortifications, to defend against a possible second Mongol invasion. The Mongols returned to Hungary in 1285, but the newly built stone-castle systems and new tactics (using a higher proportion of heavily armed knights) stopped them. The invading Mongol force was defeated near Pest by the royal army of Ladislaus IV of Hungary. As with later invasions, it was repelled handily, the Mongols losing much of their invading force.\n\nThe Kingdom of Hungary reached one of its greatest extents during the Árpádian kings, yet royal power was weakened at the end of their rule in 1301. After a destructive period of interregnum (1301–1308), the first Angevin king, Charles I of Hungary – a bilineal descendant of the Árpád dynasty – successfully restored royal power, and defeated oligarch rivals, the so-called \"little kings\". The second Angevin Hungarian king, Louis the Great (1342–1382), led many successful military campaigns from Lithuania to Southern Italy (Kingdom of Naples), and was also King of Poland from 1370. After King Louis died without a male heir, the country was stabilized only when Sigismund of Luxembourg (1387–1437) succeeded to the throne, who in 1433 also became Holy Roman Emperor. Sigismund was also (in several ways) a bilineal descendant of the Árpád dynasty.\n\nThe first Hungarian Bible translation was completed in 1439. For half a year in 1437, there was an antifeudal and anticlerical peasant revolt in Transylvania, the Budai Nagy Antal Revolt, which was strongly influenced by Hussite ideas.\n\nFrom a small noble family in Transylvania, John Hunyadi grew to become one of the country's most powerful lords, thanks to his outstanding capabilities as a mercenary commander. He was elected governor then regent. He was a successful crusader against the Ottoman Turks, one of his greatest victories being the Siege of Belgrade in 1456.\n\nThe last strong king of medieval Hungary was the Renaissance king Matthias Corvinus (1458–1490), son of John Hunyadi. His election was the first time that a member of the nobility mounted to the Hungarian royal throne without dynastic background. He was a successful military leader and an enlightened patron of the arts and learning. His library, the Bibliotheca Corviniana, was Europe's greatest collection of historical chronicles, philosophic and scientific works in the 15th century, and second only in size to the Vatican Library. The library is a UNESCO World Heritage Site.\n\nThe serfs and common people considered him a just ruler because he protected them from excessive demands from and other abuses by the magnates. Under his rule, in 1479, the Hungarian army destroyed the Ottoman and Wallachian troops at the Battle of Breadfield. Abroad he defeated the Polish and German imperial armies of Frederick at Breslau (Wrocław). Matthias' mercenary standing army, the Black Army of Hungary, was an unusually large army for its time, and it conquered parts of Austria, Vienna (1485) and parts of Bohemia.\n\nKing Matthias died without lawful sons, and the Hungarian magnates procured the accession of the Pole Vladislaus II (1490–1516), supposedly because of his weak influence on Hungarian aristocracy. Hungary's international role declined, its political stability shaken, and social progress was deadlocked. In 1514, the weakened old King Vladislaus II faced a major peasant rebellion led by György Dózsa, which was ruthlessly crushed by the nobles, led by John Zápolya.\n\nThe resulting degradation of order paved the way for Ottoman pre-eminence. In 1521, the strongest Hungarian fortress in the South, Nándorfehérvár (today's Belgrade, Serbia), fell to the Turks. The early appearance of Protestantism further worsened internal relations in the country.\n\nAfter some 150 years of wars with the Hungarians and other states, the Ottomans gained a decisive victory over the Hungarian army at the Battle of Mohács in 1526, where King Louis II died while fleeing. Amid political chaos, the divided Hungarian nobility elected two kings simultaneously, John Zápolya and Ferdinand I of the Habsburg dynasty. With the conquest of Buda by the Turks in 1541, Hungary was divided into three parts and remained so until the end of the 17th century. The north-western part, termed as Royal Hungary, was annexed by the Habsburgs who ruled as Kings of Hungary. The eastern part of the kingdom became independent as the Principality of Transylvania, under Ottoman (and later Habsburg) suzerainty. The remaining central area, including the capital Buda, was known as the Pashalik of Buda.\n\nThe vast majority of the seventeen and nineteen thousand Ottoman soldiers in service in the Ottoman fortresses in the territory of Hungary were Orthodox and Muslim Balkan Slavs rather than ethnic Turkish people. Orthodox Southern Slavs were also acting as akinjis and other light troops intended for pillaging in the territory of present-day Hungary. In 1686, the Holy League's army, containing over 74,000 men from various nations, reconquered Buda from the Turks. After some more crushing defeats of the Ottomans in the next few years, the entire Kingdom of Hungary was removed from Ottoman rule by 1718. The last raid into Hungary by the Ottoman vassals Tatars from Crimea took place in 1717. The constrained Habsburg Counter-Reformation efforts in the 17th century reconverted the majority of the kingdom to Catholicism. The ethnic composition of Hungary was fundamentally changed as a consequence of the prolonged warfare with the Turks. A large part of the country became devastated, population growth was stunted, and many smaller settlements perished. The Austrian-Habsburg government settled large groups of Serbs and other Slavs in the depopulated south, and settled Germans (called Danube Swabians) in various areas, but Hungarians were not allowed to settle or re-settle in the south of the Great Plain.\n\nBetween 1703 and 1711, there was a large-scale uprising led by Francis II Rákóczi, who after the dethronement of the Habsburgs in 1707 at the Diet of Ónod, took power provisionally as the Ruling Prince of Hungary for the wartime period, but refused the Hungarian Crown and the title \"King\". The uprisings lasted for years. After 8 years of war with the Habsburg Empire, the Hungarian Kuruc army lost the last main battle at Trencsén (1708).\n\nDuring the Napoleonic Wars and afterwards, the Hungarian Diet had not convened for decades. In the 1820s, the Emperor was forced to convene the Diet, which marked the beginning of a Reform Period (1825–1848, ). Count István Széchenyi, one of the most prominent statesmen of the country, recognized the urgent need of modernization and his message got through. The Hungarian Parliament was reconvened in 1825 to handle financial needs. A liberal party emerged and focused on providing for the peasantry. Lajos Kossuth – a famous journalist at that time – emerged as leader of the lower gentry in the Parliament. A remarkable upswing started as the nation concentrated its forces on modernization even though the Habsburg monarchs obstructed all important liberal laws relating to civil and political rights and economic reforms. Many reformers (Lajos Kossuth, Mihály Táncsics) were imprisoned by the authorities.\n\nOn 15 March 1848, mass demonstrations in Pest and Buda enabled Hungarian reformists to push through a list of 12 demands. Under governor and president Lajos Kossuth and the first Prime Minister, Lajos Batthyány, the House of Habsburg was dethroned.\nThe Habsburg Ruler and his advisors skillfully manipulated the Croatian, Serbian and Romanian peasantry, led by priests and officers firmly loyal to the Habsburgs, and induced them to rebel against the Hungarian government, though the Hungarians were supported by the vast majority of the Slovak, German and Rusyn nationalities and by all the Jews of the kingdom, as well as by a large number of Polish, Austrian and Italian volunteers. In July 1849 the Hungarian Parliament proclaimed and enacted the first laws of ethnic and minority rights in the world. Many members of the nationalities gained the coveted highest positions within the Hungarian Army, like General János Damjanich, an ethnic Serb who became a Hungarian national hero through his command of the 3rd Hungarian Army Corps or Józef Bem, who was Polish and also became a national hero in Hungary. Initially, the Hungarian forces (\"Honvédség\") defeated Austrian armies. To counter the successes of the Hungarian revolutionary army, Habsburg Emperor Franz Joseph I asked for help from the \"Gendarme of Europe\", Czar Nicholas I, whose Russian armies invaded Hungary. This made Artúr Görgey surrender in August 1849. The leader of the Austrian army, Julius Jacob von Haynau, became governor of Hungary for a few months, and ordered the execution of the 13 Martyrs of Arad, leaders of the Hungarian army, and Prime Minister Batthyány in October 1849. Lajos Kossuth escaped into exile. Following the war of 18481849, the whole country was in \"passive resistance\".\n\nBecause of external and internal problems, reforms seemed inevitable and major military defeats of Austria forced the Habsburgs to negotiate the Austro-Hungarian Compromise of 1867, by which the dual Monarchy of Austria–Hungary was formed. This Empire had the second largest area in Europe (after the Russian Empire), and it was the third most populous (after Russia and the German Empire). The two realms were governed separately by two parliaments from two capital cities, with a common monarch and common external and military policies. Economically, the empire was a customs union. The old Hungarian Constitution was restored, and Franz Joseph I was crowned as King of Hungary. The era witnessed impressive economic development. The formerly backward Hungarian economy became relatively modern and industrialized by the turn of the 20th century, although agriculture remained dominant until 1890. In 1873, the old capital Buda and Óbuda were officially united with Pest, thus creating the new metropolis of Budapest. Many of the state institutions and the modern administrative system of Hungary were established during this period.\n\nAfter the Assassination in Sarajevo, the Hungarian prime minister István Tisza and his cabinet tried to avoid the outbreak and escalating of a war in Europe, but their diplomatic efforts were unsuccessful. Austria–Hungary drafted 9 million (fighting forces: 7.8 million) soldiers in World War I (over 4 million from the Kingdom of Hungary) on the side of Germany, Bulgaria and Turkey. The troops raised in the Kingdom of Hungary spent little time defending the actual territory of Hungary, with the exceptions of the Brusilov Offensive in June 1916, and a few months later, when the Romanian army made an attack into Transylvania, both of which were repelled. In comparison, of the total army, Hungary's loss ratio was more than any other nations of Austria-Hungary. The Central Powers conquered Serbia. Romania declared war. The Central Powers conquered Southern Romania and the Romanian capital Bucharest. In 1916 Emperor Franz Joseph died, and the new monarch Charles IV sympathized with the pacifists. With great difficulty, the Central powers stopped and repelled the attacks of the Russian Empire.\n\nThe Eastern front of the Allied (Entente) Powers completely collapsed. The Austro-Hungarian Empire then withdrew from all defeated countries. On the Italian front, the Austro-Hungarian army made no progress against Italy after January 1918. Despite great Eastern successes, Germany suffered complete defeat on the more important Western front. By 1918, the economic situation had deteriorated (strikes in factories were organized by leftist and pacifist movements) and uprisings in the army had become commonplace. In the capital cities, the Austrian and Hungarian leftist liberal movements (the maverick parties) and their leaders supported the separatism of ethnic minorities. Austria-Hungary signed a general armistice in Padua on 3 November 1918. In October 1918, Hungary's union with Austria was dissolved.\n\nFollowing the First World War, Hungary underwent a period of profound political upheaval, beginning with the Aster Revolution in 1918, which brought the social-democratic Mihály Károlyi to power as Prime Minister. Károlyi dissolved the union with Austria and disarmed the Hungarian Army, leaving the country without any national defense. The Little Entente, sensing an opportunity, invaded the country from three sides—Romania invaded Transylvania, Czechoslovakia annexed Upper Hungary (today's Slovakia), and a joint Serb-French coalition annexed Vojvodina and other southern regions. In March 1919, communists led by Béla Kun ousted the Károlyi government and proclaimed the Hungarian Soviet Republic (\"Tanácsköztársaság\"), followed by a thorough Red Terror campaign. Despite some successes on the Czechoslovak front, Kun's forces were ultimately unable to resist the Romanian invasion; by August 1919, Romanian troops occupied Budapest and ousted Kun.\n\nIn November 1919, rightist forces led by former Austro-Hungarian admiral Miklós Horthy entered Budapest; exhausted by the war and its aftermath, the populace accepted Horthy's leadership. In January 1920, parliamentary elections were held and Horthy was proclaimed Regent of the reestablished Kingdom of Hungary, inaugurating the so-called \"Horthy era\" (\"Horthy-kor\"). The new government worked quickly to normalize foreign relations while turning a blind eye to a White Terror that swept through the countryside; extrajudicial killings of suspected communists and Jews lasted well into 1920. On June 4 of that year, the Treaty of Trianon established new borders for Hungary. The country lost 71% of its territory and 66% of its antebellum population, as well as many sources of raw materials and its sole port, Fiume. Though the revision of the Treaty quickly rose to the top of the national political agenda, the Horthy government was not willing to resort to military intervention to do so.\n\nThe Horthy regime's initial years were occupied by putsch attempts by Charles IV, the Austro-Hungarian pretender; continued suppression of communists; and a migration crisis triggered by the Trianon territorial changes. Though free elections continued, Horthy's personality, and those of his personally selected prime ministers, dominated the political scene. The government's actions continued to drift right with the passage of antisemitic laws and, due to the continued isolation of the Little Entente, economic and then political gravitation toward Italy and Germany. The Great Depression further exacerbated the situation and the popularity of fascist politicians such as Gyula Gömbös and Ferenc Szálasi, promising economic and social recovery, rose.\n\nHorthy's nationalist agenda reached its apogee in 1938 and 1940, when the Nazis rewarded Hungary's staunchly pro-Germany foreign policy in the First and Second Vienna Awards, respectively, peacefully restoring ethnic-Hungarian-majority areas lost after Trianon. In 1939, Hungary regained further territory from Czechoslovakia through force. Hungary formally joined the Axis Powers on 20 November 1940, and in 1941, participated in the invasion of Yugoslavia, gaining some of its former territories in the south.\n\nHungary formally entered World War II as an Axis Power on 26 June 1941, declaring war on the Soviet Union after unidentified planes bombed Kassa, Munkács, and Rahó. Hungarian troops fought on the Eastern Front for two years. Despite some early successes, the Hungarian government began seeking a secret peace pact with the Allies after the Second Army suffered catastrophic losses at the River Don in January 1943. Learning of the planned defection, German troops occupied Hungary on 19 March 1944 to guarantee Horthy's compliance. In October, as the Soviet front approached and the Hungarian government made further efforts to disengage from the war, German troops ousted Horthy and installed a puppet government under Szálasi's fascist Arrow Cross Party. Szálasi pledged all the country's capabilities in service of the German war machine. By October 1944, the Soviets had reached the river Tisza, and despite some losses, succeeded in encircling and besieging Budapest in December.\n\nHungary participated in the Holocaust. During the German occupation in May–June 1944, the Arrow Cross and Hungarian police deported nearly 440,000 Jews, mainly to Auschwitz. Nearly all of these were murdered. The Swedish Diplomat Raoul Wallenberg managed to save a considerable number of Hungarian Jews by giving them Swedish passports. Rudolf Kastner (original spelling Kasztner), one of the leaders of the Hungarian Aid and Rescue Committee, bribed senior SS officers such as Adolf Eichmann to allow some Jews to escape. Other diplomats also organized false papers and safe houses for Jews in Budapest and hundreds of Hungarians were executed by the Arrow Cross for sheltering Jews. The Horthy government's complicity in the Holocaust remains a point of controversy and contention.\n\nThe war left Hungary devastated, destroying over 60% of the economy and causing significant loss of life. As many as 280,000 Hungarians were raped, murdered and executed or deported for slave labor by Czechoslovaks, Soviet Red Army troops, and Yugoslavs.\n\nOn 13 February 1945, Budapest surrendered; by April, German troops left the country under Soviet military occupation. 200,000 Hungarians were expelled from Czechoslovakia in exchange for 70,000 Slovaks living in Hungary. 202,000 ethnic Germans were expelled to Germany, and through the 1947 Paris Peace Treaties, Hungary was again reduced to its immediate post-Trianon borders.\n\nFollowing the defeat of Nazi Germany, Hungary became a satellite state of the Soviet Union. The Soviet leadership selected Mátyás Rákosi to front the Stalinization of the country, and Rákosi ruled \"de facto\" ruled Hungary from 1949 to 1956. His government's policies of militarization, industrialization, collectivization, and war compensation led to a severe decline in living standards. In imitation of Stalin's KGB, the Rákosi government established a secret political police, the ÁVH, to enforce the new regime. The purges that followed saw approximately 350,000 officials and intellectuals imprisoned or executed from 1948 to 1956. Many freethinkers, democrats, and Horthy-era dignitaries were secretly arrested and extrajudicially interned in domestic and foreign Gulags. Some 600,000 Hungarians were deported to Soviet labor camps, where at least 200,000 died.\n\nAfter Stalin's death in 1953, the Soviet Union pursued a program of destalinization that was inimical to Rákosi, leading to his deposition. The following political cooling saw the ascent of Imre Nagy to the premiership, and the growing interest of students and intellectuals in political life. Nagy promised market liberalization and political openness, while Rákosi opposed both vigorously. Rákosi eventually managed to discredit Nagy and replace him with the more hard-line Ernő Gerő. Hungary joined the Warsaw Pact in May 1955, as societal dissatisfaction with the regime swelled. Following the firing on peaceful demonstrations by Soviet soldiers and secret police, and rallies throughout the country on 23 October 1956, protesters took to the streets in Budapest, initiating the 1956 Revolution. In an effort to quell the chaos, Nagy returned as premier, promised free elections, and took Hungary out of the Warsaw Pact.\n\nThe violence nonetheless continued as revolutionary militias sprung up against the Soviet Army and the ÁVH; the roughly 3,000-strong resistance fought Soviet tanks using Molotov cocktails and machine-pistols. Though the preponderance of the Soviets was immense, they suffered heavy losses, and by 30 October 1956 most Soviet troops had withdrawn from Budapest to garrison the countryside. For a time, the Soviet leadership was unsure how to respond to developments in Hungary, but eventually decided to intervene to prevent a destabilization of the Soviet bloc. On 4 November reinforcements of more than 150,000 troops and 2,500 tanks entered the country from the Soviet Union. Nearly 20,000 Hungarians were killed resisting the intervention, while an additional 21,600 were imprisoned afterwards for political reasons. Some 13,000 were interned and 230 brought to trial and executed. Nagy was captured to be executed in 1958. Because borders had briefly been open, nearly a quarter of a million people had fled the country by the time the revolution was suppressed.\n\nAfter a second, briefer period of Soviet military occupation, János Kádár, Nagy's former Minister of State, was chosen by the Soviet leadership to head the new government and chair the new ruling Socialist Workers' Party (MSzMP). Kádár quickly normalized the situation. In 1963, the government granted a general amnesty and released the majority of those imprisoned for their active participation in the uprising. Kádár proclaimed a new policy line, according to which the people were no longer compelled to profess loyalty to the party if they tacitly accepted the Socialist regime as a fact of life. In many speeches, he described this as, \"Those who are not against us are with us.\" Kádár introduced new planning priorities in the economy, such as allowing farmers significant plots of private land within the collective farm system (\"háztáji gazdálkodás\"). The living standard rose as consumer good and food production took precedence over military production, which was reduced to one tenth of pre-revolutionary levels.\n\nIn 1968, the New Economic Mechanism (NEM) introduced free-market elements into socialist command economy. From the 1960s through the late 1980s, Hungary was often referred to as \"the happiest barrack\" within the Eastern bloc. During the latter part of the Cold War Hungary's GDP per capita was fourth only to East Germany, Czechoslovakia, and the Soviet Union itself. As a result of this relatively high standard of living, a more liberalized economy, a less censored press, and less restricted travel rights, Hungary was generally considered one of the more liberal countries in which to live in Central Europe during communism. In the 1980s, however, living standards steeply declined again due to a worldwide recession to which communism was unable to respond. By the time Kádár died in 1989, the Soviet Union was in steep decline and a younger generation of reformists saw liberalization as the solution to economic and social issues.\n\nHungary's transition from communism to democracy and capitalism (\"rendszerváltás\", \"regime change\") was peaceful and prompted by economic stagnation, domestic political pressure, and changing relations with other Warsaw Pact countries. Although the MSzMP began Round Table Talks with various opposition groups in March 1989, the reburial of Imre Nagy as a revolutionary martyr that June is widely considered the symbolic end of communism in Hungary. Over 100,000 people attended the Budapest ceremony without any significant government interference, and many speakers openly called for Soviet troops to leave the country. Free elections were held in May 1990, which saw the Hungarian Democratic Forum, a major conservative opposition group, elected to the head of a coalition government. József Antall became the first democratically-elected Prime Minister since World War II.\n\nWith the removal of state subsidies and rapid privatization in 1991, Hungary was affected by a severe economic recession. The Antall government's austerity measures proved unpopular, and the Communist Party's legal and political heir, the Socialist Party, won the subsequent 1994 elections. This abrupt shift in the political landscape was repeated in 1998 and 2002; each electoral cycle, the governing party was ousted and the erstwhile opposition elected. Like most other post-communist European states, however, Hungary broadly pursued an integrationist agenda, joining NATO in 1999 and the European Union in 2004. As a NATO member, Hungary was involved in the Yugoslav Wars.\n\nIn 2006, major protests erupted after it leaked that socialist PM Ferenc Gyurcsány's had claimed in a private speech that his party \"lied\" to win the recent elections. The popularity of left-wing parties plummeted in the ensuing political upheaval, and in 2010, Viktor Orbán's national-conservative Fidesz was elected to a parliamentary supermajority. The legislature consequently approved a new constitution, among other sweeping governmental and legal changes. Although these developments were met with and still engender controversy, Fidesz secured a second supermajority in 2014. In 2015 Fidesz lost its two-thirds majority in parliament after a by-election defeat.\n\nHungary's geography has traditionally been defined by its two main waterways, the Danube and Tisza rivers. The common tripartite division of the country into three sections—\"Dunántúl\" (\"beyond the Danube\", Transdanubia), \"Tiszántúl\" (\"beyond the Tisza\"), and \"Duna-Tisza köze\" (\"between the Danube and Tisza\")—is a reflection of this. The Danube flows north-south right through the center of contemporary Hungary, and the entire country lies within its drainage basin.\n\nTransdanubia, which stretches westward from the center of the country toward Austria, is a primarily hilly region with a terrain varied by low mountains. These include the very eastern stretch of the Alps, \"Alpokalja\", in the west of the country, the Transdanubian Mountains in the central region of Transdanubia, and the Mecsek Mountains and Villány Mountains in the south. The highest point of the area is the Írott-kő in the Alps, at . The Little Hungarian Plain (\"Kisalföld\") is found in northern Transdanubia. Lake Balaton and Lake Hévíz, the largest lake in Central Europe and the largest thermal lake in the world, respectively, are in Transdanubia as well.\n\nThe \"Duna-Tisza köze\" and \"Tiszántúl\" are characterized mainly by the Great Hungarian Plain (\"Alföld\"), which stretches across most of the eastern and southeastern areas of the country. To the north of the Plain are the foothills of the Carpathians in a wide band near the Slovakian border. The Kékes at is the tallest mountain in Hungary and is found here.\n\nPhytogeographically, Hungary belongs to the Central European province of the Circumboreal Region within the Boreal Kingdom. According to the WWF, the territory of Hungary belongs to the ecoregion of Pannonian mixed forests.\n\nHungary has 10 national parks, 145 minor nature reserves, and 35 landscape protection areas.\n\nHungary has a continental climate, with hot summers with low overall humidity levels but frequent rainshowers and mildly cold snowy winters. Average annual temperature is . Temperature extremes are on 20 July 2007 at Kiskunhalas in the summer and on 16 February 1940 Miskolc-Görömbölytapolca in the winter. Average high temperature in the summer is and average low temperature in the winter is . The average yearly rainfall is approximately . A small, southern region of the country near Pécs enjoys a reputation for a Mediterranean climate, but in reality it is only slightly warmer than the rest of the country and still receives snow during the winter.\nHungary is ranked sixth in an environmental protection index by \"GW\"/\"CAN\".\n\nHungary is a unitary, parliamentary, representative democratic republic. The Hungarian political system operates under a framework reformed in 2012, constitutional document known as Fundamental Law of Hungary. Amendments generally require a two-thirds majority of parliament, the fundamental principles of the constitution, as expressed in the articles guaranteeing human dignity, the separation of powers, the state structure, and the rule of law are valid in perpetuity. Members of Parliament (\"országgyűlési képviselő\") are elected to the highest organ of state authority, the unicameral \"Országgyűlés\" (National Assembly) in every four years. 199 MPs are elected to the National Assembly in a single round first-past-the-post election with an election threshold of 5%.\n\nThe Prime Minister (\"miniszterelnök\") elected by the National Assembly and serves as the head of government and exercises executive power. Therefore, traditionally, the Prime Minister is the leader of the party with the most seats in parliament. The Prime Minister selects Cabinet ministers and has the exclusive right to dismiss them. Cabinet nominees must appear before consultative open hearings before one or more parliamentary committees, survive a vote in the National Assembly, and be formally approved by the President. The cabinet is responsible to the parliament.\n\nThe President of the Republic (\"köztársasági elnök\") serves as the head of state and is elected by the National Assembly every five years. The head of state invested primarily with representative responsibilities and powers. He receives foreign heads of state and formally nominates the Prime Minister at the recommendation of the National Assembly. He is also the Commander-in-chief of the country's armed forces. Importantly, the President may veto a piece of legislation or send it to the 15-member Constitutional Court for review. The third-highest official in Hungary is the Speaker of the National Assembly, who is elected by the National Assembly and responsible for overseeing the daily sessions of the body.\n\nThe debt-to-GDP ratio of Hungary had its peak in 2011 when it stood at 83% and decreased since then. According to Eurostat, the government gross debt of Hungary amounts to 25.119 billion HUF or 74.1% of its GDP in 2016. The government achieved a budget deficit 1.9% of the GDP in 2015. Hungary's credit rating by credit rating agencies Standard & Poor's, Moody's and Fitch Ratings stands at Investment Grade \"BBB\" with a stable outlook in 2016.\n\nSince the fall of communism, Hungary has a multi-party system. The last Hungarian parliamentary election took place on 6 April 2014. This parliamentary election was the 7th since the 1990 first multi-party election. The result was a victory for Fidesz–KDNP alliance, preserving its two-thirds majority with Viktor Orbán remaining Prime Minister. It was the first election according to the new Constitution of Hungary which went into force on 1 January 2012. The new electoral law also entered into force that day. The voters elected 199 MPs instead of previous 386 lawmakers. The current political landscape in Hungary is dominated by the conservative Fidesz, who have a near supermajority, and two medium-sized parties, the left-wing Hungarian Socialist Party (\"MSZP\") and nationalist Jobbik.\n\nThe democratic character of the Hungarian parliament was reestablished with the fall of the Iron Curtain and the end of communist dictatorship in 1989. Today's parliament is still called \"Országgyűlés\" just like in royal times, but in order to differentiate between the historical royal diet is referred to as \"National Assembly\" now. The Diet of Hungary was a legislative institution in the medieval kingdom of Hungary from the 1290s, and in its successor states, Royal Hungary and the Habsburg kingdom of Hungary throughout the Early Modern period. The articles of the 1790 diet set out that the diet should meet at least once every 3 years, but, since the diet was called by the Habsburg monarchy, this promise was not kept on several occasions thereafter. As a result of the Austro-Hungarian Compromise, it was reconstituted in 1867. The Latin term \"Natio Hungarica\" (\"Hungarian nation\") was used to designate the political elite which had participation in the diet, consisting of the nobility, the Catholic clergy, and a few enfranchised burghers, regardless of language or ethnicity.\n\nThe judicial system of Hungary is a civil law system divided between courts with regular civil and criminal jurisdiction and administrative courts with jurisdiction over litigation between individuals and the public administration. Hungarian law is codified and based on German law and in a wider sense, civil law or Roman law. The court system for civil and criminal jurisdiction consists of local courts (\"járásbíróság\"), regional appellate courts (\"ítélőtábla\"), and the supreme court (\"Kúria\"). Hungary's highest courts are located in Budapest.\n\nLaw enforcement in Hungary is split among the Police and Border Guards, and the National Tax and Customs Administration. The Hungarian Police is the main and largest state law enforcement agency in Hungary. It carries nearly all general police duties such as criminal investigation, patrol activity, traffic policing, border control. It is led by the National Police Commissioner under the control of the Minister of the Interior. The body is divided into county police departments which are also divided into regional and town police departments. The National Police also have child agencies with nationwide jurisdiction, such as the police force often mocked as the Hungarian FBI \"Nemzeti Nyomozó Iroda\" (National Bureau of Investigation), a civilian police force specialised in investigating serious crimes, the gendarmerie-like, militarised \"Készenléti Rendőrség\" (Operational Police) mainly dealing with riots and often enforcing local police forces. Due to Hungary's accession to the Schengen Treaty, the Police and Border Guards were merged into a single national corps, with the Border Guards becoming Police Officers. This merger took place in January 2008. The Customs and Excise Authority remained to be subject to the Ministry of Finance under the National Tax and Customs Administration.\n\nHungary is a unitary state divided into 19 counties (\"megye\"). In addition, the capital (\"főváros\"), Budapest, is independent of any county government. The counties and the capital are the 20 NUTS third-level units of Hungary. The counties are further subdivided into 174 ridings (\"járás\") as of 1 January 2013. There are also 23 towns with county rights (\"megyei jogú város\"), sometimes known as \"urban counties\" in English. The local authorities of these towns have extended powers, but these towns belong to the territory of the respective county instead of being independent territorial units. County councils and municipalities have different roles and separate responsibilities relating to local government. The role of the counties are basically administrative and focus on strategic development, while preschools, public water utilities, garbage disposal, elderly care and rescue services are administered by the municipalities.\n\nSince 1996, the counties and City of Budapest have been grouped into 7 regions for statistical and development purposes. These seven regions constitute NUTS' second-level units of Hungary. They are Central Hungary, Central Transdanubia, Northern Great Plain, Northern Hungary, Southern Transdanubia, Southern Great Plain, and Western Transdanubia.\n\nHungary wields considerable influence in Central and Eastern Europe and is a middle power in international affairs. The foreign policy of Hungary is based on four basic commitments: to Atlantic co-operation, to European integration, to international development and to international law. The Hungarian economy is fairly open and relies strongly on international trade.\n\nHungary has been a member of the United Nations since December 1955 and a member of the European Union, NATO, the OECD, the Visegrád Group, the WTO, the World Bank, the AIIB and the IMF. Hungary took on the presidency of the Council of the European Union for half a year in 2011 and the next will be in 2024. In 2015, Hungary was the fifth largest OECD Non-DAC donor of development aid in the world, which represents 0.13% of its Gross National Income.\n\nHungary's capital city, Budapest, is home to more than 100 embassies and representative bodies as an international political actor. Hungary hosts the main and regional headquarters of many international organizations as well, including European Institute of Innovation and Technology, European Police College, United Nations High Commissioner for Refugees, Food and Agriculture Organization of the United Nations, International Centre for Democratic Transition, Institute of International Education, International Labour Organization, International Organization for Migration, International Red Cross, Regional Environmental Center for Central and Eastern Europe, Danube Commission and others.\n\nSince 1989, Hungary's top foreign policy goal has been achieving integration into Western economic and security organizations. Hungary joined the Partnership for Peace program in 1994 and has actively supported the IFOR and SFOR missions in Bosnia. Hungary since 1989 has also improved its often frosty neighborly relations by signing basic treaties with Romania, Slovakia, and Ukraine. These renounce all outstanding territorial claims and lay the foundation for constructive relations. However, the issue of ethnic Hungarian minority rights in Romania, Slovakia and Serbia periodically causes bilateral tensions to flare up. Hungary since 1989 has signed all of the OSCE documents, and served as the OSCE's Chairman-in-Office in 1997. Hungary's record of implementing CSCE \"Helsinki Final Act\" provisions, including those on reunification of divided families, remains among the best in Central and Eastern Europe.\n\nThe 2016 Global Peace Index ranked Hungary 19th out of 163 countries. The President holds the title of commander-in-chief of the nation's armed forces. The Ministry of Defence jointly with Chief of staff administers the armed forces, including the Hungarian Ground Force and the Hungarian Air Force. Since 2007, the Hungarian Armed Forces is under a unified command structure. The Ministry of Defence maintains the political and civil control over the army. A subordinate Joint Forces Command is coordinating and commanding the HDF corps. In 2016, the armed forces had 31,080 personnel on active duty, the operative reserve brought the total number of troops to fifty thousand. In 2017, military spending will be $1.21 billion, about 0.94% of the country's GDP, well below the NATO target of 2%. In 2012, the government adopted a resolution in which it pledged to increase defence spending to 1.4% of GDP by 2022.\n\nMilitary service is voluntary, though conscription may occur in wartime. In a significant move for modernization, Hungary decided in 2001 to buy 14 JAS 39 Gripen fighter aircraft for about 800 million EUR. Hungarian National Cyber Security Center is re-organized in 2016 in order to become more efficient through cyber security.\n\nIn 2016, the Hungarian military has about 700 troops stationed in foreign countries as part of international peacekeeping forces, including 100 HDF troops in the NATO-led ISAF force in Afghanistan, 210 Hungarian soldiers in Kosovo under command of KFOR, and 160 troops in Bosnia and Herzegovina. Hungary sent 300 strong logistics unit to Iraq in order to help the US occupation with armed transport convoys, though public opinion opposed the country's participation in the war. One soldier was killed in action because of a roadside bomb in Iraq.\n\nDuring the 18th and 19th century, Hungarian Hussars rose to international fame and served as a model for light cavalry in many European countries. In 1848–49 HDF achieved successes against better-trained and equipped Austrian forces, despite the Austrian advantage in numbers. The 1848–49 Winter Campaign of Józef Bem and the Spring Campaign of Artúr Görgey are to this day taught at military schools, including at West Point Academy in the United States. In 1872, the Ludovica Military Academy officially began training cadets. By 1873 HDF already had over 2,800 officers and 158,000 men organized into eighty-six battalions and fifty-eight squadrons. During WWI, out of the eight million men mobilized by Austro Hungarian Empire, over one million died. During the 1930s and early 1940s, Hungary was preoccupied with regaining the territories and population lost in the Trianon peace treaty at Versailles in 1920. Conscription was introduced on a national basis in 1939. The peacetime strength of the Royal Hungarian Army grew to 80,000 men organized into seven corps commands. During WWII the Hungarian Second Army was near to total devastation on banks of the Don River in December 1942 in Battle for Stalingrad. During the Socialist and the Warsaw Pact era (1947–1989), the entire 200,000 strong Southern Group of Forces was garrisoned in Hungary, complete with artillery, tank regiments, air force and missile troops with nuclear weapons.\n\nHungary is an OECD high-income mixed economy with very high human development index and skilled labour force with the 16th lowest income inequality in the world, furthermore it is the 15th most complex economy according to the Economic Complexity Index. The Hungarian is the 57th-largest economy in the world (out of 188 countries measured by IMF) with $265.037 billion output, and ranks 49th in the world in terms of GDP per capita measured by purchasing power parity. Hungary is an export-oriented market economy with a heavy emphasis on foreign trade, thus the country is the 36th largest export economy in the world. The country has more than $100 billion export in 2015 with high, $9.003 billion trade surplus, of which 79% went to the EU and 21% was extra-EU trade. Hungary has a more than 80% privately owned economy with 39,1% overall taxation, which provides the basis for the country's welfare economy. On the expenditure side, household consumption is the main component of GDP and accounts for 50 percent of its total use, followed by gross fixed capital formation with 22 percent and government expenditure with 20 percent.\n\nHungary continues to be one of the leading nations for attracting foreign direct investment in Central and Eastern Europe, the inward FDI in the country was $119.8 billion in 2015, while Hungary invests more than $50 billion abroad. , the key trading partners of Hungary were Germany, Austria, Romania, Slovakia, France, Italy, Poland and Czech Republic. Major industries include food processing, pharmaceuticals, motor vehicles, information technology, chemicals, metallurgy, machinery, electrical goods, and tourism (in 2014 Hungary welcomed 12.1 million international tourists).\nHungary is the largest electronics producer in Central and Eastern Europe. Electronics manufacturing and research are among the main drivers of innovation and economic growth in the country. In the past 20 years Hungary has also grown into a major center for mobile technology, information security, and related hardware research.\nThe employment rate in the economy was 65.0% in 2015, the employment structure shows the characteristics of post-industrial economies, 63.2% of employed workforce work in service sector, the industry contributed by 29.7%, while agriculture with 7.1%. Unemployment rate was 6.2% in 2015 December, down from 11% during the financial crisis of 2007–08.\nHungary is part of the European single market which represents more than 508 million consumers. Several domestic commercial policies are determined by agreements among European Union members and by EU legislation. \n\nLarge Hungarian companies are included in the BUX, the Hungarian stock market index listed on Budapest Stock Exchange. Well-known companies include the Fortune Global 500 firm MOL Group, the OTP Bank, Gedeon Richter, Magyar Telekom, CIG Pannonia, FHB Bank, Zwack Unicum and more. Besides this Hungary has a large portion of specialised small and medium enterprise, for example a significant number of automotive suppliers and technology start ups among others.\n\nBudapest is the financial and business capital of Hungary. The capital is a significant economic hub, classified as an Alpha- world city in the study by the Globalization and World Cities Research Network and it is the second fastest-developing urban economy in Europe as GDP per capita in the city increased by 2.4 per cent and employment by 4.7 per cent compared to the previous year in 2014. On the national level, Budapest is the primate city of Hungary regarding business and economy, accounting for 39% of the national income, the city has a gross metropolitan product more than $100 billion in 2015, making it one of the largest regional economies in the European Union. Budapest is also among the Top 100 GDP performing cities in the world, measured by PricewaterhouseCoopers and in a global city competitiveness ranking by EIU, Budapest stands before Tel Aviv, Lisbon, Moscow and Johannesburg among others.\n\nHungary maintains its own currency, the Hungarian forint (HUF), although the economy fulfills the Maastricht criteria with the exception of public debt, but it is also significantly below the EU average with the level of 75.3% in 2015. The Hungarian National Bank—founded in 1924, after the dissolution of Austro-Hungarian Empire—is currently focusing on price stability with an inflation target of 3%.\n\nHungary's achievements in science and technology have been significant, and research and development efforts form an integral part of the country's economy. Hungary has been the home of some of the most prominent researchers in various scientific disciplines, notably physics, mathematics, chemistry and engineering. Scientific research in the country is supported partly by industry and partly by the state, through the network of Hungarian universities and by scientific state-institutions such as Hungarian Academy of Sciences. 13 Hungarian scientists have received the Nobel Prize. Until 2012 three individuals: Csoma, János Bolyai and Tihanyi were included in the UNESCO Memory of the world register as well as the collective contributions: Tabula Hungariae and Bibliotheca Corviniana. Contemporary, internationally well-known Hungarian scientists include: mathematician László Lovász, physicist Albert-László Barabási, physicist Ferenc Krausz, and biochemist Árpád Pusztai.\n\nHungary is famous for its excellent mathematics education which has trained numerous outstanding scientists. Famous Hungarian mathematicians include father Farkas Bolyai and son János Bolyai, who was one of the founders of non-Euclidean geometry; Paul Erdős, famed for publishing in over forty languages and whose Erdős numbers are still tracked, and John von Neumann, a key contributor in the fields of quantum mechanics and game theory, a pioneer of digital computing, and the chief mathematician in the Manhattan Project. Many Hungarian scientists, including Erdős, von Neumann, Leó Szilárd, Eugene Wigner, Rudolf E. Kálmán, and Edward Teller emigrated to the US during the 20th century dictatorships.\n\nHungary has a highly developed road, railway, air and water transport system. Budapest, the capital, serves as an important hub for the Hungarian railway system (\"MÁV\"). The capital is served by three large train stations called \"Keleti\" (Eastern), \"Nyugati\" (Western), and \"Déli\" (Southern) \"pályaudvar\"s. Szolnok is the most important railway hub outside Budapest, while Tiszai Railway Station in Miskolc and the main stations of Pécs, Győr, Szeged, and Székesfehérvár are also key to the network.\n\nBudapest, Debrecen, Miskolc, and Szeged have tram networks. The Budapest Metro is the second-oldest underground metro system in the world; its Line 1 dates from 1896 and is a World Heritage Site. The system consists of four lines. A commuter rail system, \"HÉV\", operates in the Budapest metropolitan area.\nHungary has a total length of approximately motorways (). Motorway sections are being added to the existing network, which already connects many major economically important cities to the capital.\nThe most important port is Budapest. Other important ones include Dunaújváros and Baja.\n\nThere are five international airports in Hungary: Budapest Liszt Ferenc, Debrecen, Sármellék (also called Hévíz-Balaton Airport), Győr-Pér, and Pécs-Pogány. The national carrier, MALÉV, operated flights to over 60, mostly European cities, but ceased operations in 2012. Low-budget airline WizzAir is based in Hungary, at Ferihegy.\n\nHungary's population was 9,937,628 according to the 2011 census, thus the country is the 5th most populous in the Central and Eastern European region and medium-sized member state of the European Union. Population density stands at 107 inhabitants per square kilometre, which is about two times higher than the world average. More than one quarter of the population lived in the Budapest metropolitan area, 6,903,858 people (69.5%) in cities and towns overall. Like most other European countries, Hungary is experiencing sub-replacement fertility, with the total fertility rate estimated at 1.43 children born/woman in 2015, lower than the replacement rate of 2.1. This is leading to gradual population decline and rapid aging. The recent decrease in birth rate occurred in the 1990s; dropping from 1.87 in 1990 to 1.28 in 1999. In 2011, the conservative government began a program to increase the birth rate with a focus on ethnic Magyars by reinstating 3 year maternity leave as well as boosting part time jobs. The birth rate has gradually increased from 1.27 children born/woman in 2011. The natural decrease in the first 10 months of 2016 was only 25,828 which was 8,162 less than the corresponding period in 2015. In 2013, 45.6% of births were to unmarried women. \nLife expectancy was 71.96 years for men and 79.62 years for women in 2015, growing continuously since the fall of Communism. \n\nTwo sizable groups of people are referred to as \"national minorities\" because their ancestors have lived in their respective regions for centuries in Hungary. There is a German minority (about 130,000) live throughout the whole country, and there is a Romani minority (about 300,000) mainly resides in the northern part of the country. According to the 2011 census, there were 8,314,029 (83.7%) Hungarians, 308,957 (3.1%) Romani, 131,951 (1.3%) Germans, 29,647 (0.3%) Slovaks, 26,345 (0.3%) Romanians, and 23,561 (0.2%) Croats in Hungary. 1,455,883 people (14.7% of the total population) did not declare their ethnicity. Thus, Hungarians made up 98.0% of people who declared their ethnicity. In Hungary, people can declare more than one ethnicity, so the sum of ethnicities is higher than the total population.\n\nToday approximately 5 million Hungarians live outside Hungary.\n\nHungarian is the official and predominant spoken language in Hungary. Hungarian is the 13th most widely spoken first language in Europe with around 13 million native speakers and it is one of 24 official and working languages of the European Union. Outside Hungary it is also spoken by communities of Hungarian people in neighbouring countries and by Hungarian diaspora communities worldwide. According to the 2011 census, 9,896,333 people (99.6%) speak Hungarian in Hungary, of whom 9,827,875 people (99%) speak it as a first language, while 68,458 people (0.7%) speak it as a second language. English (1,589,180 speakers, 16.0%), and German (1,111,997 speakers, 11.2%) are the most widely spoken foreign languages, while there are several recognized minority languages in Hungary (Croatian, German, Romanian, Romani, Serbian, Slovak, Slovenian, and Ukrainian).\n\nHungarian (Magyar) is a member of the Uralic language family, unrelated to any neighboring language and distantly related to Finnish and Estonian. It is the largest of the Uralic languages in terms of the number of speakers and the only one spoken in Central Europe. There are sizable populations of Hungarian speakers in Romania, the Czech and Slovak Republics, the former Yugoslavia, Ukraine, Israel, and the U.S. Smaller groups of Hungarian speakers live in Canada, Slovenia, and Austria. Standard Hungarian is based on the variety spoken in the capital of Budapest, although use of the standard dialect is enforced, Hungarian has a number of urban and rural dialects.\n\nHungary is a historically Christian country. Hungarian historiography identifies the foundation of the Hungarian state with Stephen I's baptism and coronation with the Holy Hungarian Crown in A.D. 1000. Stephen promulgated Roman Catholicism as the state religion, and his successors were traditionally known as the Apostolic Kings. The Catholic Church in Hungary remained strong through the centuries, and the Archbishop of Esztergom was granted extraordinary temporal privileges as prince-primate of Hungary. Contemporary Hungary has no official religion, but the constitution \"recognizes Christianity's nation-building role\". Hungary is a secular country, and freedom of religion is a constitutional right.\n\nWith the onset of the Protestant Reformation, most Hungarians took up first Lutheranism, then soon afterwards Calvinism. In the second half of the 16th century, however, Jesuits led a successful campaign of Counterreformation and the country once again became predominantly Catholic. Eastern parts of the country, especially around Debrecen (\"\"the Calvinist Rome\"\"), retained strong Protestant communities. Orthodox Christianity in Hungary is associated with the country's ethnic minorities: Romanians, Rusyns, Ukrainians, and Serbs.\n\nHistorically, Hungary was home to a significant Jewish community. Some Hungarian Jews were able to escape the Holocaust during World War II, but most (perhaps 550,000) either were deported to concentration camps, from which the majority did not return, or were murdered by the Hungarian Arrow Cross fascists.\n\nThe most recent, 2011 census shows that the majority of Hungarians are Christians (52.9%), with Roman Catholics (\"Katolikusok\") (37.1%) and Hungarian Reformed Calvinists (\"Reformátusok\") (11.1%) making up the bulk of these alongside Lutherans (\"Evangélikusok\") (2.2%), Greek Catholics (0.3%), and Jehovah's Witnesses (0.1%). Jewish (0.1%), and Muslim (0.06%) communities are in the minority, although this is complicated by the fact that 27.2% of respondents did not declare their religion while 16.7% declared themselves irreligious, another 1.5% atheist.\n\nAccording to new polls about Religiosity in the European Union in 2012 by Eurobarometer found that Christianity is the largest religion in Hungary accounting 71% of Hungarians. Catholics are the largest Christian group in Hungary, accounting for 58% of Hungary citizens, while Protestants make up 7%, and Other Christian make up 6%. Non-believer/Agnostic account 21%, Atheist account's 1%. In the Eurostat – Eurobarometer poll of 2005, 44% of Hungarians answered that they believed there is a God, 31% answered they believed there is some sort of spirit or life force, and 19% that they do not believe there is a God, spirit, or life force.\n\nEducation in Hungary are predominantly public, run by the Ministry of Education. Preschool kindergarten education is compulsory and provided for all children between three and six years old, after which school attendance is also compulsory until age of sixteen. Primary education usually lasts for eight years. Secondary education includes three traditional types of schools focused on different academic levels: the Gymnasium enrols the most gifted children and prepares students for university studies; the secondary vocational schools for intermediate students lasts four years and the technical school prepares pupils for vocational education and the world of work. The system is partly flexible and bridges exist, graduates from a vocational school can achieve a two years program to have access to vocational higher education for instance. The Trends in International Mathematics and Science Study (TIMSS) rated 13–14-year-old pupils in Hungary among the bests in the world for maths and science.\n\nMost of the Hungarian universities are public institutions, and students traditionally study without fee payment. The general requirement for university is the Matura. The Hungarian public higher education system includes universities and other higher education institutes, that provide both education curricula and related degrees up to doctoral degree and also contribute to research activities. Health insurance for students is free until the end of their studies. English and German language is important in Hungarian higher education, there are a number of degree programs that are taught in these languages, which attracts thousands of exchange students every year. Hungary's higher education and training has been ranked 44 out of 148 countries in the Global competitiveness Report 2014. \n\nHungary has a long tradition of higher education reflecting the existence of established knowledge economy. The established universities in Hungary include some of the oldest in the world, the first was the University of Pécs founded in 1367 which is still functioning, although in the year 1276, the university of Veszprém was destroyed by the troops of Peter Csák, but it was never rebuilt. Sigismund established Óbuda University in 1395. Another, Universitas Istropolitana, was established 1465 in Pozsony by Mattias Corvinus.\nNagyszombat University was founded in 1635 and moved to Buda in 1777 and it is called Eötvös Loránd University today. The world's first institute of technology was founded in Selmecbánya, Kingdom of Hungary in 1735, its legal successor is the University of Miskolc. The Budapest University of Technology and Economics is considered the oldest institute of technology in the world with university rank and structure, its legal predecessor the Institutum Geometrico-Hydrotechnicum was founded in 1782 by Emperor Joseph II.\n\nThe Hungarian health care system is one of universal health care largely financed by government national health insurance. According to the OECD 100% of the total population is covered by universal health insurance, which is absolutely free for children, students, pensioners, people with low income, handicapped people, priests and other church employees. According to the OECD Hungary spent 7.8% of its GDP on health care in 2012. Total health expenditure was 1,688.7 US$ per capita in 2011, 1,098.3 US$ governmental-fund (65%) and 590.4 US$ private-fund (35%).\n\nHungary is one of the main destinations of medical tourism in Europe. The country leads in dental tourism, its share is 42% in Europe and 21% worldwide. Plastic surgery is also a key sector, 30% of the clients come from abroad. Hungary is home to numerous medicinal spas, spa tourism sometimes combined with other treatments. \n\n62,979 deaths (49.4% of all) in Hungary were caused by cardiovascular disease in 2013. Number of cardiovascular disease deaths peaked in 1985 with 79,355, declining continuously since the fall of Communism. The second most important cause of death was cancer with 33,274 (26.2% of all), stagnating since the 1990s. Number of accident deaths dropped from 8,760 in 1990 to 3,654 in 2013, number of suicides from 4,911 in 1983 to 2,093 in 2013 (21.1 per 100,000 people), the lowest data registered since 1956. There are huge differences between the western and eastern parts of Hungary, heart disease, hypertension, stroke and suicide is prevalent in the mostly agricultural and low-income characteristic Great Plain, but infrequent in the high-income and middle class characteristic Western Transdanubia and Central Hungary. Smoking also causes significant losses to Hungarian society. 28% of the adult population smoked in 2012, dropped to 19% in 2013 due to strict regulation. Nationwide smoking bans expanded to every indoor public place, the sale of tobacco is limited to state-controlled tobacco shops called National Tobacco Shop. Homicide rate was 1.3 per 100,000 people, which is among the lowest in the World.\n\nHungary is home to the largest synagogue in Europe (Great Synagogue), built in 1859 in Moorish Revival style with a capacity of 3000 people, the largest medicinal bath in Europe (Széchenyi Medicinal Bath), completed in 1913 in Modern Renaissance Style and located in the City park, the biggest building in Hungary with its length (the Parliament building), one of the largest basilicas in Europe (Esztergom Basilica), the second largest territorial abbey in the world (Pannonhalma Archabbey), and the largest early Christian necropolis outside Italy (Pécs).\n\nNotable architectural styles in Hungary include Historicism and Art Nouveau, or rather several variants of Art Nouveau. In contrast to Historicism, Hungarian Art Nouveau is based on the national architectural characteristics. Taking the eastern origins of the Hungarians into account, Ödön Lechner (1845–1914), the most important figure in Hungarian Art Nouveau, was initially inspired by Indian and Syrian architecture, and later by traditional Hungarian decorative designs. In this way, he created an original synthesis of architectural styles. By applying them to three-dimensional architectural elements, he produced a version of Art Nouveau that was specific to Hungary.\n\nTurning away from the style of Lechner, yet taking inspiration from his approach, the group of \"Young People\" (\"Fiatalok\"), which included Károly Kós and Dezsö Zrumeczky, were to use the characteristic structures and forms of traditional Hungarian architecture to achieve the same end.\n\nBesides the two principal styles, Budapest also displays local versions of trends originating from other European countries. The Sezession from Vienna, the German Jugendstil, Art Nouveau from Belgium and France, and the influence of English and Finnish architecture are all reflected in the buildings constructed at the turn of the 20th century. Béla Lajta initially adopted Lechner's style, subsequently drawing his inspiration from English and Finnish trends; after developing an interest in the Egyptian style, he finally arrived at modern architecture. Aladár Árkay took almost the same route. István Medgyaszay developed his own style, which differed from Lechner's, using stylised traditional motifs to create decorative designs in concrete. In the sphere of applied arts, those chiefly responsible for promoting the spread of Art Nouveau were the School and Museum of Decorative Arts, which opened in 1896.\n\nForeigners have unexpectedly \"discovered\" that a significantly large portion of the citizens live in old and architecturally valuable buildings. In the Budapest downtown area almost all the buildings are about one hundred years old, with thick walls, high ceilings, and motifs on the front wall.\n\nThe music of Hungary consists mainly of traditional Hungarian folk music and music by prominent composers such as Liszt and Bartók, considered to be the greatest Hungarian composers . Other composers of international renown are Dohnányi, Franz Schmidt, Zoltán Kodály, Gabriel von Wayditch, Rudolf Wagner-Régeny, László Lajtha, Franz Lehár, Imre Kálmán, Sándor Veress and Rózsa. Hungarian traditional music tends to have a strong dactylic rhythm, as the language is invariably stressed on the first syllable of each word.\n\nHungary also has a number of internationally renowned composers of contemporary classical music, György Ligeti, György Kurtág, Péter Eötvös, Zoltán Kodály and Zoltán Jeney among them. One of the greatest Hungarian composers, Béla Bartók, was also among the most significant musicians of the 20th century. His music was invigorated by the themes, modes, and rhythmic patterns of the Hungarian and neighboring folk music traditions he studied, which he synthesized with influences from his contemporaries into his own distinctive style .\n\nHungary has made many contributions to the fields of folk, popular and classical music. Hungarian folk music is a prominent part of the national identity and continues to play a major part in Hungarian music. Hungarian folk music has been significant in former country parts that belong – since the 1920 Treaty of Trianon – to neighbouring countries such as Romania, Slovakia, southern Poland and especially in southern Slovakia and Transylvania; both regions have significant numbers of Hungarians.\nAfter the establishment of a music academy led by Ferenc Erkel and Franz Liszt Hungary produced an important number of art musicians:\n\nBroughton claims that Hungary's \"infectious sound has been surprisingly influential on neighboring countries (thanks perhaps to the common Austro-Hungarian history) and it's not uncommon to hear Hungarian-sounding tunes in Romania, Slovakia and southern Poland\". It is also strong in the Szabolcs-Szatmár area and in the southwest part of Transdanubia, near the border with Croatia. The Busójárás carnival in Mohács is a major Hungarian folk music event, formerly featuring the long-established and well-regarded Bogyiszló orchestra.\n\nHungarian classical music has long been an \"experiment, made from Hungarian antedecents and on Hungarian soil, to create a conscious musical culture [using the] musical world of the folk song\". Although the Hungarian upper class has long had cultural and political connections with the rest of Europe, leading to an influx of European musical ideas, the rural peasants maintained their own traditions such that by the end of the 19th century Hungarian composers could draw on rural peasant music to (re)create a Hungarian classical style. For example, Bartók collected folk songs from across Central and Eastern Europe, including Romania and Slovakia, while Kodály was more interested in creating a distinctively Hungarian musical style.\n\nDuring the era of Communist rule in Hungary (1944–1989), a Song Committee scoured and censored popular music for traces of subversion and ideological impurity. Since then, however, the Hungarian music industry has begun to recover, producing successful performers in the fields of jazz such as trumpeter Rudolf Tomsits, pianist-composer Károly Binder and, in a modernized form of Hungarian folk, Ferenc Sebő and Márta Sebestyén. The three giants of Hungarian rock, Illés, Metró and Omega, remain very popular, especially Omega, which has followings in Germany and beyond as well as in Hungary. Older veteran underground bands such as Beatrice, from the 1980s, also remain popular.\n\nIn the earliest times, Hungarian language was written in a runic-like script (although it was not used for literature purposes in the modern interpretation). The country switched to the Latin alphabet after being Christianized under the reign of Stephen I of Hungary (1000–1038).\nThe oldest remained written record in Hungarian language is a fragment in the Establishing charter of the abbey of Tihany (1055) which contains several Hungarian terms, among them the words \"feheruuaru rea meneh hodu utu rea\", \"up the military road to Fehérvár\" The rest of the document was written in Latin.\n\nThe oldest remaining complete text in Hungarian language is the Funeral Sermon and Prayer \"(Halotti beszéd és könyörgés)\" (1192–1195), a translation of a Latin sermon.\nThe oldest remaining poem in Hungarian is the Old Hungarian Laments of Mary \"(Ómagyar Mária-siralom)\", also a (not very strict) translation from Latin, from the 13th century. It is also the oldest surviving Uralic poem.\nAmong the first chronicles about Hungarian history were Gesta Hungarorum (\"Deeds of the Hungarians\") by the unknown author usually called \"Anonymus\", and Gesta Hunnorum et Hungarorum (\"Deeds of the Huns and the Hungarians\") by Simon Kézai. Both are in Latin. These chronicles mix history with legends, so historically they are not always authentic. Another chronicle is the \"Képes krónika\" (Illustrated Chronicle), which was written for Louis the Great.\n\nRenaissance literature flourished under the reign of King Matthias (1458–1490). Janus Pannonius, although he wrote in Latin, counts as one of the most important persons in Hungarian literature, being the only significant Hungarian Humanist poet of the period. The first printing house was also founded during Matthias' reign, by András Hess, in Buda. The first book printed in Hungary was the Chronica Hungarorum.\nThe most important poets of the period was Bálint Balassi (1554–1594) and Miklós Zrínyi (1620–1664).\n\nBalassi's poetry shows Mediaeval influences, his poems can be divided into three sections: love poems, war poems and religious poems. Zrínyi's most significant work, the epic \"Szigeti veszedelem\" (\"Peril of Sziget\", written in 1648/49) is written in a fashion similar to the \"Iliad\", and recounts the heroic Battle of Szigetvár, where his great-grandfather died while defending the castle of Szigetvár.\nAmong the religious literary works the most important is the Bible translation by Gáspár Károli (The second Hungarian Bible translation in the history), the Protestant pastor of Gönc, in 1590. The translation is called the \"Bible of Vizsoly\", after the town where it was first published. (See Bible translations into Hungarian for more details.)\nThe Hungarian enlightenment took place about fifty years after the French enlightenment. The first enlightened writers were Maria Theresia's bodyguards (György Bessenyei, János Batsányi and others). The greatest poets of the time were Mihály Csokonai Vitéz and Dániel Berzsenyi.\nThe greatest figure of the language reform was Ferenc Kazinczy. The Hungarian language became feasible for all type of scientific explanations from this time, and furthermore many new words were coined for describing new inventions.\n\nHungarian literature has recently gained some renown outside the borders of Hungary (mostly through translations into German, French and English). Some modern Hungarian authors have become increasingly popular in Germany and Italy especially Sándor Márai, Péter Esterházy, Péter Nádas and Imre Kertész. The latter is a contemporary Jewish writer who survived the Holocaust and won the Nobel Prize for literature in 2002.\nThe older classics of Hungarian literature and Hungarian poetry have remained almost totally unknown outside Hungary. János Arany, a famous 19th-century Hungarian poet, is still much loved in Hungary (especially his collection of Ballads), among several other \"true classics\" like Sándor Petőfi, the poet of the Revolution of 1848, Endre Ady, Mihály Babits, Dezső Kosztolányi, Attila József and János Pilinszky. Other well-known Hungarian authors are László Krasznahorkai, Ferenc Móra, Géza Gárdonyi, Zsigmond Móricz, Gyula Illyés, Albert Wass, Miklós Szentkuthy and Magda Szabó.\n\nHungarian cuisine is a prominent feature of the Hungarian culture, just like the art of hospitality. Traditional dishes such as the world-famous Goulash (\"gulyás\" stew or \"gulyás\" soup) feature prominently. Dishes are often flavoured with paprika (ground red peppers), a Hungarian innovation. The paprika powder, obtained from a special type of pepper, is one of the most common spices used in typical Hungarian cuisine. The best quality of paprika comes from the city of Kalocsa .\nThick, heavy Hungarian sour cream called \"tejföl\" is often used to soften the dishes' flavour. The famous Hungarian hot river fish soup called Fisherman's soup or \"halászlé\" is usually a rich mixture of several kinds of poached fish.\n\nOther dishes are chicken paprikash, foie gras made of goose liver, \"pörkölt\" stew, \"vadas\", (game stew with vegetable gravy and dumplings), trout with almonds and salty and sweet dumplings, like \"túrós csusza\", (dumplings with fresh quark cheese and thick sour cream). Desserts include the iconic Dobos Cake, strudels (\"rétes\"), filled with apple, cherry, poppy seed or cheese, Gundel pancake, plum dumplings (\"szilvás gombóc\"), \"somlói\" dumplings, dessert soups like chilled sour cherry soup and sweet chestnut puree, \"gesztenyepüré\" (cooked chestnuts mashed with sugar and rum and split into crumbs, topped with whipped cream). \"Perec\" and \"kifli\" are widely popular pastries.\n\nThe \"csárda\" is the most distinctive type of Hungarian inn, an old-style tavern offering traditional cuisine and beverages. \"Borozó\" usually denotes a cozy old-fashioned wine tavern, \"pince\" is a beer or wine cellar and a \"söröző\" is a pub offering draught beer and sometimes meals. The \"bisztró\" is an inexpensive restaurant often with self-service. The \"büfé\" is the cheapest place, although one may have to eat standing at a counter. Pastries, cakes and coffee are served at the confectionery called \"cukrászda\", while an \"eszpresszó\" is a cafeteria.\n\nPálinka: is a fruit brandy, distilled from fruit grown in the orchards situated on the Great Hungarian Plain. It is a spirit native to Hungary and comes in a variety of flavours including apricot (\"barack\") and cherry (\"cseresznye\"). However, plum (\"szilva\") is the most popular flavour. Beer: Beer goes well with many traditional Hungarian dishes. The five main Hungarian brands are: Borsodi, Soproni, Arany Ászok, Kõbányai, and Dreher.\n\nWine: As Hugh Johnson says in \"The History of Wine\", the territory of Hungary is ideal for wine-making. Since the fall of communism there has been a renaissance in Hungarian wine-making. The choice of quality wine is widening from year to year. The country can be divided to six wine regions: North-Transdanubia, Lake Balaton, South-Pannónia, Duna-region or Alföld, Upper-Hungary and Tokaj-Hegyalja.\n\nHungarian wine regions offer a great variety of styles: the main products of the country are elegant and full-bodied dry whites with good acidity, although complex sweet whites (Tokaj), elegant (Eger) and full-bodied robust reds (Villány and Szekszárd). The main varieties are: Olaszrizling, Hárslevelű, Furmint, Pinot gris or Szürkebarát, Chardonnay (whites), Kékfrankos (or Blaufrankisch in German), Kadarka, Portugieser, Zweigelt, Cabernet sauvignon, Cabernet franc and Merlot. The most famous wines from Hungary are Tokaji Aszú and Egri Bikavér .\nTokaji, meaning \"of Tokaj\", or \"from Tokaj\" in Hungarian, is used to label wines from the wine region of Tokaj-Hegyalja. Tokaji wine has received accolades from numerous great writers and composers including Beethoven, Liszt, Schubert and Goethe; Joseph Haydn's favorite wine was a Tokaji . Louis XV and Frederick the Great tried to outdo one another in the excellence of the vintages they stocked when they treated guests like Voltaire to Tokaji. Napoleon III, the last Emperor of France, ordered 30–40 barrels of Tokaji for the Court every year . Gustav III never had any other wine to drink . In Russia, customers included Peter the Great and Empress Elizabeth of Russia .\n\nFor over 150 years, a blend of 40 Hungarian herbs has been used to create the liqueur Unicum. Unicum is a bitter, dark-coloured liqueur that can be drunk as an apéritif or after a meal, thus helping the digestion.\n\nHungary is a land of thermal water. A passion for spa culture and Hungarian history have been connected from the very beginning. Hungarian spas feature Roman, Greek, Turkish, and northern country architectural elements.\n\nBecause of an advantageous geographical location, good quality thermal water can be found in great quantities on over 80% of Hungary's territory. Approximately 1,500 thermal springs can be found in Hungary (more than 100 just in the Capital area). There are approximately 450 public baths in Hungary.\n\nThe Romans heralded the first age of spas in Hungary. The remains of their bath complexes are still to be seen in Óbuda. Spa culture was revived during the Turkish Invasion and the thermal springs of Buda were used for the construction of a number of bathhouses, some of which such as (Király Baths, Rudas Baths) are still functioning.\n\nIn the 19th century, the advancement in deep drilling and medical science provided the springboard for a further leap in bathing culture. Grand spas such as Gellért Baths, Lukács Baths, Margaret Island, and Széchenyi Medicinal Bath are a reflection of this resurgence in popularity. The Széchenyi Thermal Bath is the largest spa complex in Europe and it was the first thermal bath built in the Pest side of Budapest . This building is a noted example of modern Renaissance Style. Located on the Buda side of Budapest, the Gellért spa is the most famous and luxurious thermal complex of the capital city.\n\nUgrós (Jumping dances): Old style dances dating back to the Middle Ages.\nSolo or couple dances accompanied by old style music, shepherd and other solo man's dances from Transylvania, and marching dances along with remnants of medieval weapon dances belong in this group.\n\nKarikázó: a circle dance performed by women only accompanied by singing of folksongs.\n\nCsárdás: New style dances developed in the 18–19th centuries is the Hungarian name for the national dances, with Hungarian embroidered costumes and energetic music. From the men's intricate bootslapping dances to the ancient women's circle dances, Csárdás demonstrates the infectious exuberance of the Hungarian folk dancing still celebrated in the villages.\n\nVerbunkos: a solo man's dance evolved from the recruiting performances of the Austro-Hungarian army.\n\nThe Legényes is a men's solo dance done by the ethnic Hungarian people living in the Kalotaszeg region of Transylvania. Although usually danced by young men, it can be also danced by older men. The dance is generally performed freestyle by one dancer at a time in front of a band. Women participate in the dance by standing in lines to the side, and singing or shouting verses while the men dance. Each man performs a number of points (dance phrases), typically four to eight without repetition. Each point consists of four parts, each lasting four counts. The first part is usually the same for everyone (there are only a few variations).\n\nIt was in the beginning of the 18th-century that the present style of Hungarian folk art took shape, incorporating both Renaissance and Baroque elements, depending on the area, as well as Persian Sassanide influences. Flowers and leaves, sometimes a bird or a spiral ornament, are the principal decorative themes. The most frequent ornament is a flower with a centerpiece resembling the eye of a peacock's feather.\n\nNearly all the manifestations of folk art practiced elsewhere in Europe also flourished among the Magyar peasantry at one time or another, their ceramics and textile being the most highly developed of all.\n\nThe finest achievements in their textile arts are the embroideries which vary from region to region. Those of Kalotaszeg in Transylvania are charming products of Oriental design, sewn chiefly in a single color – red, blue, or black. Soft in line, the embroideries are applied on altar cloths, pillow-cases and sheets.\n\nIn Hungary proper, Sárköz in Transdanubia and the Matyóföld in the Great Hungarian Plain produce the finest embroideries. In the Sárköz region the women's caps show black and white designs as delicate as lace, and give evidence of the people's wonderfully subtle artistic feeling. The embroidery motifs applied to women's wear have also been transposed to tablecloths and runners suitable for modern use as wall decorations.\n\nThese vessels, made of black clay, reflect more than three hundred years of traditional Transdanubian folk patterns and shapes. No two are precisely alike, since all work is done by hand, including both the shaping and the decorating. The imprints are made by the thumb or a finger of the ceramist who makes the piece.\n\nFounded in 1826, Herend Porcelain is one of the world's largest ceramic factories, specializing in luxury hand painted and gilded porcelain. In the mid-19th century it was purveyor to the Habsburg Dynasty and aristocratic customers throughout Europe. Many of its classic patterns are still in production. After the fall of communism in Hungary the factory was privatised and is now 75% owned by its management and workers, exporting to over 60 countries of the world.\n\nZsolnay Porcelain Manufacture is a Hungarian manufacturer of porcelain, pottery, ceramics, tiles and stoneware. The company introduced the eosin glazing process and pyrogranite ceramics.\nThe Zsolnay factory was established by Miklós Zsolnay in Pécs, Hungary, to produce stoneware and ceramics in 1853. In 1863, his son, Vilmos Zsolnay (1828–1900) joined the company and became its manager and director after several years. He led the factory to worldwide recognition by demonstrating its innovative products at world fairs and international exhibitions, including the 1873 World Fair in Vienna, then at the 1878 World Fair in Paris, where Zsolnay received a Grand Prix.\n\nHungarian athletes have been successful contenders in the Olympic Games, only seven countries have won more Olympic medals than Hungary, with a total of 497 medals ranking eighth in an all-time Olympic Games medal count. Hungary has the third-highest number of Olympic medals per capita and second-highest number of gold medals per capita in the world. Hungary has historically excelled in Olympic water sports. In water polo the Hungarian team is the leading medal winner by a significant margin and in swimming Hungarian men are fourth most successful overall, while the women are eighth most successful overall. They have also seen success in canoeing and kayaking they are the third most successful overall.\n\nIn 2015 the Assembly of the Hungarian Olympic Committee and the Assembly of Budapest decided to bid for the 2024 Summer Olympics. Budapest has lost several bids to host the games, in 1916, 1920, 1936, 1944, and 1960 to Berlin, Antwerp, London, and Rome, respectively. The Hungarian Parliament also voted to support the bid on 28 January 2016, later Budapest City Council approved list of venues and Budapest became an official candidate for the 2024 Summer Olympic Games.\n\nHungary hosted many global sport event in the past, among others the 1997 World Amateur Boxing Championships, 2000 World Fencing Championships, 2001 World Allround Speed Skating Championships, 2008 World Interuniversity Games, 2008 World Modern Pentathlon Championships, 2010 ITU World Championship Series, 2011 IIHF World Championship, 2013 World Fencing Championships, 2013 World Wrestling Championships, 2014 World Masters Athletics Championships and will in the future, like 2017 World Aquatics Championships, 2017 World Judo Championships, only in the last two decade. Besides these, Hungary was the home of many European-level tournaments, like 2006 European Aquatics Championships, 2010 European Aquatics Championships, 2013 European Judo Championships, 2013 European Karate Championships and will be the host of 4 matches in the UEFA Euro 2020, which will be held in the 67,889-seat new multi-purpose Puskás Ferenc Stadium.\n\nThe Hungarian Grand Prix in Formula One has been held at the Hungaroring just outside Budapest, which circuit has FIA Grade 1 license. Since 1986, the race has been a round of the FIA Formula One World Championship. At the 2013 Hungarian Grand Prix, it was confirmed that Hungary will continue to host a Formula 1 race until 2021. The track was completely resurfaced for the first time in early 2016, and it was announced the Grand Prix's deal was extended for a further 5 years, until 2026.\n\nChess is also a popular and successful sport in Hungary, the Hungarian players are the 10th most powerful overall on the ranking of World Chess Federation. There are about 54 Grandmasters and 118 International Masters in Hungary, which is more than in France or United Kingdom. World top junior player is the Hungarian Richárd Rapport currently on the FIDE World Rankings, while Judit Polgár generally considered the strongest female chess player of all time. Some of the world's best sabre athletes have historically also hailed from Hungary, and in 2009, the Hungarian national ice hockey team qualified for their first IIHF World Championship, in 2015, they qualified for their second World Championship in the top division.\n\nHungary has won three Olympic football titles, finished runners-up in the 1938 and 1954 FIFA World Cups, and third in the 1964 UEFA European Football Championship. Hungary revolutionized the sport in the 1950s, laying the tactical fundamentals of total football and dominating international football with the \"Aranycsapat\" (\"Golden Team\"), which included Ferenc Puskás, top goalscorer of the 20th century, to whom FIFA dedicated its newest award, the Puskás Award. The side of that era has the second all-time highest Football Elo Ranking in the world, with 2166, and one of the longest undefeated runs in football history, remaining unbeaten in 31 games spanning more than four years.\n\nThe post-golden age decades saw a gradually weakening Hungary, though recently there is renewal in all aspects. The Hungarian Children's Football Federation was founded in 2008, as youth development thrives. For the first time in Hungarian football's history, they hosted the 2010 UEFA Futsal Championship in Budapest and Debrecen, the first time the MLSZ staged a UEFA finals tournament. Also, the national teams have produced some surprise successes such as beating Euro 2004 winner Greece 3–2 and 2006 FIFA World Cup winner Italy 3–1. On the latest UEFA Euro 2016 Hungary wins the Group F and farewell in the quarterfinals.\n", "id": "13275", "title": "Hungary"}
{"url": "https://en.wikipedia.org/wiki?curid=13276", "text": "Historiography\n\nHistoriography is the study of the methodology of historians in developing history as an academic discipline, and by extension is any body of historical work on a particular subject. The historiography of a specific topic covers how historians have studied that topic using particular sources, techniques, and theoretical approaches. Scholars discuss historiography by topic – such as the \"Historiography of the United Kingdom\", the \"Historiography of Canada\", \"Historiography of the British Empire\", the \"historiography of early Islam\", the \"historiography of China\" – and different approaches and genres, such as political history and social history. Beginning in the nineteenth century, with the ascent of academic history, there developed a body of historiographic literature. The extent to which historians are influenced by their own groups and loyalties – such as to their nation state – is a debated question.\n\nThe research interests of historians change over time, and there has been a shift away from traditional diplomatic, economic, and political history toward newer approaches, especially social and cultural studies. From 1975 to 1995, the proportion of professors of history in American universities identifying with social history increased from 31 to 41 percent, while the proportion of political historians decreased from 40 to 30 percent. In 2007, of 5,723 faculty in the departments of history at British universities, 1,644 (29%) identified themselves with social history and 1,425 (25%) identified themselves with political history.\n\nIn the early modern period, the term \"historiography\" meant \"the writing of history\", and \"historiographer\" meant \"historian\". In that sense certain official historians were given the title \"Historiographer Royal\": in Sweden (from 1618), England (from 1660), and Scotland (from 1681). The Scottish post is still in existence.\n\nHistoriography was more recently defined as \"the study of the way history has been and is written – the history of historical writing... When you study 'historiography' you do not study the events of the past directly, but the changing interpretations of those events in the works of individual historians.\"\n\nUnderstanding the past appears to be a universal human need, and the telling of history has emerged independently in civilisations around the world. What constitutes history is a philosophical question (see philosophy of history). The earliest chronologies date back to Mesopotamia and ancient Egypt, though no historical writers in these early civilizations were known by name. For the purposes of this article, history is taken to mean written history recorded in a narrative format for the purpose of informing future generations about events. Before writing, there was only oral history or oral tradition.\n\nIn China, the earliest history was recorded in oracle bone script which was deciphered and may date back to around late 2nd millennium BCE. The \"Zuo Zhuan\", attributed to Zuo Qiuming in the , is the earliest written of narrative history in the world and covers the period from . The \"Classic of History\" is one of the Five Classics of Chinese classic texts and one of the earliest narratives of China. The \"Spring and Autumn Annals\", the official chronicle of the State of Lu covering the period from , is among the earliest surviving historical texts to be arranged on annalistic principles in the world. It is traditionally attributed to Confucius(551–479 BCE). \"Zhan Guo Ce\" was a renowned ancient Chinese historical compilation of sporadic materials on the Warring States period compiled between the .\n\nSima Qian (around ) was the first in China to lay the groundwork for professional historical writing. His written work was the \"Shiji\" (\"Records of the Grand Historian\"), a monumental lifelong achievement in literature. Its scope extends as far back as the , and it includes many treatises on specific subjects and individual biographies of prominent people, and also explores the lives and deeds of commoners, both contemporary and those of previous eras. His work influenced every subsequent author of history in China, including the prestigious Ban family of the Eastern Han Dynasty era.\n\nTraditional Chinese historiography describes history in terms of dynastic cycles. In this view, each new dynasty is founded by a morally righteous founder. Over time, the dynasty becomes morally corrupt and dissolute. Eventually, the dynasty becomes so weak as to allow its replacement by a new dynasty.\n\nThe tradition of Korean historiography was established with the \"Samguk Sagi\", a history of Korea from its allegedly earliest times. It was compiled by Goryeo court historian Kim Busik after its commission by King Injong of Goryeo (r. 1122 - 1146). It was completed in 1145 and relied not only on earlier Chinese histories for source material, but also on the \"Hwarang Segi\" written by the Silla historian Kim Daemun in the 8th century. The latter work is now lost.\n\nThe earliest works of history produced in Japan were the \"Rikkokushi\", a corpus of six national histories covering the history of Japan from its mythological beginnings until the 9th century. The first of these works were the \"Nihon Shoki\", compiled by Prince Toneri in 720.\n\nThe earliest known systematic historical thought emerged in ancient Greece, a development which would be an important influence on the writing of history elsewhere around the Mediterranean region. Greek historians greatly contributed to the development of historical methodology. The earliest known critical historical works were \"The Histories\", composed by Herodotus of Halicarnassus (484–425 BCE) who became known as the \"father of history\". Herodotus attempted to distinguish between more and less reliable accounts, and personally conducted research by travelling extensively, giving written accounts of various Mediterranean cultures. Although Herodotus' overall emphasis lay on the actions and characters of men, he also attributed an important role to divinity in the determination of historical events.\n\nThe generation following Herodotus witnessed a spate of local histories of the individual city-states (\"poleis\"), written by the first of the local historians who employed the written archives of city and sanctuary. Dionysius of Halicarnassus characterized these historians as the forerunners of Thucydides, and these local histories continued to be written into Late Antiquity, as long as the city-states survived. Two early figures stand out: Hippias of Elis, who produced the lists of winners in the Olympic Games that provided the basic chronological framework as long as the pagan classical tradition lasted, and Hellanicus of Lesbos, who compiled more than two dozen histories from civic records, all of them now lost.\n\nThucydides largely eliminated divine causality in his account of the war between Athens and Sparta, establishing a rationalistic element which set a precedent for subsequent Western historical writings. He was also the first to distinguish between cause and immediate origins of an event, while his successor Xenophon ( – ) introduced autobiographical elements and character studies in his Anabasis.\n\nThe proverbial Philippic attacks of the Athenian orator Demosthenes () on Philip II of Macedon marked the height of ancient political agitation. The now lost history of Alexander's campaigns by the diadoch Ptolemy I () may represent the first historical work composed by a ruler. Polybius ( – ) wrote on the rise of Rome to world prominence, and attempted to harmonize the Greek and Roman points of view.\n\nThe Chaldean priest Berossus () composed a Greek-language \"History of Babylonia\" for the Seleucid king Antiochus I, combining Hellenistic methods of historiography and Mesopotamian accounts to form a unique composite. Reports exist of other near-eastern histories, such as that of the Phoenician historian Sanchuniathon; but he is considered semi-legendary and writings attributed to him are fragmentary, known only through the later historians Philo of Byblos and Eusebius, who asserted that he wrote before even the Trojan war.\n\nThe Romans adopted the Greek tradition, writing at first in Greek, but eventually chronicling their history in a freshly non-Greek language. While early Roman works were still written in Greek, the \"Origines\", composed by the Roman statesman Cato the Elder (), was written in Latin, in a conscious effort to counteract Greek cultural influence. It marked the beginning of Latin historical writings. Hailed for its lucid style, Julius Caesar's () \"de Bello Gallico\" exemplifies autobiographical war coverage. The politician and orator Cicero () introduced rhetorical elements in his political writings.\n\nStrabo ( – ) was an important exponent of the Greco-Roman tradition of combining geography with history, presenting a descriptive history of peoples and places known to his era. Livy ( – ) records the rise of Rome from city-state to empire. His speculation about what would have happened if Alexander the Great had marched against Rome represents the first known instance of alternate history.\n\nBiography, although popular throughout antiquity, was introduced as a branch of history by the works of Plutarch ( – ) and Suetonius ( – after ) who described the deeds and characters of ancient personalities, stressing their human side. Tacitus () denounces Roman immorality by praising German virtues, elaborating on the topos of the Noble savage.\n\nChristian historiography began early, perhaps as early as Luke-Acts, which is the primary source for the Apostolic Age, though its historical reliability is disputed. In the first Christian centuries, the New Testament canon was developed. The growth of Christianity and its enhanced status in the Roman Empire after Constantine I (see State church of the Roman Empire) led to the development of a distinct Christian historiography, influenced by both Christian theology and the nature of the Christian Bible, encompassing new areas of study and views of history. The central role of the Bible in Christianity is reflected in the preference of Christian historians for written sources, compared to the classical historians' preference for oral sources and is also reflected in the inclusion of politically unimportant people. Christian historians also focused on development of religion and society. This can be seen in the extensive inclusion of written sources in the \"Ecclesiastical History\" written by Eusebius of Caesarea around 324 and in the subjects it covers. Christian theology considered time as linear, progressing according to divine plan. As God's plan encompassed everyone, Christian histories in this period had a universal approach. For example, Christian writers often included summaries of important historical events prior to the period covered by the work.\n\nWriting history was popular among Christian monks and clergy in the Middle Ages. They wrote about the history of Jesus Christ, that of the Church and that of their patrons, the dynastic history of the local rulers. In the Early Middle Ages historical writing often took the form of annals or chronicles recording events year by year, but this style tended to hamper the analysis of events and causes. An example of this type of writing is the Anglo-Saxon Chronicles, which were the work of several different writers: it was started during the reign of Alfred the Great in the late 9th century, but one copy was still being updated in 1154. Some writers in the period did construct a more narrative form of history. These included Gregory of Tours, and more successfully Bede who wrote both secular and ecclesiastical history and is known for writing the \"Ecclesiastical History of the English People\".\n\nDuring the Renaissance, history was written about states or nations. The study of history changed during the Enlightenment and Romanticism. Voltaire described the history of certain ages that he considered important, rather than describing events in chronological order. History became an independent discipline. It was not called \"philosophia historiae\" anymore, but merely history (\"historia\").\n\nMuslim historical writings first began to develop in the 7th century, with the reconstruction of the Prophet Muhammad's life in the centuries following his death. With numerous conflicting narratives regarding Muhammad and his companions from various sources, it was necessary to verify which sources were more reliable. In order to evaluate these sources, various methodologies were developed, such as the \"science of biography\", \"science of hadith\" and \"Isnad\" (chain of transmission). These methodologies were later applied to other historical figures in the Islamic civilization. Famous historians in this tradition include Urwah (d. 712), Wahb ibn Munabbih (d. 728), Ibn Ishaq (d. 761), al-Waqidi (745–822), Ibn Hisham (d. 834), Muhammad al-Bukhari (810–870) and Ibn Hajar (1372–1449). Historians of the medieval Islamic world also developed an interest in world history.\n\nIslamic historical writing eventually culminated in the works of the Arab Muslim historian Ibn Khaldun (1332–1406), who published his historiographical studies in the \"Muqaddimah\" (translated as \"Prolegomena\") and \"Kitab al-I'bar\" (\"Book of Advice\"). His work was forgotten until it was rediscovered in the late 19th century.\n\nDuring the Age of Enlightenment, the modern development of historiography through the application of scrupulous methods began.\n\nFrench \"philosophe\" Voltaire (1694–1778) had an enormous influence on the development of historiography during the Age of Enlightenment through his demonstration of fresh new ways to look at the past. Guillaume de Syon argues:\n\nVoltaire's best-known histories are \"The Age of Louis XIV\" (1751), and his \"Essay on the Customs and the Spirit of the Nations\" (1756). He broke from the tradition of narrating diplomatic and military events, and emphasized customs, social history and achievements in the arts and sciences. He was the first scholar to make a serious attempt to write the history of the world, eliminating theological frameworks, and emphasizing economics, culture and political history. Although he repeatedly warned against political bias on the part of the historian, he did not miss many opportunities to expose the intolerance and frauds of the church over the ages. Voltaire advised scholars that anything contradicting the normal course of nature was not to be believed. Although he found evil in the historical record, he fervently believed reason and educating the illiterate masses would lead to progress.\n\nVoltaire explains his view of historiography in his article on \"History\" in Diderot's \"Encyclopédie\": \"\"One demands of modern historians more details, better ascertained facts, precise dates, more attention to customs, laws, mores, commerce, finance, agriculture, population.\"\" \"My chief object,\" he wrote in 1739, \"is not political or military history, it is the history of the arts, of commerce, of civilization – in a word, – of the human mind.\" Voltaire's histories used the values of the Enlightenment to evaluate the past. He helped free historiography from antiquarianism, Eurocentrism, religious intolerance and a concentration on great men, diplomacy, and warfare. Peter Gay says Voltaire wrote \"very good history\", citing his \"scrupulous concern for truths\", \"careful sifting of evidence\", \"intelligent selection of what is important\", \"keen sense of drama\", and \"grasp of the fact that a whole civilization is a unit of study.\"\n\nAt the same time, philosopher David Hume was having a similar effect on the study of history in Great Britain. In 1754 he published the \"History of England\", a 6-volume work which extended \"From the Invasion of Julius Caesar to the Revolution in 1688\". Hume adopted a similar scope to Voltaire in his history; as well as the history of Kings, Parliaments, and armies, he examined the history of culture, including literature and science, as well. His short biographies of leading scientists explored the process of scientific change and he developed new ways of seeing scientists in the context of their times by looking at how they interacted with society and each other – he paid special attention to Francis Bacon, Robert Boyle, Isaac Newton and William Harvey.\n\nHe also argued that the quest for liberty was the highest standard for judging the past, and concluded that after considerable fluctuation, England at the time of his writing had achieved \"the most entire system of liberty, that was ever known amongst mankind.\"\n\nThe apex of Enlightenment history was reached with Edward Gibbon's monumental six-volume work, \"The History of the Decline and Fall of the Roman Empire\", published on 17 February 1776. Because of its relative objectivity and heavy use of primary sources, its methodology became a model for later historians. This has led to Gibbon being called the first \"modern historian\". The book sold impressively, earning its author a total of about £9000. Biographer Leslie Stephen wrote that thereafter, \"His fame was as rapid as it has been lasting.\"\n\nGibbon's work has been praised for its style, its piquant epigrams and its effective irony. Winston Churchill memorably noted, \"I set out upon...Gibbon's \"Decline and Fall of the Roman Empire\" [and] was immediately dominated both by the story and the style... I devoured Gibbon. I rode triumphantly through it from end to end and enjoyed it all.\" Gibbon was pivotal in the secularizing and 'desanctifying' of history, remarking, for example, on the \"want of truth and common sense\" of biographies composed by Saint Jerome. Unusually for an 18th-century historian, Gibbon was never content with secondhand accounts when the primary sources were accessible (though most of these were drawn from well-known printed editions). \"I have always endeavoured,\" he says, \"to draw from the fountain-head; that my curiosity, as well as a sense of duty, has always urged me to study the originals; and that, if they have sometimes eluded my search, I have carefully marked the secondary evidence, on whose faith a passage or a fact were reduced to depend.\" In this insistence upon the importance of primary sources, Gibbon broke new ground in the methodical study of history:\n\nIn accuracy, thoroughness, lucidity, and comprehensive grasp of a vast subject, the 'History' is unsurpassable. It is the one English history which may be regarded as definitive... Whatever its shortcomings the book is artistically imposing as well as historically unimpeachable as a vast panorama of a great period.\n\nThe tumultuous events surrounding the French Revolution inspired much of the historiography and analysis of the early 19th century. Interest in the 1688 Glorious Revolution was also rekindled by the Great Reform Act of 1832 in England.\n\nThomas Carlyle published his three-volume \"\", in 1837. The first volume was accidentally burned by John Stuart Mill's maid. Carlyle rewrote it from scratch. Carlyle's style of historical writing stressed the immediacy of action, often using the present tense. He emphasised the role of forces of the spirit in history and thought that chaotic events demanded what he called 'heroes' to take control over the competing forces erupting within society. He considered the dynamic forces of history as being the hopes and aspirations of people that took the form of ideas, and were often ossified into ideologies. Carlyle's \"The French Revolution\" was written in a highly unorthodox style, far removed from the neutral and detached tone of the tradition of Gibbon. Carlyle presented the history as dramatic events unfolding in the present as though he and the reader were participants on the streets of Paris at the famous events. Carlyle's invented style was epic poetry combined with philosophical treatise. It is rarely read or cited in the last century.\n\nIn his main work \"Histoire de France\" (1855), French historian Jules Michelet (1798-1874) coined the term Renaissance (meaning \"rebirth\" in French), as a period in Europe's cultural history that represented a break from the Middle Ages, creating a modern understanding of humanity and its place in the world. The 19-volume work covered French history from Charlemagne to the outbreak of the French Revolution. His inquiry into manuscript and printed authorities was most laborious, but his lively imagination, and his strong religious and political prejudices, made him regard all things from a singularly personal point of view.\n\nMichelet was one of the first historians to shift the emphasis of history to the common people, rather than the leaders and institutions of the country. He had a decisive impact on scholars. Gayana Jurkevich argues that led by Michelet:\n\nHippolyte Taine (1828-1893) was the chief theoretical influence of French naturalism, a major proponent of sociological positivism, and one of the first practitioners of historicist criticism, who was unable to secure an academic position. He pioneered the idea of \"the milieu\" as an active historical force which amalgamated geographical, psychological, and social factors. Historical writing for him was a search for general laws. His brilliant style kept his writing in circulation long after his theoretical approaches were passé.\n\nOne of the major progenitors of the history of culture and art, was the Swiss historian Jacob Burckhardt Siegfried Giedion described Burckhardt's achievement in the following terms: \"The great discoverer of the age of the Renaissance, he first showed how a period should be treated in its entirety, with regard not only for its painting, sculpture and architecture, but for the social institutions of its daily life as well.\" Burckhardt's best known work is \"The Civilization of the Renaissance in Italy\" (1860).\n\nHis most famous work was \"The Civilization of the Renaissance in Italy\", published in 1860; it was the most influential interpretation of the Italian Renaissance in the nineteenth century and is still widely read. According to John Lukacs, he was the first master of cultural history, which seeks to describe the spirit and the forms of expression of a particular age, a particular people, or a particular place. His innovative approach to historical research stressed the importance of art and its inestimable value as a primary source for the study of history. He was one of the first historians to rise above the narrow nineteenth-century notion that \"history is past politics and politics current history.\n\nBy the mid-19th century, scholars were beginning to analyse the history of institutional change, particularly the development of constitutional government. William Stubbs's \"Constitutional History of England\" (3 vols., 1874–78) was an important influence on this developing field. The work traced the development of the English constitution from the Teutonic invasions of Britain until 1485, and marked a distinct step in the advance of English historical learning. He argued that the theory of the unity and continuity of history should not remove distinctions between ancient and modern history. He believed that, though work on ancient history is a useful preparation for the study of modern history, either may advantageously be studied apart. He was a good palaeographer, and excelled in textual criticism, in examination of authorship, and other such matters, while his vast erudition and retentive memory made him second to none in interpretation and exposition.\n\nThe modern academic study of history and methods of historiography were pioneered in 19th-century German universities, especially the University of Göttingen. Leopold von Ranke (1795–1886) at Berlin was a pivotal influence in this regard, and was the founder of modern source-based history. According to Caroline Hoefferle, \"Ranke was probably the most important historian to shape historical profession as it emerged in Europe and the United States in the late 19th century.\"\n\nSpecifically, he implemented the seminar teaching method in his classroom, and focused on archival research and analysis of historical documents. Beginning with his first book in 1824, the \"History of the Latin and Teutonic Peoples from 1494 to 1514\", Ranke used an unusually wide variety of sources for a historian of the age, including \"memoirs, diaries, personal and formal missives, government documents, diplomatic dispatches and first-hand accounts of eye-witnesses\". Over a career that spanned much of the century, Ranke set the standards for much of later historical writing, introducing such ideas as reliance on primary sources, an emphasis on narrative history and especially international politics (\"aussenpolitik\"). Sources had to be solid, not speculations and rationalizations. His credo was to write history the way it was. He insisted on primary sources with proven authenticity.\nRanke also rejected the 'teleological approach' to history, which traditionally viewed each period as inferior to the period which follows. In Ranke's view, the historian had to understand a period on its own terms, and seek to find only the general ideas which animated every period of history. In 1831 and at the behest of the Prussian government, Ranke founded and edited the first historical journal in the world, called \"Historisch-Politische Zeitschrift\".\n\nAnother important German thinker was Georg Wilhelm Friedrich Hegel, whose theory of historical progress ran counter to Ranke's approach. In Hegel's own words, his philosophical theory of \"World history... represents the development of the spirit's consciousness of its own freedom and of the consequent realization of this freedom.\". This realization is seen by studying the various cultures that have developed over the millennia, and trying to understand the way that freedom has worked itself out through them:\n\nWorld history is the record of the spirit's efforts to attain knowledge of what it is in itself. The Orientals do not know that the spirit or man as such are free in themselves. And because they do not know that, they are not themselves free. They only know that One is free... The consciousness of freedom first awoke among the Greeks, and they were accordingly free; but, like the Romans, they only knew that Some, and not all men as such, are free... The Germanic nations, with the rise of Christianity, were the first to realize that All men are by nature free, and that freedom of spirit is his very essence.\nKarl Marx introduced the concept of historical materialism into the study of world historical development. In his conception, the economic conditions and dominant modes of production determined the structure of society at that point. In his view five successive stages in the development of material conditions would occur in Western Europe. The first stage was primitive communism where property was shared and there was no concept of \"leadership\". This progressed to a slave society where the idea of class emerged and the State developed. Feudalism was characterized by an aristocracy working in partnership with a theocracy and the emergence of the Nation-state. Capitalism appeared after the bourgeois revolution when the capitalists (or their merchant predecessors) overthrew the feudal system and established a market economy, with\nprivate property and Parliamentary democracy. Marx then predicted the eventual proletarian revolution that would result in the attainment of socialism, followed by Communism, where property would be communally owned.\n\nPrevious historians had focused on cyclical events of the rise and decline of rulers and nations. Process of nationalization of history, as part of national revivals in the 19th century, resulted with separation of \"one's own\" history from common universal history by such way of perceiving, understanding and treating the past that constructed history as history of a nation. A new discipline, sociology, emerged in the late 19th century and analyzed and compared these perspectives on a larger scale.\n\nThomas Macaulay produced his most famous work of history, \"The History of England from the Accession of James the Second\", in 1848. His writings are famous for their ringing prose and for their confident, sometimes dogmatic, emphasis on a progressive model of British history, according to which the country threw off superstition, autocracy and confusion to create a balanced constitution and a forward-looking culture combined with freedom of belief and expression. This model of human progress has been called the Whig interpretation of history.\n\nHis legacy continues to be controversial; Gertrude Himmelfarb wrote that \"most professional historians have long since given up reading Macaulay, as they have given up writing the kind of history he wrote and thinking about history as he did.\" However, J. R. Western wrote that: \"Despite its age and blemishes, Macaulay's \"History of England\" has still to be superseded by a full-scale modern history of the period\".\n\nThe term Whig history, coined by Herbert Butterfield in his short book \"The Whig Interpretation of History\" in 1931, means the approach to historiography which presents the past as an inevitable progression towards ever greater liberty and enlightenment, culminating in modern forms of liberal democracy and constitutional monarchy. In general, Whig historians emphasized the rise of constitutional government, personal freedoms and scientific progress. The term has been also applied widely in historical disciplines outside of British history (the history of science, for example) to criticize any teleological (or goal-directed), hero-based, and transhistorical narrative.\n\nPaul Rapin de Thoyras's history of England, published in 1723, became \"the classic Whig history\" for the first half of the 18th century. It was later supplanted by the immensely popular \"The History of England\" by David Hume. Whig historians emphasized the achievements of the Glorious Revolution of 1688. This included James Mackintosh's \"History of the Revolution in England in 1688\", William Blackstone's \"Commentaries on the Laws of England\" and Henry Hallam's \"Constitutional History of England\".\n\nThe most famous exponent of 'Whiggery' was Thomas Babington Macaulay, who published the first volumes of his \"The History of England from the Accession of James II\" in 1848. It proved an immediate success and replaced Hume's history to become the new orthodoxy. His 'Whiggish convictions' are spelled out in his first chapter:\n\nThis consensus was steadily undermined during the post-World War I re-evaluation of European history, and Butterfield's critique exemplified this trend. Intellectuals no longer believed the world was automatically getting better and better. Subsequent generations of academic historians have similarly rejected Whig history because of its presentist and teleological assumption that history is driving toward some sort of goal. Other criticized 'Whig' assumptions included viewing the British system as the apex of human political development, assuming that political figures in the past held current political beliefs (anachronism), considering British history as a march of progress with inevitable outcomes and presenting political figures of the past as heroes, who advanced the cause of this political progress, or villains, who sought to hinder its inevitable triumph. J. Hart says \"a Whig interpretation requires human heroes and villains in the story.\"\n\n20th century historiography in major countries is characterized by a move to universities and academic research centers. Popular history continued to be written by self-educated amateurs, but scholarly history increasingly became the province of PhD's trained in research seminars at a university. The training emphasized working with primary sources in archives. Seminars taught graduate students how to review the historiography of the topics, so that they could understand the conceptual frameworks currently in use, and the criticisms regarding their strengths and weaknesses. Western Europe and the United States took leading roles in this development. The emergence of area studies of other regions also developed historiographical practices.\n\nThe French Annales School radically changed the focus of historical research in France during the 20th century by stressing long-term social history, rather than political or diplomatic themes. The school emphasized the use of quantification and the paying of special attention to geography.\nThe \"Annales d'histoire économique et sociale\" journal was founded in 1929 in Strasbourg by Marc Bloch and Lucien Febvre. These authors, the former a medieval historian and the latter an early modernist, quickly became associated with the distinctive \"Annales\" approach, which combined geography, history, and the sociological approaches of the Année Sociologique (many members of which were their colleagues at Strasbourg) to produce an approach which rejected the predominant emphasis on politics, diplomacy and war of many 19th and early 20th-century historians as spearheaded by historians whom Febvre called Les Sorbonnistes. Instead, they pioneered an approach to a study of long-term historical structures (\"la longue durée\") over events and political transformations. Geography, material culture, and what later Annalistes called \"mentalités\", or the psychology of the epoch, are also characteristic areas of study. The goal of the Annales was to undo the work of the Sorbonnistes, to turn French historians away from the narrowly political and diplomatic toward the new vistas in social and economic history. For early modern Mexican history, the work of Marc Bloch's student François Chevalier on the formation of landed estates (haciendas) from the sixteenth century to the seventeenth had a major impact on Mexican history and historiography, setting off an important debate about whether landed estates were basically feudal or capitalistic.\n\nAn eminent member of this school, Georges Duby, described his approach to history as one that relegated the sensational to the sidelines and was reluctant to give a simple accounting of events, but strived on the contrary to pose and solve problems and, neglecting surface disturbances, to observe the long and medium-term evolution of economy, society and civilisation. The Annalistes, especially Lucien Febvre, advocated a \"histoire totale\", or \"histoire tout court\", a complete study of a historical problem.\n\nThe second era of the school was led by Fernand Braudel and was very influential throughout the 1960s and 1970s, especially for his work on the Mediterranean region in the era of Philip II of Spain. Braudel developed the idea, often associated with Annalistes, of different modes of historical time: \"l'histoire quasi immobile\" (motionless history) of historical geography, the history of social, political and economic structures (\"la longue durée\"), and the history of men and events, in the context of their structures. His 'longue durée' approach stressed slow, and often imperceptible effects of space, climate and technology on the actions of human beings in the past. The \"Annales\" historians, after living through two world wars and major political upheavals in France, were deeply uncomfortable with the notion that multiple ruptures and discontinuities created history. They preferred to stress slow change and the longue durée. They paid special attention to geography, climate, and demography as long-term factors. They considered the continuities of the deepest structures were central to history, beside which upheavals in institutions or the superstructure of social life were of little significance, for history lies beyond the reach of conscious actors, especially the will of revolutionaries.\n\nNoting the political upheavals in Europe and especially in France in 1968, Eric Hobsbawm argued that \"in France the virtual hegemony of Braudelian history and the \"Annales\" came to an end after 1968, and the international influence of the journal dropped steeply.\" Multiple responses were attempted by the school. Scholars moved in multiple directions, covering in disconnected fashion the social, economic, and cultural history of different eras and different parts of the globe. By the time of crisis the school was building a vast publishing and research network reaching across France, Europe, and the rest of the world. Influence indeed spread out from Paris, but few new ideas came in. Much emphasis was given to quantitative data, seen as the key to unlocking all of social history. However, the Annales ignored the developments in quantitative studies underway in the U.S. and Britain, which reshaped economic, political and demographic research.\n\nMarxist historiography developed as a school of historiography influenced by the chief tenets of Marxism, including the centrality of social class and economic constraints in determining historical outcomes (historical materialism). Friedrich Engels wrote \"The Peasant War in Germany\", which analysed social warfare in early Protestant Germany in terms of emerging capitalist classes. Although it lacked a rigorous engagement with archival sources, it indicated an early interest in history from below and class analysis, and it attempts a dialectical analysis. Another treatise of Engels, \"The Condition of the Working Class in England in 1844\", was salient in creating the socialist impetus in British politics from then on, e.g. the Fabian Society.\n\nR. H. Tawney was an early historian working in this tradition. \"The Agrarian Problem in the Sixteenth Century\" (1912) and \"Religion and the Rise of Capitalism\" (1926), reflected his ethical concerns and preoccupations in economic history. He was profoundly interested in the issue of the enclosure of land in the English countryside in the sixteenth and seventeenth centuries and in Max Weber's thesis on the connection between the appearance of Protestantism and the rise of capitalism. His belief in the rise of the gentry in the century before the outbreak of the Civil War in England provoked the 'Storm over the Gentry' in which his methods were subjected to severe criticisms by Hugh Trevor-Roper and John Cooper.\n\nHistoriography in the Soviet Union was greatly influenced by Marxist historiography, as historical materialism was extended into the Soviet version of dialectical materialism.\n\nA circle of historians inside the Communist Party of Great Britain (CPGB) formed in 1946 and became a highly influential cluster of British Marxist historians, who contributed to history from below and class structure in early capitalist society. While some members of the group (most notably Christopher Hill and E. P. Thompson) left the CPGB after the 1956 Hungarian Revolution, the common points of British Marxist historiography continued in their works. They placed a great emphasis on the subjective determination of history.\n\nChristopher Hill's studies on 17th-century English history were widely acknowledged and recognised as representative of this school. His books include \"Puritanism and Revolution\" (1958), \"Intellectual Origins of the English Revolution\" (1965 and revised in 1996), \"The Century of Revolution\" (1961), \"AntiChrist in 17th-century England\" (1971), \"The World Turned Upside Down\" (1972) and many others.\n\nE. P. Thompson pioneered the study of history from below in his work, \"The Making of the English Working Class\", published in 1963. It focused on the forgotten history of the first working-class political left in the world in the late-18th and early-19th centuries. In his preface to this book, Thompson set out his approach to writing history from below:\n\nThompson's work was also significant because of the way he defined \"class.\" He argued that class was not a structure, but a relationship that changed over time. He opened the gates for a generation of labor historians, such as David Montgomery and Herbert Gutman, who made similar studies of the American working classes.\n\nOther important Marxist historians included Eric Hobsbawm, C. L. R. James, Raphael Samuel, A. L. Morton and Brian Pearce.\n\nAlthough Marxist historiography made important contributions to the history of the working class, oppressed nationalities, and the methodology of history from below, its chief problematic aspect was its argument on the nature of history as \"determined\" or \"dialectical\"; this can also be stated as the relative importance of subjective and objective factors in creating outcomes. It increasingly fell out of favour in the 1960s and '70s. Geoffrey Elton was important in undermining the case for a Marxist historiography, which he argued was presenting seriously flawed interpretations of the past. In particular, Elton was opposed to the idea that the English Civil War was caused by socioeconomic changes in the 16th and 17th centuries, arguing instead that it was due largely to the incompetence of the Stuart kings.\n\nIn dealing with the era of the Second World War, Addison notes that in Britain by the 1990s, labour history was, \"in sharp decline\", because:\nBiography has been a major form of historiography since the days when Plutarch wrote the parallel lives of great Roman and Greek leaders. It is a field especially attractive to nonacademic historians, and often to the wives or children of famous men who have access to the trove of letters and documents. Academic historians tend to downplay biography because it pays too little attention to broad social, cultural, political and economic forces, and perhaps too much attention to popular psychology. The \",Great Man\" tradition in Britain originated in the multi-volume \"Dictionary of National Biography\" (which originated in 1882 and issued updates into the 1970s); it continues to this day in the new \"Oxford Dictionary of National Biography.\" In the United States, the \"Dictionary of American Biography\" was planned in the late 1920s and appeared with numerous supplements into the 1980s. It has now been displaced by the \"American National Biography\" as well as numerous smaller historical encyclopedias that give thorough coverage to Great Persons. Bookstores do a thriving business in biographies, which sell far more copies than the esoteric monographs based on post-structuralism, cultural, racial or gender history. Michael Holroyd says the last forty years \",may be seen as a golden age of biography\" but nevertheless calls it the \"shallow end of history.\" Nicolas Barker argues that \",more and more biographies command an ever larger readership\", as he speculates that biography has come \",to express the spirit of our age.\"\n\nMarxist historian E. H. Carr developed a controversial theory of history in his 1961 book \"What Is History?\", which proved to be one of the most influential books ever written on the subject. He presented a middle-of-the-road position between the empirical or (Rankean) view of history and R. G. Collingwood's idealism, and rejected the empirical view of the historian's work being an accretion of \"facts\" that he or she has at their disposal as nonsense. He maintained that there is such a vast quantity of information that the historian always chooses the \"facts\" he or she decides to make use of. In Carr's famous example, he claimed that millions had crossed the Rubicon, but only Julius Caesar's crossing in 49 BC is declared noteworthy by historians. For this reason, Carr argued that Leopold von Ranke's famous dictum \"wie es eigentlich gewesen\" (show what actually happened) was wrong because it presumed that the \"facts\" influenced what the historian wrote, rather than the historian choosing what \"facts of the past\" he or she intended to turn into \"historical facts\". At the same time, Carr argued that the study of the facts may lead the historian to change his or her views. In this way, Carr argued that history was \"an unending dialogue between the past and present\".\n\nCarr is held by some critics to have had a deterministic outlook in history. Others have modified or rejected this use of the label \"determinist\". He took a hostile view of those historians who stress the workings of chance and contingency in the workings of history. In Carr's view, no individual is truly free of the social environment in which they live, but contended that within those limitations, there was room, albeit very narrow room for people to make decisions that affect history. Carr emphatically contended that history was a social science, not an art, because historians like scientists seek generalizations that helped to broaden the understanding of one's subject.\n\nOne of Carr's most forthright critics was Hugh Trevor-Roper, who argued that Carr's dismissal of the \"might-have-beens of history\" reflected a fundamental lack of interest in examining historical causation. Trevor-Roper asserted that examining possible alternative outcomes of history was far from being a \"parlour-game\" was rather an essential part of the historians' work, as only by considering all possible outcomes of a given situation could a historian properly understand the period.\n\nThe controversy inspired Sir Geoffrey Elton to write his 1967 book \"The Practice of History\". Elton criticized Carr for his \"whimsical\" distinction between the \"historical facts\" and the \"facts of the past\", arguing that it reflected \"...an extraordinarily arrogant attitude both to the past and to the place of the historian studying it\". Elton, instead, strongly defended the traditional methods of history and was also appalled by the inroads made by postmodernism. Elton saw the duty of historians as empirically gathering evidence and objectively analyzing what the evidence has to say. As a traditionalist, he placed great emphasis on the role of individuals in history instead of abstract, impersonal forces. Elton saw political history as the highest kind of history. Elton had no use for those who seek history to make myths, to create laws to explain the past, or to produce theories such as Marxism.\n\nClassical and European history was part of the 19th century grammar curriculum. American history became a topic later in the 19th century.\n\nIn the historiography of the United States, there were a series of major approaches in the 20th century. In 2009-2012, there were an average of 16,000 new academic history books published in the U.S. every year.\n\nFrom 1910 to the 1940s, \"Progressive\" historiography was dominant, especially in political studies. It stressed the central importance of class conflict in American history. Important leaders included Vernon L. Parrington, Carl L. Becker, Arthur M. Schlesinger, Sr., John Hicks, and C. Vann Woodward. The movement established a strong base at the History Department at the University of Wisconsin with Curtis Nettels, William Hesseltine, Merle Curti, Howard K. Beale, Merrill Jensen, Fred Harvey Harrington (who became the university president), William Appleman Williams, and a host of graduate students. Charles A. Beard was the most prominent representative with his \"Beardian\" approach that reached both scholars and the general public.\n\nIn covering the Civil War, Charles and Mary Beard did not find it useful to examine nationalism, unionism, states' rights, slavery, abolition or the motivations of soldiers in battle. Instead, they proclaimed it was a:\n\nArthur Schlesinger, Jr. wrote the \"Age of Jackson\" (1945), one of the last major books from this viewpoint. Schlesinger made Jackson a hero for his successful attacks on the Second Bank of the United States. His own views were clear enough: \"Moved typically by personal and class, rarely by public, considerations, the business community has invariably brought national affairs to a state of crisis and exasperated the rest of society into dissatisfaction bordering on revolt.\"\n\nConsensus history emphasizes the basic unity of American values and downplays conflict as superficial. It was especially attractive in the 1950s and 1960s. Prominent leaders included Richard Hofstadter, Louis Hartz, Daniel Boorstin, Allan Nevins, Clinton Rossiter, Edmund Morgan, and David M. Potter. In 1948 Hofstadter made a compelling statement of the consensus model of the U.S. political tradition:\nConsensus history was rejected by New Left viewpoints that attracted a younger generation of radical historians in the 1960s. These viewpoints stress conflict and emphasize the central roles of class, race and gender. The history of dissent, and the experiences of racial minorities and disadvantaged classes was central to the narratives produced by New Left historians.\n\nSocial history, sometimes called the \"new social history,\" is a broad branch that studies the experiences of ordinary people in the past. It had major growth as a field in the 1960s and 1970s, and still is well represented in history departments. However, after 1980 the \"cultural turn\" directed the next generation to new topics. In the two decades from 1975 to 1995, the proportion of professors of history in U.S. universities identifying with social history rose from 31% to 41%, while the proportion of political historians fell from 40% to 30%.\n\nThe growth was enabled by the social sciences, computers, statistics, new data sources such as individual census information, and summer training programs at the Newberry Library and the University of Michigan. The New Political History saw the application of social history methods to politics, as the focus shifted from politicians and legislation to voters and elections.\n\nThe Social Science History Association was formed in 1976 as an interdisciplinary group with a journal \"Social Science History\" and an annual convention. The goal was to incorporate in historical studies perspectives from all the social sciences, especially political science, sociology and economics. The pioneers shared a commitment to quantification. However, by the 1980s the first blush of quantification had worn off, as traditional historians counterattacked. Harvey J. Graff says:\nMeanwhile, quantitative history became well-established in other disciplines, especially economics (where they called it \"cliometrics\"), as well as in political science. In history, however, quantification remained central to demographic studies, but slipped behind in political and social history as traditional narrative approaches made a comeback.\n\nLatin America is the former Spanish American empire in the Western Hemisphere plus Portuguese Brazil. Professional historians pioneered the creation of this field, starting in the late nineteenth century. The term “Latin America” did not come into general usage until the twentieth century and in some cases it was rejected. The historiography of the field has been more fragmented than unified, with historians of Spanish America and Brazil generally remaining in separate spheres. Another standard division within the historiography is the temporal factor, with works falling into either the early modern period (or “colonial era”) or the post-independence (or “national”) period, from the early nineteenth onward. Relatively few works span the two eras and few works except textbooks unite Spanish America and Brazil. There is a tendency to focus on histories of particular countries or regions (the Andes, the Southern Cone, the Caribbean) with relatively little comparative work.\n\nHistorians of Latin America have contributed to various types of historical writing, but one major, innovative development in Spanish American history is the emergence of ethnohistory, the history of indigenous peoples, especially in Mexico based on alphabetic sources in Spanish or in indigenous languages.\n\nFor the early modern period, the emergence of Atlantic history, based on comparisons and linkages of Europe, the Americas, and Africa from 1450-1850 that developed as a field in its own right has integrated early modern Latin American history into a larger framework. For all periods, global or world history have focused on the connections between areas, likewise integrating Latin America into a larger perspective. Latin America's importance to world history is notable but often overlooked. “Latin America’s central, and sometimes pioneering, role in the development of globalization and modernity did not cease with the end of colonial rule and the early modern period. Indeed, the region’s political independence places it at the forefront of two trends that are regularly considered thresholds of the modern world. The first is the so-called liberal revolution, the shift from monarchies of the ancien régime, where inheritance legitimated political power, to constitutional republics... The second, and related, trend consistently considered a threshold of modern history that saw Latin America in the forefront is the development of nation-states.”\n\nHistorical research appears in a number of specialized journals. These include \"Hispanic American Historical Review\" (est. 1918), published by the Conference on Latin American History; \"The Americas\", (est. 1944); \"Journal of Latin American Studies\" (1969); \"Canadian Journal of Latin American and Caribbean Studies\",( est.1976) \"Bulletin of Latin American Research\", (est. 1981); \"Colonial Latin American Review\" (1992); and \"Colonial Latin American Historical Review\" (est. 1992). \"Latin American Research Review\" (est. 1969), published by the Latin American Studies Association, does not focus primarily on history, but it has often published historiographical essays on particular topics. \n\nGeneral works on Latin American history have appeared since the 1950s, when the teaching of Latin American history expanded in U.S. universities and colleges. Most attempt full coverage of Spanish America and Brazil from the conquest to the modern era, focusing on institutional, political, social and economic history. An important, eleven volume treatment of Latin American history is \"The Cambridge History of Latin America\", with separate volumes on the colonial era, nineteenth century, and the twentieth century. There is a small number of general works that have gone through multiple editions. Major trade publishers have also issued edited volumes on Latin American history and historiography. Reference works include the Handbook of Latin American Studies, which publishes articles by area experts, with annotated bibliographic entries, and the \"Encyclopedia of Latin American History and Culture\".\n\nWorld history, as a distinct field of historical study, emerged as an independent academic field in the 1980s. It focused on the examination of history from a global perspective and looked for common patterns that emerged across all cultures. The basic thematic approach of this field was to analyse two major focal points: integration – (how processes of world history have drawn people of the world together), and difference – (how patterns of world history reveal the diversity of the human experience).\n\nArnold J. Toynbee's ten-volume \"A Study of History\", written between 1933 and 1954, was an important influence on this developing field. He took a comparative topical approach to 26 independent civilizations and demonstrated that they displayed striking parallels in their origin, growth, and decay. He proposed a universal model to each of these civilizations, detailing the stages through which they all pass: genesis, growth, time of troubles, universal state, and disintegration. With his endless output of papers, articles, speeches and presentations, and numerous books translated into many languages, Toynbee was perhaps the world’s most read and discussed scholar in the 1940s and 1950s. Yet Toynbee's work lost favor among both the general public and scholars by the 1960s, due to the religious and spiritual outlook that permeates the largest part of his work. His work has seldom been read or cited in recent decades.\n\nChicago historian William H. McNeill wrote \"The Rise of the West\" (1965) to improve upon Toynbee by showing how the separate civilizations of Eurasia interacted from the very beginning of their history, borrowing critical skills from one another, and thus precipitating still further change as adjustment between traditional old and borrowed new knowledge and practice became necessary. He then discusses the dramatic effect of Western civilization on others in the past 500 years of history. McNeill took a broad approach organized around the interactions of peoples across the globe. Such interactions have become both more numerous and more continual and substantial in recent times. Before about 1500, the network of communication between cultures was that of Eurasia. The term for these areas of interaction differ from one world historian to another and include \"world-system\" and \"ecumene.\" His emphasis on cultural fusions influenced historical theory significantly.\n\nThe \"cultural turn\" of the 1980s and 1990s affected scholars in most areas of history. Inspired largely by anthropology, it turned away from leaders, ordinary people and famous events to look at the use of language and cultural symbols to represent the changing values of society.\n\nThe British historian Peter Burke finds that cultural studies has numerous spinoffs, or topical themes it has strongly influenced. The most important include gender studies and postcolonial studies, as well as memory studies, and film studies.\n\nDiplomatic historian Melvyn P. Leffler finds that the problem with the \"cultural turn\" is that the culture concept is imprecise, and may produce excessively broad interpretations, because it:\nMemory studies is a new field, focused on how nations and groups (and historians) construct and select their memories of the past in order to celebrate (or denounce) key features, thus making a statement of their current values and beliefs. Historians have played a central role in shaping the memories of the past as their work is diffused through popular history books and school textbooks. French sociologist Maurice Halbwachs, opened the field with \"La mémoire collective\" (Paris: 1950).\n\nMany historians examine the how the memory of the past has been constructed, memorialized or distorted. Historians examine how legends are invented. For example, there are numerous studies of the memory of atrocities from World War II, notably the Holocaust in Europe and Japanese behavior in Asia. British historian Heather Jones argues that the historiography of the First World War in recent years has been reinvigorated by the cultural turn. Scholars have raised entirely new questions regarding military occupation, radicalization of politics, race, and the male body.\n\nRepresentative of recent scholarship is a collection of studies on the \"Dynamics of Memory and Identity in Contemporary Europe\" SAGE has published the scholarly journal \"Memory Studies\" since 2008, and the book series ‘Memory Studies’ was launched by Palgrave Macmillan in 2010 with 5-10 titles a year.\n\nThe historical journal, a forum where academic historians could exchange ideas and publish newly discovered information, came into being in the 19th century. The early journals were similar to those for the physical sciences, and were seen as a means for history to become more professional. Journals also helped historians to establish various historiographical approaches, the most notable example of which was \"Annales. Économies. Sociétés. Civilisations.\", a publication of the Annales School in France. Journals now typically have one or more editors and associate editors, an editorial board, and a pool of scholars to whom articles that are submitted are sent for confidential evaluation. The editors will send out new books to recognized scholars for reviews that usually run 500 to 1000 words. The vetting and publication process often takes months or longer. Publication in a prestigious journal (which accept 10% or fewer of the articles submitted) is an asset in the academic hiring and promotion process. Publication demonstrates that the author is conversant with the scholarly field. Page charges and fees for publication are uncommon in history. Journals are subsidized by universities or historical societies, scholarly associations, and subscription fees from libraries and scholars. Increasingly they are available through library pools that allow many academic institutions to pool subscriptions to online versions. Most libraries have a system for obtaining specific articles through inter-library loan.\n\n\nAccording to Lawrence Stone, narrative has traditionally been the main rhetorical device used by historians. In 1979, at a time when the new Social History was demanding a social-science model of analysis, Stone detected a move back toward the narrative. Stone defined narrative as follows: it is organized chronologically; it is focused on a single coherent story; it is descriptive rather than analytical; it is concerned with people not abstract circumstances; and it deals with the particular and specific rather than the collective and statistical. He reported that, \"More and more of the 'new historians' are now trying to discover what was going on inside people's heads in the past, and what it was like to live in the past, questions which inevitably lead back to the use of narrative.\"\n\nHistorians committed to a social science approach, however, have criticized the narrowness of narrative and its preference for anecdote over analysis, and its use of clever examples rather than statistically verified empirical regularities.\n\nSome of the common topics in historiography are:\n\nHow a historian approaches historical events is one of the most important decisions within historiography. It is commonly recognised by historians that, in themselves, individual historical facts dealing with names, dates and places are not particularly meaningful. Such facts will only become useful when assembled with other historical evidence, and the process of assembling this evidence is understood as a particular historiographical approach.\n\nThe most influential historiographical approaches are:\n\n\nImportant related fields include:\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n", "id": "13276", "title": "Historiography"}
{"url": "https://en.wikipedia.org/wiki?curid=13277", "text": "Holy Roman Empire\n\nThe Holy Roman Empire () was a multi-ethnic complex of territories in central Europe that developed during the Early Middle Ages and continued until its dissolution in 1806. The largest territory of the empire after 962 was the Kingdom of Germany, though it also came to include the Kingdom of Bohemia, the Kingdom of Burgundy, the Kingdom of Italy, and numerous other territories.\n\nOn 25 December 800, Pope Leo III crowned the Frankish king Charlemagne as Emperor, reviving the title in Western Europe, more than three centuries after the fall of the Western Roman Empire. The title continued in the Carolingian family until 888 and from 896 to 899, after which it was contested by the rulers of Italy in a series of civil wars until the death of the last Italian claimant, Berengar, in 924. The title was revived in 962 when Otto I was crowned emperor, fashioning himself as the successor of Charlemagne and beginning a continuous existence of the empire for over eight centuries. Some historians refer to the coronation of Charlemagne as the origin of the empire, while others prefer the coronation of Otto I as its beginning. Scholars generally concur, however, in relating an evolution of the institutions and principles constituting the empire, describing a gradual assumption of the imperial title and role.\n\nThe precise term \"Holy Roman Empire\" was not used until the 13th century, but the concept of \"translatio imperii\", the notion that he held supreme power inherited from the emperors of Rome, was fundamental to the prestige of the emperor. The office of Holy Roman Emperor was traditionally elective, although frequently controlled by dynasties. The German prince-electors, the highest-ranking noblemen of the empire, usually elected one of their peers as \"King of the Romans,\" and he would later be crowned emperor by the Pope; the tradition of papal coronations was discontinued in the 16th century. The empire never achieved the extent of political unification formed in France, evolving instead into a decentralized, limited elective monarchy composed of hundreds of sub-units, principalities, duchies, counties, Free Imperial Cities, and other domains. The power of the emperor was limited, and while the various princes, lords, bishops and cities of the empire were vassals who owed the emperor their allegiance, they also possessed an extent of privileges that gave them \"de facto\" independence within their territories. Emperor Francis II dissolved the empire on 6 August 1806, after the creation of the Confederation of the Rhine by Napoleon.\n\nIn various languages the Holy Roman Empire was known as: , , , , , , . Before 1157, the realm was merely referred to as the Roman Empire. The term \"sacrum\" (\"holy\", in the sense of \"consecrated\") in connection with the medieval Roman Empire was used beginning in 1157, under Frederick I Barbarossa (\"Holy Empire\") – the term was added to reflect Frederick's ambition to dominate Italy and the Papacy; the form \"Holy Roman Empire\" is attested from 1254 onward.\n\nIn a decree following the 1512 Diet of Cologne, the name was changed to Holy Roman Empire of the German Nation (, ), a form first used in a document in 1474. The new title was adopted partly because the Empire had lost most of its Italian and Burgundian (Kingdom of Arles) territories by the late 15th century, but also to emphasize the new importance of the German Imperial Estates in ruling the Empire due to the Imperial Reform. By the end of the 18th century, the term 'Holy Roman Empire of the German Nation' had fallen out of official use. Contradicting the traditional view concerning that designation, Hermann Weisert has stated in a study on imperial titulature that, despite the claim of many textbooks, the name \"Holy Roman Empire of the German Nation\" never had an official status and points out that documents were thirty times as likely to omit the national suffix as include it.\n\nIn a famous assessment of the name, the French Enlightenment writer Voltaire remarked sardonically: \"This agglomeration which was called and which still calls itself the Holy Roman Empire was in no way holy, nor Roman, nor an empire.\"\n\nAs Roman power in Gaul declined during the 5th century, local Germanic tribes assumed control. In the late 5th and early 6th centuries, the Merovingians, under Clovis I and his successors, consolidated Frankish tribes and extended hegemony over others to gain control of northern Gaul and the middle Rhine river valley region. By the middle of the 8th century, however, the Merovingians had been reduced to figureheads, and the Carolingians, led by Charles Martel, had become the \"de facto\" rulers. In 751, Martel’s son Pepin became King of the Franks, and later gained the sanction of the Pope. The Carolingians would maintain a close alliance with the Papacy.\n\nIn 768 Pepin’s son Charlemagne became King of the Franks and began an extensive expansion of the realm. He eventually incorporated the territories of present-day France, Germany, northern Italy, and beyond, linking the Frankish kingdom with Papal lands. On Christmas Day of 800, Pope Leo III crowned Charlemagne emperor, restoring the title in the west for the first time in over three centuries.\n\nAfter Charlemagne died in 814, the imperial crown was disputed among the Carolingian rulers of Western Francia and Eastern Francia, with first the western king (Charles the Bald) and then the eastern (Charles the Fat) attaining the prize. After the death of Charles the Fat in 888, however, the Carolingian Empire broke apart, and was never restored. According to Regino of Prüm, the parts of the realm \"spewed forth kinglets\", and each part elected a kinglet \"from its own bowels\". After the death of Charles the Fat, those crowned emperor by the pope controlled only territories in Italy. The last such emperor was Berengar I of Italy, who died in 924.\n\nAround 900, autonomous stem duchies (Franconia, Bavaria, Swabia, Saxony and Lotharingia) reemerged in East Francia. After the Carolingian king Louis the Child died without issue in 911, East Francia did not turn to the Carolingian ruler of West Francia to take over the realm but instead elected one of the dukes, Conrad of Franconia, as \"Rex Francorum Orientalium\". On his deathbed, Conrad yielded the crown to his main rival, Henry the Fowler of Saxony (r. 919–36), who was elected king at the Diet of Fritzlar in 919. Henry reached a truce with the raiding Magyars, and in 933 he won a first victory against them in the Battle of Riade.\n\nHenry died in 936, but his descendants, the Liudolfing (or Ottonian) dynasty, would continue to rule the Eastern kingdom for roughly a century. Upon Henry the Fowler's death, Otto, his son and designated successor, was elected King in Aachen in 936. He overcame a series of revolts from an elder brother and from several dukes. After that, the king managed to control the appointment of dukes and often also employed bishops in administrative affairs.\n\nIn 951, Otto came to the aid of Adelaide, the widowed queen of Italy, defeating her enemies, marrying her, and taking control over Italy. In 955, Otto won a decisive victory over the Magyars in the Battle of Lechfeld. In 962, Otto was crowned Emperor by Pope John XII, thus intertwining the affairs of the German kingdom with those of Italy and the Papacy. Otto's coronation as Emperor marked the German kings as successors to the Empire of Charlemagne, which through the concept of \"translatio imperii\", also made them consider themselves as successors to Ancient Rome.\n\nThe kingdom had no permanent capital city. Kings traveled between residences (called Kaiserpfalz) to discharge affairs. However, each king preferred certain places; in Otto's case, this was the city of Magdeburg. Kingship continued to be transferred by election, but Kings often ensured their own sons were elected during their lifetimes, enabling them to keep the crown for their families. This only changed after the end of the Salian dynasty in the 12th century.\n\nIn 963, Otto deposed the current pope John XII and chose Pope Leo VIII as the new pope (although John XII and Leo VIII both claimed the papacy until 964, when John XII died). This also renewed the conflict with the Eastern Emperor in Constantinople, especially after Otto's son Otto II (r. 967–83) adopted the designation \"imperator Romanorum\". Still, Otto formed marital ties with the east when he married the Byzantine princess Theophanu. Their son, Otto III, came to the throne only three years old, and was subjected to a power struggle and series of regencies until his age of majority in 994. Up to that time, he had remained in Germany, while a deposed Duke, Crescentius II, ruled over Rome and part of Italy, ostensibly in his stead.\n\nIn 996 Otto III appointed his cousin Gregory V, the first German Pope. A foreign pope and foreign papal officers were seen with suspicion by Roman nobles, who were led by Crescentius II to revolt. Otto III's former mentor Antipope John XVI briefly held Rome, until the Holy Roman Emperor seized the city.\n\nOtto died young in 1002, and was succeeded by his cousin Henry II, who focused on Germany.\n\nHenry II died in 1024, and Conrad II, first of the Salian Dynasty, was elected king only after some debate among dukes and nobles. This group eventually developed into the college of Electors.\n\nThe Holy Roman Empire became eventually composed of four kingdoms and numerous other territories. The kingdoms were:\n\n\nKings often employed bishops in administrative affairs and often determined who would be appointed to ecclesiastical offices. In the wake of the Cluniac Reforms, this involvement was increasingly seen as inappropriate by the Papacy. The reform-minded Pope Gregory VII was determined to oppose such practices, which led to the Investiture Controversy with King Henry IV (r. 1056–1106). He repudiated the Pope's interference and persuaded his bishops to excommunicate the Pope, whom he famously addressed by his born name \"Hildebrand\", rather than his regnal name \"Pope Gregory VII\". The Pope, in turn, excommunicated the king, declared him deposed, and dissolved the oaths of loyalty made to Henry. The king found himself with almost no political support and was forced to make the famous Walk to Canossa in 1077, by which he achieved a lifting of the excommunication at the price of humiliation. Meanwhile, the German princes had elected another king, Rudolf of Swabia. Henry managed to defeat him but was subsequently confronted with more uprisings, renewed excommunication, and even the rebellion of his sons. After his death, his second son, Henry V, reached an agreement with the Pope and the bishops in the 1122 Concordat of Worms. The political power of the Empire was maintained, but the conflict had demonstrated the limits of the ruler's power, especially in regard to the Church, and it robbed the king of the sacral status he had previously enjoyed. The Pope and the German princes had surfaced as major players in the political system of the empire.\n\nWhen the Salian dynasty ended with Henry V's death in 1125, the princes chose not to elect the next of kin, but rather Lothair, the moderately powerful but already old Duke of Saxony. When he died in 1137, the princes again aimed to check royal power; accordingly they did not elect Lothair's favoured heir, his son-in-law Henry the Proud of the Welf family, but Conrad III of the Hohenstaufen family, the grandson of Emperor Henry IV and thus a nephew of Emperor Henry V. This led to over a century of strife between the two houses. Conrad ousted the Welfs from their possessions, but after his death in 1152, his nephew Frederick I \"Barbarossa\" succeeded him and made peace with the Welfs, restoring his cousin Henry the Lion to his—albeit diminished—possessions.\n\nThe Hohenstaufen rulers increasingly lent land to \"ministerialia\", formerly non-free service men, who Frederick hoped would be more reliable than dukes. Initially used mainly for war services, this new class of people would form the basis for the later knights, another basis of imperial power. A further important constitutional move at Roncaglia was the establishment of a new peace mechanism for the entire empire, the Landfrieden, with the first imperial one being issued in 1103 under Henry IV at Mainz. This was an attempt to abolish private feuds, between the many dukes and other people, and to tie the Emperor's subordinates to a legal system of jurisdiction and public prosecution of criminal acts—a predecessor of the modern concept of \"rule of law\". Another new concept of the time was the systematic foundation of new cities by the Emperor and by the local dukes. These were partly caused by the explosion in population, and they also concentrated economic power at strategic locations. Before this, cities had only existed in the form of old Roman foundations or older bishoprics. Cities that were founded in the 12th century include Freiburg, possibly the economic model for many later cities, and Munich.\n\nFrederick I, also called Frederick Barbarossa, was crowned Emperor in 1155. He emphasized the \"Romanness\" of the empire, partly in an attempt to justify the power of the Emperor independent of the (now strengthened) Pope. An imperial assembly at the fields of Roncaglia in 1158 reclaimed imperial rights in reference to Justinian's Corpus Juris Civilis. Imperial rights had been referred to as \"regalia\" since the Investiture Controversy, but were enumerated for the first time at Roncaglia. This comprehensive list included public roads, tariffs, coining, collecting punitive fees, and the investiture, the seating and unseating of office holders. These rights were now explicitly rooted in Roman Law, a far-reaching constitutional act.\n\nFrederick's policies were primarily directed at Italy, where he clashed with the increasingly wealthy and free-minded cities of the north, especially Milan. He also embroiled himself in another conflict with the Papacy by supporting a candidate elected by a minority against Pope Alexander III (1159–81). Frederick supported a succession of antipopes before finally making peace with Alexander in 1177. In Germany, the Emperor had repeatedly protected Henry the Lion against complaints by rival princes or cities (especially in the cases of Munich and Lübeck). Henry gave only lackluster support to Frederick's policies, and in a critical situation during the Italian wars, Henry refused the Emperor's plea for military support. After returning to Germany, an embittered Frederick opened proceedings against the Duke, resulting in a public ban and the confiscation of all his territories. In 1190, Frederick participated in the Third Crusade and died in the Armenian Kingdom of Cilicia.\n\nDuring the Hohenstaufen period, German princes facilitated a successful, peaceful eastward settlement of lands that were uninhabited or inhabited sparsely by West Slavs. German speaking farmers, traders, and craftsmen from the western part of the Empire, both Christians and Jews, moved into these areas. The gradual Germanization of these lands was a complex phenomenon that should not be interpreted in the biased terms of 19th-century nationalism. The eastward settlement expanded the influence of the empire to include Pomerania and Silesia, as did the intermarriage of the local, still mostly Slavic, rulers with German spouses. The Teutonic Knights were invited to Prussia by Duke Konrad of Masovia to Christianize the Prussians in 1226. The monastic state of the Teutonic Order () and its later German successor state of Prussia were, however, never part of the Holy Roman Empire.\n\nUnder the son and successor of Frederick Barbarossa, Henry VI, the Hohenstaufen dynasty reached its apex. Henry added the Norman kingdom of Sicily to his domains, held English king Richard the Lionheart captive, and aimed to establish a hereditary monarchy when he died in 1197. As his son, Frederick II, though already elected king, was still a small child and living in Sicily, German princes chose to elect an adult king, resulting in the dual election of Frederick Barbarossa's youngest son Philip of Swabia and Henry the Lion's son Otto of Brunswick, who competed for the crown. Otto prevailed for a while after Philip was murdered in a private squabble in 1208, until he began to also claim Sicily.\n\nPope Innocent III, who feared the threat posed by a union of the empire and Sicily, now supported Frederick II, who marched to Germany and defeated Otto. After his victory, Frederick did not act upon his promise to keep the two realms separate – though he had made his son Henry king of Sicily before marching on Germany, he still reserved real political power for himself. This continued after Frederick was crowned Emperor in 1220. Fearing Frederick's concentration of power, the Pope finally excommunicated the Emperor. Another point of contention was the crusade, which Frederick had promised but repeatedly postponed. Now, although excommunicated, Frederick led the Sixth Crusade in 1228, which ended in negotiations and a temporary restoration of the Kingdom of Jerusalem.\n\nDespite his imperial claims, Frederick's rule was a major turning point towards the disintegration of central rule in the Empire. While concentrated on establishing a modern, centralized state in Sicily, he was mostly absent from Germany and issued far-reaching privileges to Germany's secular and ecclesiastical princes: In the 1220 \"Confoederatio cum principibus ecclesiasticis,\" Frederick gave up a number of \"regalia\" in favour of the bishops, among them tariffs, coining, and fortification. The 1232 \"Statutum in favorem principum\" mostly extended these privileges to secular territories. Although many of these privileges had existed earlier, they were now granted globally, and once and for all, to allow the German princes to maintain order north of the Alps while Frederick concentrated on Italy. The 1232 document marked the first time that the German dukes were called \"domini terræ,\" owners of their lands, a remarkable change in terminology as well.\n\nThe Kingdom of Bohemia was a significant regional power during the Middle Ages. In 1212, King Ottokar I (bearing the title \"king\" since 1198) extracted a Golden Bull of Sicily (a formal edict) from the emperor Frederick II, confirming the royal title for Ottokar and his descendants and the Duchy of Bohemia was raised to a kingdom. Bohemian kings would be exempt from all future obligations to the Holy Roman Empire except for participation in the imperial councils. Charles IV set Prague to be the seat of the Holy Roman Emperor.\n\nAfter the death of Frederick II in 1250, the German kingdom was divided between his son Conrad IV (died 1254) and the anti-king, William of Holland (died 1256). Conrad's death was followed by the Interregnum, during which no king could achieve universal recognition, allowing the princes to consolidate their holdings and become even more independent rulers. After 1257, the crown was contested between Richard of Cornwall, who was supported by the Guelph party, and Alfonso X of Castile, who was recognized by the Hohenstaufen party but never set foot on German soil. After Richard's death in 1273, the Interregnum ended with the unanimous election of Rudolf I of Germany, a minor pro-Staufen count.\n\nDuring the 13th century, a general structural change in how land was administered prepared the shift of political power towards the rising bourgeoisie at the expense of aristocratic feudalism that would characterize the Late Middle Ages. Instead of personal duties, money increasingly became the common means to represent economic value in agriculture. Peasants were increasingly required to pay tribute for their lands. The concept of \"property\" began to replace more ancient forms of jurisdiction, although they were still very much tied together. In the territories (not at the level of the Empire), power became increasingly bundled: Whoever owned the land had jurisdiction, from which other powers derived. It is important to note, however, that jurisdiction at this time did not include legislation, which virtually did not exist until well into the 15th century. Court practice heavily relied on traditional customs or rules described as customary.\n\nDuring this time territories began to transform into the predecessors of modern states. The process varied greatly among the various lands and was most advanced in those territories that were most identical to the lands of the old Germanic tribes, \"e.g.\" Bavaria. It was slower in those scattered territories that were founded through imperial privileges.\n\nThe difficulties in electing the king eventually led to the emergence of a fixed college of prince-electors (\"Kurfürsten\"), whose composition and procedures were set forth in the Golden Bull of 1356, which remained valid until 1806. This development probably best symbolizes the emerging duality between emperor and realm (\"Kaiser und Reich\"), which were no longer considered identical. The Golden Bull also set forth the system for election of the Holy Roman Emperor. The emperor now was to be elected by a majority rather than by consent of all seven electors. For electors the title became hereditary, and they were given the right to mint coins and to exercise jurisdiction. Also their sons were to know the imperial languages – German, Latin, Italian, and Czech.\n\nThe shift in power away from the emperor is also revealed in the way the post-Hohenstaufen kings attempted to sustain their power. Earlier, the Empire's strength (and finances) greatly relied on the Empire's own lands, the so-called \"Reichsgut\", which always belonged to the king of the day and included many Imperial Cities. After the 13th century, the relevance of the \"Reichsgut\" faded, even though some parts of it did remain until the Empire's end in 1806. Instead, the \"Reichsgut\" was increasingly pawned to local dukes, sometimes to raise money for the Empire, but more frequently to reward faithful duty or as an attempt to establish control over the dukes. The direct governance of the \"Reichsgut\" no longer matched the needs of either the king or the dukes.\n\nThe kings beginning with Rudolf I of Germany increasingly relied on the lands of their respective dynasties to support their power. In contrast with the \"Reichsgut\", which was mostly scattered and difficult to administer, these territories were relatively compact and thus easier to control. In 1282, Rudolf I thus lent Austria and Styria to his own sons. In 1312, Henry VII of the House of Luxembourg was crowned as the first Holy Roman Emperor since Frederick II. After him all kings and emperors relied on the lands of their own family (\"Hausmacht\"): Louis IV of Wittelsbach (king 1314, emperor 1328–47) relied on his lands in Bavaria; Charles IV of Luxembourg, the grandson of Henry VII, drew strength from his own lands in Bohemia. Interestingly, it was thus increasingly in the king's own interest to strengthen the power of the territories, since the king profited from such a benefit in his own lands as well.\n\nThe \"constitution\" of the Empire still remained largely unsettled at the beginning of the 15th century. Although some procedures and institutions had been fixed, for example by the Golden Bull of 1356, the rules of how the king, the electors, and the other dukes should cooperate in the Empire much depended on the personality of the respective king. It therefore proved somewhat damaging that Sigismund of Luxemburg (king 1410, emperor 1433–1437) and Frederick III of Habsburg (king 1440, emperor 1452–1493) neglected the old core lands of the empire and mostly resided in their own lands. Without the presence of the king, the old institution of the \"Hoftag\", the assembly of the realm's leading men, deteriorated. The \"Imperial Diet\" as a legislative organ of the Empire did not exist at that time. The dukes often conducted feuds against each other - feuds that, more often than not, escalated into local wars.\n\nSimultaneously, the Catholic Church experienced crises of its own, with wide-reaching effects in the Empire. The conflict between several papal claimants (two anti-popes and the \"legitimate\" Pope) ended only with the Council of Constance (1414–1418); after 1419 the Papacy directed much of its energy to suppressing the Hussites. The medieval idea of unifying all Christendom into a single political entity, with the Church and the Empire as its leading institutions, began to decline.\n\nWith these drastic changes, much discussion emerged in the 15th century about the Empire itself. Rules from the past no longer adequately described the structure of the time, and a reinforcement of earlier \"Landfrieden\" was urgently called for. During this time, the concept of \"reform\" emerged, in the original sense of the Latin verb \"re-formare\" – to regain an earlier shape that had been lost.\n\nWhen Frederick III needed the dukes to finance a war against Hungary in 1486, and at the same time had his son (later Maximilian I) elected king, he faced a demand from the united dukes for their participation in an Imperial Court. For the first time, the assembly of the electors and other dukes was now called the Imperial Diet (German \"Reichstag\") (to be joined by the Imperial Free Cities later). While Frederick refused, his more conciliatory son finally convened the Diet at Worms in 1495, after his father's death in 1493. Here, the king and the dukes agreed on four bills, commonly referred to as the \"Reichsreform\" (Imperial Reform): a set of legal acts to give the disintegrating Empire some structure. For example, this act produced the Imperial Circle Estates and the \"Reichskammergericht\" (Imperial Chamber Court), institutions that would—to a degree—persist until the end of the Empire in 1806.\n\nHowever, it took a few more decades for the new regulation to gain universal acceptance and for the new court to begin to function effectively; only in 1512 would the Imperial Circles be finalized. The King also made sure that his own court, the \"Reichshofrat\", continued to operate in parallel to the \"Reichskammergericht\". Also in 1512 the Empire received its new title, the \"Heiliges Römisches Reich Deutscher Nation\" (\"Holy Roman Empire of the German Nation\").\n\nIn 1516, Ferdinand II of Aragon, grandfather of the future Holy Roman Emperor Charles V, died. Due to a combination of (1) the traditions of dynastic succession in Aragon, which permitted maternal inheritance with no precedence for female rule; (2) the insanity of Charles's mother, Joanna of Castile; and (3) the insistence by his remaining grandfather, Maximilian I, that he take up his royal titles, Charles initiated his reign in Castile and Aragon, a union which evolved into Spain, in conjunction with his mother. This ensured for the first time that all the realms of what is now Spain would be united by one monarch under one nascent Spanish crown. The founding territories retained their separate governance codes and laws. In 1519, already reigning as \"Carlos I\" in Spain, Charles took up the imperial title as \"Karl V\". The balance (and imbalance) between these separate inheritances would be defining elements of his reign, and would ensure that personal union between the Spanish and German crowns would be short-lived. The latter would end up going to a more junior branch of the Habsburgs in the person of Charles's brother Ferdinand, while the senior branch continued rule in Spain and in the Burgundian inheritance in the person of Charles's son, Philip II of Spain.\n\nIn addition to conflicts between his Spanish and German inheritances, conflicts of religion would be another source of tension during the reign of Charles V. Before Charles's reign in the Holy Roman Empire began, in 1517, Martin Luther launched what would later be known as the Reformation. At this time, many local dukes saw it as a chance to oppose the hegemony of Emperor Charles V. The empire then became fatally divided along religious lines, with the north, the east, and many of the major cities—Strasbourg, Frankfurt and Nuremberg—becoming Protestant while the southern and western regions largely remained Catholic.\n\nCharles V continued to battle the French and the Protestant princes in Germany for much of his reign. After his son Philip married Queen Mary of England, it appeared that France would be completely surrounded by Habsburg domains, but this hope proved unfounded when the marriage produced no children. In 1555, Paul IV was elected pope and took the side of France, whereupon an exhausted Charles finally gave up his hopes of a world Christian empire. He abdicated and divided his territories between Philip and Ferdinand of Austria. The Peace of Augsburg ended the war in Germany and accepted the existence of the Protestant princes, although not Calvinism, Anabaptism, or Swiss Reformed.\n\nGermany would enjoy relative peace for the next six decades. On the eastern front, the Turks continued to loom large as a threat, although war would mean further compromises with the Protestant princes, and so the Emperor sought to avoid it. In the west, the Rhineland increasingly fell under French influence. After the Dutch revolt against Spain erupted, the Empire remained neutral; de facto allowing the Netherlands to depart the empire in 1581, a succession acknowledged in 1648. A side effect was the Cologne War, which ravaged much of the upper Rhine.\n\nAfter Ferdinand died in 1564, his son Maximilian II became Emperor, and like his father, accepted the existence of Protestantism and the need for occasional compromise with it. Maximilian was succeeded in 1576 by Rudolf II, a strange man who preferred classical Greek philosophy to Christianity and lived an isolated existence in Bohemia. He became afraid to act when the Catholic Church was forcibly reasserting control in Austria and Hungary and the Protestant princes became upset over this. Imperial power sharply deteriorated by the time of Rudolf's death in 1612. When Bohemians rebelled against the Emperor, the immediate result was the series of conflicts known as the Thirty Years' War (1618–48), which devastated the Empire. Foreign powers, including France and Sweden, intervened in the conflict and strengthened those fighting Imperial power, but also seized considerable territory for themselves. The long conflict so bled the Empire that it never recovered its strength.\n\nAt the Battle of Vienna (1683), the Army of the Holy Roman Empire, led by the Polish King John III Sobieski, decisively defeated a large Turkish army, ending the western colonial Ottoman advance and leading to the eventual dismemberment of the Ottoman Empire in Europe. The HRE army was half Polish/Lithuanian Commonwealth forces, mostly cavalry, and half Holy Roman Empire forces (German/Austrian), mostly infantry.\n\nThe actual end of the empire came in several steps. The Peace of Westphalia in 1648, which ended the Thirty Years' War, gave the territories almost complete independence. The Swiss Confederation, which had already established quasi-independence in 1499, as well as the Northern Netherlands, left the Empire. The Habsburg Emperors focused on consolidating their own estates in Austria and elsewhere.\n\nBy the rise of Louis XIV, the Habsburgs were chiefly dependent on their hereditary lands to counter the rise of Prussia, some of whose territories lay inside the Empire. Throughout the 18th century, the Habsburgs were embroiled in various European conflicts, such as the War of the Spanish Succession, the War of the Polish Succession and the War of the Austrian Succession. The German dualism between Austria and Prussia dominated the empire's history after 1740.\n\nFrom 1792 onwards, revolutionary France was at war with various parts of the Empire intermittently.\n\nThe German mediatization was the series of mediatizations and secularizations that occurred between 1795 and 1814, during the latter part of the era of the French Revolution and then the Napoleonic Era. \"Mediatization\" was the process of annexing the lands of one imperial estate to another, often leaving the annexed some rights. For example, the estates of the Imperial Knights were formally mediatised in 1806, having \"de facto\" been seized by the great territorial states in 1803 in the so-called \"Rittersturm\". \"Secularization\" was the abolition of the temporal power of an ecclesiastical ruler such as a bishop or an abbot and the annexation of the secularized territory to a secular territory.\n\nThe empire was dissolved on 6 August 1806, when the last Holy Roman Emperor Francis II (from 1804, Emperor Francis I of Austria) abdicated, following a military defeat by the French under Napoleon at Austerlitz (see Treaty of Pressburg). Napoleon reorganized much of the Empire into the Confederation of the Rhine, a French satellite. Francis' House of Habsburg-Lorraine survived the demise of the empire, continuing to reign as Emperors of Austria and Kings of Hungary until the Habsburg empire's final dissolution in 1918 in the aftermath of World War I.\n\nThe Napoleonic Confederation of the Rhine was replaced by a new union, the German Confederation, in 1815, following the end of the Napoleonic Wars. It lasted until 1866 when Prussia founded the North German Confederation, a forerunner of the German Empire which united the German-speaking territories outside of Austria and Switzerland under Prussian leadership in 1871. This state developed into modern Germany.\n\nThe only princely member state of the Holy Roman Empire that has preserved its status as a monarchy until today is the Principality of Liechtenstein. The only Free Imperial Cities still being states within Germany are Hamburg and Bremen. All other historic member states of the HRE were either dissolved or are republican successor states to their princely predecessor states.\n\nThe Holy Roman Empire was not a highly centralized state like most countries today. Instead, it was divided into dozens—eventually hundreds—of individual entities governed by kings, dukes, counts, bishops, abbots and other rulers, collectively known as princes. There were also some areas ruled directly by the Emperor. At no time could the Emperor simply issue decrees and govern autonomously over the Empire. His power was severely restricted by the various local leaders.\n\nFrom the High Middle Ages onwards, the Holy Roman Empire was marked by an uneasy coexistence of the princes of the local territories who were struggling to take power away from it. To a greater extent than in other medieval kingdoms such as France and England, the Emperors were unable to gain much control over the lands that they formally owned. Instead, to secure their own position from the threat of being deposed, Emperors were forced to grant more and more autonomy to local rulers, both nobles and bishops. This process began in the 11th century with the Investiture Controversy and was more or less concluded with the 1648 Peace of Westphalia. Several Emperors attempted to reverse this steady dissemination of their authority, but were thwarted both by the papacy and by the princes of the Empire.\n\nThe number of territories in the Empire was considerable, rising to about 300 at the time of the Peace of Westphalia. Many of these \"Kleinstaaten\" (\"little states\") covered no more than a few square miles, and/or included several non-contiguous pieces, so the Empire was often called a \"Flickenteppich\" (\"patchwork carpet\").\n\nAn entity was considered a \"Reichsstand\" (imperial estate) if, according to feudal law, it had no authority above it except the Holy Roman Emperor himself. The imperial estates comprised:\n\nFor a list of \"Reichsstände\" in 1792, see List of Imperial Diet participants (1792).\n\nA prospective Emperor had first to be elected King of the Romans (Latin: \"Rex romanorum\"; German: \"römischer König\"). German kings had been elected since the 9th century; at that point they were chosen by the leaders of the five most important tribes (the Salian Franks of Lorraine, Ripuarian Franks of Franconia, Saxons, Bavarians and Swabians). In the Holy Roman Empire, the main dukes and bishops of the kingdom elected the King of the Romans. In 1356, Emperor Charles IV issued the Golden Bull, which limited the electors to seven: the King of Bohemia, the Count Palatine of the Rhine, the Duke of Saxony, the Margrave of Brandenburg and the archbishops of Cologne, Mainz, and Trier. During the Thirty Years' War, the Duke of Bavaria was given the right to vote as the eighth elector, and the Duke of Brunswick-Lüneburg (colloquially, Hanover) was granted a ninth electorate; additionally, the Napoleonic Wars resulted in several electorates being reallocated, but these new electors never voted before the Empire's dissolution. A candidate for election would be expected to offer concessions of land or money to the electors in order to secure their vote.\n\nAfter being elected, the King of the Romans could theoretically claim the title of \"Emperor\" only after being crowned by the Pope. In many cases, this took several years while the King was held up by other tasks: frequently he first had to resolve conflicts in rebellious northern Italy, or was in quarrel with the Pope himself. Later Emperors dispensed with the papal coronation altogether, being content with the styling \"Emperor-Elect\": the last Emperor to be crowned by the Pope was Charles V in 1530.\n\nThe Emperor had to be male and of noble blood. No law required him to be a Catholic, but as the majority of the Electors adhered to this faith, no Protestant was ever elected. Whether and to what degree he had to be German was disputed among the Electors, contemporary experts in constitutional law, and the public. During the Middle Ages, some Kings and Emperors were not of German origin, but since the Renaissance, German heritage was regarded as vital for a candidate in order to be eligible for imperial office.\n\nThe Imperial Diet (\"Reichstag\", or \"Reichsversammlung\") was the legislative body of the Holy Roman Empire and theoretically superior to the emperor himself. It was divided into three classes. The first class, the Council of Electors, consisted of the electors, or the princes who could vote for King of the Romans. The second class, the Council of Princes, consisted of the other princes. The Council of Princes was divided into two \"benches,\" one for secular rulers and one for ecclesiastical ones. Higher-ranking princes had individual votes, while lower-ranking princes were grouped into \"colleges\" by geography. Each college had one vote.\n\nThe third class was the Council of Imperial Cities, which was divided into two colleges: Swabia and the Rhine. The Council of Imperial Cities was not fully equal with the others; it could not vote on several matters such as the admission of new territories. The representation of the Free Cities at the Diet had become common since the late Middle Ages. Nevertheless, their participation was formally acknowledged only as late as in 1648 with the Peace of Westphalia ending the Thirty Years' War.\n\nThe Empire also had two courts: the \"Reichshofrat\" (also known in English as the Aulic Council) at the court of the King/Emperor, and the \"Reichskammergericht\" (Imperial Chamber Court), established with the Imperial Reform of 1495.\n\nAs part of the Imperial Reform, six Imperial Circles were established in 1500; four more were established in 1512. These were regional groupings of most (though not all) of the various states of the Empire for the purposes of defence, imperial taxation, supervision of coining, peace-keeping functions and public security. Each circle had its own parliament, known as a \"Kreistag\" (\"Circle Diet\"), and one or more directors, who coordinated the affairs of the circle. Not all imperial territories were included within the imperial circles, even after 1512; the Lands of the Bohemian Crown were excluded, as were Switzerland, the imperial fiefs in northern Italy, the lands of the Imperial Knights, and certain other small territories like the Lordship of Jever.\n\nThe Army of the Holy Roman Empire (German \"Reichsarmee\", \"Reichsheer\" or \"Reichsarmatur\"; Latin \"exercitus imperii\") was created in 1422 and came to an end even before the Empire as the result of the Napoleonic Wars. It must not be confused with the Imperial Army (\"Kaiserliche Armee\") of the Emperor.\n\nDespite appearances to the contrary, the Army of the Empire did not constitute a permanent standing army that was always at the ready to fight for the Empire. When there was danger, an Army of the Empire was mustered from among the elements constituting it, in order to conduct an imperial military campaign or \"Reichsheerfahrt\". In practice, the imperial troops often had local allegiances stronger than their loyalty to the Emperor.\n\n\nRoman Catholicism constituted the single official religion of the Empire until 1555.\n\nLutheranism was officially recognized in the Peace of Augsburg of 1555, and Calvinism in the Peace of Westphalia of 1648. Those two constituted the only officially recognized Protestant denominations, while various other Protestant confessions such as Anabaptism, Arminianism, etc. coexisted illegally within the Empire.\n\nLargest cities or towns of the Empire by year:\n\n\n\n\n\n", "id": "13277", "title": "Holy Roman Empire"}
{"url": "https://en.wikipedia.org/wiki?curid=13279", "text": "Holiday\n\nA holiday is a day set aside by custom or by law on which normal activities, especially business or work, are suspended or reduced. Generally, holidays are intended to allow individuals to celebrate or commemorate an event or tradition of cultural or religious significance. Holidays may be designated by governments, religious institutions, or other groups or organizations. The degree to which normal activities are reduced by a holiday may depend on local laws, customs, the type of job being held or even personal choices.\n\nThe concept of holidays often originated in connection with religious observances. The intention of a holiday was typically to allow individuals to tend to religious duties associated with important dates on the calendar. In most modern societies, however, holidays serve as much of a recreational function as any other weekend days or activities.\n\nIn many societies there are important distinctions between holidays designated by governments and holidays designated by religious institutions. For example, in many predominantly Christian nations, government-designed holidays may center on Christian holidays, though non-Christians may instead observe religious holidays associated with their faith. In some cases, a holiday may only be nominally observed. For example, many Jews in the Americas and Europe treat the relatively minor Jewish holiday of Hanukkah as a \"working holiday\", changing very little of their daily routines for this day.\n\nThe word \"holiday\" has differing connotations in different regions. In the United States the word is used exclusively to refer to the nationally, religiously or culturally observed day(s) of rest or celebration, or the events themselves, whereas in the United Kingdom and other Commonwealth nations, the word may refer to the period of time where leave from one’s duties has been agreed, and is used as a synonym to the US preferred \"vacation\". This time is usually set aside for rest, travel and/or the participation in recreational activities, with entire industries targeted to coincide or enhance these experiences. The days of leave may not coincide with any specific customs or laws. Employers and educational institutes may designate ‘holidays’ themselves which may or may not overlap nationally or culturally relevant dates, which again comes under this connotation, but it is the first implication detailed that this article is concerned with.\n\nThe word \"holiday\" comes from the Old English word \"hāligdæg\" (\"hālig\" \"holy\" + \"dæg\" \"day\"). The word originally referred only to special religious days. In modern use, it means any special day of rest or relaxation, as opposed to normal days away from work or school.\n\nWinter in the Northern Hemisphere features many holidays that involve festivals and feasts. The Christmas and holiday season surrounds the Christmas and other holidays, and is celebrated by many religions and cultures. Usually, this period begins near the start of November and ends with New Year's Day. \"Holiday season\" is, somewhat, a commercial term that applies, in the US, to the period that begins with Thanksgiving and ends with New Year's Eve. Some Christian countries consider the end of the festive season to be after the feast of Epiphany.\n\nSovereign nations and territories observe holidays based on events of significance to their history. For example, Americans celebrate Independence Day, celebrating the signing of the Declaration of Independence in 1776.\n\nOther secular (non-religious) holidays are observed nationally, internationally (often in conjunction with organizations such as the United Nations), and across multi-country regions. An example of a major secular holiday is the Lunar New Year, which is celebrated across Asia. Many other days are marked to celebrate events or people, but are not strictly holidays as time off work is rarely given; examples include Arbor Day (originally US), Labor Day (celebrated sometimes under different names and on different days in different countries), and Earth Day (22 April).\n\nThese are holidays that are not traditionally marked on calendars. These holidays are celebrated by various groups and individuals. Some promote a cause, others recognize historical events not officially recognized, and others are \"funny\" holidays celebrated with humorous intent. For example, Monkey Day is celebrated on December 14, International Talk Like a Pirate Day is observed on September 19, and Blasphemy Day is held on September 30. Another example April Fool's Day on April 1.\n\nMany holidays are linked to faiths and religions (see etymology above). Christian holidays are defined as part of the liturgical year, the chief ones being Easter and Christmas. The Orthodox Christian and Western-Roman Catholic patronal feast day or \"name day\" are celebrated in each place's patron saint's day, according to the Calendar of saints. Jehovah's Witnesses annually commemorate \"The Memorial of Jesus Christ's Death\", but do not celebrate other holidays with any religious significance such as Easter, Christmas or New Year's. This holds especially true for those holidays that have combined and absorbed rituals, overtones or practices from non-Christian beliefs into the celebration, as well as those holidays that distract from or replace the worship of Jehovah. In Islam, the largest holidays are Eid ul-Fitr (immediately after Ramadan) and Eid al-Adha (at the end of the Hajj). Ahmadi Muslims additionally celebrate Promised Messiah Day, Promised Reformer Day, and Khilafat Day, but contrary to popular belief, neither are regarded as holidays. Hindus, Jains and Sikhs observe several holidays, one of the largest being Diwali (Festival of Light). Japanese holidays contain references to several different faiths and beliefs. Celtic, Norse, and Neopagan holidays follow the order of the Wheel of the Year. Some are closely linked to Swedish festivities. The Bahá'í Faith observes 11 annual holidays on dates determined using the Bahá'í calendar. Jews have two holiday seasons: the Spring Feasts of Pesach (Passover) and Shavuot (Weeks, called Pentecost in Greek); and the Fall Feasts of Rosh Hashanah (Head of the Year), Yom Kippur (Day of Atonement), Sukkot (Tabernacles), and Shemini Atzeret (Eighth Day of Assembly).\n\n\n", "id": "13279", "title": "Holiday"}
{"url": "https://en.wikipedia.org/wiki?curid=13287", "text": "Hobby\n\nA hobby is a regular activity that is done for enjoyment, typically during one's leisure time. Hobbies can include collecting themed items and objects, engaging in creative and artistic pursuits, playing sports, or pursuing other amusements. A list of hobbies is lengthy and always changing as interests and fashions change. By continually participating in a particular hobby, one can acquire substantial skill and knowledge in that area. Engagement in hobbies has increased since the late nineteenth century as workers have more leisure time and advancing production and technology have provided more support for leisure activities. As some hobbies have become less popular, like stamp collecting, others have been created following technological advances, like video games.\n\nHobbyists are a part of a wider group of people engaged in leisure pursuits where the boundaries of each group overlap to some extent. The \"Serious Leisure Perspective\" groups hobbyists with amateurs and volunteers and identifies three broad groups of leisure activity with hobbies being found mainly in the Serious leisure category.\n\n\"a. Casual leisure\" is intrinsically rewarding, short-lived, pleasurable activity requiring little or no preparation\n\n\"b. Serious leisure\" is the systematic pursuit of an amateur, hobbyist, or volunteer that is substantial, rewarding and results in a sense of accomplishment.\n\n\"c. Project-based leisure\" is a short-term often a one-off project that is rewarding.\n\nIn the 16th century, the term \"hobyn \" had the meaning of \"small horse and pony \". The term \"hobby horse\" was documented in a 1557 payment confirmation for a \"Hobbyhorse\" from Reading, England. The item, originally called a \"Tourney Horse\", was made of a wooden or basketwork frame with an artificial tail and head. It was designed for a child to mimic riding a real horse. By 1816 the derivative, \"hobby\", was introduced into the vocabulary of a number of English people. Over the course of subsequent centuries, the term came to be associated with recreation and leisure. In the 17th century, the term was used in a pejorative sense by suggesting that a hobby was a childish pursuit, however in the 18th century with a more industrial society and more leisure time, hobbies took on greater respectability A hobby is also called a pastime, derived from the use of hobbies to pass the time. A hobby became an activity that is practised regularly and usually with some worthwhile purpose. Hobbies are usually, but not always, practised primarily for interest and enjoyment, rather than financial reward.\n\nThe origins pursuits that others thought somewhat childish or trivial. However, as early as 1676 Sir Matthew Hale, in \"Contemplations Moral and Divine\", wrote \"Almost every person hath some hobby horse or other wherein he prides himself.\" He was acknowledging that a \"hobby horse\" produces a legitimate sense of pride. By the mid 18th century there was a flourishing of hobbies as working people had more regular hours of work and greater leisure time. They spent more time to pursue interests that brought them satisfaction. However, there was concern that these working people might not use their leisure time in worthwhile pursuits. \"The hope of weaning people away from bad habits by the provision of counter-attractions came to the fore in the 1830s, and has rarely waned since. Initially the bad habits were perceived to be of a sensual and physical nature, and the counter attractions, or perhaps more accurately alternatives, deliberately cultivated rationality and the intellect.\" The flourishing book and magazine trade of the day encouraged worthwhile hobbies and pursuits. The burgeoning manufacturing trade made materials used in hobbies cheap and was responsive to the changing interests of hobbyists.\n\nThe English have been identified as enthusiastic hobbyists, as George Orwell observed. \"[A]nother English characteristic which is so much a part of us that we barely notice it … is the addiction to hobbies and spare-time occupations, the privateness of English life. We are a nation of flower-lovers, but also a nation of stamp-collectors, pigeon-fanciers, amateur carpenters, coupon-snippers, darts-players, crossword-puzzle fans. All the culture that is most truly native centres round things which even when they are communal are not official—the pub, the football match, the back garden, the fireside and the ‘nice cup of tea’.\"\n\nDeciding what to include in a list of hobbies provokes debate because it is difficult to decide which pleasurable pass-times can also be described as hobbies. During the 20th century the term hobby usually brought to mind activities such as stamp collecting, embroidery, knitting, painting, woodwork, photography, but not activities like listening to music, watching television or reading. These latter activities bring pleasure but lack the sense of achievement that is usually associated with a hobby. They are usually not structured, organised pursuits, as are most hobbies. The pleasure of a hobby is usually associated with making something of value or achieving something of value. \"Such leisure is socially valorised precisely because it produces feelings of satisfaction with something that looks very much like work but that is done of its own sake.\" \"Hobbies are a contradiction: they take work and turn it into leisure, and take leisure and turn it into work.\"\n\nThe terms amateur and hobbyist are often used interchangeably. Stebbins has a framework which distinguishes the terms has a useful categorisation of leisure in which he separates \"casual\" leisure from \"serious Leisure\". He describes serious leisure as that undertaken by \"amateurs\", \"hobbyists\" and \"volunteers\". \"Amateurs\" engage in pursuits that have a professional counterpart, such as playing an instrument or astronomy. Hobbyists engage in five broad types of activity: \"collecting\", \"making and tinkering\" (like embroidery and car restoration), \"activity participation\" (like fishing and singing), \"sports and games\", and \"liberal-arts\" hobbies (like languages, cuisine, literature). Volunteers commit to organisations where they work as guides, counsellors, gardeners and so on. The separation of the amateur from the hobbyist is because the amateur has the ethos of the professional practitioner as a guide to practice. An amateur clarinetist is conscious of the role and procedures of a professional clarinetist.\n\nA large proportion of hobbies are mainly solitary in nature. However, individual pursuit of a hobby often includes club membership, organised sharing of products and regular communication between participants. For many hobbies there is an important role in being in touch with fellow hobbyists. Some hobbies of course are communal in nature, like choral singing and volunteering.\n\nDuring the 20th century there was extensive research into the important role that play has in human development. While most evident in childhood, play continues throughout life for many adults in the form of games, hobbies, and sport.\n\nThe type of hobbies that people engage in changes as the world changes. In the 21st century the video game industry is very large hobby involving millions of adults in various forms of 'play'. Stamp collecting has declined along with the decline in the importance of the postal system. Woodwork and knitting have declined as hobbies as manufactured goods provide cheap alternatives for handmade goods. Through the internet an online community has become a hobby for many people, sharing advice, information and support, and in some cases, allowing a traditional hobby, such as collecting, to flourish and support trading in a new environment .\n\nPeople who engage in hobbies are those who have an interests and time to pursue them. Children have long been an important group of hobbyists because they often having enthusiasms for collecting, making and exploring and they tend to have plenty of leisure time. The growth in hobbies occurred following industrialisation which gave workers set time for leisure. During the Depression there was an increase in participation in hobbies, because unemployed had time and a desire to be purposefully occupied. Hobbies are often pursued with increased interest by retired people because they have time and seek the intellectual and physical stimulation of a hobby. Studies of ageing and society support the value of hobbies in healthy ageing.\n\nHobbies are a diverse set of activities and it is difficult to categorize them in a logical manner. The following categorization of hobbies was developed by Stebbins. \n\nCollecting includes seeking, locating, acquiring, organizing, cataloging, displaying and storing. Collecting is appealing to many people due to their interest in a particular subject and a desire to categorise and make order out of complexity. Some collectors are generalists, accumulating items from countries of the world. Others focus on a subtopic within their area of interest, perhaps 19th century postage stamps, milk bottle labels from Sussex, or Mongolian harnesses and tack. \nCollecting is an ancient hobby, with the list of coin collectors showing Caesar Augustus as an early coin collector. Sometimes collectors have turned their hobby into a business, becoming commercial dealers that trade in the items being collected.\n\nAn alternative to collecting physical objects is collecting records of events of a particular kind. Examples include train spotting, bird-watching, aircraft spotting, railfans, and any other form of systematic recording a particular phenomenon. The recording form can be written, photographic, online, or any combination of forms.\n\nScale modeling is making a replica of a real object in a smaller scale goes back to prehistoric times with small clay \"dolls\" and other children's toys having been found near known populated areas. The Greeks, Romans, and Persians took the form to a greater depth during their years of world domination, using scale replicas of enemy fortifications, coastal defense lines, and other geographic fixtures to plan battles.\n\nAt the turn of the Industrial Age and on through the 1920s, families could often afford things such as electric trains, wind-up toys (typically boats or cars) and the increasingly valuable tin toy soldiers.\n\nModel engineering refers to building functioning machinery in metal, such as internal combustion motors and live steam models or locomotives. This is a demanding hobby, requiring a multitude of large and expensive tools, such as lathes and mills. This hobby originated in the United Kingdom in the late 19th century, later spreading and flourishing in the mid-20th century. Due to the expense and space required, it is becoming rare.\n\nScale modeling as we know it today became popular shortly after World War II. Before 1946, children as well as adults were content in carving and shaping wooden replicas from block wood kits, often depicting enemy aircraft to help with identification in case of an invasion.\n\nWith the advent of modern plastics, the amount of skill required to get the basic shape accurately shown for any given subject was lessened, making it easier for people of all ages to begin assembling replicas in varying scales. Superheroes, aeroplanes, boats, cars, tanks, artillery, and even figures of soldiers became quite popular subjects to build, paint and display. Although almost any subject can be found in almost any scale, there are common scales for such miniatures which remain constant today. The most popular scales for each subject are (in order of popularity):\n\n3D Printing is a relatively new technology and is already a major hobby as the cost of printers has fallen sharply. It is a good example of how hobbyists quickly engage with new technologies, communicate with one another and become producers related to their former hobby. 3D Modeling is the process of making mathematical representations of three dimensional items and is an aspect of 3D printing.\n\nDressmaking has been a major hobby up until the late 20th century, partly in order to make cheap clothes, but also as a creative design and craft challenge. It has been reduced by the low cost of manufactured clothes.\n\nCooking is for some people an interest, a hobby, a challenge and a source of significant satisfaction. For many other people it is a job, a chore, a necessary duty, like cleaning. In the early 21st century the importance of cooking as a hobby is demonstrated by the high popularity of competitive television cooking programs.\n\nTinkering is 'dabbling' with the making process, often applied to the major hobby of tinkering with car repairs, and various kinds of restoration: of furniture, antique cars etc. It also applies to household tinkering: repairing a wall, laying a pathway etc.\n\nOutdoor pursuits are the group of activities which occur outdoors. These hobbies include gardening, hill walking, hiking, backpacking, cycling, canoeing, climbing, caving, fishing, hunting, wildlife viewing (as birdwatching) and engaging in watersports and snowsports.\n\nDepending on an individual's desired level of adrenaline, outdoors experiences are considered one type of hobby. While many enjoy an adrenaline rush or just an escape from reality, outdoor recreational activities can also be an extremely effective medium in education and team building.\n\nAs interest increases, so has the desire for commercial outdoor pursuits. Outdoor recreational supply stores have opened in large numbers and are thriving, as have outdoor pursuit journalism and magazines, both on paper and the Internet.\n\nThe increased accessibility of outdoor pursuit resources has been the source of some negative publicity over the years, with complaints of the destruction of landscape. An example is the destruction of hillsides as footpaths are eroded due to an excessive number of visitors.\n\nResidential gardening most often takes place in or about one's own residence, in a space referred to as the garden. Although a garden typically is located on the land near a residence, it may also be located on a roof, in an atrium, on a balcony, in a windowbox, or on a patio or vivarium.\n\nGardening also takes place in non-residential green areas, such as parks, public or semi-public gardens (botanical gardens or zoological gardens), amusement and theme parks, along transportation corridors, and around tourist attractions and hotels. In these situations, a staff of gardeners or groundskeepers maintains the gardens.\nIndoor gardening is growing houseplants within a residence or building, in a conservatory, or in a greenhouse. Indoor gardens are sometimes incorporated into air conditioning or heating systems.\n\nWater gardening is growing plants that have adapted to pools and ponds. Bog gardens are also considered a type of water garden. These all require special conditions and considerations. A simple water garden may consist solely of a tub containing the water and plant(s).\n\nContainer gardening is concerned with growing plants in containers that are placed above the ground.\n\nMany hobbies involve performances by the hobbyist, such as singing, acting, juggling, magic, dancing, playing a musical instrument, martial arts and other performing arts.\n\nSome hobbies result in an end product. Examples of this would be woodworking, photography, moviemaking, jewelry making, software projects such as Photoshopping and home music or video production, making bracelets, artistic projects such as drawing, painting, writing, etc., The design, creation, and wearing a costume based on an already existing creative property - Cosplay, creating models out of card stock or paper – called papercraft. Hobbies also include higher-end projects like building or restoring a car, or building a computer from scratch.\n\nFor computer savvy do-it-yourself hobbyists, CNC (Computer Numerical Control) machining is also popular. A CNC machine can be assembled and programmed to make different parts from wood or metal.\n\nReading, books, ebooks, magazines, comics, or newspapers, along with browsing the internet is a common hobby, and one that can trace its origins back hundreds of years. A love of literature, later in life, may be sparked by an interest in reading children's literature as a child.\n\nStebbins makes a distinction between an amateur sports person playing a sport that has a professional equivalent such as football or tennis and a hobbyist playing a less formal sport or game that are rule bound but have no professional equivalent like deck tennis and long distance trekking. Amateur sport ranges from very informal play to highly competitive practice.\n\nEvidence suggests that playing sports helps improve physical and mental health.\n\nThere have been many instances where hobbyists and amateurs have achieved significant discoveries and developments. These are a small sample. \n\n", "id": "13287", "title": "Hobby"}
{"url": "https://en.wikipedia.org/wiki?curid=13288", "text": "Holland\n\nHolland is a region and former province on the western coast of the Netherlands. The name \"Holland\" is also frequently used to informally refer to the whole of the country of the Netherlands. This usage is commonly accepted in other countries, and not entirely uncommon among the Dutch themselves, though some in the Netherlands and particularly in other regions of the country may find it undesirable, misleading or insulting.\n\nFrom the 10th to the 16th century, Holland proper was a unified political region within the Holy Roman Empire as a county ruled by the Counts of Holland. By the 17th century, Holland had risen to become a maritime and economic power, dominating the other provinces of the newly independent Dutch Republic.\n\nThe area of the former County of Holland roughly coincides with the two current Dutch provinces of North Holland and South Holland, which together include the Netherlands' three largest cities: the \"de jure\" capital city of Amsterdam; Rotterdam, home of Europe's largest port; and the seat of government of The Hague.\n\nThe name \"Holland\" first appeared in sources in 866 for the region around Haarlem, and by 1064 was being used as the name of the entire county. By this time, the inhabitants of Holland were referring to themselves as \"Hollanders\". \"Holland\" is derived from the Middle Dutch term \"holtland\" (\"wooded land\"). This spelling variation remained in use until around the 14th century, at which time the name stabilised as \"Holland\" (alternative spellings at the time were \"Hollant\" and \"Hollandt\"). A popular folk etymology holds that \"Holland\" is derived from \"hol land\" (\"hollow land\") and was inspired by the low-lying geography of Holland.\n\nThe proper name of the area in both Dutch and English is \"Holland\". Holland is a part of the Netherlands. \"Holland\" is informally used in English and other languages, including sometimes the Dutch language itself, to mean the whole of the modern country of the Netherlands. This example of \"pars pro toto\" or synecdoche is similar to the tendency to refer to the United Kingdom as \"England\", and developed due to Holland becoming the dominant province and thus having the majority of political and economic interactions with other countries.\n\nUnder Napoleon this usage was made official, the puppet kingdom ruled by his brother Louis Bonaparte being given the name \"Kingdom of Holland\" – but this was dropped after Napoleon's defeat and the restoration of the House of Orange.\n\nThe people of Holland are referred to as \"Hollanders\" in both Dutch and English. Today this refers specifically to people from the current provinces of North Holland and South Holland. Strictly speaking, the term \"Hollanders\" does not refer to people from the other provinces in the Netherlands, but colloquially \"Hollanders\" is sometimes used in this wider sense.\n\nIn Dutch, the Dutch word \"\"Hollands\"\" is the adjectival form for \"\"Holland\"\". The Dutch word \"\"Hollands\"\" is also colloquially and occasionally used by some Dutch people in the sense of \"\"Nederlands\"\" (Dutch), but then often with the intention of contrasting with other types of Dutch people or language, for example Limburgish, the Belgian form of the Dutch language (\"Flemish\"), or even any southern variety of Dutch within the Netherlands itself.\n\nIn English, \"Dutch\" refers to the Netherlands as a whole, but there is no commonly used adjective for \"Holland\". The word \"Hollandish\" is no longer in common use. \"Hollandic\" is the name linguists give to the dialect spoken in Holland, and is occasionally also used by historians and when referring to pre-Napoleonic Holland.\n\nInitially, Holland was a remote corner of the Holy Roman Empire. Gradually, its regional importance increased until it began to have a decisive, and ultimately dominant, influence on the History of the Netherlands.\n\nUntil the start of the 12th century, the inhabitants of the area that became Holland were known as Frisians. The area was initially part of Frisia. At the end of the 9th century, West-Frisia became a separate county in the Holy Roman Empire. The first Count known about with certainty was Dirk I, who ruled from 896 to 931. He was succeeded by a long line of counts in the House of Holland (who were in fact known as counts of Frisia until 1101). When John I, count of Holland, died childless in 1299, the county was inherited by John II of Avesnes, count of Hainaut. By the time of William V (House of Wittelsbach; 1354–1388) the count of Holland was also the count of Hainaut and Zealand.\n\nAfter the St. Lucia's flood in 1287 the part of Frisia west of the later Zuiderzee, West Friesland, was conquered. As a result, most provincial institutions, including the States of Holland and West Frisia, would for more than five centuries refer to \"Holland and West Frisia\" as a unit. The Hook and Cod wars started around this time and ended when the countess of Holland, Jacoba or Jacqueline was forced to give up Holland to the Burgundian Philip III, known as Philip the Good, in 1432.\n\nIn 1432, Holland became part of the Burgundian Netherlands and since 1477 of the Habsburg Seventeen Provinces. In the 16th century the county became the most densely urbanised region in Europe, with the majority of the population living in cities. Within the Burgundian Netherlands, Holland was the dominant province in the north; the political influence of Holland largely determined the extent of Burgundian dominion in that area. The last count of Holland was Philip III, better known as Philip II, king of Spain. He was deposed in 1581 by the Act of Abjuration, although the kings of Spain continued to carry the titular appellation of Count of Holland until the Peace of Münster signed in 1648.\n\nIn the Dutch Rebellion against the Habsburgs during the Eighty Years' War, the naval forces of the rebels, the Watergeuzen, established their first permanent base in 1572 in the town of Brill. In this way, Holland, now a sovereign state in a larger Dutch confederation, became the centre of the rebellion. It became the cultural, political and economic centre of the United Provinces (), in the 17th century, the Dutch Golden Age, the wealthiest nation in the world. After the King of Spain was deposed as the count of Holland, the executive and legislative power rested with the States of Holland, which was led by a political figure who held the office of Grand Pensionary.\n\nThe largest cities in the Dutch Republic were in the province of Holland, such as Amsterdam, Rotterdam, Leiden, Alkmaar, The Hague, Delft, Dordrecht and Haarlem. From the great ports of Holland, Hollandic merchants sailed to and from destinations all over Europe, and merchants from all over Europe gathered to trade in the warehouses of Amsterdam and other trading cities of Holland.\n\nMany Europeans thought of the United Provinces first as \"Holland\" rather than as the \"Republic of the Seven United Provinces of the Netherlands\". A strong impression of \"Holland\" was planted in the minds of other Europeans, which then was projected back onto the Republic as a whole. Within the provinces themselves, a gradual slow process of cultural expansion took place, leading to a \"Hollandification\" of the other provinces and a more uniform culture for the whole of the Republic. The dialect of urban Holland became the standard language.\n\nThe formation of the Batavian Republic, inspired by the French revolution, led to a more centralised government. Holland became a province of a unitary state. Its independence was further reduced by an administrative reform in 1798, in which its territory was divided into several departments called \"Amstel\", \"Delf\", \"Texel\", and part of \"Schelde en Maas\".\n\nFrom 1806 to 1810 Napoleon styled his vassal state, governed by his brother Louis Napoleon and shortly by the son of Louis, Napoleon Louis Bonaparte, as the \"Kingdom of Holland\". This kingdom encompassed much of what would become the modern Netherlands. The name reflects how natural at the time it had become to equate Holland with the non-Belgian Netherlands as a whole.\n\nDuring the period the Low Countries were annexed by the French Empire and actually incorporated into France (from 1810 to 1813), Holland was divided into départements Zuyderzée, and Bouches-de-la-Meuse. From 1811 to 1813 Charles-François Lebrun, duc de Plaisance served as governor-general. He was assisted by Antoine de Celles, Goswin de Stassart and François Jean-Baptiste d'Alphonse.\n\nAfter 1813, Holland was restored as a province of the United Kingdom of the Netherlands. Holland was divided into the present provinces North Holland and South Holland in 1840, after the Belgian Revolution of 1830. This reflected a historical division of Holland along the IJ into a Southern Quarter (\"Zuiderkwartier\") and a Northern Quarter (\"Noorderkwartier\"), but the actual division is different from the old division. From 1850, a strong process of nation formation took place, the Netherlands being culturally unified and economically integrated by a modernisation process, with the cities of Holland as its centre.\n\nHolland is situated in the west of the Netherlands. A maritime region, Holland lies on the North Sea at the mouths of the Rhine and the Meuse (Maas). It has numerous rivers and lakes and an extensive inland canal and waterway system. To the south is Zealand. The region is bordered on the east by the IJsselmeer and four different provinces of the Netherlands.\n\nHolland is protected from the sea by a long line of coastal dunes. Most of the land area behind the dunes consists of polder landscape lying well below sea level. At present the lowest point in Holland is a polder near Rotterdam, which is about below sea level. Continuous drainage is necessary to keep Holland from flooding. In earlier centuries windmills were used for this task. The landscape was (and in places still is) dotted with windmills, which have become a symbol of Holland.\n\nHolland is (land and water included), making it roughly 13% of the area of the Netherlands. Looking at land alone, it is in area. The combined population is 6.1 million.\n\nThe main cities in Holland are Amsterdam, Rotterdam and The Hague. Amsterdam is formally the capital of the Netherlands and its largest city. The Port of Rotterdam is Europe's largest and most important harbour and port. The Hague is the seat of government of the Netherlands. These cities, combined with Utrecht and other smaller municipalities, effectively form a single metroplex—a conurbation called Randstad.\n\nThe Randstad area is one of the most densely populated regions of Europe, but still relatively free of urban sprawl. There are strict zoning laws. Population pressures are enormous, property values are high, and new housing is constantly under development on the edges of the built-up areas. Surprisingly, much of the province still has a rural character. The remaining agricultural land and natural areas are highly valued and protected. Most of the arable land is used for intensive agriculture, including horticulture and greenhouse agri-businesses.\n\nThe land that is now Holland had never been stable. Over the millennia the geography of the region had been dynamic. The western coastline shifted up to to the east and storm surges regularly broke through the row of coastal dunes. The Frisian Isles, originally joined to the mainland, became detached islands in the north. The main rivers, the Rhine and the Meuse (Maas), flooded regularly and changed course repeatedly and dramatically.\n\nThe people of Holland found themselves living in an unstable, watery environment. Behind the dunes on the coast of the Netherlands a high peat plateau had grown, forming a natural protection against the sea. Much of the area was marsh and bog. By the tenth century the inhabitants set about cultivating this land by draining it. However, the drainage resulted in extreme soil shrinkage, lowering the surface of the land by up to .\n\nTo the south of Holland, in Zeeland, and to the north, in Frisia, this development led to catastrophic storm floods literally washing away entire regions, as the peat layer disintegrated or became detached and was carried away by the flood water. From the Frisian side the sea even flooded the area to the east, gradually hollowing Holland out from behind and forming the Zuiderzee (the present IJsselmeer). This inland sea threatened to link up with the \"drowned lands\" of Zealand in the south, reducing Holland to a series of narrow dune barrier islands in front of a lagoon. Only drastic administrative intervention saved the county from utter destruction. The counts and large monasteries took the lead in these efforts, building the first heavy emergency dikes to bolster critical points. Later special autonomous administrative bodies were formed, the \"waterschappen\" (\"water control boards\"), which had the legal power to enforce their regulations and decisions on water management. As the centuries went by, they eventually constructed an extensive dike system that covered the coastline and the polders, thus protecting the land from further incursions by the sea.\n\nHowever, the Hollanders did not stop there. Starting around the 16th century, they took the offensive and began land reclamation projects, converting lakes, marshy areas and adjoining mudflats into polders. This continued right into the 20th century. As a result, historical maps of mediaeval and early modern Holland bear little resemblance to the maps of today.\n\nThis ongoing struggle to master the water played an important role in the development of Holland as a maritime and economic power and in the development of the character of the people of Holland.\n\nHolland tends to be associated with a particular image. The stereotypical image of Holland is an artificial amalgam of tulips, windmills, clogs, cheese and traditional dress (\"klederdracht\"). As is the case with many stereotypes, this is far from the truth and reality of life in Holland. This can at least in part be explained by the active exploitation of these stereotypes in promotions of Holland and the Netherlands. In fact only in a few of the more traditional villages, such as Volendam and locations in the Zaan area, are the different costumes with wooden shoes still worn by some inhabitants.\n\nThe predominance of Holland in the Netherlands has resulted in regionalism on the part of the other provinces. This is a reaction to the perceived threat that Holland poses to the identities and local cultures of the other provinces. The other provinces have a strong, and often negative, image of Holland and the Hollanders, to whom certain qualities are ascribed within a mental geography, a conceptual mapping of spaces and their inhabitants. On the other hand, some Hollanders take Holland's cultural dominance for granted and treat the concepts of \"Holland\" and the \"Netherlands\" as coincidental. Consequently, they see themselves not primarily as \"Hollanders\", but simply as \"Dutch\" (\"Nederlanders\"). This phenomenon has been called \"hollandocentrism\".\n\nThe predominant language spoken in Holland is Dutch. Hollanders sometimes refer to the Dutch language as \"\"Hollands,\"\" instead of the standard term \"Nederlands\". Inhabitants of Belgium and other provinces of the Netherlands refer to \"Hollands\" to indicate someone speaking in a Hollandic dialect, or strong accent.\n\nStandard Dutch was historically largely based on the dialect of the County of Holland, incorporating many traits derived from the dialects of the previously more powerful Duchy of Brabant and County of Flanders. Strong dialectal variation still exists throughout the Low Countries. Today, Holland-proper is the region where the original dialects are least spoken, in many areas having been completely replaced by standard Dutch, and the Randstad has the largest influence on the developments of the standard language—with the exception of the Dutch spoken in Belgium.\n\nDespite this correspondence between standard Dutch and the Dutch spoken in the Randstad, there are local variations within Holland itself that differ from standard Dutch. The main cities each have their own modern urban dialect, that can be considered a sociolect. A small number of people, especially in the area north of Amsterdam, still speak the original dialect of the county, Hollandic. The Hollandic dialect is present in the north: Volendam and Marken and the area around there, West Friesland and the Zaanstreek; and in a south-eastern fringe bordering on the provinces of North Brabant and Utrecht. In the south on the island of Goeree-Overflakkee, Zealandic is spoken.\n\nThe province of Holland gave its name to a number of colonial settlements and discovered regions that were called \"Nieuw Holland\" or New Holland. The most extensive of these was the island continent presently known as Australia: New Holland was first applied to Australia in 1644 by the Dutch seafarer Abel Tasman as a Latin \"Nova Hollandia\", and remained in international use for 190 years. On the same voyage he named New Zealand after the Dutch province of Zeeland. In the Netherlands \"Nieuw Holland\" would remain the usual name of the continent until the end of the 19th century; it is now no longer in use there, the Dutch name today being \"Australië\".\n\n", "id": "13288", "title": "Holland"}
{"url": "https://en.wikipedia.org/wiki?curid=13289", "text": "History of the Netherlands\n\nThe history of the Netherlands is the history of seafaring people thriving on a lowland river delta on the North Sea in northwestern Europe. Records begin with the four centuries during which the region formed a militarized border zone of the Roman empire. This came under increasing pressure from Germanic peoples moving westwards. As Roman power collapsed and the Middle Ages began, three dominant Germanic peoples coalesced in the area, Frisians in the north and coastal areas, Low Saxons in the northeast, and the Franks in the south.\n\nDuring the Middle Ages, the descendants of the Carolingian dynasty came to dominate the area and then extended their rule to a large part of Western Europe. The region of the Netherlands therefore became part of Lower Lotharingia within the Frankish Holy Roman Empire. For several centuries, lordships such as Brabant, Holland, Zeeland, Friesland, Guelders and others held a changing patchwork of territories. There was no unified equivalent of the modern Netherlands.\nBy 1433, the Duke of Burgundy had assumed control over most of the lowlands territories in Lower Lotharingia; he created the Burgundian Netherlands which included modern Belgium, Luxembourg, and a part of France.\n\nThe Catholic kings of Spain took strong measures against the new Protestantism and other dissent, which polarized those peoples of present-day Belgium and Holland. The subsequent Dutch revolt led to splitting the Burgundian Netherlands into a Catholic French and Dutch-speaking \"Spanish Netherlands\" (approximately modern) Belgium and Luxembourg, and a northern \"United Provinces\", which spoke Dutch and was predominantly Protestant, with a large Catholic minority. It became the modern Netherlands.\n\nIn the Dutch Golden Age, which had its zenith around 1667, there was a flowering of trade, industry, the arts and the sciences. A rich worldwide Dutch empire developed and the Dutch East India Company became one of the earliest and most important of national mercantile companies based on entrepreneurship and trade.\n\nDuring the 18th century the power and wealth of the Netherlands declined. A series of wars with the more powerful British and French neighbors weakened it. Britain seized the North American colony of New Amsterdam, turning it into New York. There was growing unrest and conflict between the Orangists and the Patriots. The French Revolution spilled over after 1789, and a pro-French Batavian Republic was established in 1795–1806. Napoleon made it a satellite state, the Kingdom of Holland (1806–1810), and later simply a French imperial province.\n\nAfter the collapse of Napoleon in 1813–15, an expanded \"United Kingdom of the Netherlands\" was created with the House of Orange as monarchs, also ruling Belgium and Luxembourg. The King imposed unpopular Protestant reforms on Belgium, which revolted in 1830 and became independent in 1839. After an initially conservative period, in the 1848 constitution the country became a parliamentary democracy with a constitutional monarch. Modern Luxembourg became officially independent from the Netherlands in 1839, but a personal union remained until 1890. Since 1890 it is ruled by another branch of the House of Nassau.\n\nThe Netherlands was neutral during the First World War, but during the Second World War, it was invaded and occupied by Nazi Germany. The Nazis, including many collaborators, rounded up and killed almost all the Jews (most famously Anne Frank). When the Dutch resistance increased, the Nazis cut off food supplies to much of the country, causing severe starvation in 1944–45. In 1942, the Dutch East Indies was conquered by Japan, but first the Dutch destroyed the oil wells that Japan needed so badly. Indonesia proclaimed its independence in 1945. Suriname gained independence in 1975. The postwar years saw rapid economic recovery (helped by the American Marshall Plan), followed by the introduction of a welfare state during an era of peace and prosperity. The Netherlands formed a new economic alliance with Belgium and Luxembourg, the Benelux, and all three became founding members of the European Union and NATO. In recent decades, the Dutch economy has been closely linked to that of Germany, and is highly prosperous.\n\nThe prehistory of the area that is now the Netherlands was largely shaped by its constantly shifting, low-lying geography.\nThe area that is now the Netherlands was inhabited by early humans at least 37,000 years ago, as attested by flint tools discovered in Woerden in 2010. In 2009 a fragment of a 40,000-year-old Neanderthal skull was found in sand dredged from the North Sea floor off the coast of Zeeland.\n\nDuring the last ice age, the Netherlands had a tundra climate with scarce vegetation and the inhabitants survived as hunter-gatherers. After the end of the ice age, various Paleolithic groups inhabited the area. It is known that around 8000 BC a Mesolithic tribe resided near Burgumer Mar (Friesland). Another group residing elsewhere is known to have made canoes. The oldest recovered canoe in the world is the Pesse canoe. According to C14 dating analysis it was constructed somewhere between 8200 BC and 7600 BC. This canoe is exhibited in the Drents Museum in Assen.\n\nAutochthonous hunter-gatherers from the Swifterbant culture are attested from around 5600 BC onwards. They are strongly linked to rivers and open water and were related to the southern Scandinavian Ertebølle culture (5300–4000 BC). To the west, the same tribes might have built hunting camps to hunt winter game, including seals.\n\nAgriculture arrived in the Netherlands somewhere around 5000 BC with the Linear Pottery culture, who were probably central European farmers. Agriculture was practised only on the loess plateau in the very south (southern Limburg), but even there it was not established permanently. Farms did not develop in the rest of the Netherlands.\n\nThere is also some evidence of small settlements in the rest of the country. These people made the switch to animal husbandry sometime between 4800 BC and 4500 BC. Dutch archaeologist Leendert Louwe Kooijmans wrote, \"It is becoming increasingly clear that the agricultural transformation of prehistoric communities was a purely indigenous process that took place very gradually.\" This transformation took place as early as 4300 BC–4000 BC and featured the introduction of grains in small quantities into a traditional broad-spectrum economy.\n\nThe Funnelbeaker culture was a farming culture extending from Denmark through northern Germany into the northern Netherlands. In this period of Dutch prehistory the first notable remains were erected: the dolmens, large stone grave monuments. They are found in Drenthe, and were probably built between 4100 BC and 3200 BC.\n\nTo the west, the Vlaardingen culture (around 2600 BC), an apparently more primitive culture of hunter-gatherers survived well into the Neolithic period.\n\nAround 2950 BCE there was a transition from the Funnelbeaker farming culture to the Corded Ware pastoralist culture, a large archeological horizon appearing in western and central Europe, that is associated with the advance of Indo-European languages. This transition was probably caused by developments in eastern Germany, and it occurred within two generations.\n\nThe Bell Beaker culture was also present in the Netherlands.\n\nThe Corded Ware and Bell Beaker cultures were not indigenous to the Netherlands but were pan-European in nature, extending across much of northern and central Europe.\n\nThe first evidence of the use of the wheel dates from this period, about 2400 BC. This culture also experimented with working with copper. Evidence of this, including stone anvils, copper knives, and a copper spearhead, was found on the Veluwe. Copper finds show that there was trade with other areas in Europe, as natural copper is not found in Dutch soil.\n\nThe Bronze age probably started somewhere around 2000 BC and lasted until around 800 BC. The earliest bronze tools have been found in the grave of a Bronze Age individual called \"the smith of Wageningen\". More Bronze Age objects from later periods have been found in Epe, Drouwen and elsewhere. Broken bronze objects found in Voorschoten were apparently destined for recycling. This indicates how valuable bronze was considered in the Bronze Age. Typical bronze objects from this period included knives, swords, axes, fibulae and bracelets.\nMost of the Bronze Age objects found in the Netherlands have been found in Drenthe. One item shows that trading networks during this period extended a far distance. Large bronze \"situlae\" (buckets) found in Drenthe were manufactured somewhere in eastern France or in Switzerland. They were used for mixing wine with water (a Roman/Greek custom). The many finds in Drenthe of rare and valuable objects, such as tin-bead necklaces, suggest that Drenthe was a trading centre in the Netherlands in the Bronze Age.\n\nThe Bell Beaker cultures (2700–2100) locally developed into the Bronze Age Barbed-Wire Beaker culture (2100–1800). In the second millennium BC, the region was the boundary between the Atlantic and Nordic horizons and was split into a northern and a southern region, roughly divided by the course of the Rhine.\n\nIn the north, the Elp culture (c. 1800 to 800 BC) was a Bronze Age archaeological culture having earthenware pottery of low quality known as \"\"Kümmerkeramik\"\" (or \"\"Grobkeramik\"\") as a marker. The initial phase was characterized by tumuli (1800–1200 BC) that were strongly tied to contemporary tumuli in northern Germany and Scandinavia, and were apparently related to the Tumulus culture (1600–1200 BC) in central Europe. This phase was followed by a subsequent change featuring Urnfield (cremation) burial customs (1200–800 BC). The southern region became dominated by the Hilversum culture (1800–800), which apparently inherited the cultural ties with Britain of the previous Barbed-Wire Beaker culture.\n\nThe Iron Age brought a measure of prosperity to the people living in the area of the present-day Netherlands. Iron ore was available throughout the country, including bog iron extracted from the ore in peat bogs (\"moeras ijzererts\") in the north, the natural iron-bearing balls found in the Veluwe and the red iron ore near the rivers in Brabant. Smiths travelled from small settlement to settlement with bronze and iron, fabricating tools on demand, including axes, knives, pins, arrowheads and swords. Some evidence even suggests the making of Damascus steel swords using an advanced method of forging that combined the flexibility of iron with the strength of steel.\n\nIn Oss, a grave dating from around 500 BC was found in a burial mound 52 metres wide (and thus the largest of its kind in western Europe). Dubbed the \"king's grave\" (\"Vorstengraf (Oss)\"), it contained extraordinary objects, including an iron sword with an inlay of gold and coral.\n\nIn the centuries just before the arrival of the Romans, northern areas formerly occupied by the Elp culture emerged as the probably Germanic Harpstedt culture while the southern parts were influenced by the Hallstatt culture and assimilated into the Celtic La Tène culture. The contemporary southern and western migration of Germanic groups and the northern expansion of the Hallstatt culture drew these peoples into each other's sphere of influence. This is consistent with Caesar's account of the Rhine forming the boundary between Celtic and Germanic tribes.\n\nThe Germanic tribes originally inhabited southern Scandinavia, Schleswig-Holstein and Hamburg, but subsequent Iron Age cultures of the same region, like Wessenstedt (800–600 BC) and Jastorf, may also have belonged to this grouping.\nThe climate deteriorating in Scandinavia around 850 BC to 760 BC and later and faster around 650 BC might have triggered migrations. Archaeological evidence suggests around 750 BC a relatively uniform Germanic people from the Netherlands to the Vistula and southern Scandinavia. In the west, the newcomers settled the coastal floodplains for the first time, since in adjacent higher grounds the population had increased and the soil had become exhausted.\n\nBy the time this migration was complete, around 250 BC, a few general cultural and linguistic groupings had emerged.\n\nOne grouping - labelled the \"North Sea Germanic\" – inhabited the northern part of the Netherlands (north of the great rivers) and extending along the North Sea and into Jutland. This group is also sometimes referred to as the \"Ingvaeones\". Included in this group are the peoples who would later develop into, among others, the early Frisians and the early Saxons.\n\nA second grouping, which scholars subsequently dubbed the \"Weser-Rhine Germanic\" (or \"Rhine-Weser Germanic\"), extended along the middle Rhine and Weser and inhabited the southern part of the Netherlands (south of the great rivers). This group, also sometimes referred to as the \"Istvaeones\", consisted of tribes that would eventually develop into the Salian Franks.\nThe Celtic culture had its origins in the central European Hallstatt culture (c. 800–450 BC), named for the rich grave finds in Hallstatt, Austria. By the later La Tène period (c. 450 BC up to the Roman conquest), this Celtic culture had, whether by diffusion or migration, expanded over a wide range, including into the southern area of the Netherlands. This would have been the northern reach of the Gauls.\n\nIn March 2005 17 Celtic coins were found in Echt (Limburg). The silver coins, mixed with copper and gold, date from around 50 BC to 20 AD. In October 2008 a horde of 39 gold coins and 70 silver Celtic coins was found in the Amby area of Maastricht. The gold coins were attributed to the Eburones people. Celtic objects have also been found in the area of Zutphen.\n\nAlthough it is rare for hoards to be found, in past decades loose Celtic coins and other objects have been found throughout the central, eastern and southern part of the Netherlands. According to archaeologists these finds confirmed that at least the Maas river valley in the Netherlands was within the influence of the La Tène culture. Dutch archaeologists even speculate that Zutphen (which lies in the centre of the country) was a Celtic area before the Romans arrived, not a Germanic one at all.\n\nScholars debate the actual extent of the Celtic influence. The Celtic influence and contacts between Gaulish and early Germanic culture along the Rhine is assumed to be the source of a number of Celtic loanwords in Proto-Germanic. But according to Belgian linguist Luc van Durme, toponymic evidence of a former Celtic presence in the Low Countries is near to utterly absent. Although there were Celts in the Netherlands, Iron Age innovations did not involve substantial Celtic intrusions and featured a local development from Bronze Age culture.\n\nSome scholars (De Laet, Gysseling, Hachmann, Kossack & Kuhn) have speculated that a separate ethnic identity, neither Germanic nor Celtic, survived in the Netherlands until the Roman period. They see the Netherlands as having been part of an Iron Age \"Nordwestblock\" stretching from the Somme to the Weser. Their view is that this culture, which had its own language, was being absorbed by the Celts to the south and the Germanic peoples from the east as late as the immediate pre-Roman period.\n\nDuring the Gallic Wars, the Belgic area south of the Oude Rijn and west of the Rhine was conquered by Roman forces under Julius Caesar in a series of campaigns from 57 BC to 53 BC. The tribes located in the area of the Netherlands at this time did not leave behind written records, so all the information known about them during this pre-Roman period is based on what the Romans and Greeks wrote about them. One of the most important is Caesar's own \"Commentarii de Bello Gallico\". Two main tribes he described as living in what is now the Netherlands were the Menapii, and the Eburones, both in the south, which is where Caesar was active. He established the principle that the Rhine defined a natural boundary between Gaul and Germania magna. But the Rhine was not a strong border, and he made it clear that there was a part of Belgic Gaul where many of the local tribes (including the Eburones) were \"Germani cisrhenani\", or in other cases, of mixed origin.\n\nThe Menapii stretched from the south of Zeeland, through North Brabant (and possibly South Holland), into the southeast of Gelderland. In later Roman times their territory seems to have been divided or reduced, so that it became mainly contained in what is now western Belgium.\n\nThe Eburones, the largest of the \"Germani Cisrhenani\" group, covered a large area including at least part of modern Dutch Limburg, stretching east to the Rhine in Germany, and also northwest to the delta, giving them a border with the Menapii. Their territory may have stretched into Gelderland.\n\nIn the delta itself, Caesar makes a passing comment about the \"Insula Batavorum\" (\"Island of the Batavi\") in the Rhine river, without discussing who lived there. Later, in imperial times, a tribe called the Batavi became very important in this region. Much later Tacitus wrote that they had originally been a tribe of the Chatti, a tribe in Germany never mentioned by Caesar. However, archaeologists find evidence of continuity, and suggest that the Chattic group may have been a small group, moving into a pre-existing (and possibly non-Germanic) people, who could even have been part of a known group such as the Eburones.\n\nThe approximately 450 years of Roman rule that followed would profoundly change the area that would become the Netherlands. Very often this involved large-scale conflict with the free Germanic tribes over the Rhine.\n\nOther tribes who eventually inhabited the islands in the delta during Roman times are mentioned by Pliny the Elder are the Cananefates in South Holland; the Frisii, covering most of the modern Netherlands north of the Oude Rijn; the Frisiabones, who apparently stretched from the delta into the North of North Brabant; the Marsacii, who stretched from the Flemish coast, into the delta; and the Sturii.\n\nCaesar reported that he eliminated the name of the Eburones but in their place the Texuandri inhabited most of North Brabant, and the modern province of Limburg, with the Maas running through it, appears to have been inhabited in imperial times by (from north to south) the Baetasii, the Catualini, the Sunuci and the Tungri. (Tacitus reported that the Tungri was a new name for the earlier \"Germani cisrhenani\".)\n\nNorth of the Old Rhine, apart from the Frisii, Pliny reports some Chauci reached into the delta, and two other tribes known from the eastern Netherlands were the Tuihanti (or Tubantes) from Twenthe in Overijssel, and the Chamavi, from Hamaland in northern Gelderland, who became one of the first tribes to be named as Frankish (see below). The Salians, also Franks, probably originated in Salland in Overijssel, before they moved into the empire, forced by Saxons in the 4th century, first into Batavia, and then into Toxandria.\n\nStarting about 15 BC, the Rhine, in the Netherlands came to be defended by the Lower Limes Germanicus. After a series of military actions, the Rhine became fixed around 12 AD as Rome's northern frontier on the European mainland. A number of towns and developments would arise along this line. The area to the south would be integrated into the Roman Empire. At first part of Gallia Belgica, this area became part of the province of Germania Inferior. The tribes already within, or relocated to, this area became part of the Roman Empire. The area to the north of the Rhine, inhabited by the Frisii and the Chauci, remained outside Roman rule but not its presence and control.\n\nRomans built military forts along the Limes Germanicus and a number of towns and smaller settlements in the Netherlands. The more notable Roman towns were at Nijmegen () and at Voorburg (Forum Hadriani).\n\nPerhaps the most evocative Roman ruin is the mysterious Brittenburg, which emerged from the sand at the beach in Katwijk several centuries ago, only to be buried again. These ruins were part of .\n\nOther Roman settlements, fortifications, temples and other structures have been found at Alphen aan de Rijn (); Bodegraven; Cuijk; Elst, Overbetuwe; Ermelo; Esch; Heerlen; Houten; Kessel, North Brabant; Oss, i.e. De Lithse Ham near Maren-Kessel; Kesteren in Neder-Betuwe; Leiden (); Maastricht; Meinerswijk (now part of Arnhem); Tiel; Utrecht (Traiectum); Valkenburg (South Holland) (); Vechten (Fectio) now part of Bunnik; Velsen; Vleuten; Wijk bij Duurstede (); Woerden ( or ); and Zwammerdam ().\n\nThe Batavians, Cananefates, and the other border tribes were held in high regard as soldiers throughout the empire, and traditionally served in the Roman cavalry. The frontier culture was influenced by the Romans, Germanic people, and Gauls. In the first centuries after Rome's conquest of Gaul, trade flourished. And Roman, Gaulish and Germanic material culture are found combined in the region.\n\nHowever, the Batavians rose against the Romans in the Batavian rebellion of 69 AD. The leader of this revolt was Batavian Gaius Julius Civilis. One of the causes of the rebellion was that the Romans had taken young Batavians as slaves. A number of Roman \"castella\" were attacked and burnt. Other Roman soldiers in Xanten and elsewhere and auxiliary troops of Batavians and Canninefatae in the legions of Vitellius) joined the revolt, thus splitting the northern part of the Roman army. In April 70 AD, a few legions sent by Vespasianus and commanded by Quintus Petillius Cerialis eventually defeated the Batavians and negotiated surrender with Gaius Julius Civilis somewhere between the Waal and the Maas near Noviomagus (Nijmegen), which was probably called \"Batavodurum\" by the Batavians. The Batavians later merged with other tribes and became part of the Salian Franks.\n\nDutch writers in the 17th and 18th centuries saw the rebellion of the independent and freedom-loving Batavians as mirroring the Dutch revolt against Spain and other forms of tyranny. According to this nationalist view, the Batavians were the \"true\" forefathers of the Dutch, which explains the recurring use of the name over the centuries. Jakarta was named \"Batavia\" by the Dutch in 1619. The Dutch republic created in 1795 on the basis of French revolutionary principles was called the Batavian Republic. Even today \"Batavian\" is a term sometimes used to describe the Dutch people. (This is similar to use of \"Gallic\" to describe the French and \"Teutonic\" to describe the Germans.)\n\nModern scholars of the Migration Period are in agreement that the Frankish identity emerged at the first half of the 3rd century out of various earlier, smaller Germanic groups, including the Salii, Sicambri, Chamavi, Bructeri, Chatti, Chattuarii, Ampsivarii, Tencteri, Ubii, Batavi and the Tungri, who inhabited the lower and middle Rhine valley between the Zuyder Zee and the river Lahn and extended eastwards as far as the Weser, but were the most densely settled around the IJssel and between the Lippe and the Sieg. The Frankish confederation probably began to coalesce in the 210s.\n\nThe Franks eventually were divided into two groups: the Ripuarian Franks (Latin: Ripuari), who were the Franks that lived along the middle-Rhine River during the Roman Era, and the Salian Franks, who were the Franks that originated in the area of the Netherlands.\n\nFranks appear in Roman texts as both allies and enemies (\"laeti\" and \"dediticii\"). By about 320, the Franks had the region of the Scheldt river (present day west Flanders and southwest Netherlands) under control, and were raiding the Channel, disrupting transportation to Britain. Roman forces pacified the region, but did not expel the Franks, who continued to be feared as pirates along the shores at least until the time of Julian the Apostate (358), when Salian Franks were allowed to settle as \"foederati\" in Toxandria, according to Ammianus Marcellinus.\n\nThree factors contributed to the disappearance of the Frisii from the northern Netherlands. First, according to the \"Panegyrici Latini\" (Manuscript VIII), the ancient Frisii were forced to resettle within Roman territory as \"laeti\" (i.e., Roman-era serfs) in c. 296. This is the last reference to the ancient Frisii in the historical record. What happened to them, however, is suggested in the archaeological record. The discovery of a type of earthenware unique to 4th-century Frisia, called \"terp Tritzum\", shows that an unknown number of them were resettled in Flanders and Kent, likely as \"laeti\" under Roman coercion.\nSecond, the environment in the low-lying coastal regions of northwestern Europe began to lower c. 250 and gradually receded over the next 200 years. Tectonic subsidence, a rising water table and storm surges combined to flood some areas with marine transgressions. This was accelerated by a shift to a cooler, wetter climate in the region. If there had been any Frisii left in Frisia, they would have drowned. \nThird, after the collapse of the Roman Empire, there was a decline in population as Roman activity stopped and Roman institutions withdrew. As a result of these three factors, the Frisii and Frisiaevones disappeared from the area. The coastal lands remained largely unpopulated for the next two centuries.\n\nAs climatic conditions improved, there was another mass migration of Germanic peoples into the area from the east. This is known as the \"Migration Period\" (\"Volksverhuizingen\"). The northern Netherlands received an influx of new migrants and settlers, mostly Saxons, but also Angles and Jutes. Many of these migrants did not stay in the northern Netherlands but moved on to England and are known today as the Anglo-Saxons. The newcomers that stayed in the northern Netherlands would eventually be referred to as \"Frisians\", although they were not descended from the ancient Frisii. These new Frisians settled in the northern Netherlands and would become the ancestors of the modern Frisians. (Because the early Frisians and Anglo-Saxons were formed from largely identical tribal confederacies, their respective languages were very similar. Old Frisian is the most closely related language to Old English and the modern Frisian dialects are in turn the closest related languages to contemporary English.) By the end of the 6th century, the Frisian territory in the northern Netherlands had expanded west to the North Sea coast and, by the 7th century, south to Dorestad. During this period most of the northern Netherlands was known as Frisia. This extended Frisian territory is sometimes referred to as \"Frisia Magna\" (or Greater Frisia).\nIn the 7th and 8th centuries, the Frankish chronologies mention this area as the kingdom of the Frisians. This kingdom comprised the coastal provinces of the Netherlands and the German North Sea coast. During this time, the Frisian language was spoken along the entire southern North Sea coast. The 7th-century Frisian Kingdom (650–734) under King Aldegisel and King Redbad, had its centre of power in Utrecht.\n\nDorestad was the largest settlement (emporia) in northwestern Europe. It had grown around a former Roman fortress. It was a large, flourishing trading place, three kilometers long and situated where the rivers Rhine and Lek diverge southeast of Utrecht near the modern town of Wijk bij Duurstede. Although inland, it was a North Sea trading centre that primarily handled goods from the Middle Rhineland. Wine was among the major products traded at Dorestad, likely from vineyards south of Mainz. It was also widely known because of its mint. Between 600 and around 719 Dorestad was often fought over between the Frisians and the Franks.\n\nAfter Roman government in the area collapsed, the Franks expanded their territories until there were numerous small Frankish kingdoms, especially at Cologne, Tournai, Le Mans and Cambrai. The kings of Tournai eventually came to subdue the other Frankish kings. By the 490s, Clovis I had conquered and united all the Frankish territories to the west of the Meuse, including those in the southern Netherlands. He continued his conquests into Gaul.\n\nAfter the death of Clovis I in 511, his four sons partitioned his kingdom amongst themselves, with Theuderic I receiving the lands that were to become Austrasia (including the southern Netherlands). A line of kings descended from Theuderic ruled Austrasia until 555, when it was united with the other Frankish kingdoms of Chlothar I, who inherited all the Frankish realms by 558. He redivided the Frankish territory amongst his four sons, but the four kingdoms coalesced into three on the death of Charibert I in 567. Austrasia (including the southern Netherlands) was given to Sigebert I. The southern Netherlands remained the northern part of Austrasia until the rise of the Carolingians.\n\nThe Franks who expanded south into Gaul settled there and eventually adopted the Vulgar Latin of the local population. However, a Germanic language was spoken as a second tongue by public officials in western Austrasia and Neustria as late as the 850s. It completely disappeared as a spoken language from these regions during the 10th century. During this expansion to the south, many Frankish people remained in the north (i.e. southern Netherlands, Flanders and a small part of northern France). A widening cultural divide grew between the Franks remaining in the north and the rulers far to the south in what is now France. Salian Franks continued to reside in their original homeland and the area directly to the south and to speak their original language, Old Frankish, which by the 9th century had evolved into Old Dutch. A Dutch-French language boundary came into existence (but this was originally south of where it is today). In the Maas and Rhine areas of the Netherlands, the Franks had political and trading centres, especially at Nijmegen and Maastricht. These Franks remained in contact with the Frisians to the north, especially in places like Dorestad and Utrecht.\n\nIn the late 19th century, Dutch historians believed that the Franks, Frisians, and Saxons were the original ancestors of the Dutch people. Some went further by ascribing certain attributes, values and strengths to these various groups and proposing that they reflected 19th-century nationalist and religious views. In particular, it was believed that this theory explained why Belgium and the southern Netherlands (i.e. the Franks) had become Catholic and the northern Netherlands (Frisians and Saxons) had become Protestant. The success of this theory was partly due to anthropological theories based on a tribal paradigm. Being politically and geographically inclusive, and yet accounting for diversity, this theory was in accordance with the need for nation-building and integration during the 1890–1914 period. The theory was taught in Dutch schools.\n\nHowever, the disadvantages of this historical interpretation became apparent. This tribal-based theory suggested that external borders were weak or non-existent and that there were clear-cut internal borders. This origins myth provided an historical premise, especially during the Second World War, for regional separatism and annexation to Germany. After 1945 the tribal paradigm lost its appeal for anthropological scholars and historians. When the accuracy of the three-tribe theme was fundamentally questioned, the theory fell out of favour.\n\nDue to the scarcity of written sources, knowledge of this period depends to a large degree on the interpretation of archaeological data. The traditional view of a clear-cut division between Frisians in the north and coast, Franks in the south and Saxons in the east has proven historically problematic. Archeological evidence suggests dramatically different models for different regions, with demographic continuity for some parts of the country and depopulation and possible replacement in other parts, notably the coastal areas of Frisia and Holland.\n\nThe language from which Old Dutch (also sometimes called Old West Low Franconian, Old Low Franconian or Old Frankish) arose is not known with certainty, but it is thought to be the language spoken by the Salian Franks. Even though the Franks are traditionally categorized as Weser-Rhine Germanic, Dutch has a number of Ingvaeonic characteristics and is classified by modern linguists as an Ingvaeonic language. Dutch also has a number of Old Saxon characteristics. There was a close relationship between Old Dutch, Old Saxon, Old English and Old Frisian. Because texts written in the language spoken by the Franks are almost non-existent, and Old Dutch texts scarce and fragmentary, not much is known about the development of Old Dutch. Old Dutch made the transition to Middle Dutch around 1150.\n\nThe Christianity that arrived in the Netherlands with the Romans appears not to have died out completely (in Maastricht, at least) after the withdrawal of the Romans in about 411.\n\nThe Franks became Christians after their king Clovis I converted to Catholicism, an event which is traditionally set in 496. Christianity was introduced in the north after the conquest of Friesland by the Franks. The Saxons in the east were converted before the conquest of Saxony, and became Frankish allies.\n\nHiberno-Scottish and Anglo-Saxon missionaries, particularly Willibrord, Wulfram and Boniface, played an important role in converting the Frankish and Frisian peoples to Christianity by the 8th century. Boniface was martyred by the Frisians in Dokkum (754).\n\nIn the early 8th century the Frisians came increasingly into conflict with the Franks to the south, resulting in a series of wars in which the Frankish Empire eventually subjugated Frisia. In 734, at the Battle of the Boarn, the Frisians in the Netherlands were defeated by the Franks, who thereby conquered the area west of the Lauwers. The Franks then conquered the area east of the Lauwers in 785 when Charlemagne defeated Widukind.\n\nThe linguistic descendants of the Franks, the modern Dutch-speakers of the Netherlands and Flanders, seem to have broken with the endonym \"Frank\" around the 9th century. By this time Frankish identity had changed from an ethnic identity to a national identity, becoming localized and confined to the modern \"Franconia\" and principally to the French province of \"Île-de-France\".\n\nAlthough the people no longer referred to themselves as \"Franks\", the Netherlands was still part of the Frankish empire of Charlemagne. Indeed, because of the Austrasian origins of the Carolingians in the area between the Rhine and the Maas, the cities of Aachen, Maastricht, Liège and Nijmegen were at the heart of Carolingian culture. Charlemagne maintained his \"palatium\" in Nijmegen at least four times.\n\nThe Carolingian empire would eventually include France, Germany, northern Italy and much of Western Europe. In 843, the Frankish empire was divided into three parts, giving rise to West Francia in the west, East Francia in the east, and Middle Francia in the centre. Most of what is today the Netherlands became part of Middle Francia; Flanders became part of West Francia. This division was an important factor in the historical distinction between Flanders and the other Dutch-speaking areas.\n\nMiddle Francia () was an ephemeral Frankish kingdom that had no historical or ethnic identity to bind its varied peoples. It was created by the Treaty of Verdun in 843, which divided the Carolingian Empire among the sons of Louis the Pious. Situated between the realms of East and West Francia, Middle Francia comprised the Frankish territory between the rivers Rhine and Scheldt, the Frisian coast of the North Sea, the former Kingdom of Burgundy (except for a western portion, later known as \"Bourgogne\"), Provence and the Kingdom of Italy.\n\nMiddle Francia fell to Lothair I, the eldest son and successor of Louis the Pious, after an intermittent civil war with his younger brothers Louis the German and Charles the Bald. In acknowledgement of Lothair's Imperial title, Middle Francia contained the imperial cities of Aachen, the residence of Charlemagne, as well as Rome. In 855, on his deathbed at Prüm Abbey, Emperor Lothair I again partitioned his realm amongst his sons. Most of the lands north of the Alps, including the Netherlands, passed to Lothair II and consecutively were named Lotharingia. After Lothair II died in 869, Lotharingia was partitioned by his uncles Louis the German and Charles the Bald in the Treaty of Meerssen in 870. Although some of the Netherlands had come under Viking control, in 870 it technically became part of East Francia, which became the Holy Roman Empire in 962.\n\nIn the 9th and 10th centuries, the Vikings raided the largely defenceless Frisian and Frankish towns lying on the coast and along the rivers of the Low Countries. Although Vikings never settled in large numbers in those areas, they did set up long-term bases and were even acknowledged as lords in a few cases. In Dutch and Frisian historical tradition, the trading centre of Dorestad declined after Viking raids from 834 to 863; however, since no convincing Viking archaeological evidence has been found at the site (as of 2007), doubts about this have grown in recent years.\n\nOne of the most important Viking families in the Low Countries was that of Rorik of Dorestad (based in Wieringen) and his brother the \"younger Harald\" (based in Walcheren), both thought to be nephews of Harald Klak. Around 850, Lothair I acknowledged Rorik as ruler of most of Friesland. And again in 870, Rorik was received by Charles the Bald in Nijmegen, to whom he became a vassal. Viking raids continued during that period. Harald’s son Rodulf and his men were killed by the people of Oostergo in 873. Rorik died sometime before 882.\n\nBuried Viking treasures consisting mainly of silver have been found in the Low Countries. Two such treasures have been found in Wieringen. A large treasure found in Wieringen in 1996 dates from around 850 and is thought perhaps to have been connected to Rorik. The burial of such a valuable treasure is seen as an indication that there was a permanent settlement in Wieringen.\n\nAround 879, Godfrid arrived in Frisian lands as the head of a large force that terrorised the Low Countries. Using Ghent as his base, they ravaged Ghent, Maastricht, Liège, Stavelot, Prüm, Cologne, and Koblenz. Controlling most of Frisia between 882 and his death in 885, Godfrid became known to history as Godfrid, Duke of Frisia. His lordship over Frisia was acknowledged by Charles the Fat, to whom he became a vassal. Godfried was assassinated in 885, after which Gerolf of Holland assumed lordship and Viking rule of Frisia came to an end.\n\nViking raids of the Low Countries continued for over a century. Remains of Viking attacks dating from 880 to 890 have been found in Zutphen and Deventer. In 920, King Henry of Germany liberated Utrecht. According to a number of chronicles, the last attacks took place in the first decade of the 11th century and were directed at Tiel and/or Utrecht.\n\nThese Viking raids occurred about the same time that French and German lords were fighting for supremacy over the middle empire that included the Netherlands, so their sway over this area was weak. Resistance to the Vikings, if any, came from local nobles, who gained in stature as a result.\n\nThe German kings and emperors ruled the Netherlands in the 10th and 11th century. Germany was called the Holy Roman Empire after the coronation of King Otto the Great as emperor. The Dutch city of Nijmegen used to be the spot of an important domain of the German emperors. Several German emperors were born and died there. (Byzantine empress Theophanu died in Nijmegen for instance.) Utrecht was also an important city and trading port at the time.\n\nThe Holy Roman Empire was not able to maintain political unity. In addition to the growing independence of the towns, local rulers turned their counties and duchies into private kingdoms and felt little sense of obligation to the emperor who reigned over large parts of the nation in name only. Large parts of what now comprise the Netherlands were governed by the Count of Holland, the Duke of Gelre, the Duke of Brabant and the Bishop of Utrecht. Friesland and Groningen in the north maintained their independence and were governed by the lower nobility.\n\nThe various feudal states were in a state of almost continual war. Gelre and Holland fought for control of Utrecht. Utrecht, whose bishop had in 1000 ruled over half of what is today the Netherlands, was marginalised as it experienced continuing difficulty in electing new bishops. At the same time, the dynasties of neighbouring states were more stable. Groningen, Drenthe and most of Gelre, which used to be part of Utrecht, became independent. Brabant tried to conquer its neighbours, but was not successful. Holland also tried to assert itself in Zeeland and Friesland, but its attempts failed.\n\nThe language and culture of most of the people who lived in the area that is now Holland were originally Frisian. The sparsely populated area was known as \"West Friesland\" (\"Westfriesland\"). As Frankish settlement progressed, the Frisians migrated away or were absorbed and the area quickly became Dutch. (The part of North Holland situated north of Alkmaar is still colloquially known as West Friesland).\n\nThe rest of Friesland in the north continued to maintain its independence during this time. It had its own institutions (collectively called the \"Frisian freedom\") and resented the imposition of the feudal system and the patriciate found in other European towns. They regarded themselves as allies of Switzerland. The Frisian battle cry was \"better dead than a slave\". They later lost their independence when they were defeated in 1498 by the German Landsknecht mercenaries of Duke Albrecht of Saxony-Meissen.\n\nThe center of power in these emerging independent territories was in the County of Holland. Originally granted as a fief to the Danish chieftain Rorik in return for loyalty to the emperor in 862, the region of Kennemara (the region around modern Haarlem) rapidly grew under Rorik's descendants in size and importance. By the early 11th century, Dirk III, Count of Holland was levying tolls on the Meuse estuary and was able to resist military intervention from his overlord, the Duke of Lower Lorraine.\n\nIn 1083, the name \"Holland\" first appears in a deed referring to a region corresponding more or less to the current province of South Holland and the southern half of what is now North Holland. Holland's influence continued to grow over the next two centuries. The counts of Holland conquered most of Zeeland but it was not until 1289 that Count Floris V was able to subjugate the Frisians in West Friesland (that is, the northern half of North Holland).\n\nAround 1000 AD there were several agricultural developments (described sometimes as an agricultural revolution) that resulted in an increase in production, especially food production. The economy started to develop at a fast pace, and the higher productivity allowed workers to farm more land or to become tradesmen.\n\nMuch of the western Netherlands was barely inhabited between the end of the Roman period until around 1100 AD, when farmers from Flanders and Utrecht began purchasing the swampy land, draining it and cultivating it. This process happened quickly and the uninhabited territory was settled in a few generations. They built independent farms that were not part of villages, something unique in Europe at the time.\n\nGuilds were established and markets developed as production exceeded local needs. Also, the introduction of currency made trading a much easier affair than it had been before. Existing towns grew and new towns sprang into existence around monasteries and castles, and a mercantile middle class began to develop in these urban areas. Commerce and town development increased as the population grew.\n\nThe Crusades were popular in the Low Countries and drew many to fight in the Holy Land. At home, there was relative peace. Viking pillaging had stopped. Both the Crusades and the relative peace at home contributed to trade and the growth in commerce.\n\nCities arose and flourished, especially in Flanders and Brabant. As the cities grew in wealth and power, they started to buy certain privileges for themselves from the sovereign, including city rights, the right to self-government and the right to pass laws. In practice, this meant that the wealthiest cities became quasi-independent republics in their own right. Two of the most important cities were Brugge and Antwerp (in Flanders) which would later develop into some of the most important cities and ports in Europe.\n\nThe Hook and Cod Wars () were a series of wars and battles in the County of Holland between 1350 and 1490. Most of these wars were fought over the title of count of Holland, but some have argued that the underlying reason was because of the power struggle of the bourgeois in the cities against the ruling nobility.\n\nThe Cod faction generally consisted of the more progressive cities of Holland. The Hook faction consisted for a large part of the conservative noblemen. Some of the main figures in this multi-generational conflict were William IV, Margaret, William V, William VI, Count of Holland and Hainaut, John and Philip the Good, Duke of Burgundy. But perhaps the most well known is Jacqueline, Countess of Hainaut.\n\nThe conquest of the county of Holland by the Duke Philip the Good of Burgundy was an odd affair. Leading noblemen in Holland invited the duke to conquer Holland, even though he had no historical claim to it. Some historians say that the ruling class in Holland wanted Holland to integrate with the Flemish economic system and adopt Flemish legal institutions. Europe had been wracked by many civil wars in the 14th and 15th centuries, while Flanders had grown rich and enjoyed peace.\n\nMost of what is now the Netherlands and Belgium was eventually united by the Duke of Burgundy in 1433. Before the Burgundian union, the Dutch identified themselves by the town they lived in, their local duchy or county or as subjects of the Holy Roman Empire. The Burgundian period is when the Dutch began the road to nationhood.\n\nHolland's trade developed rapidly, especially in the areas of shipping and transport. The new rulers defended Dutch trading interests. The fleets of Holland defeated the fleets of the Hanseatic League several times. Amsterdam grew and in the 15th century became the primary trading port in Europe for grain from the Baltic region. Amsterdam distributed grain to the major cities of Belgium, Northern France and England. This trade was vital to the people of Holland, because Holland could no longer produce enough grain to feed itself. Land drainage had caused the peat of the former wetlands to reduce to a level that was too low for drainage to be maintained.\n\nCharles V (1500–58) was born and raised in the Flemish city of Ghent; he spoke French. Charles extended the Burgundian territory with the annexation of Tournai, Artois, Utrecht, Groningen and Guelders. The Seventeen Provinces had been unified by Charles's Burgundian ancestors, but nominally were fiefs of either France or the Holy Roman Empire. When he was a minor, his aunt Margaret acted as regent until 1515. France relinquished its ancient claim on Flanders in 1528.\nFrom 1515 to 1523, Charles's government in the Netherlands had to contend with the rebellion of Frisian peasants (led by Pier Gerlofs Donia and Wijard Jelckama). Gelre attempted to build up its own state in northeast Netherlands and northwest Germany. Lacking funds in the 16th century, Gelre had its soldiers provide for themselves by pillaging enemy terrain. These soldiers were a great menace to the Burgundian Netherlands, as when they pillaged The Hague.\n\nThe dukes of Burgundy over the years through astute marriages, purchases and wars, had taken control of the Seventeen Provinces that made up the Low Countries. They are now the Netherlands in the north, the Southern Netherlands (now Belgium) in the south, and Luxemburg in the southeast. Known as the \"Burgundian Circle,\" these lands came under the control of the Habsburg family. Charles (1500–58) became the owner in 1506, but in 1515 he left to become king of Spain and later became the Holy Roman Emperor. Charles turned over control to regents (his close relatives), and in practice rule was exercised by Spaniards he controlled. The provinces each had their own governments and courts, controlled by the local nobility, and their own traditions and rights (\"liberties\") dating back centuries. Likewise the numerous cities had their own legal rights and local governments, usually controlled by the merchants, On top of this the Spanish had imposed an overall government, the Estates General of the Netherlands, with its own officials and courts. The Spanish officials sent by Charles ignored traditions and the Dutch nobility as well as local officials, inciting an anti-Spanish sense of nationalism, and leading to the Dutch Revolt. With the emergence of the Protestant Reformation, Charles—now the Emperor—was determined to crush Protestantism and never compromise with it. Unrest began in the south, centered in the large rich metropolis of Antwerp. The Netherlands was an especially rich unit of the Spanish realm, especially after the Treaty of Cateau-Cambresis of 1559; it ended four decades of warfare between France and Spain and allowed Spain to reposition its army.\n\nIn 1548, Charles granted the Netherlands status as an entity in which many of the laws of the Holy Roman Empire became obsolete. The \"Transaction of Augsburg.\" created the Burgundian Circle of the Holy Roman Empire, which comprised the Netherlands and Franche-Comté. A year later the Pragmatic Sanction of 1549 stated that the Seventeen Provinces could only be passed on to his heirs as a composite entity.\n\nDuring the 16th century, the Protestant Reformation rapidly gained ground in northern Europe, especially in its Lutheran and Calvinist forms. Dutch Protestants, after initial repression, were tolerated by local authorities. By the 1560s, the Protestant community had become a significant influence in the Netherlands, although it clearly formed a minority then. In a society dependent on trade, freedom and tolerance were considered essential. Nevertheless, the Catholic rulers Charles V, and later Philip II, made it their mission to defeat Protestantism, which was considered a heresy by the Catholic Church and a threat to the stability of the whole hierarchical political system. On the other hand, the intensely moralistic Dutch Protestants insisted their Biblical theology, sincere piety and humble lifestyle was morally superior to the luxurious habits and superficial religiosity of the ecclesiastical nobility. The rulers' harsh punitive measures led to increasing grievances in the Netherlands, where the local governments had embarked on a course of peaceful coexistence. In the second half of the century, the situation escalated. Philip sent troops to crush the rebellion and make the Netherlands once more a Catholic region.\n\nIn the first wave of the Reformation Lutheranism won over the elites in Antwerp and the South. The Spanish successfully suppressed it there, and Lutheranism only flourished in east Friesland.\n\nThe second wave of the Reformation, came in the form of Anabaptism, that was popular among ordinary farmers in Holland and Friesland. Anabaptists were socially very radical and equalitarian; they believed that the apocalypse was very near. They refused to live the old way, and began new communities, creating considerable chaos. A prominent Dutch anabaptist was Menno Simons, who initiated the Mennonite church. The movement was allowed in the north, but never grew to a large scale.\n\nThe third wave and most permanent wave of the Reformation, was Calvinism. It arrived in the Netherlands in the 1540s, converting many of the elite and the common population, especially in Flanders. The Catholic Spanish responded with harsh persecution and introduced the Inquisition of the Netherlands. Calvinists rebelled. First there was the iconoclasm in 1566, which was the systematic destruction of statues of saints and other Catholic devotional depictions in churches. In 1566 William the Silent, a Calvinist, started the Eighty Years' War to liberate all Dutch of whatever religion from Catholic Spain. Blum says, \"His patience, tolerance, determination, concern for his people, and belief in government by consent held the Dutch together and kept alive their spirit of revolt.\" The provinces of Holland and Zeeland, being mainly Calvinist by 1572, submitted to the rule of William. The other states remained almost entirely Catholic.\n\nThe Netherlands was a valuable part of the Spanish Empire, especially after the Treaty of Cateau-Cambresis of 1559. This treaty ended a forty-year period of warfare between France and Spain conducted in Italy from 1521 to 1559. The Treaty of Cateau-Cambresis was somewhat of a watershed—not only for the battleground that Italy had been, but also for northern Europe. Spain had been keeping troops in the Netherlands to be ready to attack France from the north as well as from the south.\n\nWith the settlement of so many major issues between France and Spain by the Treaty of Cateau-Cambresis, there was no longer any reason to keep Spanish troops in the Netherlands. Thus, the people of the Netherlands could get on with their peacetime pursuits. As they did so they found that there was a great deal of demand for their products. Fishing had long been an important part of the economy of the Netherlands. However, now the fishing of herring alone came to occupy 2,000 boats operating out of Dutch ports. Spain, still the Dutch trader's best customer, was buying fifty large ships full of furniture and household utensils from Flanders merchants. Additionally, Dutch woolen goods were desired everywhere. The Netherlands bought and processed enough Spanish wool to sell four million florins of wool products through merchants in Bruges. So strong was the Dutch appetite for raw wool at this time that they bought nearly as much English wool as they did Spanish wool. Total commerce with England alone amounted to 24 million florins. Much of the export going to England resulted in pure profit to the Dutch because the exported items were of their own manufacture. The Netherlands was just starting to enter its \"Golden Age.\" Brabant and Flanders were the richest and most flourishing parts of the Dutch Republic at the time. The Netherlands was one of the richest places in the world. The population reached 3 million in 1560, with 25 cities of 10,000 people or more, by far the largest urban presence in Europe; with the trading and financial center of Antwerp being especially important (population 100,000). Spain could not afford to lose this rich land, nor allow it to fall from Catholic control. Thus came 80 years of warfare.\n\nA devout Catholic, Philip was appalled by the success of the Reformation in the Low Countries, which had led to an increasing number of Calvinists. His attempts to enforce religious persecution of the Protestants, and his centralization of government, law enforcement, and taxes, made him unpopular and led to a revolt. Fernando Alvarez de Toledo, Duke of Alba, was sent with a Spanish Army to punish the unruly Dutch in 1567.\n\nThe only opposition the Duke of Alba faced in his march across the Netherlands were the nobles, Lamoral, Count of Egmont; Philippe de Montmorency, Count of Horn and others. With the approach of Alba and the Spanish army, William the Silent of Orange fled to Germany with his three brothers and his whole family on 11 April 1567. The Duke of Alba sought to meet and negotiate with the nobles that now faced him with armies. However, when the nobles arrived in Brussels they were all arrested and Egmont and Horn were executed. Alba then revoked all the prior treaties that Margaret, the Duchess of Parma had signed with the Protestants of the Netherlands and instituted the Inquisition to enforce the decrees of the Council of Trent.\n\nThe Dutch War for Independence from Spain is frequently called the Eighty Years' War (1568–1648). The first fifty years (1568 through 1618) were uniquely a war between Spain and the Netherlands. During the last thirty years (1618–1648) the conflict between Spain and the Netherlands was submerged in the general European War that became known as the Thirty Years War. The seven rebellious provinces of the Netherlands were eventually united by the Union of Utrecht in 1579 and formed the Republic of the Seven United Netherlands (also known as the \"United Provinces\"). The Act of Abjuration or \"Plakkaat van Verlatinghe\" was signed on 26 July 1581, and was the formal declaration of independence of the northern Low Countries from the Spanish king.\n\nWilliam of Orange (Slot Dillenburg, 24 April 1533 – Delft, 10 July 1584), the founder of the Dutch royal family, led the Dutch during the first part of the war, following the death of Egmont and Horn in 1568. The very first years were a success for the Spanish troops. However, the Dutch countered subsequent sieges in Holland. At several points the Spanish soldiers committed massacres known as Spanish Fury; the most famous 'Spanish Fury' was the sack of Antwerp in 1576, killing 10,000.\n\nIn a war composed mostly of sieges rather than battles, Governor-General Alexander Farnese proved his mettle. His strategy was to offer generous terms for the surrender of a city: there would be no more \"Spanish furies\" (massacres) or looting; historic urban privileges were retained; there was a full pardon and amnesty; return to the Catholic Church would be gradual. The conservative Catholics in the south and east supported the Spanish. Farnese recaptured Antwerp and nearly all of what became Belgium. Most of the Dutch-speaking territory in the Netherlands was taken from Spain, but not in Flanders, which to this day remains part of Belgium. Flanders was the most radical anti-Spanish territory. Many Flemish fled to Holland, among them half of the population of Antwerp, 3/4 of Bruges and Ghent and the entire population of Nieuwpoort, Dunkerque and countryside. His successful campaign gave the Catholics control of the lower half of the Low Countries, and was part of the Catholic Counter-Reformation.\n\nThe war dragged on for another half century, but the main fighting was over. The Peace of Westphalia, signed in 1648, confirmed the independence of the United Provinces from Spain. The Dutch people started to develop a national identity since the 15th century, but they officially remained a part of the Holy Roman Empire until 1648. National identity was mainly formed by the province people came from. Holland was the most important province by far. The republic of the Seven Provinces came to be known as Holland across Europe.\n\nThe Catholics in the Netherlands were an outlawed minority that had been suppressed by the Calvinists. After 1572, however, they made a striking comeback (also as part of the Catholic Counter-Reformation), setting up seminaries, reforming their Church, and sending missionaries into Protestant districts. Laity often took the lead; the Calvinist government often arrested or harassed priests who seemed too effective. Catholic numbers stabilized at about a third of the population in the Netherlands; they were strongest in the southeast.\n\nDuring the Eighty Years' War the Dutch provinces became the most important trading centre of Northern Europe, replacing Flanders in this respect. During the Golden Age, there was a great flowering of trade, industry, the arts and the sciences in the Netherlands. In the 17th and 18th centuries, the Dutch were arguably the most economically wealthy and scientifically advanced of all European nations. This new, officially Calvinist nation flourished culturally and economically, creating what historian Simon Schama has called an \"embarrassment of riches\". Speculation in the tulip trade led to a first stock market crash in 1637, but the economic crisis was soon overcome. Due to these developments the 17th century has been dubbed the Golden Age of the Netherlands.\n\nThe invention of the sawmill enabled the construction of a massive fleet of ships for worldwide trading and for defence of the republic's economic interests by military means. National industries such as shipyards and sugar refineries expanded as well.\nThe Dutch, traditionally able seafarers and keen mapmakers, obtained an increasingly dominant position in world trade, a position which before had been occupied by the Portuguese and Spaniards. In 1602 the Dutch East India Company (Dutch: \"Verenigde Oostindische Compagnie\" or \"VOC\") was founded. It was the first-ever multinational corporation, financed by shares that established the first modern stock exchange. It became the world's largest commercial enterprise of the 17th century. To finance the growing trade within the region, the Bank of Amsterdam was established in 1609, the precursor to, if not the first true central bank.\n\nDutch ships hunted whales off Svalbard, traded spices in India and Indonesia (via the Dutch East India Company) and founded colonies in New Amsterdam (now New York), South Africa and the West Indies. In addition some Portuguese colonies were conquered, namely in Northeastern Brazil, Angola, Indonesia and Ceylon. In 1640 by the Dutch East India Company began a trade monopoly with Japan through the trading post on Dejima.\n\nThe Dutch also dominated trade between European countries. The Low Countries were favorably positioned on a crossing of east-west and north-south trade routes and connected to a large German hinterland through the Rhine river. Dutch traders shipped wine from France and Portugal to the Baltic lands and returned with grain destined for countries around the Mediterranean Sea. By the 1680s, an average of nearly 1000 Dutch ships entered the Baltic Sea each year. The Dutch were able to gain control of much of the trade with the nascent English colonies in North America and following the end of war with Spain in 1648, Dutch trade with that country also flourished.\nRenaissance Humanism, of which Desiderius Erasmus (c. 1466–1536) was an important advocate, had also gained a firm foothold and was partially responsible for a climate of tolerance. Overall, levels of tolerance were sufficiently high to attract religious refugees from other countries, notably Jewish merchants from Portugal who brought much wealth with them. The revocation of the Edict of Nantes in France in 1685 resulted in the immigration of many French Huguenots, many of whom were shopkeepers or scientists. Still tolerance had its limits, as philosopher Baruch de Spinoza (1632–1677) would find out. Due to its climate of intellectual tolerance the Dutch Republic attracted scientists and other thinkers from all over Europe. Especially the renowned University of Leiden (established in 1575 by the Dutch stadtholder, William of Oranje, as a token of gratitude for Leiden's fierce resistance against Spain during the Eighty Years War) became a gathering place for these people. For instance French philosopher René Descartes lived in Leiden from 1628 until 1649.\n\nDutch lawyers were famous for their knowledge of international law of the sea and commercial law. Hugo Grotius (1583–1645) played a leading part in the foundation of international law. Again due to the Dutch climate of tolerance, book publishers flourished. Many books about religion, philosophy and science that might have been deemed controversial abroad were printed in the Netherlands and secretly exported to other countries. Thus during the 17th century the Dutch Republic became more and more Europe's publishing house.\n\nChristiaan Huygens (1629–1695) was a famous astronomer, physicist and mathematician. He invented the pendulum clock, which was a major step forward towards exact timekeeping. He contributed to the fields of optics. The most famous Dutch scientist in the area of optics is certainly Anton van Leeuwenhoek, who invented or greatly improved the microscope (opinions differ) and was the first to methodically study microscopic life, thus laying the foundations for the field of microbiology. Famous Dutch hydraulic engineer Jan Leeghwater (1575–1650) gained important victories in The Netherlands's eternal battle against the sea. Leeghwater added a considerable amount of land to the republic by converting several large lakes into polders, pumping all water out with windmills.\n\nPainting was the dominant art form in 17th-century Holland. Dutch Golden Age painting followed many of the tendencies that dominated Baroque art in other parts of Europe, as with the Utrecht Caravaggisti, but was the leader in developing the subjects of still life, landscape, and genre painting. Portraiture were also popular, but history painting – traditionally the most-elevated genre struggled to find buyers. Church art was virtually non-existent, and little sculpture of any kind produced. While art collecting and painting for the open market was also common elsewhere, art historians point to the growing number of wealthy Dutch middle-class and successful mercantile patrons as driving forces in the popularity of certain pictorial subjects. Today, the best-known painters of the Dutch Golden Age are the period's most dominant figure Rembrandt, the Delft master of genre Johannes Vermeer, the innovative landscape painter Jacob van Ruisdael, and Frans Hals, who infused new life into portraiture. Some notable artistic styles and trends include Haarlem Mannerism, Utrecht Caravaggism, the School of Delft, the Leiden fijnschilders, and Dutch classicism.\nDue to the thriving economy, cities expanded greatly. New town halls, weighhouses and storehouses were built. Merchants that had gained a fortune ordered a new house built along one of the many new canals that were dug out in and around many cities (for defence and transport purposes), a house with an ornamented façade that befitted their new status. In the countryside, many new castles and stately homes were built. Most of them have not survived. Starting at 1595 Reformed churches were commissioned, many of which are still landmarks today. The most famous Dutch architects of the 17th century were Jacob van Campen, Pieter Post, Pieter Vingbooms, Lieven de Key, Hendrick de Keyser. Overall, Dutch architecture, which generally combined traditional building styles with some foreign elements, did not develop to the level of painting.\n\nThe Golden Age was also an important time for developments in literature. Some of the major figures of this period were Gerbrand Adriaenszoon Bredero, Jacob Cats, Pieter Corneliszoon Hooft and Joost van den Vondel. Since Latin was the lingua franca of education, relatively few men could speak, write, and read Dutch all at the same time.\n\nMusic did not develop very much in the Netherlands since the Calvinists considered it an unnecessary extravagance, and organ music was forbidden in Reformed Church services, although it remained common at secular functions.\n\nThe \"Dutch West India Company\" was a chartered company (known as the \"GWC\") of Dutch merchants. On 2 June 1621, it was granted a for a trade monopoly in the West Indies (meaning the Caribbean) by the Republic of the Seven United Netherlands and given jurisdiction over the African slave trade, Brazil, the Caribbean, and North America. Its area of operations stretched from West Africa to the Americas, and the Pacific islands. The company became instrumental in the Dutch colonization of the Americas. The first forts and settlements in Guyana and on the Amazon River date from the 1590s. Actual colonization, with Dutch settling in the new lands, was not as common as with England and France. Many of the Dutch settlements were lost or abandoned by the end of that century, but the Netherlands managed to retain possession of Suriname and a number of Dutch Caribbean islands.\n\nThe colony was a private business venture to exploit the fur trade in beaver pelts. New Netherland was slowly settled during its first decades, partially as a result of policy mismanagement by the Dutch West India Company (WIC), and conflicts with Native Americans. During the 1650s, the colony experienced dramatic growth and became a major port for trade in the Atlantic World, tolerating a highly diverse ethnic mix. The surrender of Fort Amsterdam to the British control in 1664 was formalized in 1667, contributing to the Second Anglo–Dutch War. In 1673 the Dutch re-took the area, but later relinquished it under the 1674 Treaty of Westminster ending the Third Anglo-Dutch War.\n\nDescendants of the original settlers played a prominent role in the History of the United States, as typified by the Roosevelt and Vanderbilt families. The Hudson Valley still boasts a Dutch heritage. The concepts of civil liberties and pluralism introduced in the province became mainstays of American political and social life.\n\nAlthough slavery was illegal inside the Netherlands it flourished in the Dutch Empire, and helped support the economy. In 1619 The Netherlands took the lead in building a large-scale slave trade between Africa and Virginia, by 1650 becoming the pre-eminent slave trading country in Europe. It was overtaken by Britain around 1700. Historians agree that in all the Dutch shipped about 550,000 African slaves across the Atlantic, about 75,000 of whom died on board before reaching their destinations. From 1596–1829, the Dutch traders sold 250,000 slaves in the Dutch Guianas, 142,000 in the Dutch Caribbean islands, and 28,000 in Dutch Brazil. In addition, tens of thousands of slaves, mostly from India and some from Africa, were carried to the Dutch East Indies and slaves from the East Indies to Africa and the West Indies.\n\nThe Dutch East India Company, called the VOC began in 1602, when the government gave it a monopoly to trade with Asia. It had many world firsts—the first multinational corporation, the first company to issue stock, and was the first megacorporation, possessing quasi-governmental powers, including the ability to wage war, negotiate treaties, coin money, and establish colonial settlements.\n\nEngland and France soon copied its model but could not match its record. Between 1602 and 1796 the VOC sent almost a million Europeans to work in the Asia trade on 4,785 ships. It returned over 2.5 million tons of Asian trade goods. The VOC enjoyed huge profits from its spice monopoly through most of the 17th century. The VOC was active chiefly in the Dutch East Indies, now Indonesia, where its base was Batavia (now Jakarta). Over the next two centuries the Company acquired additional ports as trading bases and safeguarded their interests by taking over surrounding territory. It remained an important trading concern and paid an 18% annual dividend for almost 200 years. Weighed down by corruption, the VOC went bankrupt in 1800. Its possessions were taken over by the government and turned into the Dutch East Indies.\n\nIn 1647, a Dutch vessel was wrecked in the present-day Table Bay at Cape Town. The marooned crew, the first Europeans to attempt settlement in the area, built a fort and stayed for a year until they were rescued. Shortly thereafter, the Dutch East India Company (in the Dutch of the day: \"Vereenigde Oostindische Compagnie\", or VOC) decided to establish a permanent settlement. The VOC, one of the major European trading houses sailing the spice route to East Asia, had no intention of colonizing the area, instead wanting only to establish a secure base camp where passing ships could shelter, and where hungry sailors could stock up on fresh supplies of meat, fruit, and vegetables. To this end, a small VOC expedition under the command of Jan van Riebeeck reached Table Bay on 6 April 1652.\n\nTo remedy a labour shortage, the VOC released a small number of VOC employees from their contracts and permitted them to establish farms with which they would supply the VOC settlement from their harvests. This arrangement proved highly successful, producing abundant supplies of fruit, vegetables, wheat, and wine; they also later raised livestock. The small initial group of \"free burghers\", as these farmers were known, steadily increased in number and began to expand their farms further north and east.\n\nThe majority of burghers had Dutch ancestry and belonged to the Calvinist Reformed Church of the Netherlands, but there were also numerous Germans as well as some Scandinavians. In 1688 the Dutch and the Germans were joined by French Huguenots, also Calvinists, who were fleeing religious persecution in France under King Louis XIV. The Huguenots in South Africa were absorbed into the Dutch population but they played a prominent role in South Africa's history.\n\nFrom the beginning, the VOC used the cape as a place to supply ships travelling between the Netherlands and the Dutch East Indies. There was a close association between the cape and these Dutch possessions in the far east. Van Riebeeck and the VOC began to import large numbers of slaves, primarily from Madagascar and Indonesia. These slaves often married Dutch settlers, and their descendants became known as the Cape Coloureds and the Cape Malays.\nDuring the 18th century, the Dutch settlement in the area of the cape grew and prospered. By the late 1700s the Cape Colony was one of the best developed European settlements outside Europe or the Americas. The two bases of the Cape Colony's economy for almost the entirety of its history were shipping and agriculture. Its strategic position meant that almost every ship sailing between Europe and Asia stopped off at the colony's capital Cape Town. The supplying of these ships with fresh provisions, fruit, and wine provided a very large market for the surplus produce of the colony.\n\nSome free burghers continued to expand into the rugged hinterlands of the north and east, many began to take up a semi-nomadic pastoralist lifestyle, in some ways not far removed from that of the Khoikhoi they had displaced. In addition to its herds, a family might have a wagon, a tent, a Bible, and a few guns. As they became more settled, they would build a mud-walled cottage, frequently located, by choice, days of travel from the nearest European settlement. These were the first of the Trekboers (Wandering Farmers, later shortened to Boers), completely independent of official controls, extraordinarily self-sufficient, and isolated from the government and the main settlement in Cape Town.\nDutch was the official language, but a dialect had formed that was quite distinct from Dutch. The Afrikaans language originated mainly from 17th-century Dutch dialects.\n\nThis Dutch dialect, sometimes referred to as the \"kitchen language\" (\"kombuistaal\"), would eventually in the late 19th century be recognised as a distinct language called Afrikaans and replace Dutch as the official language of the Afrikaners.\n\nAs the 18th century drew to a close, Dutch mercantile power began to fade and the British moved in to fill the vacuum. They seized the Cape Colony in 1795 to prevent it from falling into French hands, then briefly relinquished it back to the Dutch (1803), before definitively conquering it in 1806. British sovereignty of the area was recognised at the Congress of Vienna in 1815. By the time the Dutch colony was seized by the British in 1806, it had grown into an established settlement with 25,000 slaves, 20,000 white colonists, 15,000 Khoisan, and 1,000 freed black slaves. Outside Cape Town and the immediate hinterland, isolated black and white pastoralists populated the country.\n\nDutch interest in South Africa was mainly as a strategically located VOC port. Yet in the 17th and 18th centuries the Dutch created the foundation of the modern state of South Africa. The Dutch legacy in South Africa is evident everywhere, but particularly in the Afrikaner people and the Afrikaans language.\n\nThe Netherlands gained independence from Spain as a result of the Eighty Years War, during which the Dutch Republic was founded. As the Netherlands was a republic, it was largely governed by an aristocracy of city-merchants called the regents, rather than by a king. Every city and province had its own government and laws, and a large degree of autonomy. After attempts to find a competent sovereign proved unsuccessful, it was decided that sovereignty would be vested in the various provincial Estates, the governing bodies of the provinces. The Estates-General, with its representatives from all the provinces, would decide on matters important to the Republic as a whole. However, at the head of each province was the stadtholder of that province, a position held by a descendant of the House of Orange. Usually the stadtholdership of several provinces was held by a single man.\n\nAfter having gained its independence in 1648, the Netherlands tried in various coalitions to help to contain France, which had replaced Spain as the strongest nation of Europe. The end of the War of the Spanish Succession (1713) marked the end of the Dutch Republic as a major player. In the 18th century, it just tried to maintain its independence and stuck to a policy of neutrality.\n\nThe economy, based on Amsterdam's role as the center of world trade, remained robust. In 1670 the Dutch merchant marine totalled 568,000 tons of shipping—about half the European total. The province of Holland was highly commercial and dominated the country. Its nobility was small and closed and had little influence, for it was numerically small, politically weak, and formed a strictly closed caste. Most land in the province of Holland was commercialized for cash crops and was owned by urban capitalists, not nobles; there were few links between Holland's nobility and the merchants. By 1650 the burgher families which had grown wealthy through commerce and become influential in government controlled the province of Holland, and to a large extent shaped national policies. The other six provinces were more rural and traditional in life style, had an active nobility, and played a small role in commerce and national politics. Instead they concentrated on their flood protections and land reclamation projects.\n\nThe Netherlands sheltered many notable refugees, including Protestants from Antwerp and Flanders, Portuguese and German Jews, French Protestants (Huguenots) (including Descartes) and English Dissenters (including the Pilgrim Fathers). Many immigrants came to the cities of Holland in the 17th and 18th century from the Protestant parts of Germany and elsewhere. The amount of first generation immigrants from outside the Netherlands in Amsterdam was nearly 50% in the 17th and 18th centuries. Indeed, Amsterdam's population consisted primarily of immigrants, if one includes second and third generation immigrants and migrants from the Dutch countryside. People in most parts of Europe were poor and many were unemployed. But in Amsterdam there was always work. Tolerance was important, because a continuous influx of immigrants was necessary for the economy. Travellers visiting Amsterdam reported their surprise at the lack of control over the influx.\n\nThe era of explosive economic growth is roughly coterminous with the period of social and cultural bloom that has been called the Dutch Golden Age, and that actually formed the material basis for that cultural era. Amsterdam became the hub of world trade, the center into which staples and luxuries flowed for sorting, processing, and distribution, and then reexported around Europe and the world.\n\nDuring 1585 through 1622 there was the rapid accumulation of trade capital, often brought in by refugee merchantes from Antwerp and other ports. The money was typically invested in high-risk ventures like pioneering expeditions to the East Indies to engage in the spice trade. These ventures were soon consolidated in the Dutch East India Company (VOC). There were similar ventures in different fields however, like the trade on Russia and the Levant. The profits of these ventures were ploughed back in the financing of new trade, which led to its exponential growth.\n\nRapid industrialization led to the rapid growth of the nonagricultural labor force and the increase in real wages during the same time. In the half-century between 1570 and 1620 this labor supply increased 3 percent per annum, a truly phenomenal growth. Despite this, nominal wages were repeatedly increased, outstripping price increases. In consequence, real wages for unskilled laborers were 62 percent higher in 1615–1619 than in 1575–1579.\n\nBy the mid-1660s Amsterdam had reached the optimum population (about 200,000) for the level of trade, commerce and agriculture then available to support it. The city contributed the largest quota in taxes to the States of Holland which in turn contributed over half the quota to the States General. Amsterdam was also one of the most reliable in settling tax demands and therefore was able to use the threat to withhold such payments to good effect.\n\nAmsterdam was governed by a body of regents, a large, but closed, oligarchy with control over all aspects of the city's life, and a dominant voice in the foreign affairs of Holland. Only men with sufficient wealth and a long enough residence within the city could join the ruling class. The first step for an ambitious and wealthy merchant family was to arrange a marriage with a long-established regent family. In the 1670s one such union, that of the Trip family (the Amsterdam branch of the Swedish arms makers) with the son of Burgomaster Valckenier, extended the influence and patronage available to the latter and strengthened his dominance of the council. The oligarchy in Amsterdam thus gained strength from its breadth and openness. In the smaller towns family interest could unite members on policy decisions but contraction through intermarriage could lead to the degeneration of the quality of the members.\n\nIn Amsterdam the network was so large that members of the same family could be related to opposing factions and pursue widely separated interests. The young men who had risen to positions of authority in the 1670s and 1680s consolidated their hold on office well into the 1690s and even the new century.\n\nAmsterdam's regents provided good services to residents. They spent heavily on the water-ways and other essential infrastructure, as well as municipal almshouses for the elderly, hospitals and churches.\n\nAmsterdam's wealth was generated by its commerce, which was in turn sustained by the judicious encouragement of entrepreneurs whatever their origin. This open door policy has been interpreted as proof of a tolerant ruling class. But toleration was practiced for the convenience of the city. Therefore, the wealthy Sephardic Jews from Portugal were welcomed and accorded all privileges except those of citizenship, but the poor Ashkenazi Jews from Eastern Europe were far more carefully vetted and those who became dependent on the city were encouraged to move on. Similarly, provision for the housing of Huguenot immigrants was made in 1681 when Louis XIV's religious policy was beginning to drive these Protestants out of France; no encouragement was given to the dispossessed Dutch from the countryside or other towns of Holland. The regents encouraged immigrants to build churches and provided sites or buildings for churches and temples for all except the most radical sects and the Catholics by the 1670s (although even the Catholics could practice quietly in a chapel within the Beguinhof).\n\nDuring the wars a tension had arisen between the Orange-Nassau leaders and the patrician merchants. The former—the Orangists—were soldiers and centralizers who seldom spoke of compromise with the enemy and looked for military solutions. They included many rural gentry as well as ordinary folk attached to the banner of the House of Orange. The latter group were the Republicans, led by the Grand Pensionary (a sort of prime minister) and the regents stood for localism, municipal rights, commerce, and peace. In 1650, the stadtholder William II, Prince of Orange suddenly died; his son was a baby and the Orangists were leaderless. The regents seized the opportunity: there would be no new stadtholder in Holland for 22 years. Johan de Witt, a brilliant politician and diplomat, emerged as the dominant figure. Princes of Orange became the stadtholder and an almost hereditary ruler in 1672 and 1748. The Dutch Republic of the United Provinces was a true republic from 1650–1672 and 1702–1748. These periods are called the First Stadtholderless Period and Second Stadtholderless Period.\n\nThe Republic and England were major rivals in world trade and naval power. Halfway through the 17th century the Republic's navy was the rival of Britain's Royal Navy as the most powerful navy in the world. The Republic fought a series of three naval wars against England in 1652–74.\n\nIn 1651, England imposed its first Navigation Act, which severely hurt Dutch trade interests. An incident at sea concerning the Act resulted in the First Anglo-Dutch War, which lasted from 1652 to 1654, ending in the Treaty of Westminster (1654), which left the Navigation Act in effect.\n\nAfter the English Restoration in 1660, Charles II tried to serve his dynastic interests by attempting to make Prince William III of Orange, his nephew, stadtholder of the Republic, using some military pressure. King Charles thought a naval war would weaken the Dutch traders and strengthen the English economy and empire, so the Second Anglo-Dutch War was launched in 1665. At first many Dutch ships were captured and the English scored great victories. However, the Raid on the Medway, in June 1667, ended the war with a Dutch victory. The Dutch recovered their trade, while the English economy was seriously hurt and its treasury nearly bankrupt. The greatly expanded Dutch navy was for years after the world's strongest. The Dutch Republic was at the zenith of its power.\n\nThe year 1672 is known in the Netherlands as the \"Disaster Year\" (\"Rampjaar\"). England declared war on the Republic, (the Third Anglo-Dutch War), followed by France, Münster and Cologne, which had all signed alliances against the Republic. France, Cologne and Münster invaded the Republic. Johan de Witt and his brother Cornelis, who had accomplished a diplomatic balancing act for a long time, were now the obvious scapegoats. They were lynched, and a new stadtholder, William III, was appointed.\n\nAn Anglo-French attempt to land on the Dutch shore were barely repelled in three desperate naval battles under command of Admiral Michiel de Ruyter. The advance of French troops from the south was halted by a costly inundation of its own heartland, by breaching river dykes. With the aid of friendly German princes, the Dutch succeeded in fighting back Cologne and Münster, after which the peace was signed with both of them, although some territory in the east was lost for ever. Peace was signed with England as well, in 1674 (Second Treaty of Westminster). In 1678, peace was made with France at the Treaty of Nijmegen, although France's Spanish and German allies felt betrayed by this.\n\nIn 1688, the relations with England reached crisis level once again. Stadtholder William III decided he had to take a huge gamble when he was invited to invade England by Protestant British nobles feuding with William's father-in-law the Catholic James II of England. This led to the Glorious Revolution and cemented the principle of parliamentary rule and Protestant ascendency in England. James fled to France, and William ascended to the English throne as co-monarch with his wife Mary, James' eldest daughter. This manoeuvre secured England as a critical ally of the United Provinces in its ongoing wars with Louis XIV of France. William was the commander of the Dutch and English armies and fleets until his death in 1702. During William's reign as King of England his primary focus was leveraging British manpower and finances to aid the Dutch against the French. The combination continued after his death as the combined Dutch, British, and mercenary army conquered Flanders and Brabant, and invaded French territory before the alliance collapsed in 1713 due to British political infighting.\n\nThe \"Second Stadtholderless Period\" () is the designation in Dutch historiography of the period between the death of stadtholder William III on 19 March 1702 and the appointment of William IV, Prince of Orange as stadtholder and captain general in all provinces of the Dutch Republic on 2 May 1747. During this period the office of stadtholder was left vacant in the provinces of Holland, Zeeland, and Utrecht, though in other provinces that office was filled by members of the House of Nassau-Dietz (later called Orange-Nassau) during various periods.\n\nDuring the period, the Republic lost its Great-Power status and its primacy in world trade, processes that went hand-in-hand, the latter causing the former. Though the economy declined considerably, causing deindustralization and deurbanization in the maritime provinces, a \"rentier\"-class kept accumulating a large capital fund that formed the basis for the leading position the Republic achieved in the international capital market. A military crisis at the end of the period caused the fall of the States-Party regime and the restoration of the Stadtholderate in all provinces. However, though the new stadtholder acquired near-dictatorial powers, this did not improve the situation.\n\nThe slow economic decline after 1730 was relative: other countries grew faster, eroding the Dutch lead and surpassing it. Wilson identifies three causes. Holland lost its world dominance in trade as competitors emerged and copied its practices, built their own ships and ports, and traded on their own account directly without going through Dutch intermediaries. Second, there was no growth in manufacturing, due perhaps to a weaker sense of industrial entrepreneurship and to the high wage scale. Third the wealthy turned their investments to foreign loans. This helped jump-start other nations and provided the Dutch with a steady income from collecting interest, but leaving them with few domestic sectors with a potential for rapid growth.\n\nAfter the Dutch fleet declined, merchant interests became dependent on the goodwill of Britain. The main focus of Dutch leaders was reducing the country's considerable budget deficits. Dutch trade and shipping remained at a fairly steady level through the 18th century, but no longer had a near monopoly and also could not match growing English and French competition. The Netherlands lost its position as the trading centre of Northern Europe to London.\n\nAlthough the Netherlands remained wealthy, investors for the nation's money became more difficult to find. Some investment went into purchases of land for estates, but most went to foreign bonds and Amsterdam remained one of Europe's banking capitals.\n\nDutch culture also declined both in the arts and sciences. Literature for example largely imitated English and French styles with little in the way of innovation or originality. The most influential intellectual was Pierre Bayle (1647–1706), a Protestant refugee from France who settled in Rotterdam where he wrote the massive Dictionnaire Historique et Critique (\"Historical and Critical Dictionary\", 1696). It had a major impact on the thinking of The Enlightenment across Europe, giving an arsenal of weapons to critics who wanted to attack religion. It was an encyclopaedia of ideas that argued that most \"truths\" were merely opinions, and that gullibility and stubbornness were prevalent.\n\nLife for the average Dutchman became slower and more relaxed than in the 18th century. The upper and middle classes continued to enjoy prosperity and high living standards. The drive to succeed seemed less urgent. Unskilled laborers remained locked in poverty and hardship. The large underclass of unemployed beggars and riffraff required government and private charity to survive.\n\nReligious life became more relaxed as well. Catholics grew from 18% to 23% of the population during the 18th century and enjoyed greater tolerance, even as they continued to be outside the political system. They became divided by the feud between moralistic Jansenists (who denied free will) and orthodox believers. One group of Jansenists formed a splinter sect, the Old Catholic Church in 1723. The upper classes willingly embraced the ideas of the Enlightenment, tempered by the tolerance that meant less hostility to organized religion compared to France.\n\nDuring the term of Anthonie van der Heim as Grand Pensionary from 1737 to 1746, the Republic slowly drifted into the War of Austrian Succession. This started as a Prusso-Austrian conflict, but eventually all the neighbours of the Dutch Republic became involved. On one side were Prussia, France and their allies and on the other Austria, Britain (after 1744) and their allies. At first the Republic strove to remain neutral in this European conflict, but it maintained garrisons in a number of fortresses in the Austrian Netherlands. French grievances and threats spurred the Republic into bring its army up to European standards (84,000 men in 1743).\n\nIn 1744 and 1745 the French attacked Dutch fortresses at Menen and Tournai. This prompted the Dutch Republic in 1745 to join the Quadruple Alliance, but this alliance was severely defeated at the Battle of Fontenoy in May 1745. In 1746 the French occupied most of the large cities in the Austrian Netherlands. Then, in April 1747, apparently as an exercise in armed diplomacy, a relatively small French military force occupied Zeelandic Flanders, part of the Dutch Republic.\n\nThis relatively innocuous invasion fully exposed the rot underlying the Dutch defences. The consequences were spectacular. Still mindful of the French invasion in the \"Disaster Year\" of 1672, many fearful people clamored for the restoration of the stadtholderate. William IV, Prince of Orange, had been waiting impatiently in the wings since acquiring his princely title in 1732. Over the next year he and his supporters engaged in a number of political battles in various provinces and towns in the Netherlands to wrest control from the regents. The aim was for William IV to obtain a firm grip on government patronage and place loyal officials in all strategic government positions. Eventually he managed to achieve this aim in all provinces.\n\nWillem Bentinck van Rhoon was a prominent Orangist. People like Bentinck hoped that gathering the reins of power in the hands of a single \"eminent head\" would soon help restore the state of the Dutch economy and finances. The regents they opposed included the Grand Pensionary Jacob Gilles and Adriaen van der Hoop. This popular revolt had religious, anti-Catholic and democratic overtones and sometimes involved mob violence. It eventually involved political agitation by Daniel Raap, Jean Rousset de Missy and the Doelisten, attacks on tax farmers (pachtersoproer), religious agitation for enforcement of the Sabbath laws and preference for followers of Gisbertus Voetius and various demands by the civil militia.\n\nThe war against the French was itself brought to a not-too-devastating end for the Dutch Republic with the Treaty of Aix-la-Chapelle (1748). The French retreated of their own accord from the Dutch frontier. William IV died unexpectedly, at the age of 40, on 22 October 1751.\n\nHis son, William V, was 3 years old when his father died, and a long regency characterised by corruption and misrule began. His mother delegated most of the powers of the regency to Bentinck and her favorite, Duke Louis Ernest of Brunswick-Lüneburg. All power was concentrated in the hands of an unaccountable few, including the Frisian nobleman Douwe Sirtema van Grovestins. Still a teenager, William V assumed the position of stadtholder in 1766, the last to hold that office. In 1767, he married Princess Wilhelmina of Prussia, the daughter of Augustus William of Prussia, niece of Frederick the Great.\n\nThe position of the Dutch during the American War of Independence was one of neutrality. William V, leading the pro-British faction within the government, blocked attempts by pro-independence, and later pro-French, elements to drag the government to war. However, things came to a head with the Dutch attempt to join the Russian-led League of Armed Neutrality, leading to the outbreak of the disastrous Fourth Anglo-Dutch War in 1780. After the signing of the Treaty of Paris (1783), the impoverished nation grew restless under William's rule.\n\nAn English historian summed him up uncharitably as \"a Prince of the profoundest lethargy and most abysmal stupidity.\" And yet he would guide his family through the difficult French-Batavian period and his son would be crowned king.\n\nThe Fourth Anglo–Dutch War (1780–1784) was a conflict between the Kingdom of Great Britain and the Dutch Republic. The war, tangentially related to the American Revolutionary War, broke out over British and Dutch disagreements on the legality and conduct of Dutch trade with Britain's enemies in that war.\n\nAlthough the Dutch Republic did not enter into a formal alliance with the United States and their allies, U.S. ambassador (and future President) John Adams managed to establish diplomatic relations with the Dutch Republic, making it the second European country to diplomatically recognize the Continental Congress in April 1782. In October 1782, a treaty of amity and commerce was concluded as well.\n\nMost of the war consisted of a series of largely successful British operations against Dutch colonial economic interests, although British and Dutch naval forces also met once off the Dutch coast. The war ended disastrously for the Dutch and exposed the weakness of the political and economic foundations of the country. The Treaty of Paris (1784), according to Fernand Braudel, \"sounded the knell of Dutch greatness.\"\n\nAfter the war with Great Britain ended disastrously in 1784, there was growing unrest and a rebellion by the anti-Orangist Patriots. The French Revolution resulted first in the establishment of a pro-French Batavian Republic (1795–1806), then the creation of the Kingdom of Holland, ruled by a member of the House of Bonaparte (1806–1810), and finally annexation by the French Empire (1810–1813).\n\nInfluenced by the American Revolution, the Patriots sought a more democratic form of government. The opening shot of this revolution is often considered to be the 1781 publication of a manifesto called \"Aan het Volk van Nederland\" (\"To the People of the Netherlands\") by Joan van der Capellen tot den Pol, who would become an influential leader of the Patriot movement. Their aim was to reduce corruption and the power held by the stadtholder, William V, Prince of Orange.\n\nSupport for the Patriots came mostly from the middle class. They formed militias called \"exercitiegenootschappen\". In 1785, there was an open Patriot rebellion, which took the form of an armed insurrection by local militias in certain Dutch towns, \"Freedom\" being the rallying cry. Herman Willem Daendels attempted to organise an overthrow of various municipal governments (vroedschap). The goal was to oust government officials and force new elections. \"Seen as a whole this revolution was a string of violent and confused events, accidents, speeches, rumours, bitter enmities and armed confrontations\", wrote French historian Fernand Braudel, who saw it as a forerunner of the French Revolution.\n\nIn 1785 the stadholder left The Hague and moved his court to Nijmegen in Guelders, a city remote from the heart of Dutch political life. In June 1787, his energetic wife Wilhelmina (the sister of Frederick William II of Prussia) tried to travel to The Hague. Outside Schoonhoven, she was stopped by Patriot militiamen and taken to a farm near Goejanverwellesluis. Within two days she was forced to return to Nijmegen, an insult not unnoticed in Prussia.\n\nThe House of Orange reacted with severity, relying on Prussian troops led by Charles William Ferdinand, Duke of Brunswick and a small contingent of British troops to suppress the rebellion. Dutch banks at this time still held much of the world's capital. Government-sponsored banks owned up to 40% of Great Britain's national debt and there were close connections to the House of Stuart. The stadholder had supported British policies after the American Revolution.\n\nThis severe military response overwhelmed the Patriots and put the stadholder firmly back in control. A small unpaid Prussian army was billeted in the Netherlands and supported themselves by looting and extortion. The exercitiegenootschappen continued urging citizens to resist the government. They distributed pamphlets, formed \"Patriot Clubs\" and held public demonstrations. The government responded by pillaging those towns where opposition continued. Five leaders were sentenced to death (but fled first). Lynchings also occurred. For a while, no one dared appear in public without an orange cockade to show their support for Orangism. Many Patriots, perhaps around 40,000 in all, fled to Brabant, France (especially Dunkirk and St. Omer) and elsewhere. However, before long the French became involved in Dutch politics and the tide turned.\n\nThe French Revolution was popular, and numerous underground clubs were promoting it when in January 1795 the French army invaded. The underground rose up, overthrew the municipal and provincial governments, and proclaimed the Batavian Republic () in Amsterdam. Stadtholder William V fled to England and the States General dissolved itself. The new government was virtually a puppet of France. The Batavian Republic enjoyed widespread support and sent soldiers to fight in the French armies. The 1799 Anglo-Russian invasion of Holland was repulsed by Batavian–French forces. Nevertheless, Napoleon replaced it because the regime of Grand Pensionary Rutger Jan Schimmelpenninck (1805–06) was insufficiently docile.\n\nThe confederal structure of the old Dutch Republic was permanently replaced by a unitary state. The 1798 constitution had a genuinely democratic character, though a coup d'état of 1801 put an authoritarian regime in power. Ministerial government was introduced for the first time in Dutch history and many of the current government departments date their history back to this period. Meanwhile, the exiled stadholder handed over the Dutch colonies in \"safekeeping\" to Great Britain and ordered the colonial governors to comply. This permanently ended the colonial empire in Guyana, Ceylon and the Cape Colony. The Dutch East Indies was returned to the Netherlands under the Anglo-Dutch Treaty of 1814.\n\nIn 1806 Napoleon restyled the Netherlands (along with a small part of what is now Germany) into the Kingdom of Holland, putting his brother Louis Bonaparte (1778–1846), on the throne. The new king was unpopular, but he was willing to cross his brother for the benefit of his new kingdom. Napoleon forced his abdication in 1810 and incorporated the Netherlands directly into the French empire, imposing economic controls and conscription of all young men as soldiers. When the French retreated from the northern provinces in 1813, a Triumvirate took over at the helm of a provisional government. Although most members of the provisional government had been among the men who had driven out William V 18 years earlier, the leaders of the provisional government knew that any new regime would have to be headed by his son, William Frederick. They also knew that it would be better in the long term if the Dutch people themselves installed the prince, rather than have him imposed on the country by the anti-French alliance. Accordingly, the Triumvirate called William Frederick back on November 30 and offered him the crown. He refused, but instead proclaimed himself \"hereditary sovereign prince\" on December 6.\n\nThe Great Powers had secretly agreed to merge the northern Netherlands with the more populated Austrian Netherlands and the smaller Prince-Bishopric of Liège into a single constitutional monarchy. Having a stronger country on France's northern border was considered (especially by Tsar Alexander) to be an important part of the strategy to keep France's power in check. In 1814, William Frederick gained sovereignty over the Austrian Netherlands and Liège as well. On March 15, 1815; with the encouragement of the powers gathered at the Congress of Vienna, William Frederick raised the Netherlands to the status of a kingdom and proclaimed himself King William I. This was made official later in 1815, when the Low Countries were formally recognized as the United Kingdom of the Netherlands, with the House of Orange-Nassau as hereditary rulers. William had thus fulfilled the nearly three-century quest of the House of Orange to unite the Low Countries under a single rule.\n\nWilliam I became king and also became the hereditary Grand Duke of Luxembourg, that was part of the Netherlands but at the same time part of the German Confederation. The newly created country had two capitals: Amsterdam and Brussels. The new nation had two equal parts. The north (Netherlands proper) had 2 million people. They spoke chiefly Dutch but were divided religiously between a Protestant majority and a large Catholic minority. The south (which would be known as \"Belgium\" after 1830) had a population of 3.4 million people. Nearly all were Catholic, but it was divided between French-speaking Walloons and Dutch-speaking Flemings. The upper and middle classes in the south were mostly French-speaking. About 60,000 Belgians were eligible to vote, compared to about 80,000 Dutchmen. Officially Amsterdam was the capital, but in a compromise the government met alternately in Brussels and The Hague.\n\nAdolphe Quetelet (1796–1874), the great Belgian statistician, calculated that the new nation was significantly better off than other states. Mortality was low, the food supply was good, education was good, public awareness was high and the charity rate was the highest in the world. The best years were in the mid-1820s.\n\nThe quality of schooling was dismal, however. According to Schama, about 1800 the local school teacher was the \"humble auxiliary of the local priest. Despised by his co-villagers and forced to subsist on the gleanings of the peasants, he combined drumming the catechism into the heads of his unruly charges with the duties of winding the town clock, ringing the church bells or digging its graves. His principal use to the community was to keep its boys out of mischief when there was no labour for them in the fields, or setting the destitute orphans of the town to the 'useful arts' of picking tow or spinning crude flax. As one would expect, standards in such an occupation were dismal.\" But in 1806 the Dutch, led by Adriaan van den Ende, energetically set out to modernise education, focusing on a new system for advanced training of teachers with an elaborate system of inspectors, training courses, teacher examinations and teaching societies. By 1826, although much smaller than France, the Dutch national government was spending 12 times more than Paris on education.\n\nWilliam I, who reigned from 1815–1840, had great constitutional power. An enlightened despot, he accepted the modernizing transformations of the previous 25 years, including equality of all before the law. However, he resurrected the estates as a political class and elevated a large number of people to the nobility. Voting rights were still limited, and only the nobility were eligible for seats in the upper house. The old provinces were reestablished in name only. The government was now fundamentally unitary, and all authority flowed from the center.\n\nWilliam I was a Calvinist and unsympathetic to the religious culture and practices of the Catholic majority. He promulgated the \"Fundamental Law of Holland\", with some modifications. This entirely overthrew the old order of things in the southern Netherlands: it abolished the privileges of the Catholic Church, and guaranteed equal protection to every religious creed and the enjoyment of the same civil and political rights to every subject of the king. It reflected the spirit of the French Revolution and in so doing did not please the Catholic bishops in the south, who had detested the Revolution.\n\nWilliam I actively promoted economic modernization. The first 15 years of the Kingdom showed progress and prosperity, as industrialization proceeded rapidly in the south, where the Industrial Revolution allowed entrepreneurs and labor to combine in a new textile industry, powered by local coal mines. There was little industry in the northern provinces, but most overseas colonies were restored, and highly profitable trade resumed after a 25-year hiatus. Economic liberalism combined with moderate monarchical authoritarianism to accelerate the adaptation of the Netherlands to the new conditions of the 19th century. The country prospered until a crisis arose in relations with the southern provinces.\n\nWilliam was determined to create a united people, even though the north and south had drifted far apart in the past three centuries. Protestants were the largest denomination in the North (population 2 million), but formed a quarter of the population in the overwhelmingly Catholic South (population 3.5 million). Nevertheless, Protestants dominated William's government and army. The Catholics did not consider themselves an integral part of the United Netherlands, preferring instead to identify with mediaeval Dutch culture. Other factors that contributed to this feeling were economic (the South was industrialising, the North had always been a merchants' nation) and linguistic (French was spoken in Wallonia and a large part of the bourgeoisie in Flemish cities).\nAfter having been dominant for a long time, the French-speaking elite in the Southern Netherlands now felt like second-class citizens.\nIn the Catholic South, William's policies were unpopular. The French-speaking Walloons strenuously rejected his attempt to make Dutch the universal language of government, while the population of Flanders was divided. Flemings in the south spoke a Dutch dialect (\"Flemish\") and welcomed the encouragement of Dutch with a revival of literature and popular culture. Other Flemings, notably the educated bourgeoisie, preferred to speak French. Although Catholics possessed legal equality, they resented their subordination to a government that was fundamentally Protestant in spirit and membership after having been the state church for centuries in the south. Few Catholics held high office in state or army. Furthermore, political liberals in the south complained about the king's authoritarian methods. All southerners complained of underrepresentation in the national legislature. Although the south was industrializing and was more prosperous than the north the accumulated grievances allowed the multiple opposition forces to coalesce. The outbreak of revolution in France in 1830 was a signal for action, at first on behalf of autonomy for Belgium, as the southern provinces were now called, and later on behalf of total independence. William dithered and his half-hearted efforts to reconquer Belgium were thwarted both by the efforts of the Belgians themselves and by the diplomatic opposition of the great powers.\n\nAt the London Conference of 1830, the chief powers of Europe ordered (in November 1830) an armistice between the Dutch and the Belgians. The first draft for a treaty of separation of Belgium and the Netherlands was rejected by the Belgians. A second draft (June 1831) was rejected by William I, who resumed hostilities. Franco-British intervention forced William to withdraw Dutch forces from Belgium late in 1831, and in 1833 an armistice of indefinite duration was concluded. Belgium was effectively independent but William’s attempts to recover Luxembourg and Limburg led to renewed tension. The London Conference of 1838–39 prepared the final Dutch-Belgian separation treaty of 1839. It divided Luxembourg and Limburg between the Dutch and Belgian crowns. The Kingdom of the Netherlands thereafter was made up of the 11 northern provinces.\n\nThe Netherlands did not industrialize as rapidly as Belgium after 1830, but it was prosperous enough. Griffiths argues that certain government policies facilitated the emergence of a national economy in the 19th century. They included the abolition of internal tariffs and guilds, a unified coinage system, modern methods of tax collection, standardized weights and measures, and the building of many roads, canals, and railroads. However, compared to Belgium, which was leading in industrialization on the Continent, the Netherlands moved slowly. Possible explanations for this difference are the higher costs due to geography and high wages, and the emphasis of entrepreneurs on trade rather than industry. \nFor example, in the Dutch coastal provinces agricultural productivity was relatively high. Hence, industrial growth arrived relatively late – after 1860 – because incentives to move to labour-intensive industry were quite weak.\nHowever, the provinces of North Brabant and Overijssel did industrialize, and they became the most economically advanced areas of the country.\n\nAs in the rest of Europe, the 19th century saw the gradual transformation of the Netherlands into a modern middle-class industrial society. The number of people employed in agriculture decreased, while the country made a strong effort to revive its stake in the highly competitive shipping and trade business. The Netherlands lagged behind Belgium until the late 19th century in industrialization, and caught up around 1920. Major industries included textiles and (later) the great Philips industrial conglomerate. Rotterdam became a major shipping and manufacturing center. Poverty slowly declined as begging largely disappeared along with steadily improving working conditions for the population.\n\nIn 1840 William I abdicated in favor of his son, William II, who attempted to carry on the policies of his father in the face of a powerful liberal movement. In 1848 unrest broke out all over Europe. Although there were no major events in the Netherlands, these foreign developments persuaded King William II to agree to liberal and democratic reform. That same year Johan Rudolf Thorbecke, a prominent liberal, was asked by the king to draft a constitution that would turn the Netherlands into a constitutional monarchy. The new constitution was proclaimed on 3 November 1848. It severely limited the king's powers (making the government accountable only to an elected parliament), and it protected civil liberties. The new liberal constitution, which put the government under the control of the States General, was accepted by the legislature in 1848. The relationship between monarch, government and parliament has remained essentially unchanged ever since.\n\nWilliam II was succeeded by William III in 1849. The new king reluctantly chose Thorbecke to head the new government, which introduced several liberal measures, notably the extension of suffrage. However, Thorbecke's government soon fell, when Protestants rioted against the Vatican's reestablishment of the Catholic episcopate, in abeyance since the 16th century. A conservative government was formed, but it did not undo the liberal measures, and the Catholics were finally given equality after two centuries of subordination. Dutch political history from the middle of the 19th century until the First World War was fundamentally one of the extension of liberal reforms in government, the reorganization and modernization of the Dutch economy, and the rise of trade unionism and socialism as working-class movements independent of traditional liberalism. The growth in prosperity was enormous, as real per capita GNP soared from 106 guilders in 1804 to 403 in 1913.\n\nReligion was a contentious issue with repeated struggles over the relations of church and state in the field of education. In 1816, the government took full control of the Dutch Reformed Church (\"Nederlands Hervormde Kerk\"). In 1857, all religious instruction was ended in public schools, but the various churches set up their own schools, and even universities. Dissident members broke away from the Netherlands Reformed Church in the Secession of 1834. They were harassed by the government under an onerous Napoleonic law prohibiting gatherings of more than 20 members without a permit. After the harassment ended in the 1850s, a number of these dissidents eventually created the Christian Reformed Church in 1869; thousands migrated to Michigan, Illinois, and Iowa in the United States. By 1900 the dissidents represented about 10% of the population, as against 45% in the Netherlands Reformed Church, which continued to be the only church to receive state money.\n\nAt mid-century, most Dutch belonged either to the Dutch Reformed churches (around 55%) or the Roman Catholic church (35 to 40%), together with smaller Protestant and Jewish groups. A large and powerful sector of nominal Protestants were in fact secular liberals seeking to minimize religious influence. In reaction a novel alliance developed with Catholics and devout Calvinists joining against secular liberals. The Catholics, who had been loosely allied with the liberals in earlier decades, turned against them on the issue of state support, which the liberals insisted should be granted only to public schools, and joined with Protestant political parties in demanding equal state support to schools maintained by religious groups.\n\nThe Netherlands remained one of the most tolerant countries in Europe towards religious belief, although conservative Protestants objected to the liberalization of the Dutch Reformed Church during the 19th century and faced opposition from the government when they tried to establish separate communities (Catholics and other non-Protestants were left unmolested by Dutch authorities). Some moved to the United States as a consequence, but as the century drew to a close, religious persecution had totally ceased.\nDutch social and political life became divided by fairly clear-cut internal borders that were emerging as the society pillarized into three separate parts based on religion. The economy was not affected. One of the people most responsible for designing pillarization was Abraham Kuyper (1837–1920), a leading politician, Protestant theologian, and journalist. Kuyper established orthodox Calvinist organizations, and also provided a theoretical framework by developing such concepts as \"sphere-sovereignty\" that celebrated Dutch society as a society of organized minorities. \"Verzuiling\" (\"pillarization\" or \"pluralism\") after 1850 became the solution to the danger of internal conflict. Everyone was part of one (and only one) pillar (\"zuil\") based chiefly on religion (Protestant, Catholic, secular). The secular pillar eventually split into a socialist/working class pillar and a liberal (pro-business) secular pillar. Each pillar built a full set of its own social organizations, including churches (for the religious pillars), political parties, schools, universities, labor unions, sport clubs, boy scout unions and other youth clubs, and newspapers. The members of different \"zuilen\" lived in close proximity in cities and villages, spoke the same language, and did business with one another, but seldom interacted informally and rarely intermarried. In politics Kuyper formed the Anti-Revolutionary Party (ARP) in 1879, and headed it until 1905.\n\nPillarization was officially recognized in the Pacification of 1917, whereby socialists and liberals achieved their goal of universal male suffrage and the religious parties were guaranteed equal funding of all schools. In 1930 radio was organized so that each pillar had full control of its own network. When television began in the late 1940s the pillars divided up time equally on the one station. In politics and civic affairs leaders of the pillar organizations cooperated and the acknowledged the right of the other pillars, so public life generally ran smoothly.\n\nThe late 19th century saw a cultural revival. The Hague School brought a revival of realist painting, 1860-1890. The world-famous Dutch painter was Vincent van Gogh, but he spent most of his career in France. Literature, music, architecture and science also flourished. A representative leader of science was Johannes Diderik van der Waals (1837–1923), a working class youth who taught himself physics, earned a PhD at the nation's leading school Leiden University, and in 1910 won the Nobel Prize for his discoveries in thermodynamics. Hendrik Lorentz (1853–1928) and his student Pieter Zeeman (1865–1943) shared the 1902 Nobel Prize in physics. Other notable scientists included biologist Hugo de Vries (1848–1935), who rediscovered Mendelian genetics.\n\nIn 1890, William III died after a long reign and was succeeded by his young daughter, Queen Wilhelmina (1880-1962). She would rule the Netherlands for 58 years. On her accession to the throne, the personal union between the Netherlands and Luxembourg ended because Luxembourg law excluded women from rule. Her remote cousin Adolphe became the Grand Duke of Luxembourg.\n\nThis was a time of further growth and colonial development, but it was marked by the difficulties of the World War I (in which the Netherlands was neutral) \nand the Great Depression. The Dutch population grew rapidly in the 20th century, as death rates fell, more lands were opened up, and industrialisation created urban jobs. Between 1900 and 1950 the population doubled from 5.1 to 10 million people.\n\nThe Dutch empire comprised the Dutch East Indies (Indonesia), as well as Surinam in South America and some minor possessions. It was smaller in 1945 than in 1815 because the Netherlands was the only colonial power that did not expand into Africa or anywhere else. The empire was run from Batavia (in Java), where the governor and his technical experts had almost complete authority with little oversight from the Hague. Successive governors improved their bureaucratic and military controls, and allowed very little voice to the locals until the 1920s.\n\nThe colony brought economic opportunity to the mother country and there was little concern at the time about it. One exception came in 1860 when Eduard Dekker, under the pen name \"Multatuli\" wrote the novel \"\", one of the most notable books in the history of Dutch literature. He criticized the exploitation of the colony, and as well had harsh words about the indigenous princes who collaborated with the governor. The book helped inspire the Indonesian independence movement in the mid-20th century as well as the \"Fair Trade\" movement for coffee at the end of the century.\n\nThe military forces in the Dutch East Indies were controlled by the governor and were not part of the regular Dutch army. As the map shows, the Dutch slowly expanded their holdings from their base in Java to include all of modern Indonesia by 1920. Most islands were not a problem but there was a long, costly campaign against the Achin (Aceh) state in northern Sumatra.\n\nThe Netherlands had not fought a major military campaign since the 1760s, and the strength of its armed forces had gradually dwindled. The Dutch decided not to ally themselves with anyone, and kept out of all European wars especially the First World War that swirled about it.\n\nThe German war plan (the Schlieffen Plan) of 1905 was modified in 1908 to invade Belgium on the way to Paris but not the Netherlands. It supplied many essential raw materials to Germany such as rubber, tin, quinine, oil and food. The British used its blockade to limit supplies that the Dutch could pass on. There were other factors that made it expedient for both the Allies and the Central Powers for the Netherlands to remain neutral. The Netherlands controlled the mouths of the Scheldt, the Rhine and the Meuse Rivers. Germany had an interest in the Rhine since it ran through the industrial areas of the Ruhr and connected it with the Dutch port of Rotterdam. Britain had an interest in the Scheldt River and the Meuse flowed from France. All countries had an interest in keeping the others out of the Netherlands so that no one's interests could be taken away or be changed. If one country were to have invaded the Netherlands, another would certainly have counterattacked to defend their own interest in the rivers. It was too big a risk for any of the belligerent nations and none wanted to risk fighting on another front.\nThe Dutch were affected by the war, troops were mobilized and conscription was introduced in the face of harsh criticism from opposition parties. In 1918, mutinies broke out in the military. Food shortages were extensive, due to the control the belligerents exercised over the Dutch. Each wanted their share of Dutch produce. As a result, the price of potatoes rose sharply because Britain had demanded so much from the Dutch. Food riots even broke out in the country. A big problem was smuggling. When Germany had conquered Belgium, the Allies saw it as enemy territory and stopped exporting to Belgium. Food became scarce for the Belgian people, since the Germans seized all food. This gave the Dutch the opportunity to start to smuggle. This, however, caused great problems in the Netherlands, including inflation and further food shortages. The Allies demanded that the Dutch stop the smuggling, and the government took measures to remain neutral. The government placed many cities under 'state of siege'. On 8 January 1916, a zone was created by the government along the border. In that zone, goods could be moved on main roads with a permit. German authorities in Belgium had an electrified fence erected all along the Belgian–Dutch border that caused many refugees from Belgium to lose their lives. The fence was guarded by older German Landsturm soldiers.\n\nAlthough both houses of the Dutch parliament were elected by the people, only men with high incomes were eligible to vote until 1917, when pressure from socialist movements resulted in elections in which all men were allowed to vote. In 1919 women also obtained the right to vote.\n\nThe worldwide Great Depression of 1929 and the early 1930s had crippling effects on the Dutch economy, lasting longer than in most other European countries. The long duration of the Great Depression in the Netherlands is often explained by the very strict fiscal policy of the Dutch government at the time, and its decision to adhere to the gold standard for much longer than most of its trading partners. The depression led to high unemployment and widespread poverty, as well as increasing social unrest.\n\nThe rise of Nazism in Germany did not go unnoticed in the Netherlands, and there was growing concern at the possibility of armed conflict, but most Dutch citizens expected that Germany would again respect Dutch neutrality.\n\nThere were separate fascist and nazi movements in the 1930s. Dutch Fascists admired Mussolini's Italy and called for a traditional corporate ideology. The membership was small, elitist and ineffective. The pro-Nazi movement, however, won support from Berlin and attempted to build a mass base by 1935. It failed because most Dutch rejected its racial ideology and calls for violence.\n\nThe defense budget was not increased until Nazi Germany remilitarized the Rhineland in 1936. The budget was further increased in 1938 (after the annexation of Austria and occupation of the Czech Sudetenland). The colonial government also increased its military budget because of increasing tension with Japan. The Dutch did not mobilize their forces until shortly before France and Great Britain declared war in September 1939. Neutrality was still the policy but the Dutch government tried to buy new arms for their badly equipped forces but a considerable share of ordered weapons never arrived.\n\nAt the outbreak of World War II in 1939, the Netherlands once again declared its neutrality. However, on 10 May 1940, Nazi Germany launched an attack on the Netherlands and Belgium and quickly overran most of the two countries. Fighting against the Dutch army proved more of a burden than foreseen; the northern attack was stopped dead, the one in the middle came to a grinding halt near the Grebbeberg and many airborne assault troops were killed and taken prisoner in the west of the country.\nOnly in the south, defenses broke but the one passage over the river Maas at Rotterdam was held by the Dutch. By 14 May, fighting in many locations had ceased and the German army could make little or no headway, So the Luftwaffe bombed Rotterdam, second largest city of the Netherlands, killing about 900 people, destroying the inner city and leaving 78,000 people homeless.\n\nFollowing the bombing and German threats of the same treatment for Utrecht, the Netherlands capitulated on 15 May, except for the province of Zeeland where French and French Moroccan troops stood side by side with the Dutch forces. Still, the royal family and some armed forces fled to the United Kingdom. Some members of the royal family eventually moved to Ottawa, Ontario, Canada until the Netherlands was liberated; Princess Margriet was born in Canadian exile.\n\nResentment of the Germans grew as the occupation became more harsh, prompting many Dutch in the latter years of the war to join the resistance. But collaboration was not uncommon either; many thousands of young Dutch males volunteered for combat service on the Russian Front with the Waffen-SS and many companies worked for the Germans.\n\nAbout 140,000 Jews lived in the Netherlands at the beginning of the war. Persecution of Dutch Jews started shortly after the occupation. At the end of the war, 40,000 Jews were still alive. Of the 100,000 Jews who did not go in to hiding, about 1,000 survived the war.\n\nOne who perished was Anne Frank, who gained worldwide fame posthumously when her diary, written in the \"achterhuis\" ('backhouse') while hiding from the Nazis, was found and published by her father, Otto Frank, the only survivor of the family.\n\nOn 8 December 1941, the day after the attack on Pearl Harbor, the Netherlands declared war on Japan. The Dutch government in exile in London had for long been working with London and with Washington to cut off oil supplies to Japan. Japanese forces invaded the Dutch East Indies on 11 January 1942. The Dutch surrendered 8 March after Japanese troops landed on Java. Dutch citizens and everybody with Dutch ancestry, the so-called \"Indo's\" were captured and put to work in labour camps or interned. As in the homeland, many Dutch ships, planes and military personnel managed to reach safe territory, in this case Australia, from where they were able to fight again.\n\nIn Europe, after the Allies landed in Normandy in June 1944, progress was slow until the Battle of Normandy ended in August 1944. German resistance collapsed in western Europe and the allied armies advanced quickly towards the Dutch border. The First Canadian Army and the Second British Army conducted operations on Dutch soil from September onwards. On 17 September a daring operation, Operation Market Garden, was executed with the goal of capturing bridges across three major rivers in the southern Netherlands. Despite desperate fighting by American, British and Polish forces, the bridge at Arnhem, across the Neder Rijn, could not be captured.\n\nAreas south of the Rhine river were liberated in the period September–December 1944, including the province of Zeeland, which was liberated in October and November in the Battle of the Scheldt. This opened Antwerp to allied shipping. The First Canadian Army held a static line along the river Meuse (Maas) from December 1944 through February 1945.\n\nThe rest of the country remained occupied until the spring of 1945. In the face of Dutch defiance the Nazis deliberately cut off food supplies resulting in near-starvation in the cities during the \"Hongerwinter\" (Hunger winter) of 1944–45. Soup kitchens were set up but many fragile people died. A few days before the Allied victory the Germans allowed emergency shipments of food.\nThe First Canadian Army launched Operation Veritable in early February, cracking the Siegfried Line and reaching the banks of the Rhine in early March. In the final weeks of the war in Europe, the First Canadian Army was charged with clearing the Netherlands of German forces.\n\nThe Liberation of Arnhem began on 12 April 1945 and proceeded to plan, as the three infantry brigades of the 49th Division leapfrogged each other through the city. Within four days Arnhem, now a ruined city, was totally under Allied control.\n\nThe Canadians then immediately advanced further into the country, encountering and defeating a German counterattack at Otterlo and Dutch SS resistance at Ede. On 27 April a temporary truce came into effect, allowing the distribution of food aid to the starving Dutch civilians in areas under German control (Operation Manna). On 5 May 1945, Generaloberst Blaskowitz agreed to the unconditional surrender of all German forces in the Netherlands, signing the surrender to Canadian general Charles Foulkes at Wageningen. (The fifth of May is now celebrated annually in the Netherlands as Liberation Day.) Three days later Germany unconditionally surrendered, bringing the war in Europe to a close.\n\nAfter the euphoria and settling of scores had ended, the Dutch were a traumatized people with a ruined economy, a shattered infrastructure and several destroyed cities including Rotterdam, Nijmegen, Arnhem and part of The Hague.\n\nAfter the war, there were reprisals against those who had collaborated with the Nazis. Artur Seyss-Inquart, Nazi Commissioner of the Netherlands, was tried at Nüremberg.\n\nIn the early post-war years the Netherlands made continued attempts to expand its territory by annexing neighbouring German territory. The larger annexation plans were continuously rejected by the United States, but the London conference of 1949 permitted the Netherlands to perform a smaller scale annexation. Most of the annexed territory was returned to Germany on 1 August 1963.\n\nOperation Black Tulip was a plan in 1945 by Dutch minister of Justice Kolfschoten to evict all Germans from the Netherlands. The operation lasted from 1946 to 1948 and in the end 3691 Germans (15% of Germans resident in the Netherlands) were deported. The operation started on 10 September 1946 in Amsterdam, where Germans and their families were taken from their homes in the middle of the night and given one hour to collect 50 kg of luggage. They were allowed to take 100 guilders. The rest of their possessions went to the state. They were taken to concentration camps near the German border, the biggest of which was Mariënbosch near Nijmegen.\n\nThe post-war years were a time of hardship, shortages and natural disaster. This was followed by large-scale public works programmes, economic recovery, European integration and the gradual introduction of a welfare state.\n\nImmediately after the war, there was rationing, including of cigarettes, textiles, washing powder and coffee. Even wooden shoes were rationed. There were severe housing shortages. In the 1950s, there was mass emigration, especially to Canada, Australia and New Zealand. Government-encouraged emigration efforts to reduce population density prompted some 500,000 Dutch people to leave the country after the war. The Netherlands failed to hold the Dutch East Indies, as Indonesia became independent and 300,000 Dutch inhabitants (and their Indonesian allies) left the islands.\n\nPostwar politics saw shifting coalition governments. The 1946 Parliamentary elections saw the Catholic People's Party (KVP) come in first just ahead of the socialist Labour party (PvdA). Louis J. M. Beel formed a new coalition cabinet. The United States began Marshall Plan aid in 1948 that pumped cash into the economy, fostered modernization of business, and encouraged economic cooperation. The 1948 elections led to a new coalition led by Labor's Willem Drees. He led four successive cabinets Drees I, Drees II, Drees III and Drees IV until late 1958. His terms saw four major political developments: the traumas of decolonization, economic reconstruction, the establishment of the Dutch welfare state, and international integration and co-operation, including the formation of Benelux, the OEEC, NATO, the ECSC, and the EEC.\n\nDespite the problems, this was a time of optimism for many. A baby boom followed the war, as young Dutch couples started planning their families. They had lived through the hardships of depression and the hell of war. They wanted to start fresh and live better lives without the poverty, starvation, terror, and extreme frugality they knew so well. They had little taste for a strictly imposed rule-oriented traditional system with its rigid hierarchies, sharp pillarized boundaries and strictly orthodox religious doctrines. They made a best seller out of the translation of \"The Common Sense Book of Baby and Child Care\" (1946), by American pediatrician Benjamin Spock. His vision of family life as companionate, permissive, enjoyable and even fun took hold, and seemed the best way to achieve family happiness in a dawning age of freedom and prosperity.\n\nWages were kept low and the recovery of consumption to prewar levels was delayed to permit rapid rebuilding of the infrastructure. In the years after the war, unemployment fell and the economy grew at an astonishing pace, despite the high birth rate. The shattered infrastructure and destroyed cities were rebuilt. A key contribution to the recovery in the postwar Netherlands came from the Marshall Plan, which provided the country with funds, goods, raw materials and produce.\n\nThe Dutch became internationally active again. Dutch corporations, particularly Royal Dutch Shell and Philips, became internationally prominent. Business people, scientists, engineers and artists from the Netherlands made important international contributions. For example, Dutch economists, especially Jan Tinbergen (1903–1994), Tjalling Koopmans (1910–1985) and Henri Theil (1924–2000), made major contributions to the mathematical and statistical methodology known as econometrics.\n\nAcross Western Europe, the period from 1973 to 1981 marked the end of the booming economy of the 1960s. The Netherlands also experienced years of negative growth after that. Unemployment increased steadily, causing rapid growth in social-security expenditures. Inflation reached double digits; government surpluses disappeared. On the positive side, rich natural gas resources were developed, providing a current account trade surplus during most of the period. Public deficits were high. According to the long-term economic analysis of Horlings and Smits, the major gains in the Dutch economy were concentrated between 1870 and 1930 and between 1950 and 1970. Rates were much lower in 1930–45 and after 1987.\n\nThe last major flood in the Netherlands took place in early February 1953, when a huge storm caused the collapse of several dikes in the southwest of the Netherlands. More than 1,800 people drowned in the ensuing inundation.\n\nThe Dutch government subsequently decided on a large-scale programme of public works (the \"Delta Works\") to protect the country against future flooding. The project took more than thirty years to complete. The Oosterscheldedam, an advanced sea storm barrier, became operational in 1986. According to Dutch government engineers, the odds of a major inundation anywhere in the Netherlands are now one in 10,000 years.\n\nThe European Coal and Steel Community (ECSC), was founded in 1951 by the six founding members: Belgium, the Netherlands and Luxembourg (the Benelux countries) and West Germany, France and Italy. Its purpose was to pool the steel and coal resources of the member states, and to support the economies of the participating countries. As a side effect, the ECSC helped defuse tensions between countries which had recently been enemies in the war. In time, this economic merger grew, adding members and broadening in scope, to become the European Economic Community, and later the European Union.\n\nThe United States started to have more influence. After the war higher education changed from a German model to more of an American model. American influences had been small in the interwar era, and during the war the Nazis had emphasised the dangers of a \"degraded\" American culture as represented by jazz. However, the Dutch became more attracted to the United States during the postwar era, perhaps partly because of antipathy towards the Nazis but certainly because of American movies and consumer goods. The Marshall Plan also introduced the Dutch to American management practices. NATO brought in American military doctrine and technology. Intellectuals, artists and the political left, however, remained more reserved about the Americans. According to Rob Kroes, the anti-Americanism in the Netherlands was ambiguous: American culture was both accepted and criticised at the same time.\n\nThe Netherlands is a founding member of the EU, NATO, OECD and WTO. Together with Belgium and Luxembourg it forms the Benelux economic union. The country is host to the Organization for the Prohibition of Chemical Weapons and five international courts: the Permanent Court of Arbitration, the International Court of Justice, the International Criminal Tribunal for the Former Yugoslavia, the International Criminal Court and the Special Tribunal for Lebanon. The first four are situated in The Hague, as is the EU's criminal intelligence agency Europol and judicial co-operation agency Eurojust. This has led to the city being dubbed \"the world's legal capital\".\n\nBy the first half of the 20th century, new organisations and leadership had developed in the Dutch East Indies. Under its Ethical Policy, the government had helped create an educated Indonesian elite. These profound changes constituted the \"Indonesian National Revival\". Increased political activism and Japanese occupation undermining Dutch rule culminated in nationalists proclaiming independence on 17 August 1945, two days after the surrender of Japan.\n\nThe Dutch East Indies had long been a valuable resource to the Netherlands, so the Dutch feared its independence. The Indonesian National Revolution followed as Indonesia attempted to secure its independence in the face of Dutch diplomatic and military opposition (sometimes brutal in nature). Increasing international pressure eventually led the Netherlands to withdraw and it formally recognised Indonesian independence on 27 December 1949. The western part of New Guinea, remained under Dutch control as Netherlands New Guinea until 1961, when the Netherlands transferred sovereignty of this area to Indonesia.\n\nDuring and after the Indonesian National Revolution, around 300,000 people, pre-dominantly \"Indos\" (Dutch-Indonesian Eurasians), left Indonesia for the Netherlands. This difficult, complex and messy mass migration was called repatriation, but the majority of this group had never set foot in the Netherlands before. This migration occurred in five distinct waves over a period of 20 years. It included Indos (many of whom spent the war years in Japanese concentration camps), former South Moluccan soldiers and their families, \"New-Guinea Issue\" Dutch citizens, Dutch citizens from Netherlands New Guinea (including Papuan civil servants and their families), and other Indos who had remained behind but later regretted their decision to take out Indonesian citizenship (called \"spijtoptanten\" in Dutch and \"warga negara\" in Indonesian).\n\nThe Indo community (now numbering around 680,000) is the largest minority group in the Netherlands. They are integrated into Dutch society, but they have also retained many aspects of their culture and have added a distinct Indonesian flavour to the Netherlands.\n\nAlthough it was originally expected that the loss of the Dutch East Indies would contribute to an economic decline, the Dutch economy experienced exceptional growth (partly because a disproportionate amount of Marshall Aid was received) in the 1950s and 1960s. In fact, the demand for labour was so strong that immigration was actively encouraged, first from Italy and Spain then later on, in larger numbers, from Turkey and Morocco.\n\nSuriname became independent on 25 November 1975. The Dutch government supported independence because it wanted to stem the flow of immigrants from Suriname and also to end its colonial status. However, about one third of the entire population of Suriname, fearing political unrest and economic decline, relocated to the Netherlands, creating a Surinamese community in the Netherlands that is now roughly as large as the population of Suriname itself.\n\nWhen the postwar baby-boom children grew up, they led the revolt in the 1960s against all rigidities in Dutch life. The 1960s and 1970s were a time of great social and cultural change, such as rapid \"ontzuiling\" (literally: depillarisation), a term that describes the decay of the old divisions along class and religious lines. A youth culture emerged all across Western Europe and the U.S., characterised by student rebellion, informality, sexual freedom, informal clothes, new hair styles, protest music, drugs and idealism. Young people, and students in particular, rejected traditional mores, and pushed for change in matters like women's rights, sexuality, disarmament and environmental issues.\n\nSecularization, or the decline in religiosity, first became noticeable after 1960 in the Protestant rural areas of Friesland and Groningen. Then, it spread to Amsterdam, Rotterdam and the other large cities in the west. Finally the Catholic southern areas showed religious declines. As the social distance between the Calvinists and Catholics narrowed (and they began to intermarry), it became possible to merge their parties. The Anti Revolutionary Party (ARP) in 1977 merged with the Catholic People's Party (KVP) and the Protestant Christian Historical Union (CHU) to form the Christian Democratic Appeal (CDA). However, a countervailing trend later appeared as the result of a religious revival in the Protestant Bible Belt, and the growth of the Muslim and Hindu communities as a result of immigration and high fertility levels.\n\nAfter 1982, there was a retrenchtment of the welfare system, especially regarding old-age pensions, unemployment benefits, and disability pensions/early retirement benefits.\n\nFollowing the election of 1994, in which the Christian democratic CDA lost a considerable portion of its representatives, the social-liberal Democrats 66 (D66) doubled in size and formed a coalition with the labour party (Netherlands) (PvdA), and the People's Party for Freedom and Democracy (VVD). This purple (government) coalition marked the first absence of the CDA in government in decades. During the Purple Coalition years, a period lasting until the rise of the populist politician Pim Fortuyn, the government addressed issues previously viewed as taboo under the Christian-influenced cabinet. At this time, the Dutch government introduced unprecedented legislation based on a policy of official tolerance (\"gedoogbeleid\"). Abortion and euthanasia were decriminalized, but stricter guidelines were set for their implementation. Drug policy, especially with regard to the regulation of cannabis, was reformed. Prostitution was legalised, but confined to brothels where the health and safety of those involved could be properly monitored. With the 2001 Same-Sex Marriage Act, the Netherlands became the first country to legalise same-sex marriage. In addition to social reforms, the Purple Coalition also presided over a period of remarkable economic prosperity.\n\nIn the 1998 election the Purple Coalition consisting of Social Democrats, and left and right wing Liberals, increased its majority. Both the social-democratic PvdA and the conservative liberal VVD grew at the cost of their junior partner in cabinet, the progressive liberal D66. The voters rewarded the Purple Coaliation for its economic performance, which had included reduction of unemployment and the budget deficit, steady growth and job creation combined with wage freezes and trimming of the welfare state, together with a policy of fiscal restraint. The result was the second Kok cabinet.\n\nThe power of the coalition waned with the introduction of List Pim Fortuyn in the Dutch general election of 2002, a populist party, which ran a distinctly anti-immigration and anti-purple campaign, citing \"Purple Chaos\" (\"Puinhopen van Paars\") as the source of the countries social woes. In the first political assassination in three centuries, Fortuyn was murdered with little over a week left before the election. In the wake of its leader's death, LPF swept the elections, entering parliament with one sixth of the seats, while the PvdA (Labour) lost half of its seats. The ensuing cabinet was formed by CDA, VVD and LPF, led by Prime Minister Jan Peter Balkenende. Though the party succeeded in displacing the rival Purple Coalition, without the charismatic figure of Pim Fortuyn at its helm, it proved to be short-lived lasting 87 days in power.\n\nTwo events changed the political landscape:\n\n\nBy 2000 the population had increased to 15.9 million people, making the Netherlands one of the most densely populated countries in the world. Urban development has led to the development of a conurbation called the \"Randstad\" (), which includes the four largest cities (Amsterdam, Rotterdam, The Hague and Utrecht), and the surrounding areas. With a population of 7,100,000 it is one of the largest conurbations in Europe.\n\nThis small nation has successfully developed into one of the most open, dynamic and prosperous countries in the world. It had the tenth-highest per capita income in the world in 2011. It has an open, market-based mixed economy, ranking 13th of 157 countries according to the Index of Economic Freedom. In May 2011, the OECD ranked the Netherlands as the \"happiest\" country in the world.\n\n\nThe American John Lothrop Motley was the first foreign historian to write a major history of the Dutch Republic. In 3500 pages he crafted a literary masterpiece that was translated into numerous languages; his dramatic story reached a wide audience in the 19th century. Motley relied heavily on Dutch scholarship and immersed himself in the sources. His style no longer attracts readers, and scholars have moved away from his simplistic dichotomies of good versus evil, Dutch versus Spanish, Catholic versus Protestant, freedom versus authoritarianism. His theory of causation over-emphasized ethnicity as an unchanging characteristic, exaggerated the importance of William of Orange, and gave undue importance to the issue religious tolerance.\n\nThe pioneering Dutch cultural historian Johan Huizinga (1872–1945), author of \"The Autumn of the Middle Ages\" (1919) (the English translation was called \"The Waning of the Middle Ages\") and \"Homo Ludens: A Study of the Play Element in Culture\" (1935), which expanded the field of cultural history and influenced the historical anthropology of younger historians of the French Annales School. He was influenced by art history and advised historians to trace \"patterns of culture\" by studying \"themes, figures, motifs, symbols, styles and sentiments.\"\n\nThe \"polder model\" continues to strongly influence historians as well as Dutch political discussion. The polder model stresses the need for finding consensus; it discourages furious debate and angry dissent in both academia and politics – in contrast to the highly developed, intense debates in Germany.\n\nThe H-Net list H-Low-Countries is published free by email and is edited by scholars. Its occasional messages serve an international community with diverse methodological approaches, archival experiences, teaching styles, and intellectual traditions, promotes discussion relevant to the region and to the different national histories in particular, with an emphasis on the Netherlands. H-Low-Countries publishes conference announcements, questions and discussions; reviews of books, journals, and articles; and tables of contents of journals on the history of the Low Countries (in both Dutch and English). After World War II both research-oriented and teaching-oriented historians have been rethinking their interpretive approaches to Dutch history, balancing traditional memories and modern scholarship. In terms of popular history, there has been an effort to ensure greater historical accuracy in museums and historic tourist sites.\n\nOnce heralded as the leading event of modern Dutch history, the Dutch Revolt lasted from 1568 to 1648, and historians have worked to interpret it for even longer. Cruz (2007) explains the major debates among scholars regarding the Dutch bid for independence from Spanish rule. While agreeing that the intellectual milieus of late 19th and 20th centuries affected historians' interpretations, Cruz argues that writings about the revolt trace changing perceptions of the role played by small countries in the history of Europe. In recent decades grand theory has fallen out of favor among most scholars, who emphasize the particular over the general. Dutch and Belgian historiography since 1945 no longer says the revolt was the culmination of an inevitable process leading to independence and freedom. Instead scholars have put the political and economic details of the towns and provinces under the microscope, while agreeing on the weaknesses of attempts at centralization by the Habsburg rulers. The most influential new studies have been rooted in demographic and economic history, though scholars continue to debate the relationship between economics and politics. The religious dimension has been viewed in terms of mentalities, exposing the minority position of Calvinism, while the international aspects have been studied more seriously by foreign historians than by the Dutch themselves.\n\nPieter Geyl was the leading historian of the Dutch Revolt, and a highly influential professor at the University of London (1919–1935) and at the State University of Utrecht (1936–58). He wrote a six-volume history of the Dutch-speaking peoples. The Nazis imprisoned him in World War II. In his political views, Geyl adopted the views of the 17th-century Dutch Louvestein faction, led by Johan van Oldenbarneveldt (1547–1619) and Johan de Witt (1625–72). It stood for liberty, toleration, and national interests in contrast to the Orange stadholders who sought to promote their own self-interest. According to Geyl, the Dutch Republic reached the peak of its powers during the 17th century. He was also a staunch nationalist and suggested that Flanders could split off from Belgium and join the Netherlands. Later he decried what he called radical nationalism and stressed more the vitality of Western Civilization. Geyl was highly critical of the world history approach of Arnold J. Toynbee.\n\nJan Romein (1893-1962) created a \"theoretical history\" in an attempt to reestablish the relevance of history to public life in the 1930s at a time of immense political uncertainty and cultural crisis, when Romein thought that history had become too inward-looking and isolated from other disciplines. Romein, a Marxist, wanted history to contribute to social improvement. At the same time, influenced by the successes of theoretical physics and his study of Oswald Spengler, Arnold J. Toynbee, Frederick John Teggart, and others, he spurred on the development of theoretical history in the Netherlands, to the point where it became a subject in its own right at the university level after the war. Romein used the term integral history as a substitute for cultural history and focused his attention on the period around the turn of the century. He concluded that a serious crisis occurred in European civilization in 1900 because of the rise of anti-Semitism, extreme nationalism, discontent with the parliamentary system, depersonalization of the state, and the rejection of positivism. European civilization waned as the result of this crisis which was accompanied by the rise of the United States, the Americanization of the world, and the emergence of Asia. His interpretation is reminiscent of that of his mentor Johan Huizinga and was criticized by his colleague Pieter Geyl.\n\nSee also: \n\n\n", "id": "13289", "title": "History of the Netherlands"}
{"url": "https://en.wikipedia.org/wiki?curid=13290", "text": "Harold and Maude\n\nHarold and Maude is a 1971 American romantic dark comedy drama directed by Hal Ashby and released by Paramount Pictures. It incorporates elements of dark humor and existentialist drama, with a plot that revolves around the exploits of a young man named Harold (played by Bud Cort) intrigued with death. Harold drifts away from the life that his detached mother (Vivian Pickles) prescribes for him, and slowly develops a strong friendship, and eventually a romantic relationship, with a 79-year-old woman named Maude (Ruth Gordon) who teaches Harold about living life to its fullest and that life is the most precious gift of all.\n\nThe film was based on a screenplay written by Colin Higgins and published as a novel in 1971. Filming locations in the San Francisco Bay Area included both Holy Cross Cemetery and Golden Gate National Cemetery, and the ruins of the Sutro Baths.\n\nCritically and commercially unsuccessful when originally released, the film developed a cult following and in 1983 began making a profit. The film is ranked number 45 on the American Film Institute's list of 100 Funniest Movies of all Time and was selected for preservation in the National Film Registry of the Library of Congress in 1997, for being \"culturally, historically or aesthetically significant\". The Criterion Collection special edition Blu-ray and DVD were released June 12, 2012.\n\nHarold Chasen (Bud Cort) is a young man obsessed with death. He stages elaborate fake suicides, attends funerals and drives a hearse, all to the chagrin of his socialite mother (Vivian Pickles).\n\nAt another stranger's funeral service, Harold meets Maude (Ruth Gordon), a 79-year-old woman who shares Harold's hobby of attending funerals. He is entranced by her quirky outlook on life, which is bright and excessively carefree in contrast with his morbidity. The pair form a bond and Maude slowly shows Harold the pleasures of art and music (including how to play banjo), and teaches him how to \"[make] the most of his time on earth\". Meanwhile, Harold's mother is determined, against Harold's wishes, to find him a wife. One by one, Harold frightens and horrifies each of his appointed dates, by appearing to commit gruesome acts such as self-immolation, self-mutilation and seppuku.\n\nAs they become closer, their friendship soon blossoms into a romance and Harold announces that he will marry Maude, resulting in disgusted outbursts from his family, psychiatrist, and priest. Maude's 80th birthday arrives and Harold throws a surprise party for her. As the couple dance, Maude tells Harold that she \"couldn't imagine a lovelier farewell\". Confused, he questions Maude as to her meaning and she reveals that she has taken an overdose of sleeping pills and will be dead by morning. She restates her firm belief that eighty is the proper age to die.\n\nHarold rushes Maude to the hospital, where she is treated unsuccessfully and dies. In the final sequence, Harold's car is seen going off a seaside cliff but after the crash, the final shot reveals Harold standing calmly atop the cliff, holding his banjo. After gazing down at the wreckage, he dances away, picking out on his banjo Cat Stevens' \"If You Want to Sing Out, Sing Out\".\n\n\nDirector Hal Ashby appears in an uncredited cameo, watching a model train at an amusement park. The amusement park is Santa Cruz Beach Boardwalk (California USA) / Penny Arcade.\n\nUCLA student Colin Higgins wrote \"Harold and Maude\" as his master’s thesis. While working as producer Edward Lewis' pool boy, Higgins showed the script to Lewis's wife, Mildred. Mildred was so impressed that she got Edward to give it to Stanley Jaffe at Paramount. Higgins sold the script with the understanding that he would direct the film but he was told he wasn't ready, after tests he shot proved unsatisfactory to the studio heads. Ashby would only commit to directing the film after getting Higgins' blessing and then, so Higgins could watch and learn from him on the set, Ashby made Higgins a co-producer. Higgins says he originally thought of the story as a play. It then became a 20-minute thesis while at film school. After the film came out, the script was turned into a novel then a play, which ran for several years in Paris.\n\nAshby felt that Maude should ideally be European and his list of possible actresses included dames Peggy Ashcroft, Edith Evans, Gladys Cooper and Celia Johnson as well as Lotte Lenya, Luise Rainer, Pola Negri, Minta Durfee and Agatha Christie. Ruth Gordon indicated that in addition she heard that Edwige Feuillere, Elisabeth Bergner, Mildred Natwick, Mildred Dunnock and Dorothy Stickney had been considered.\n\nFor Harold, in addition to Bud Cort, Ashby considered all promising unknowns, Richard Dreyfuss, Bob Balaban and John Savage. Also on his list were John Rubinstein, for whom Higgins had written the part and then up-and-coming British pop star Elton John, whom Ashby had seen live and hoped would also do the music.\n\nAnne Brebner, the casting director, was almost cast as Harold's mother, when Vivian Pickles was briefly unable to do the role.\n\nWhen Harold and Maude are talking candidly at her home he tells her that he has \"died a few times\". He describes how, when he was at boarding school, he set his chemistry lab on fire and escaped through a hole in the floor, going home believing his school career was at an end and he was free. When the police came to his house, Harold watched as they told his mother that he had died in the fire and saw her collapse into the policemen's arms. As he reaches this part of the story, Harold bursts into tears and declares, \"I decided then I enjoyed being dead\".\n\nThroughout the movie, Harold \"dies\" seven to eight times. He tells his psychologist at one early juncture that he has made similar attempts, in all fifteen times now, which he calls a rough estimate.\n\n\n\"Harold and Maude\" received mixed reviews, with several critics being offended by the film's dark humor. Roger Ebert, in a review dated January 1, 1972, gave the film 1 and a half out of 4 stars. He wrote, \"And so what we get, finally, is a movie of attitudes. Harold is death, Maude life, and they manage to make the two seem so similar that life's hardly worth the extra bother. The visual style makes everyone look fresh from the Wax Museum, and all the movie lacks is a lot of day-old gardenias and lilies and roses in the lobby, filling the place with a cloying sweet smell. Nothing more to report today. Harold doesn't even make pallbearer.\" Vincent Canby also panned the film, stating that the actors \"are so aggressive, so creepy and off-putting, that Harold and Maude are obviously made for each other, a point the movie itself refuses to recognize with a twist ending that betrays, I think, its life-affirming pretensions.\"\n\nThe reputation of the film has increased greatly; Rotten Tomatoes, which labeled the film as \"Certified Fresh\", gave it a score of 86% based on 42 reviews, with an average score of 7.6/10. A consensus on the site read, \"Hal Ashby's comedy is too dark and twisted for some, and occasionally oversteps its bounds, but there's no denying the film's warm humor and big heart.\" In 2005, the Writers Guild of America ranked the screenplay #86 on its list of 101 Greatest Screenplays ever written. Sight & Sound magazine conducts a poll every ten years of the world's finest film directors, to find out the Ten Greatest Films of All Time. This poll has been going since 1992 and has become the most recognised poll of its kind in the world. In 2012, Niki Caro, Wanuri Kahiu and Cyrus Frisch voted for \"Harold and Maude\". Frisch commented: \"An encouragement to think beyond the obvious!\"\n\nOn June 12, 2012, The Criterion Collection released \"Harold and Maude\" for Region 1 on DVD and Blu-ray, both of which includes a collection of audio excerpts of director Hal Ashby from January 11, 1972 and of screenwriter Colin Higgins from January 10, 1979, a new video interview with Yusuf/Cat Stevens, a new audio commentary by Ashby biographer Nick Dawson and producer Charles B. Mulvehill, and a booklet which includes a new film essay by film and television critic Matt Zoller Seitz. Exclusive to the Blu-ray edition are a new digital restoration of the film with uncompressed monaural soundtrack and an optional remastered uncompressed stereo soundtrack. Other exclusives are a \"New York Times\" profile of actress Ruth Gordon from 1971, an interview from 1997 with actor Bud Cort and cinematographer John Alonzo, and an interview from 2001 with executive producer Mildred Lewis.\n\n\"Harold and Maude\" is #45 on the American Film Institute’s list of 100 Years... 100 Laughs, the list of the top 100 films in American comedy. The list was released in 2000. Two years later, AFI released the list AFI's 100 Years... 100 Passions honoring the most romantic films for the past 100 years, \"Harold and Maude\" ranked #69. In September 2008, \"Empire\" listed \"Harold and Maude\" as #65 in \"Empire\"'s 500 Greatest Movies of All Time. \"Entertainment Weekly\" ranked the film #4 on their list of “The Top 50 Cult Films.”\n\nIn June 2008, AFI revealed its \"Ten Top Ten\"—the best ten films in ten \"classic\" American film genres—after polling over 1,500 people from the creative community. \"Harold and Maude\" was acknowledged as the ninth best film in the romantic comedy genre.\n\nThe film is recognized by American Film Institute in these lists:\n\nAt the 29th Golden Globe Awards, Bud Cort and Ruth Gordon received a nomination for Best Actor and Best Actress in a Musical or Comedy film, respectively.\n\nThe music in \"Harold and Maude\" was composed and performed by Cat Stevens. He had been suggested by Elton John to do the music after John had dropped out of the project. Stevens composed two original songs for the film, \"Don't Be Shy\" and \"If You Want to Sing Out, Sing Out\" and performed instrumental and alternate versions of the songs \"On the Road to Find Out\", \"I Wish, I Wish\", \"Miles from Nowhere\", \"Tea for the Tillerman\", \"I Think I See the Light\", \"Where Do the Children Play?\" and \"Trouble\" which were either on the album \"Mona Bone Jakon\" or \"Tea for the Tillerman\". Those albums had been released before the film. \"Don't Be Shy\" and \"If You Want to Sing Out, Sing Out\" were not released on an album, until his 1984 compilation \"\".\n\nThere is some additional non-Cat Stevens music in the film. \"Greensleeves\" is played on the harp during dinner. During the scene where Harold is floating face-down in the swimming pool, the opening bars of Tchaikovsky's Piano Concerto No. 1 are heard. A marching band is also heard playing a John Philip Sousa march outside the church following a funeral.\n\nThe first soundtrack was released in Japan in 1972 on vinyl and cassette, (A&M Records GP-216). It omitted the two original songs and all instrumental and alternate versions of songs and was generally composed of re-released material that was in the film, along with five songs that were not in the film.\n\n\nThe second soundtrack was released in December 2007, by Vinyl Films Records, as a vinyl-only limited-edition release of 2,500 copies. It contained a 30-page oral history of the making of the film, the most extensive series of interviews yet conducted on \"Harold and Maude\".\n\n\nColin Higgins later adapted the story into a stage play. The original Broadway production, starring Janet Gaynor as Maude and Keith McDermott as Harold, closed after four performances in February 1980.\n\nA French adaptation for television, translated and written by Jean-Claude Carrière, appeared in 1978. It was also adapted for the stage by the Compagnie Viola Léger in Moncton, New Brunswick, starring Roy Dupuis \n\nHiggins expressed interest in 1978 about both a sequel and prequel to \"Harold and Maude\". The sequel, \"Harold's Story\", would have Cort portray Harold's life after Maude. Higgins also imagined a prequel showing Maude's life before Harold, \"Grover and Maude\" had Maude learning how to steal cars from Grover Muldoon, the character portrayed by Richard Pryor in Higgins' 1976 film \"Silver Streak\". Higgins wanted Gordon and Pryor to reprise their roles.\n\n\n", "id": "13290", "title": "Harold and Maude"}
{"url": "https://en.wikipedia.org/wiki?curid=13291", "text": "Habitus (sociology)\n\nHabitus is a system of embodied dispositions, tendencies that organize the ways in which individuals perceive the social world around them and react to it. These dispositions are usually shared by people with similar background (in terms of social class, religion, nationality, ethnicity, education, profession etc.), as the habitus is acquired through \"mimesis\" and reflects the lived reality to which individuals are socialized, their individual experience and objective opportunities. Thus, the habitus represents the way group culture and personal history shape the body and the mind, and as a result, shape social action in the present.\n\nPierre Bourdieu suggested that the habitus consists of both the \"hexis\" (the tendency to hold and use one's body in a certain ways, such as posture and accent) and more abstract mental habits, schemes of perception, classification, appreciation, feeling, and action. These schemes are not mere habits: Bourdieu suggested they allow individuals to find new solutions to new situations without calculated deliberation, based on their gut feelings and intuitions, which Bourdieu believed were collective and socially shaped. These attitudes, mannerisms, tastes, moral intuitions and habits have influence on the individual's life chances, thus the habitus is both structured by an individuals' objective past position in the social structure; and structuring its future life path. Pierre Bourdieu argued that the reproduction of the social structure results from the habitus of individuals (Bourdieu, 1987).\n\nThe notion of habitus is extremely influential (with 400,000 Google Scholar publications using it), yet it also evoked criticism for its alleged determinism, as Bourdieu compared social actors to \"automata\" (while relying on Leibniz's theory of Monads).\n\nThe concept of habitus has been used as early as Aristotle but in contemporary usage was introduced by Marcel Mauss and later Maurice Merleau-Ponty. However, it was Pierre Bourdieu who turned it into a cornerstone of his sociology, and used it to solve the sociological problem of agency and structure: the habitus is shaped by structural position and generates action, thus when people act and demonstrate agency they simultaneously reflect and reproduce social structure. Bourdieu elaborated his theory of the habitus while borrowing ideas on cognitive and generative schemes from Noam Chomsky and Jean Piaget dependency on history and human memory. For instance, a certain behaviour or belief becomes part of a society's structure when the original purpose of that behaviour or belief can no longer be recalled and becomes socialized into individuals of that culture.\n\nLoïc Wacquant wrote that habitus is an old philosophical notion, originating in the thought of Aristotle, whose notion of \"hexis\" (\"state\") was translated into \"habitus\" by the Medieval Scholastics. Bourdieu first adapted the term in his 1967 postface to Erwin Panofsky's \"Gothic Architecture and Scholasticism\". The term was earlier used in sociology by Norbert Elias in \"The Civilizing Process\" (1939) and in Marcel Mauss's account of \"body techniques\" (techniques du corps). The concept is also present in the work of Max Weber, Gilles Deleuze, and Edmund Husserl.\n\nMauss defined habitus as those aspects of culture that are anchored in the body or daily practices of individuals, groups, societies, and nations. It includes the totality of learned habits, bodily skills, styles, tastes, and other non-discursive knowledges that might be said to \"go without saying\" for a specific group (Bourdieu 1990:66-67) — in that way it can be said to operate beneath the level of rational ideology.\n\nAccording to Bourdieu, habitus is composed of:\n\nThe term has also been adopted in literary criticism, adapting from Bourdieu's usage of the term. For example, Joe Moran's examination of authorial identities in \"Star Authors: Literary Celebrity in America\" uses the term in discussion of how authors develop a habitus formed around their own celebrity and status as authors, which manifests in their writing.\n\nBourdieu's principle of habitus is interwoven with the concept of structuralism in literary theory. Peter Barry explains, \"in the structuralist approach to literature there is a constant movement away from interpretation of the individual literary work and a parallel drive towards understanding the larger structures which contain them\" (2009, p. 39). There is therefore a strong desire to understand the larger influencing factors which makes an individual literary work. As Bourdieu explains, habitus \"are structured structures, generative principles of distinct and distinctive practices – what the worker eats, and especially the way he eats it, the sport he practices and the way he practices it, his political opinions and the way he expresses them are systematically different from the industrial proprietor's corresponding activities / habitus are also structuring structures, different classifying schemes classification principles, different principles of vision and division, different tastes. Habitus make different differences; they implement distinctions between what is good and what is bad, what is right and what is wrong, between what is distinguished and what is vulgar, and so on, but they are not the same. Thus, for instance, the same behaviour or even the same good can appear distinguished to one person, pretentious to someone else, and cheap or showy to yet another\" (Bourdieu, 1996). As a result, habitus may be employed in literary theory in order to understand those larger, external structures which influence individual theories and works of literature.\n\n\n\nBody habitus (or \"bodily habitus\") is the medical term for physique, and is categorized as either endomorphic (overweight), ectomorphic (underweight) or mesomorphic (normal weight). In this sense, habitus can be understood as the physical and constitutional characteristics of an individual, especially as related to the tendency to develop a certain disease. For example, \"Marfanoid bodily habitus\".\n\n", "id": "13291", "title": "Habitus (sociology)"}
